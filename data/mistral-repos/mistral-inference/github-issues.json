[
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/247",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/247/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/247/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/247/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/247",
    "id": 3122450059,
    "node_id": "I_kwDOKY_97s66HM6L",
    "number": 247,
    "title": "[BUG: No arguments expected for \"install\" command, got \".\" watson@MacBookPro mistral-inference % poetry install .",
    "user": {
      "login": "davidthewatson",
      "id": 150892,
      "node_id": "MDQ6VXNlcjE1MDg5Mg==",
      "avatar_url": "https://avatars.githubusercontent.com/u/150892?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/davidthewatson",
      "html_url": "https://github.com/davidthewatson",
      "followers_url": "https://api.github.com/users/davidthewatson/followers",
      "following_url": "https://api.github.com/users/davidthewatson/following{/other_user}",
      "gists_url": "https://api.github.com/users/davidthewatson/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/davidthewatson/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/davidthewatson/subscriptions",
      "organizations_url": "https://api.github.com/users/davidthewatson/orgs",
      "repos_url": "https://api.github.com/users/davidthewatson/repos",
      "events_url": "https://api.github.com/users/davidthewatson/events{/privacy}",
      "received_events_url": "https://api.github.com/users/davidthewatson/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2025-06-05T19:48:35Z",
    "updated_at": "2025-06-05T19:51:11Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.13.3 (main, Apr  8 2025, 13:54:08) [Clang 17.0.0 (clang-1700.0.13.3)]\n\napparently poetry doesn't like \".\". I dunno, I don't use poetry. \n\nThis is macos Apple Silicon on M1 Pro. FWIW, recommend using the rust invasion or innovation? of python tooling gone awry with uv, which goes a lot further, a lot faster. Armen Ronacher can't be wrong.\n\nThanks!\n```\n\n### Pip Freeze\n\n```shell\npython3 -m pip freeze\ncertifi==2025.4.26\ncffi==1.17.1\ngpg==1.24.3\npackaging==25.0\npycparser==2.22\nwheel @ file:///opt/homebrew/Cellar/python%403.13/3.13.2/libexec/wheel-0.45.1-py3-none-any.whl#sha256=b9235939e2096903717cb6bfc132267f8a7e46deb2ec3ef9c5e234ea301795d0\n```\n\n### Reproduction Steps\n\n1. Copy install lines from github project.\n2. Crash on poetry install .\n\n### Expected Behavior\n\nInstall!\n\n### Additional Context\n\nswitch ro uv. tastes great. less filling. simon willison knows. ask him. he's closer to your shores than I am.\n\n### Suggested Solutions\n\nuv.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/247/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/247/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/246",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/246/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/246/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/246/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/246",
    "id": 3085735222,
    "node_id": "I_kwDOKY_97s637JU2",
    "number": 246,
    "title": "Attention and FFN layers' register_forward_hook() not working, while Transformer block works",
    "user": {
      "login": "fkggggg",
      "id": 95512399,
      "node_id": "U_kgDOBbFnTw",
      "avatar_url": "https://avatars.githubusercontent.com/u/95512399?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/fkggggg",
      "html_url": "https://github.com/fkggggg",
      "followers_url": "https://api.github.com/users/fkggggg/followers",
      "following_url": "https://api.github.com/users/fkggggg/following{/other_user}",
      "gists_url": "https://api.github.com/users/fkggggg/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/fkggggg/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/fkggggg/subscriptions",
      "organizations_url": "https://api.github.com/users/fkggggg/orgs",
      "repos_url": "https://api.github.com/users/fkggggg/repos",
      "events_url": "https://api.github.com/users/fkggggg/events{/privacy}",
      "received_events_url": "https://api.github.com/users/fkggggg/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2025-05-23T09:11:01Z",
    "updated_at": "2025-05-27T17:06:35Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]\n```\n\n### Pip Freeze\n\n```shell\naccelerate==1.7.0\naiohappyeyeballs==2.6.1\naiohttp==3.11.18\naiosignal==1.3.2\nannotated-types @ file:///croot/annotated-types_1709542908624/work\nasync-timeout==5.0.1\nattrs @ file:///croot/attrs_1734533101012/work\nautoawq==0.2.9\nboto3 @ file:///croot/boto3_1743092127406/work\nbotocore @ file:///croot/botocore_1743061876997/work\nBrotli @ file:///croot/brotli-split_1736182456865/work\ncertifi @ file:///croot/certifi_1745939216646/work/certifi\ncharset-normalizer @ file:///croot/charset-normalizer_1721748349566/work\nclick @ file:///croot/click_1744271578095/work\ndatasets==3.6.0\ndill==0.3.8\ndocstring_parser==0.16\nfilelock @ file:///croot/filelock_1744281381737/work\nfire==0.7.0\nfrozenlist==1.6.0\nfsspec==2025.3.0\ngmpy2 @ file:///croot/gmpy2_1738085463648/work\nhuggingface-hub==0.31.4\nidna @ file:///croot/idna_1714398848350/work\nJinja2 @ file:///croot/jinja2_1741710844255/work\njmespath @ file:///croot/jmespath_1700144569655/work\njoblib @ file:///croot/joblib_1718217211762/work\njsonschema @ file:///croot/jsonschema_1728486696720/work\njsonschema-specifications @ file:///croot/jsonschema-specifications_1699032386549/work\nlit @ file:///croot/llvm-package_1741800901749/work/llvm/utils/lit\nMarkupSafe @ file:///croot/markupsafe_1738584038848/work\nmistral_common==1.5.4\nmistral_inference==1.6.0\nmkl-service==2.4.0\nmkl_fft @ file:///io/mkl313/mkl_fft_1730824109137/work\nmkl_random @ file:///io/mkl313/mkl_random_1730823916628/work\nmodelscope==1.26.0\nmpmath @ file:///croot/mpmath_1690848262763/work\nmultidict==6.4.4\nmultiprocess==0.70.16\nnetworkx @ file:///croot/networkx_1737039604450/work\nnumpy @ file:///croot/numpy_and_numpy_base_1747238018250/work/dist/numpy-2.2.5-cp310-cp310-linux_x86_64.whl#sha256=5a6df30fd2c407292da04652f137bbbe50d4765b8e20b11b2e225dadf36c269e\nnvidia-cublas-cu12==12.6.4.1\nnvidia-cuda-cupti-cu12==12.6.80\nnvidia-cuda-nvrtc-cu12==12.6.77\nnvidia-cuda-runtime-cu12==12.6.77\nnvidia-cudnn-cu12==9.5.1.17\nnvidia-cufft-cu12==11.3.0.4\nnvidia-cufile-cu12==1.11.1.6\nnvidia-curand-cu12==10.3.7.77\nnvidia-cusolver-cu12==11.7.1.2\nnvidia-cusparse-cu12==12.5.4.2\nnvidia-cusparselt-cu12==0.6.3\nnvidia-nccl-cu12==2.26.2\nnvidia-nvjitlink-cu12==12.6.85\nnvidia-nvtx-cu12==12.6.77\npackaging @ file:///croot/packaging_1734472117206/work\npandas==2.2.3\npillow @ file:///croot/pillow_1744613067434/work\npropcache==0.3.1\npsutil==7.0.0\npyarrow==20.0.0\npydantic @ file:///croot/pydantic_1734736067156/work\npydantic_core @ file:///croot/pydantic-core_1734726052986/work\nPySocks @ file:///home/builder/ci_310/pysocks_1640793678128/work\npython-dateutil @ file:///croot/python-dateutil_1716495738603/work\npytz==2025.2\nPyYAML @ file:///croot/pyyaml_1728657952215/work\nreferencing @ file:///croot/referencing_1699012038513/work\nregex @ file:///croot/regex_1736540786412/work\nrequests @ file:///croot/requests_1730999120400/work\nrpds-py @ file:///croot/rpds-py_1736541261634/work\ns3transfer @ file:///croot/s3transfer_1738245147924/work\nsacremoses @ file:///tmp/build/80754af9/sacremoses_1633107328213/work\nsafetensors @ file:///croot/safetensors_1741361308036/work\nsentencepiece @ file:///croot/sentencepiece-split_1742566759237/work/python\nsimple-parsing==0.1.7\nsix @ file:///croot/six_1744271502820/work\nsympy @ file:///croot/sympy_1738108488918/work\ntermcolor @ file:///croot/termcolor_1668084651543/work\ntiktoken==0.9.0\ntokenizers @ file:///croot/tokenizers_1741370336077/work\ntorch==2.7.0\ntqdm @ file:///croot/tqdm_1738943501192/work\ntransformers==4.52.2\ntriton==3.3.0\ntyping-inspection @ file:///croot/typing-inspection_1746023470701/work\ntyping_extensions @ file:///croot/typing_extensions_1734714854207/work\ntzdata==2025.2\nurllib3 @ file:///croot/urllib3_1737133630106/work\nxformers==0.0.30\nxxhash==3.5.0\nyarl==1.20.0\nzstandard==0.23.0\n```\n\n### Reproduction Steps\n\nI'm encountering an issue where the register_forward_hook() function does not seem to work correctly in the attention and feed-forward network (FFN) layers. However, when using it within the transformer block, everything functions as expected.\n\nCould anyone provide insights or solutions on why this discrepancy occurs?\n\nThanks!\n\nHere is my code\n```import torch\nimport torch.nn.functional as F\nfrom mistral_inference.transformer import Transformer\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\nfrom mistral_common.protocol.instruct.messages import UserMessage\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\n\n\ndef custom_generate(tokens, model, max_tokens, temperature, eos_id, device):\n    model.eval()\n    input_ids = torch.tensor(tokens[0], dtype=torch.long, device=device)\n    out_tokens = []\n\n    handles = []\n\n    for i in range(len(model.layers)):\n        layer = model.layers[str(i)]\n\n        def make_attn_hook():\n            def hook(module, input, output):\n                print(f\"[HOOK] Attention layer {i} input shape: {input[0].shape}\")\n            return hook\n        \n        def make_ffn_hook():\n            def hook(module, input, output):\n                print(f\"[HOOK] FFN layer {i} input shape: {input[0].shape}\")\n            return hook\n        \n        def make_transform_hook():\n            def hook(module, input, output):\n                print(f\"[HOOK] Transform layer {i} input shape: {input[0].shape}\")\n            return hook\n\n        handles.append(layer.attention.register_forward_hook(make_attn_hook()))\n        handles.append(layer.feed_forward.register_forward_hook(make_ffn_hook()))\n        handles.append(layer.register_forward_hook(make_transform_hook()))\n\n    for _ in range(max_tokens):\n        \n        seqlens = [input_ids.shape[0]]\n\n        with torch.no_grad():\n            logits = model.forward(input_ids, seqlens=seqlens)\n\n        next_token_logits = logits[-1, :]  # [vocab_size]\n\n        if temperature > 0:\n            next_token_probs = F.softmax(next_token_logits / temperature, dim=-1)\n            next_token = torch.multinomial(next_token_probs, num_samples=1)\n        else:\n            next_token = next_token_logits.argmax(dim=-1, keepdim=True)\n\n        out_tokens.append(next_token.item())\n\n        if next_token.item() == eos_id:\n            break\n\n        input_ids = torch.cat([input_ids, next_token], dim=-1)\n\n    for h in handles:\n        h.remove()\n\n    return out_tokens\n\nif __name__ == \"__main__\":\n    mistral_models_path = \"/data/Mistral-7B\"\n\n    tokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tokenizer.model.v3\")\n    model = Transformer.from_folder(mistral_models_path)\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    activations = {}\n\n    completion_request = ChatCompletionRequest(messages=[UserMessage(content=\"Use the numbers 1, 2, 3, 4 and the operations +, \u2212, *, / to calculate 24.\")])\n    tokens = tokenizer.encode_chat_completion(completion_request).tokens\n\n    out_tokens = custom_generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id, device=device)\n    result = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens)\n    print(\"Generated text:\", result)\n```\n\nand the output is \n```\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\n[HOOK] Transform layer 31 input shape: torch.Size([95, 4096])\nGenerated text: Here are some possible expressions that calculate 24 using the given numbers and operations:\n\n1. (4 * 3) + (4 * 2) + 1\n2. 4 * (3 + 2) + 1\n3. 4 * 3 + 2 +\n```\n\nObserve that the hooks attached to the attention and FFN layers do not trigger as expected.\n\n### Expected Behavior\n\nThe register_forward_hook() should successfully register and trigger during the forward pass of both attention/FFN layers and transformer blocks.\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/246/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/246/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/245",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/245/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/245/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/245/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/245",
    "id": 3017395515,
    "node_id": "I_kwDOKY_97s6z2c07",
    "number": 245,
    "title": "[BUG: Parse error: FormatException\uff1aUnterminated string (at character 174).",
    "user": {
      "login": "woaidangyang",
      "id": 40676046,
      "node_id": "MDQ6VXNlcjQwNjc2MDQ2",
      "avatar_url": "https://avatars.githubusercontent.com/u/40676046?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/woaidangyang",
      "html_url": "https://github.com/woaidangyang",
      "followers_url": "https://api.github.com/users/woaidangyang/followers",
      "following_url": "https://api.github.com/users/woaidangyang/following{/other_user}",
      "gists_url": "https://api.github.com/users/woaidangyang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/woaidangyang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/woaidangyang/subscriptions",
      "organizations_url": "https://api.github.com/users/woaidangyang/orgs",
      "repos_url": "https://api.github.com/users/woaidangyang/repos",
      "events_url": "https://api.github.com/users/woaidangyang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/woaidangyang/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2025-04-24T13:58:22Z",
    "updated_at": "2025-04-24T13:58:22Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nParse error: FormatException\uff1aUnterminated string (at character 174).\n...del\": \"mistral-large-latest\", \"choices\": [ \"index\": 0\"delta\": { \"role\": \"assistant\" } } ],\n\n\"data\": {\n    \"id\": \"alf51ba2df4545862217c008456f5f\",\n    \"object\": \"chat.completion.chunk\",\n    \"created\": 1745502014,\n    \"model\": \"mistral-large-latest\"\n}\n\n}\n```\n\n### Pip Freeze\n\n```shell\nI'm using OpenRouter's integration function to call Mistral ai API.\n```\n\n### Reproduction Steps\n\nHere is the url: https://api.mistral.ai/v1/chat/completions\n\n### Expected Behavior\n\nreturn the answer.\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/245/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/245/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/243",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/243/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/243/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/243/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/243",
    "id": 2978457950,
    "node_id": "I_kwDOKY_97s6xh6le",
    "number": 243,
    "title": "max output token and knowledge cutoff for Mistral-8B-Instruct-2410",
    "user": {
      "login": "zhoumengbo",
      "id": 79833433,
      "node_id": "MDQ6VXNlcjc5ODMzNDMz",
      "avatar_url": "https://avatars.githubusercontent.com/u/79833433?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/zhoumengbo",
      "html_url": "https://github.com/zhoumengbo",
      "followers_url": "https://api.github.com/users/zhoumengbo/followers",
      "following_url": "https://api.github.com/users/zhoumengbo/following{/other_user}",
      "gists_url": "https://api.github.com/users/zhoumengbo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/zhoumengbo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/zhoumengbo/subscriptions",
      "organizations_url": "https://api.github.com/users/zhoumengbo/orgs",
      "repos_url": "https://api.github.com/users/zhoumengbo/repos",
      "events_url": "https://api.github.com/users/zhoumengbo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/zhoumengbo/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2025-04-08T02:53:12Z",
    "updated_at": "2025-05-21T09:02:35Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nHello,\n\nI would like to ask two questions about the Mistral-8B-Instruct-2410:\n\n1. **What is the maximum number of output tokens** the model can generate during inference?\n   - For example, is there a known limit like 2048, 8192 tokens?\n\n2. **What is the knowledge cutoff date** for this version?\n   - Is the model trained on data up to a specific month or year (e.g., 2023-03, 2023-08, etc.)?\n\nI\u2019ve searched the documentation but couldn\u2019t find a definitive answer to these two questions.\n\nThank you in advance for your help!\n```\n\n### Pip Freeze\n\n```shell\nNone\n```\n\n### Reproduction Steps\n\nNone\n\n### Expected Behavior\n\nNone\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/243/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/243/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/242",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/242/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/242/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/242/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/242",
    "id": 2962387661,
    "node_id": "I_kwDOKY_97s6wknLN",
    "number": 242,
    "title": "[BUG: No such file or directory: 'mistral_models/Mixtral-8x7b-Instruct-v0.1/params.json'",
    "user": {
      "login": "Lorenz5622",
      "id": 91588395,
      "node_id": "U_kgDOBXWHKw",
      "avatar_url": "https://avatars.githubusercontent.com/u/91588395?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Lorenz5622",
      "html_url": "https://github.com/Lorenz5622",
      "followers_url": "https://api.github.com/users/Lorenz5622/followers",
      "following_url": "https://api.github.com/users/Lorenz5622/following{/other_user}",
      "gists_url": "https://api.github.com/users/Lorenz5622/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Lorenz5622/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Lorenz5622/subscriptions",
      "organizations_url": "https://api.github.com/users/Lorenz5622/orgs",
      "repos_url": "https://api.github.com/users/Lorenz5622/repos",
      "events_url": "https://api.github.com/users/Lorenz5622/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Lorenz5622/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2025-04-01T06:26:25Z",
    "updated_at": "2025-04-01T14:44:48Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\n(mixtral) root@autodl-container-4c3247ac55-3930647f:~/autodl-tmp/mistral-inference/mistral_models# python eval.py\nTraceback (most recent call last):\n  File \"/root/autodl-tmp/mistral-inference/mistral_models/eval.py\", line 16, in <module>\n    model = Transformer.from_folder(mistral_models_path)\n  File \"/root/autodl-tmp/mistral-inference/src/mistral_inference/transformer.py\", line 306, in from_folder\n    with open(Path(folder) / \"params.json\", \"r\") as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'mistral_models/Mixtral-8x7b-Instruct-v0.1/params.json'\n```\n\n### Pip Freeze\n\n```shell\nannotated-types==0.7.0\nanyio==4.9.0\nattrs==23.2.0\nbackports.tarfile==1.2.0\nbuild==1.2.2.post1\nCacheControl==0.14.2\ncertifi==2025.1.31\ncffi==1.17.1\ncharset-normalizer==3.4.1\ncleo==2.1.0\ncrashtest==0.4.1\ncryptography==44.0.2\ndistlib==0.3.9\ndocstring_parser==0.16\ndulwich==0.22.8\nexceptiongroup==1.2.1\nfastjsonschema==2.21.1\nfilelock==3.14.0\nfindpython==0.6.3\nfire==0.6.0\nfsspec==2024.5.0\nh11==0.14.0\nhttpcore==1.0.7\nhttpx==0.28.1\nhuggingface-hub==0.29.3\nidna==3.10\nimportlib_metadata==8.6.1\niniconfig==2.0.0\ninstaller==0.7.0\njaraco.classes==3.4.0\njaraco.context==6.0.1\njaraco.functools==4.1.0\njeepney==0.9.0\nJinja2==3.1.4\njsonschema==4.21.1\njsonschema-specifications==2023.12.1\nkeyring==25.6.0\nMarkupSafe==2.1.5\nmistral_common==1.5.4\n-e git+https://github.com/mistralai/mistral-inference.git@6eb35510403825cfb430b0004443053e8c4b70dc#egg=mistral_inference\nmore-itertools==10.6.0\nmpmath==1.3.0\nmsgpack==1.1.0\nmypy==1.10.0\nmypy-extensions==1.0.0\nmypy-protobuf==3.6.0\nnetworkx==3.2.1\nnumpy==1.26.4\nnvidia-cublas-cu12==12.1.3.1\nnvidia-cuda-cupti-cu12==12.1.105\nnvidia-cuda-nvrtc-cu12==12.1.105\nnvidia-cuda-runtime-cu12==12.1.105\nnvidia-cudnn-cu12==8.9.2.26\nnvidia-cufft-cu12==11.0.2.54\nnvidia-curand-cu12==10.3.2.106\nnvidia-cusolver-cu12==11.4.5.107\nnvidia-cusparse-cu12==12.1.0.106\nnvidia-cusparselt-cu12==0.6.2\nnvidia-nccl-cu12==2.20.5\nnvidia-nvjitlink-cu12==12.5.40\nnvidia-nvtx-cu12==12.1.105\npackaging==24.0\npbs-installer==2025.3.17\npillow==11.1.0\npkginfo==1.12.1.2\nplatformdirs==4.3.7\npluggy==1.5.0\npoetry==2.1.2\npoetry-core==2.1.2\nprotobuf==5.27.0\npycparser==2.22\npydantic==2.9.2\npydantic_core==2.23.4\npyproject_hooks==1.2.0\npytest==7.4.4\nPyYAML==6.0.2\nRapidFuzz==3.12.2\nreferencing==0.35.1\nregex==2024.11.6\nrequests==2.32.3\nrequests-toolbelt==1.0.0\nrpds-py==0.18.1\nruff==0.2.2\nsafetensors==0.4.3\nSecretStorage==3.3.3\nsentencepiece==0.2.0\nshellingham==1.5.4\nsimple_parsing==0.1.5\nsix==1.16.0\nsniffio==1.3.1\nsympy==1.12\ntermcolor==2.4.0\ntiktoken==0.9.0\ntokenizers==0.21.1\ntomli==2.0.1\ntomlkit==0.13.2\ntorch==2.3.0\ntqdm==4.67.1\ntransformers==4.50.3\ntriton==2.3.0\ntrove-classifiers==2025.3.19.19\ntypes-protobuf==4.24.0.20240129\ntyping-inspection==0.4.0\ntyping_extensions==4.12.0\nurllib3==2.3.0\nvirtualenv==20.29.3\nxformers==0.0.26.post1\nzipp==3.21.0\nzstandard==0.23.0\n```\n\n### Reproduction Steps\n\n1. follow the instructions in Installation\n2. download Mixtral-8x7b-Instruct-v0.1 from hugging face\n3. use intruction: torchrun --nproc-per-node 2 --no-python mistral-demo $M8x7B_DIR\n4. output: [rank1]: FileNotFoundError: [Errno 2] No such file or directory: '/root/autodl-tmp/mistral-inference/mistral_models/Mixtral-8x7b-Instruct-v0.1/params.json'\n5. follow the instruction in hugging face, the same output like \"no params.json\".\n\n### Expected Behavior\n\nPlease add file params.json into [mistralai/Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) in huggingface, so I can successfully use mixtral-inference, thanks.\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/242/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/242/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/241",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/241/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/241/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/241/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/241",
    "id": 2935787738,
    "node_id": "PR_kwDOKY_97s6Pe54R",
    "number": 241,
    "title": "Release 1.6.0",
    "user": {
      "login": "juliendenize",
      "id": 40604584,
      "node_id": "MDQ6VXNlcjQwNjA0NTg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/40604584?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/juliendenize",
      "html_url": "https://github.com/juliendenize",
      "followers_url": "https://api.github.com/users/juliendenize/followers",
      "following_url": "https://api.github.com/users/juliendenize/following{/other_user}",
      "gists_url": "https://api.github.com/users/juliendenize/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/juliendenize/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/juliendenize/subscriptions",
      "organizations_url": "https://api.github.com/users/juliendenize/orgs",
      "repos_url": "https://api.github.com/users/juliendenize/repos",
      "events_url": "https://api.github.com/users/juliendenize/events{/privacy}",
      "received_events_url": "https://api.github.com/users/juliendenize/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": {
      "login": "juliendenize",
      "id": 40604584,
      "node_id": "MDQ6VXNlcjQwNjA0NTg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/40604584?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/juliendenize",
      "html_url": "https://github.com/juliendenize",
      "followers_url": "https://api.github.com/users/juliendenize/followers",
      "following_url": "https://api.github.com/users/juliendenize/following{/other_user}",
      "gists_url": "https://api.github.com/users/juliendenize/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/juliendenize/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/juliendenize/subscriptions",
      "organizations_url": "https://api.github.com/users/juliendenize/orgs",
      "repos_url": "https://api.github.com/users/juliendenize/repos",
      "events_url": "https://api.github.com/users/juliendenize/events{/privacy}",
      "received_events_url": "https://api.github.com/users/juliendenize/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "assignees": [
      {
        "login": "juliendenize",
        "id": 40604584,
        "node_id": "MDQ6VXNlcjQwNjA0NTg0",
        "avatar_url": "https://avatars.githubusercontent.com/u/40604584?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/juliendenize",
        "html_url": "https://github.com/juliendenize",
        "followers_url": "https://api.github.com/users/juliendenize/followers",
        "following_url": "https://api.github.com/users/juliendenize/following{/other_user}",
        "gists_url": "https://api.github.com/users/juliendenize/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/juliendenize/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/juliendenize/subscriptions",
        "organizations_url": "https://api.github.com/users/juliendenize/orgs",
        "repos_url": "https://api.github.com/users/juliendenize/repos",
        "events_url": "https://api.github.com/users/juliendenize/events{/privacy}",
        "received_events_url": "https://api.github.com/users/juliendenize/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      }
    ],
    "milestone": null,
    "comments": 0,
    "created_at": "2025-03-20T14:59:20Z",
    "updated_at": "2025-03-20T15:01:45Z",
    "closed_at": "2025-03-20T15:01:45Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/241",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/241",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/241.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/241.patch",
      "merged_at": "2025-03-20T15:01:45Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/241/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/241/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/240",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/240/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/240/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/240/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/240",
    "id": 2935549194,
    "node_id": "PR_kwDOKY_97s6PeGBK",
    "number": 240,
    "title": "Remove file refs",
    "user": {
      "login": "juliendenize",
      "id": 40604584,
      "node_id": "MDQ6VXNlcjQwNjA0NTg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/40604584?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/juliendenize",
      "html_url": "https://github.com/juliendenize",
      "followers_url": "https://api.github.com/users/juliendenize/followers",
      "following_url": "https://api.github.com/users/juliendenize/following{/other_user}",
      "gists_url": "https://api.github.com/users/juliendenize/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/juliendenize/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/juliendenize/subscriptions",
      "organizations_url": "https://api.github.com/users/juliendenize/orgs",
      "repos_url": "https://api.github.com/users/juliendenize/repos",
      "events_url": "https://api.github.com/users/juliendenize/events{/privacy}",
      "received_events_url": "https://api.github.com/users/juliendenize/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2025-03-20T13:42:59Z",
    "updated_at": "2025-03-20T14:50:14Z",
    "closed_at": "2025-03-20T14:50:14Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/240",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/240",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/240.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/240.patch",
      "merged_at": "2025-03-20T14:50:14Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/240/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/240/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/239",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/239/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/239/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/239/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/239",
    "id": 2932509078,
    "node_id": "PR_kwDOKY_97s6PULxs",
    "number": 239,
    "title": "Add support to Mistral Small 3.1",
    "user": {
      "login": "juliendenize",
      "id": 40604584,
      "node_id": "MDQ6VXNlcjQwNjA0NTg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/40604584?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/juliendenize",
      "html_url": "https://github.com/juliendenize",
      "followers_url": "https://api.github.com/users/juliendenize/followers",
      "following_url": "https://api.github.com/users/juliendenize/following{/other_user}",
      "gists_url": "https://api.github.com/users/juliendenize/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/juliendenize/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/juliendenize/subscriptions",
      "organizations_url": "https://api.github.com/users/juliendenize/orgs",
      "repos_url": "https://api.github.com/users/juliendenize/repos",
      "events_url": "https://api.github.com/users/juliendenize/events{/privacy}",
      "received_events_url": "https://api.github.com/users/juliendenize/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": {
      "login": "juliendenize",
      "id": 40604584,
      "node_id": "MDQ6VXNlcjQwNjA0NTg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/40604584?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/juliendenize",
      "html_url": "https://github.com/juliendenize",
      "followers_url": "https://api.github.com/users/juliendenize/followers",
      "following_url": "https://api.github.com/users/juliendenize/following{/other_user}",
      "gists_url": "https://api.github.com/users/juliendenize/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/juliendenize/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/juliendenize/subscriptions",
      "organizations_url": "https://api.github.com/users/juliendenize/orgs",
      "repos_url": "https://api.github.com/users/juliendenize/repos",
      "events_url": "https://api.github.com/users/juliendenize/events{/privacy}",
      "received_events_url": "https://api.github.com/users/juliendenize/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "assignees": [
      {
        "login": "juliendenize",
        "id": 40604584,
        "node_id": "MDQ6VXNlcjQwNjA0NTg0",
        "avatar_url": "https://avatars.githubusercontent.com/u/40604584?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/juliendenize",
        "html_url": "https://github.com/juliendenize",
        "followers_url": "https://api.github.com/users/juliendenize/followers",
        "following_url": "https://api.github.com/users/juliendenize/following{/other_user}",
        "gists_url": "https://api.github.com/users/juliendenize/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/juliendenize/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/juliendenize/subscriptions",
        "organizations_url": "https://api.github.com/users/juliendenize/orgs",
        "repos_url": "https://api.github.com/users/juliendenize/repos",
        "events_url": "https://api.github.com/users/juliendenize/events{/privacy}",
        "received_events_url": "https://api.github.com/users/juliendenize/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      }
    ],
    "milestone": null,
    "comments": 0,
    "created_at": "2025-03-19T16:50:56Z",
    "updated_at": "2025-03-20T13:37:47Z",
    "closed_at": "2025-03-20T13:37:47Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/239",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/239",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/239.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/239.patch",
      "merged_at": "2025-03-20T13:37:47Z"
    },
    "body": "This PR adds support to [Mistral Small 3.1](https://mistral.ai/news/mistral-small-3-1) recently released. ",
    "closed_by": {
      "login": "juliendenize",
      "id": 40604584,
      "node_id": "MDQ6VXNlcjQwNjA0NTg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/40604584?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/juliendenize",
      "html_url": "https://github.com/juliendenize",
      "followers_url": "https://api.github.com/users/juliendenize/followers",
      "following_url": "https://api.github.com/users/juliendenize/following{/other_user}",
      "gists_url": "https://api.github.com/users/juliendenize/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/juliendenize/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/juliendenize/subscriptions",
      "organizations_url": "https://api.github.com/users/juliendenize/orgs",
      "repos_url": "https://api.github.com/users/juliendenize/repos",
      "events_url": "https://api.github.com/users/juliendenize/events{/privacy}",
      "received_events_url": "https://api.github.com/users/juliendenize/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/239/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/239/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/238",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/238/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/238/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/238/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/238",
    "id": 2923240505,
    "node_id": "I_kwDOKY_97s6uPRw5",
    "number": 238,
    "title": "Transformer.from_folder - Can we specify FlashAttention ?",
    "user": {
      "login": "amitbcp",
      "id": 13197403,
      "node_id": "MDQ6VXNlcjEzMTk3NDAz",
      "avatar_url": "https://avatars.githubusercontent.com/u/13197403?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/amitbcp",
      "html_url": "https://github.com/amitbcp",
      "followers_url": "https://api.github.com/users/amitbcp/followers",
      "following_url": "https://api.github.com/users/amitbcp/following{/other_user}",
      "gists_url": "https://api.github.com/users/amitbcp/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/amitbcp/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/amitbcp/subscriptions",
      "organizations_url": "https://api.github.com/users/amitbcp/orgs",
      "repos_url": "https://api.github.com/users/amitbcp/repos",
      "events_url": "https://api.github.com/users/amitbcp/events{/privacy}",
      "received_events_url": "https://api.github.com/users/amitbcp/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2025-03-16T18:44:52Z",
    "updated_at": "2025-03-16T18:44:52Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\n-\n```\n\n### Pip Freeze\n\n```shell\npip freeze | grep mistral\nmistral_common==1.5.1\nmistral_inference==1.5.0\n```\n\n### Reproduction Steps\n\n```python\nself.model_path = model_path\n        try:\n            from mistral_inference.transformer import Transformer\n            from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n        except ImportError as err:\n            logging.critical('Please install `mistral-inference` and `mistral_common`')\n            raise err\n\n        if os.path.exists(model_path):\n            cache_path = model_path\n        else:\n            if get_cache_path(model_path) is None:\n                snapshot_download(repo_id=model_path)\n            cache_path = get_cache_path(self.model_path, repo_type='models')\n\n        self.tokenizer = MistralTokenizer.from_file(f'{cache_path}/tekken.json')\n        model = Transformer.from_folder(cache_path, device='cpu')\n        model.cuda()\n        self.model = model\n        self.max_tokens = 2048\n``` \n\n### Expected Behavior\n\n1. The inference for Pixtral is super slow. Is their a way to specify to use flash-attention2 ?\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/238/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/238/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/237",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/237/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/237/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/237/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/237",
    "id": 2882345145,
    "node_id": "I_kwDOKY_97s6rzRi5",
    "number": 237,
    "title": "[BUG: Stream does not work with custom json mode",
    "user": {
      "login": "brochier",
      "id": 20535690,
      "node_id": "MDQ6VXNlcjIwNTM1Njkw",
      "avatar_url": "https://avatars.githubusercontent.com/u/20535690?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/brochier",
      "html_url": "https://github.com/brochier",
      "followers_url": "https://api.github.com/users/brochier/followers",
      "following_url": "https://api.github.com/users/brochier/following{/other_user}",
      "gists_url": "https://api.github.com/users/brochier/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/brochier/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/brochier/subscriptions",
      "organizations_url": "https://api.github.com/users/brochier/orgs",
      "repos_url": "https://api.github.com/users/brochier/repos",
      "events_url": "https://api.github.com/users/brochier/events{/privacy}",
      "received_events_url": "https://api.github.com/users/brochier/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2025-02-26T17:35:34Z",
    "updated_at": "2025-02-27T09:52:04Z",
    "closed_at": "2025-02-27T09:50:07Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.11.6 (main, Apr  8 2024, 17:17:59) [Clang 15.0.0 (clang-1500.3.9.4)]\n```\n\n### Pip Freeze\n\n```shell\naiohappyeyeballs==2.4.4\naiohttp==3.11.11\naiosignal==1.3.2\naltair==5.5.0\nannotated-types==0.7.0\nanyio==4.8.0\nappnope==0.1.4\nargon2-cffi==23.1.0\nargon2-cffi-bindings==21.2.0\narrow==1.3.0\nasgiref==3.8.1\nasttokens==2.4.1\nasync-lru==2.0.4\nattrs==24.3.0\nbabel==2.16.0\nbackoff==2.2.1\nbcrypt==4.2.1\nbeautifulsoup4==4.12.3\nblack==24.10.0\nbleach==6.1.0\nblinker==1.9.0\nBrotli==1.1.0\nbuild==1.2.2.post1\ncachetools==5.5.0\ncertifi==2024.12.14\ncffi==1.17.0\ncharset-normalizer==3.4.1\nchroma-hnswlib==0.7.6\nchromadb==0.6.3\nclick==8.1.8\ncoloredlogs==15.0.1\ncomm==0.2.2\ndebugpy==1.8.5\ndecorator==5.1.1\ndefusedxml==0.7.1\nDeprecated==1.2.18\ndistro==1.9.0\ndocstring_parser==0.16\ndocutils==0.21.2\ndurationpy==0.9\net-xmlfile==1.1.0\nexecuting==2.1.0\nfastapi==0.115.8\nfastjsonschema==2.20.0\nfeedgenerator==2.1.0\nffmpeg==1.4\nffprobe==0.5\nfilelock==3.16.1\nfiletype==1.2.0\nflatbuffers==25.2.10\nfqdn==1.5.1\nfrozenlist==1.5.0\nfsspec==2024.12.0\ngitdb==4.0.12\nGitPython==3.1.44\ngoogle-ai-generativelanguage==0.6.15\ngoogle-api-core==2.24.1\ngoogle-api-python-client==2.160.0\ngoogle-auth==2.38.0\ngoogle-auth-httplib2==0.2.0\ngoogle-cloud-aiplatform==1.81.0\ngoogle-cloud-bigquery==3.29.0\ngoogle-cloud-core==2.4.2\ngoogle-cloud-resource-manager==1.14.1\ngoogle-cloud-storage==2.19.0\ngoogle-crc32c==1.6.0\ngoogle-generativeai==0.8.4\ngoogle-resumable-media==2.7.2\ngoogleapis-common-protos==1.66.0\ngrpc-google-iam-v1==0.14.0\ngrpcio==1.70.0\ngrpcio-status==1.70.0\nh11==0.14.0\nhttpcore==1.0.7\nhttplib2==0.22.0\nhttptools==0.6.4\nhttpx==0.28.1\nhttpx-sse==0.4.0\nhuggingface-hub==0.27.1\nhumanfriendly==10.0\nidna==3.10\nimportlib_metadata==8.5.0\nimportlib_resources==6.5.2\nipykernel==6.29.5\nipython==8.27.0\nisoduration==20.11.0\njedi==0.19.1\nJinja2==3.1.5\njiter==0.8.2\njson5==0.9.25\njsonpatch==1.33\njsonpointer==3.0.0\njsonschema==4.23.0\njsonschema-specifications==2024.10.1\njupyter-events==0.10.0\njupyter-lsp==2.2.5\njupyter_client==8.6.2\njupyter_core==5.7.2\njupyter_server==2.14.2\njupyter_server_terminals==0.5.3\njupyterlab==4.2.5\njupyterlab_pygments==0.3.0\njupyterlab_server==2.27.3\nkubernetes==32.0.1\nlangchain==0.3.19\nlangchain-chroma==0.2.2\nlangchain-core==0.3.35\nlangchain-google-genai==2.0.9\nlangchain-google-vertexai==2.0.14\nlangchain-mistralai==0.2.4\nlangchain-ollama==0.2.2\nlangchain-openai==0.3.0\nlangchain-text-splitters==0.3.6\nlangsmith==0.2.11\nMarkdown==3.7\nmarkdown-it-py==3.0.0\nMarkupSafe==3.0.2\nmatplotlib-inline==0.1.7\nmdurl==0.1.2\nmistune==3.0.2\nmmh3==5.1.0\nmonotonic==1.6\nmpmath==1.3.0\nmultidict==6.1.0\nmutagen==1.47.0\nmypy-extensions==1.0.0\nnarwhals==1.22.0\nnbclient==0.10.0\nnbconvert==7.16.4\nnbformat==5.10.4\nnest-asyncio==1.6.0\nnotebook==7.2.2\nnotebook_shim==0.2.4\nnumpy==1.26.4\noauthlib==3.2.2\nollama==0.4.6\nonnxruntime==1.20.1\nopenai==1.59.7\nopenpyxl==3.1.5\nopentelemetry-api==1.30.0\nopentelemetry-exporter-otlp-proto-common==1.30.0\nopentelemetry-exporter-otlp-proto-grpc==1.30.0\nopentelemetry-instrumentation==0.51b0\nopentelemetry-instrumentation-asgi==0.51b0\nopentelemetry-instrumentation-fastapi==0.51b0\nopentelemetry-proto==1.30.0\nopentelemetry-sdk==1.30.0\nopentelemetry-semantic-conventions==0.51b0\nopentelemetry-util-http==0.51b0\nordered-set==4.1.0\norjson==3.10.14\noverrides==7.7.0\npackaging==24.2\npandas==2.2.3\npandocfilters==1.5.1\nparso==0.8.4\npathspec==0.12.1\npdfkit==1.0.0\npelican==4.9.1\npexpect==4.9.0\npillow==11.1.0\nplatformdirs==4.3.6\nposthog==3.15.1\nprometheus_client==0.20.0\nprompt_toolkit==3.0.47\npropcache==0.2.1\nproto-plus==1.26.0\nprotobuf==5.29.3\npsutil==6.0.0\nptyprocess==0.7.0\npure_eval==0.2.3\npyarrow==19.0.0\npyasn1==0.6.1\npyasn1_modules==0.4.1\npycparser==2.22\npycryptodomex==3.20.0\npydantic==2.10.5\npydantic_core==2.27.2\npydeck==0.9.1\nPygments==2.19.1\nPyMuPDF==1.24.6\nPyMuPDFb==1.24.6\npyparsing==3.2.1\nPyPika==0.48.9\npyproject_hooks==1.2.0\npython-dateutil==2.9.0.post0\npython-dotenv==1.0.1\npython-json-logger==2.0.7\npytz==2024.2\nPyYAML==6.0.2\npyzmq==26.2.0\nreferencing==0.36.1\nregex==2024.11.6\nrequests==2.32.3\nrequests-oauthlib==2.0.0\nrequests-toolbelt==1.0.0\nrfc3339-validator==0.1.4\nrfc3986-validator==0.1.1\nrich==13.9.4\nrpds-py==0.22.3\nrsa==4.9\nSend2Trash==1.8.3\nshapely==2.0.7\nshellingham==1.5.4\nsix==1.17.0\nsmmap==5.0.2\nsniffio==1.3.1\nsoupsieve==2.6\nSQLAlchemy==2.0.37\nstack-data==0.6.3\nstarlette==0.45.3\nstreamlit==1.42.2\nsympy==1.13.3\ntenacity==9.0.0\nterminado==0.18.1\ntiktoken==0.8.0\ntinycss2==1.3.0\ntokenizers==0.21.0\ntoml==0.10.2\ntornado==6.4.2\ntqdm==4.67.1\ntraitlets==5.14.3\ntyper==0.15.1\ntypes-python-dateutil==2.9.0.20240821\ntyping_extensions==4.12.2\ntzdata==2024.2\nUnidecode==1.3.8\nuri-template==1.3.0\nuritemplate==4.1.1\nurllib3==2.3.0\nuv==0.4.4\nuvicorn==0.34.0\nuvloop==0.21.0\nwatchdog==6.0.0\nwatchfiles==0.22.0\nwcwidth==0.2.13\nwebcolors==24.8.0\nwebencodings==0.5.1\nwebsocket-client==1.8.0\nwebsockets==12.0\nwrapt==1.17.2\nyarl==1.18.3\nyt-dlp==2024.7.16\nzipp==3.21.0\n```\n\n### Reproduction Steps\n\nYou can use this python code:\n\n```python\nimport os\nimport getpass\nfrom langchain_mistralai.chat_models import ChatMistralAI\n\n\nif \"MISTRAL_API_KEY\" not in os.environ:\n    os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter your Mistral API key: \")\n\nmodel = ChatMistralAI(\n    temperature=0, max_retries=2, model=\"mistral-small-latest\", streaming=True\n)\n\noutput_schema = {\n    \"title\": \"biggest_cities\",\n    \"description\": \"\",\n    \"type\": \"object\",\n    \"properties\": {\n        \"cities\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"\"}\n    },\n    \"required\": [\"cities\"],\n}\n\nmodel_with_structure = model.with_structured_output(\n    output_schema, method=\"function_calling\"\n)\n\nfor chunk in model_with_structure.stream(\"What are the 10 biggest cities in France?\"):\n    print(chunk)\n```\n\n### Expected Behavior\n\nI need to stream the response of the LLM call when forcing the output to follow a structured output. However, the response is returned at once. Streaming is not implemented. \n\nI created a related issue in LangChain: https://github.com/langchain-ai/langchain/issues/29860\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": {
      "login": "brochier",
      "id": 20535690,
      "node_id": "MDQ6VXNlcjIwNTM1Njkw",
      "avatar_url": "https://avatars.githubusercontent.com/u/20535690?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/brochier",
      "html_url": "https://github.com/brochier",
      "followers_url": "https://api.github.com/users/brochier/followers",
      "following_url": "https://api.github.com/users/brochier/following{/other_user}",
      "gists_url": "https://api.github.com/users/brochier/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/brochier/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/brochier/subscriptions",
      "organizations_url": "https://api.github.com/users/brochier/orgs",
      "repos_url": "https://api.github.com/users/brochier/repos",
      "events_url": "https://api.github.com/users/brochier/events{/privacy}",
      "received_events_url": "https://api.github.com/users/brochier/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/237/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/237/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/236",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/236/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/236/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/236/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/236",
    "id": 2775717544,
    "node_id": "I_kwDOKY_97s6lchao",
    "number": 236,
    "title": "[BUG: mistral-inference\u4e0b\u8f7d\u6210\u529f\u540e \u8fd0\u884cmistral-demo\u62a5\u9519  command not found",
    "user": {
      "login": "sjfievxcjkfd2",
      "id": 151891674,
      "node_id": "U_kgDOCQ2u2g",
      "avatar_url": "https://avatars.githubusercontent.com/u/151891674?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sjfievxcjkfd2",
      "html_url": "https://github.com/sjfievxcjkfd2",
      "followers_url": "https://api.github.com/users/sjfievxcjkfd2/followers",
      "following_url": "https://api.github.com/users/sjfievxcjkfd2/following{/other_user}",
      "gists_url": "https://api.github.com/users/sjfievxcjkfd2/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sjfievxcjkfd2/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sjfievxcjkfd2/subscriptions",
      "organizations_url": "https://api.github.com/users/sjfievxcjkfd2/orgs",
      "repos_url": "https://api.github.com/users/sjfievxcjkfd2/repos",
      "events_url": "https://api.github.com/users/sjfievxcjkfd2/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sjfievxcjkfd2/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2025-01-08T15:43:22Z",
    "updated_at": "2025-01-08T15:43:22Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\n(cot) intern2@yile-173-173:~/mistral-inference$ mistral-chat Mistral-7B-v0.1\r\n-bash: mistral-chat: command not found\n```\n\n\n### Pip Freeze\n\n```shell\n(cot) intern2@yile-173-173:~/mistral-inference$ mistral-chat Mistral-7B-v0.1\r\n-bash: mistral-chat: command not found\n```\n\n\n### Reproduction Steps\n\n\u4e0b\u8f7d\u4e86mistral-inference\u4f46\u6ca1\u6709bin\u6587\u4ef6\uff0c\u6dfb\u52a0\u4e0d\u4e86\u7cfb\u7edf\u53d8\u91cf\uff0c\u8fd0\u884c\u5931\u8d25\n\n### Expected Behavior\n\n11\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/236/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/236/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/235",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/235/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/235/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/235/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/235",
    "id": 2722432576,
    "node_id": "I_kwDOKY_97s6iRQZA",
    "number": 235,
    "title": "[BUG: https://mistral.ai/news/mistral-large-2407/ Are there relevant papers, and what are the metrics used to measure the dataset?     For example, Is the evaluation metric for MultiPL-E pass@1 ?",
    "user": {
      "login": "886gb",
      "id": 147044258,
      "node_id": "U_kgDOCMO3og",
      "avatar_url": "https://avatars.githubusercontent.com/u/147044258?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/886gb",
      "html_url": "https://github.com/886gb",
      "followers_url": "https://api.github.com/users/886gb/followers",
      "following_url": "https://api.github.com/users/886gb/following{/other_user}",
      "gists_url": "https://api.github.com/users/886gb/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/886gb/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/886gb/subscriptions",
      "organizations_url": "https://api.github.com/users/886gb/orgs",
      "repos_url": "https://api.github.com/users/886gb/repos",
      "events_url": "https://api.github.com/users/886gb/events{/privacy}",
      "received_events_url": "https://api.github.com/users/886gb/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-12-06T08:49:01Z",
    "updated_at": "2024-12-06T08:49:01Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nAre there relevant papers, and what are the metrics used to measure the dataset?     For example, Is the evaluation metric for MultiPL-E pass@1 ?\n```\n\n\n### Pip Freeze\n\n```shell\nAre there relevant papers, and what are the metrics used to measure the dataset?     For example, Is the evaluation metric for MultiPL-E pass@1 ?\n```\n\n\n### Reproduction Steps\n\nAre there relevant papers, and what are the metrics used to measure the dataset?     For example, Is the evaluation metric for MultiPL-E pass@1 ?\n\n### Expected Behavior\n\nAre there relevant papers, and what are the metrics used to measure the dataset?     For example, Is the evaluation metric for MultiPL-E pass@1 ?\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/235/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/235/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/234",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/234/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/234/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/234/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/234",
    "id": 2650617977,
    "node_id": "PR_kwDOKY_97s6BkOtg",
    "number": 234,
    "title": "Missing new line",
    "user": {
      "login": "theophilegervet",
      "id": 14276221,
      "node_id": "MDQ6VXNlcjE0Mjc2MjIx",
      "avatar_url": "https://avatars.githubusercontent.com/u/14276221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/theophilegervet",
      "html_url": "https://github.com/theophilegervet",
      "followers_url": "https://api.github.com/users/theophilegervet/followers",
      "following_url": "https://api.github.com/users/theophilegervet/following{/other_user}",
      "gists_url": "https://api.github.com/users/theophilegervet/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/theophilegervet/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/theophilegervet/subscriptions",
      "organizations_url": "https://api.github.com/users/theophilegervet/orgs",
      "repos_url": "https://api.github.com/users/theophilegervet/repos",
      "events_url": "https://api.github.com/users/theophilegervet/events{/privacy}",
      "received_events_url": "https://api.github.com/users/theophilegervet/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-11-11T23:21:20Z",
    "updated_at": "2024-11-12T06:42:54Z",
    "closed_at": "2024-11-12T06:42:54Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/234",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/234",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/234.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/234.patch",
      "merged_at": "2024-11-12T06:42:54Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/234/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/234/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/233",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/233/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/233/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/233/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/233",
    "id": 2639542410,
    "node_id": "I_kwDOKY_97s6dVDiK",
    "number": 233,
    "title": "[BUG: ] Do we have a paper of a doc describing Mixtral-8x7B and Mixtral-8x22B model architectures?",
    "user": {
      "login": "vipannalla",
      "id": 37598732,
      "node_id": "MDQ6VXNlcjM3NTk4NzMy",
      "avatar_url": "https://avatars.githubusercontent.com/u/37598732?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vipannalla",
      "html_url": "https://github.com/vipannalla",
      "followers_url": "https://api.github.com/users/vipannalla/followers",
      "following_url": "https://api.github.com/users/vipannalla/following{/other_user}",
      "gists_url": "https://api.github.com/users/vipannalla/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vipannalla/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vipannalla/subscriptions",
      "organizations_url": "https://api.github.com/users/vipannalla/orgs",
      "repos_url": "https://api.github.com/users/vipannalla/repos",
      "events_url": "https://api.github.com/users/vipannalla/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vipannalla/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-11-07T00:18:48Z",
    "updated_at": "2024-11-24T01:03:46Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nN/A\n```\n\n\n### Pip Freeze\n\n```shell\nN/A\n```\n\n\n### Reproduction Steps\n\nN/A\n\n### Expected Behavior\n\nN/A\n\n### Additional Context\n\nWe have a Mixtral implementation on JAX which works fine with 8x7B model but it generated garbage output with 8x22B model. I couldn't find any paper or doc describing the detailed architeture, is there any?\r\n\r\nThe only different noticed is Mixtral-8x7B uses tokenizer-v1 and Mixtral-8x22B uses tokenizer-v3. I also understand they have different number of params (47B vs 141B). However beyond this, do both models pretty much share exact model architecture? Are there any subtle differences in implementation I'm missing? Where can I find more details?\r\n\r\nThanks\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/233/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/233/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/232",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/232/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/232/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/232/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/232",
    "id": 2598893387,
    "node_id": "I_kwDOKY_97s6a5_dL",
    "number": 232,
    "title": "Invalid Identifier Error When Exporting Environment Variable 12B_DIR",
    "user": {
      "login": "alexander-knox",
      "id": 149740967,
      "node_id": "U_kgDOCOzdpw",
      "avatar_url": "https://avatars.githubusercontent.com/u/149740967?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/alexander-knox",
      "html_url": "https://github.com/alexander-knox",
      "followers_url": "https://api.github.com/users/alexander-knox/followers",
      "following_url": "https://api.github.com/users/alexander-knox/following{/other_user}",
      "gists_url": "https://api.github.com/users/alexander-knox/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/alexander-knox/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/alexander-knox/subscriptions",
      "organizations_url": "https://api.github.com/users/alexander-knox/orgs",
      "repos_url": "https://api.github.com/users/alexander-knox/repos",
      "events_url": "https://api.github.com/users/alexander-knox/events{/privacy}",
      "received_events_url": "https://api.github.com/users/alexander-knox/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-10-19T08:21:18Z",
    "updated_at": "2024-10-19T08:21:18Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.12.3 (main, Sep 11 2024, 14:17:37) [GCC 13.2.0]\n```\n\n\n### Pip Freeze\n\n```shell\nannotated-types==0.7.0\r\nattrs==24.2.0\r\ncertifi==2024.8.30\r\ncharset-normalizer==3.4.0\r\ndocstring_parser==0.16\r\nfilelock==3.16.1\r\nfire==0.7.0\r\nfsspec==2024.9.0\r\nidna==3.10\r\nJinja2==3.1.4\r\njsonschema==4.23.0\r\njsonschema-specifications==2024.10.1\r\nMarkupSafe==3.0.2\r\nmistral_common==1.4.4\r\nmistral_inference==1.5.0\r\nmpmath==1.3.0\r\nnetworkx==3.4.1\r\nnumpy==2.1.2\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==9.1.0.70\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-nccl-cu12==2.20.5\r\nnvidia-nvjitlink-cu12==12.6.77\r\nnvidia-nvtx-cu12==12.1.105\r\npillow==10.4.0\r\npydantic==2.9.2\r\npydantic_core==2.23.4\r\nreferencing==0.35.1\r\nregex==2024.9.11\r\nrequests==2.32.3\r\nrpds-py==0.20.0\r\nsafetensors==0.4.5\r\nsentencepiece==0.2.0\r\nsetuptools==75.2.0\r\nsimple-parsing==0.1.6\r\nsympy==1.13.3\r\ntermcolor==2.5.0\r\ntiktoken==0.7.0\r\ntorch==2.4.1\r\ntriton==3.0.0\r\ntyping_extensions==4.12.2\r\nurllib3==2.2.3\r\nxformers==0.0.28.post1\n```\n\n\n### Reproduction Steps\n\n1. Inside of a Bash shell, attempt to execute the command example shown on line 79 of the README.md file located in this project's root directory, i.e. \"export 12B_DIR=$MISTRAL_MODEL/12B_Nemo\"\r\n2. Receive the error: \"-bash: export: `12B_DIR=/home/my/path/mistral_models/12B_Nemo': not a valid identifier\"\r\n\n\n### Expected Behavior\n\nSuccessful export of the environment variable.\n\n### Additional Context\n\nOther shells may or may not have this problem? But in Bash, environment variables must not begin with a digit or number.\n\n### Suggested Solutions\n\nPerhaps the variable could be renamed to DIR_12B?\r\n\r\nFirst issue I've ever found. Hope this is OK. Thank you for your hard work on this amazing project.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/232/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/232/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/231",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/231/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/231/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/231/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/231",
    "id": 2592015263,
    "node_id": "PR_kwDOKY_97s5-1kCO",
    "number": 231,
    "title": "[Relesae 1.5]",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": {
      "login": "pierrestock",
      "id": 9300642,
      "node_id": "MDQ6VXNlcjkzMDA2NDI=",
      "avatar_url": "https://avatars.githubusercontent.com/u/9300642?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pierrestock",
      "html_url": "https://github.com/pierrestock",
      "followers_url": "https://api.github.com/users/pierrestock/followers",
      "following_url": "https://api.github.com/users/pierrestock/following{/other_user}",
      "gists_url": "https://api.github.com/users/pierrestock/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pierrestock/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pierrestock/subscriptions",
      "organizations_url": "https://api.github.com/users/pierrestock/orgs",
      "repos_url": "https://api.github.com/users/pierrestock/repos",
      "events_url": "https://api.github.com/users/pierrestock/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pierrestock/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "assignees": [
      {
        "login": "pierrestock",
        "id": 9300642,
        "node_id": "MDQ6VXNlcjkzMDA2NDI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/9300642?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/pierrestock",
        "html_url": "https://github.com/pierrestock",
        "followers_url": "https://api.github.com/users/pierrestock/followers",
        "following_url": "https://api.github.com/users/pierrestock/following{/other_user}",
        "gists_url": "https://api.github.com/users/pierrestock/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/pierrestock/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/pierrestock/subscriptions",
        "organizations_url": "https://api.github.com/users/pierrestock/orgs",
        "repos_url": "https://api.github.com/users/pierrestock/repos",
        "events_url": "https://api.github.com/users/pierrestock/events{/privacy}",
        "received_events_url": "https://api.github.com/users/pierrestock/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      }
    ],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-10-16T14:07:13Z",
    "updated_at": "2024-10-16T14:08:23Z",
    "closed_at": "2024-10-16T14:08:23Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/231",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/231",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/231.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/231.patch",
      "merged_at": "2024-10-16T14:08:23Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/231/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/231/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/230",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/230/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/230/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/230/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/230",
    "id": 2591925464,
    "node_id": "PR_kwDOKY_97s5-1Sc0",
    "number": 230,
    "title": "Add per-layer sliding window",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-10-16T13:39:05Z",
    "updated_at": "2024-10-16T14:06:14Z",
    "closed_at": "2024-10-16T14:06:14Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/230",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/230",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/230.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/230.patch",
      "merged_at": "2024-10-16T14:06:14Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/230/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/230/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/229",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/229/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/229/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/229/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/229",
    "id": 2582729695,
    "node_id": "I_kwDOKY_97s6Z8VPf",
    "number": 229,
    "title": "[BUG: Using the fine-tuned Mistral-7B-v0.1 for inference, when encountering the backslash escape character '', the inference stalls, very slow, but after a few minutes, it continues generating.",
    "user": {
      "login": "Essence9999",
      "id": 66725845,
      "node_id": "MDQ6VXNlcjY2NzI1ODQ1",
      "avatar_url": "https://avatars.githubusercontent.com/u/66725845?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Essence9999",
      "html_url": "https://github.com/Essence9999",
      "followers_url": "https://api.github.com/users/Essence9999/followers",
      "following_url": "https://api.github.com/users/Essence9999/following{/other_user}",
      "gists_url": "https://api.github.com/users/Essence9999/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Essence9999/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Essence9999/subscriptions",
      "organizations_url": "https://api.github.com/users/Essence9999/orgs",
      "repos_url": "https://api.github.com/users/Essence9999/repos",
      "events_url": "https://api.github.com/users/Essence9999/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Essence9999/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-10-12T09:39:06Z",
    "updated_at": "2024-10-12T09:39:06Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n```\n\n\n### Pip Freeze\n\n```shell\naccelerate==0.30.1\r\naiofiles==23.2.1\r\naiohttp==3.9.1\r\naioprometheus==23.12.0\r\naiosignal==1.3.1\r\naltair==5.2.0\r\nannotated-types==0.6.0\r\nanyio==4.2.0\r\nasync-timeout==4.0.3\r\nattrs==23.2.0\r\naudioread==3.0.1\r\nauto-gptq==0.6.0\r\nautoawq==0.2.5\r\nautoawq_kernels==0.0.6\r\nbitsandbytes==0.41.1\r\ncertifi==2023.11.17\r\ncffi==1.17.0\r\ncharset-normalizer==3.3.2\r\nclick==8.1.7\r\ncloudpickle==3.0.0\r\ncmake==3.29.2\r\ncoloredlogs==15.0.1\r\ncontourpy==1.2.0\r\ncupy-cuda12x==12.1.0\r\ncycler==0.12.1\r\ndatasets==2.16.1\r\ndecorator==5.1.1\r\ndill==0.3.7\r\ndiskcache==5.6.3\r\ndistro==1.9.0\r\ndocstring-parser==0.15\r\neinops==0.7.0\r\nexceptiongroup==1.2.0\r\nfastapi==0.108.0\r\nfastrlock==0.8.2\r\nffmpy==0.3.1\r\nfilelock==3.13.1\r\nfire==0.6.0\r\nfonttools==4.47.0\r\nfrozenlist==1.4.1\r\nfsspec==2023.10.0\r\ngalore-torch==1.0\r\ngekko==1.0.6\r\ngguf==0.9.1\r\ngradio==4.21.0\r\ngradio_client==0.12.0\r\nh11==0.14.0\r\nhttpcore==1.0.2\r\nhttptools==0.6.1\r\nhttpx==0.26.0\r\nhuggingface-hub==0.23.3\r\nhumanfriendly==10.0\r\nidna==3.6\r\nimportlib-resources==6.1.1\r\nimportlib_metadata==8.4.0\r\ninteregular==0.3.3\r\njieba==0.42.1\r\nJinja2==3.1.2\r\njoblib==1.3.2\r\njsonschema==4.20.0\r\njsonschema-specifications==2023.12.1\r\nkiwisolver==1.4.5\r\nlark==1.1.9\r\nlazy_loader==0.4\r\nlibrosa==0.10.2.post1\r\n-e git+https://githubfast.com/hiyouga/LLaMA-Factory.git@6b62550af1acda93246e05b37061f2ad7db58e55#egg=llamafactory\r\n-e git+https://githubfast.com/hiyouga/LLaMA-Factory.git@6b62550af1acda93246e05b37061f2ad7db58e55#egg=llmtuner\r\nllvmlite==0.42.0\r\nlm-format-enforcer==0.10.6\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.3\r\nmatplotlib==3.8.2\r\nmdurl==0.1.2\r\nmpmath==1.3.0\r\nmsgpack==1.0.8\r\nmsgspec==0.18.6\r\nmultidict==6.0.4\r\nmultiprocess==0.70.15\r\nnest-asyncio==1.6.0\r\nnetworkx==3.2.1\r\nninja==1.11.1.1\r\nnltk==3.8.1\r\nnumba==0.59.0\r\nnumpy==1.26.3\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==9.1.0.70\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-ml-py==12.550.52\r\nnvidia-nccl-cu12==2.20.5\r\nnvidia-nvjitlink-cu12==12.3.101\r\nnvidia-nvtx-cu12==12.1.105\r\nopenai==1.31.1\r\noptimum==1.16.1\r\norjson==3.9.10\r\noutlines==0.0.46\r\npackaging==23.2\r\npandas==2.1.4\r\npeft==0.11.1\r\npillow==10.2.0\r\nplatformdirs==4.2.2\r\npooch==1.8.2\r\nprometheus-fastapi-instrumentator==7.0.0\r\nprometheus_client==0.20.0\r\nprotobuf==4.25.1\r\npsutil==5.9.7\r\npy-cpuinfo==9.0.0\r\npyairports==2.1.1\r\npyarrow==14.0.2\r\npyarrow-hotfix==0.6\r\npycountry==24.6.1\r\npycparser==2.22\r\npydantic==2.8.2\r\npydantic_core==2.20.1\r\npydub==0.25.1\r\nPygments==2.17.2\r\npynvml==11.5.0\r\npyparsing==3.1.1\r\npython-dateutil==2.8.2\r\npython-dotenv==1.0.1\r\npython-multipart==0.0.9\r\npytz==2023.3.post1\r\nPyYAML==6.0.1\r\npyzmq==26.0.3\r\nquantile-python==1.1\r\nray==2.9.3\r\nreferencing==0.32.0\r\nregex==2023.12.25\r\nrequests==2.31.0\r\nrich==13.7.0\r\nrouge==1.0.1\r\nrouge-chinese==1.0.3\r\nrpds-py==0.16.2\r\nruff==0.3.7\r\nsafetensors==0.4.1\r\nscikit-learn==1.5.1\r\nscipy==1.11.4\r\nsemantic-version==2.10.0\r\nsentencepiece==0.1.99\r\nshellingham==1.5.4\r\nshtab==1.6.5\r\nsix==1.16.0\r\nsniffio==1.3.0\r\nsoundfile==0.12.1\r\nsoxr==0.5.0\r\nsse-starlette==1.8.2\r\nstarlette==0.32.0.post1\r\nsympy==1.12\r\ntermcolor==2.4.0\r\nthreadpoolctl==3.5.0\r\ntiktoken==0.6.0\r\ntokenizers==0.19.1\r\ntomlkit==0.12.0\r\ntoolz==0.12.0\r\ntorch==2.4.0\r\ntorchvision==0.19.0\r\ntqdm==4.66.1\r\ntransformers==4.43.4\r\ntransformers-stream-generator==0.0.4\r\ntriton==3.0.0\r\ntrl==0.9.3\r\ntyper==0.12.3\r\ntyping_extensions==4.12.2\r\ntyro==0.6.3\r\ntzdata==2023.4\r\nurllib3==2.1.0\r\nuvicorn==0.25.0\r\nuvloop==0.19.0\r\nvllm==0.5.5\r\nvllm-flash-attn==2.6.1\r\nvllm-nccl-cu12==2.18.1.0.4.0\r\nwatchfiles==0.21.0\r\nwebsockets==11.0.3\r\nxformers==0.0.27.post2\r\nxxhash==3.4.1\r\nyarl==1.9.4\r\nzipp==3.20.1\r\nzstandard==0.22.0\n```\n\n\n### Reproduction Steps\n\nCUDA_VISIBLE_DEVICES=0 llamafactory-cli chat /home/dotouch/work/projects/LLaMA-Factory/zscript/inference/mistral.yaml\r\n\r\n\r\nmistral.yaml\r\n#model_name_or_path: /home/dotouch/work/projects/LLaMA-Factory/models/mistral_ns_demo/\r\nmodel_name_or_path: /home/dotouch/work/projects/model/Mistral-7B-v0.3/\r\nadapter_name_or_path: /home/dotouch/work/projects/LLaMA-Factory/checkpoint/mistral_ns_tmp/checkpoint-500/\r\n#adapter_name_or_path: /home/dotouch/work/projects/LLaMA-Factory/checkpoint/mistral_ns/checkpoint-1200/\r\ntemplate: default\r\nfinetuning_type: lora\r\nmax_new_tokens: 12000\r\n\r\n\n\n### Expected Behavior\n\nexecute smoothly\n\n### Additional Context\n\nexample:\r\n\"interface_conf\": \"{\\\"port0\\\":{\\\"subnet_name\\\":\\\"9334\\\",\\\"pppoe_enable\\\":0,\\\"pppoe_id\\\":null,\\\"dhcp_enable\\\":0,\\\"mci_user_group_id\\\":null,\\\"mci_user_group_name\\\":null,\\\"server_mci_user_group_id\\\":null,\\\"server_mci_user_group_name\\\":null,\\\"server_mci_user_group_pname\\\":null,\\\"tunnel_srv6_client\\\":null,\\\"tunnel_srv6_server\\\":null,\\\"cinterface\\\":\\\"port0\\\",\\\"access_type\\\":null,\\\"ip_addr_src\\\":\\\"172.1.1.1\\\",\\\"ip_addr_src_end\\\":\\\"172.1.1.10\\\",\\\"ip_addr_src_order\\\":\\\"1\\\",\\\"ip_addr_src_step\\\":\\\"1\\\",\\\"ip_addr_src_step_num\\\":\\\"1\\\",\\\"lan_arp_enable\\\":\\\"0\\\",\\\"ip_addr_dest\\\":\\\"173.1.1.1\\\",\\\"ip_addr_dest_end\\\":\\\"173.1.1.1\\\",\\\"ip_addr_dest_order\\\":\\\"1\\\",\\\"ip_addr_dest_step\\\":\\\"1\\\",\\\"ip_addr_dest_step_num\\\":\\\"1\\\",\\\"ip_port_hop\\\":\\\"1\\\",\\\"enabled_vlan\\\":\\\"0\\\",\\\"enable_ipsec\\\":\\\"0\\\",\\\"client_server\\\":\\\"client\\\",\\\"vlan_id\\\":null,\\\"vlan_pri\\\":null,\\\"vlan_ip\\\":null,\\\"vlan_netmask\\\":null,\\\"vlan_gateway\\\":null,\\\"ipsec_static_type\\\":\\\"1\\\",\\\"ipsec_static_count\\\":\\\"1\\\",\\\"ipsec_static_local_gw\\\":null,\\\"ipsec_static_local_gw_netmask\\\":null,\\\"ipsec_static_local_gw_step\\\":\\\"1\\\",\\\"ipsec_static_remote_gw\\\":null,\\\"ipsec_static_remote_gw_netmask\\\":null,\\\"ipsec_static_remote_gw_step\\\":\\\"1\\\",\\\"ipsec_static_sip_start\\\":null,\\\"ipsec_static_sip_end\\\":null,\\\"ipsec_static_sip_netmask\\\":null,\\\"ipsec_static_sip_step\\\":null,\\\"ipsec_static_dip_start\\\":null,\\\"ipsec_static_dip_end\\\":null,\\\"ipsec_static_dip_netmask\\\":null,\\\"ipsec_static_dip_step\\\":null,\\\"ipsec_static_in_esp_spi\\\":null,\\\"ipsec_static_in_esp_iv\\\":null,\\\"ipsec_static_in_esp_seq_hop_num\\\":\\\"1\\\",\\\"ipsec_static_in_esp_seq_repeat_cnt\\\":\\\"1\\\",\\\"ipsec_static_in_esp_seq_start\\\":\\\"1\\\",\\\"ipsec_static_in_enc_algo\\\":\\\"AES128_CBC\\\",\\\"ipsec_static_in_enc_str\\\":null,\\\"ipsec_static_in_auth_algo\\\":\\\"HMAC_SHA1_96\\\",\\\"ipsec_static_in_auth_str\\\":null,\\\"ipsec_static_in_next_header\\\":null,\\\"ipsec_static_in_padding_str\\\":null,\\\"ipsec_static_out_esp_spi\\\":null,\\\"ipsec_static_out_esp_iv\\\":null,\\\"ipsec_static_out_esp_seq_hop_num\\\":\\\"1\\\",\\\"ipsec_static_out_esp_seq_repeat_cnt\\\":\\\"1\\\",\\\"ipsec_static_out_esp_seq_start\\\":\\\"1\\\",\\\"ipsec_static_out_enc_algo\\\":\\\"AES128_CBC\\\",\\\"ipsec_static_out_enc_str\\\":null,\\\"ipsec_static_out_auth_algo\\\":\\\"HMAC_SHA1_96\\\",\\\"ipsec_static_out_auth_str\\\":null,\\\"ipsec_static_out_next_header\\\":null,\\\"ipsec_static_out_padding_str\\\":null,\\\"ipsec_static_client_config_file\\\":null,\\\"ipsec_static_calculate_delay_type\\\":\\\"0\\\",\\\"ipsec_static_calculate_delay_en_port\\\":\\\"port0\\\",\\\"ipsec_static_calculate_delay_en_key_pos\\\":null,\\\"ipsec_static_calculate_delay_en_pci\\\":\\\"0000:04:00.0\\\",\\\"ipsec_static_calculate_delay_de_port\\\":\\\"port1\\\",\\\"ipsec_static_calculate_delay_de_key_pos\\\":null,\\\"ipsec_static_calculate_delay_de_pci\\\":\\\"0000:0b:00.0\\\",\\\"gw_ver\\\":\\\"ipv4\\\",\\\"ike_ver\\\":\\\"ikev2\\\",\\\"kmp_dh_group\\\":\\\"modp1024\\\",\\\"kmp_hash_alg\\\":\\\"hmac_md5\\\",\\\"kmp_enc_alg\\\":\\\"3des_cbc\\\",\\\"sm4_type\\\":null,\\\"kmp_auth_method\\\":\\\"psk\\\",\\\"kmp_auth_rsa_padding\\\":\\\"pkcs1\\\",\\\"isakmp_id_type\\\":\\\"fqdn\\\",\\\"srv_isakmp_id_type\\\":\\\"fqdn\\\",\\\"kmp_prf_alg\\\":\\\"hmac_sha1\\\",\\\"tunnel\\\":\\\"1\\\",\\\"ipsec_flow_start_interval\\\":\\\"0\\\",\\\"ipsec_dpd_interval\\\":\\\"0\\\",\\\"ipsec_nonce_size\\\":\\\"32\\\",\\\"ipsec_frag_size\\\":\\\"0\\\",\\\"send_timeout\\\":\\\"5\\\",\\\"max_retransmit\\\":\\\"5\\\",\\\"kmp_sa_nego_time_limit\\\":\\\"60\\\",\\\"ike_lifetime\\\":\\\"28800\\\",\\\"default_sport\\\":\\\"1025\\\",\\\"ipsec_transform\\\":\\\"esp\\\",\\\"esp_auth_alg\\\":\\\"hmac_sha1\\\",\\\"esp_enc_alg\\\":\\\"3des_cbc\\\",\\\"anti_replay_window\\\":\\\"0\\\",\\\"ah_auth_alg\\\":\\\"hmac_sha1\\\",\\\"sald_lifetime\\\":\\\"28800\\\",\\\"nat_keepalive_interval\\\":\\\"300\\\",\\\"nat_source_port\\\":\\\"4500\\\",\\\"nat_dest_port\\\":\\\"4500\\\",\\\"nat_orig_dest_port\\\":\\\"500\\\",\\\"branch_access_number\\\":\\\"1\\\",\\\"ike_taskgroup_interval\\\":\\\"1\\\",\\\"ipsec_modify_ftp_ip\\\":null,\\\"ipsec_modify_ftp_user\\\":null,\\\"ipsec_modify_ftp_password\\\":null,\\\"ipsec_modify_ftp_path\\\":null,\\\"traffic_select_type\\\":\\\"1\\\",\\\"resp_sip\\\":[null],\\\"resp_netmask\\\":[\\\"24\\\"],\\\"initiator_sip\\\":[null],\\\"initiator_netmask\\\":[\\\"24\\\"],\\\"traffic_select_file\\\":null,\\\"request_ip_enable\\\":\\\"1\\\",\\\"request_internal_addr\\\":\\\"1\\\",\\\"local_cert\\\":null,\\\"local_private\\\":null,\\\"local_enc_cert\\\":null,\\\"local_enc_private\\\":null,\\\"dest_cert\\\":null,\\\"dest_private\\\":null,\\\"dest_enc_cert\\\":null,\\\"dest_enc_private\\\":null,\\\"local_ca_cert\\\":null,\\\"dest_ca_cert\\\":null,\\\"xauth_username\\\":null,\\\"xauth_password\\\":null,\\\"eap_method_type\\\":\\\"eap_md5\\\",\\\"eap_identity_type\\\":\\\"fqdn\\\",\\\"eap_identity\\\":null,\\\"eap_password\\\":null,\\\"eap_vendor\\\":\\\"0\\\",\\\"eap_dest_cert\\\":null,\\\"eap_dest_private\\\":null,\\\"eap_local_ca_cert\\\":null,\\\"eap_dest_ca_cert\\\":null,\\\"tunnel_vlan_id\\\":null,\\\"tunnel_vlan_pri\\\":null,\\\"srv6_qinq_outer_vlan_id\\\":null,\\\"srv6_qinq_outer_vlan_pri\\\":null,\\\"srv6_qinq_inner_vlan_id\\\":null,\\\"srv6_qinq_inner_vlan_pri\\\":null,\\\"vxlan_vni\\\":null,\\\"vxlan_local_ip\\\":null,\\\"vxlan_remote_ip\\\":null,\\\"vxlan_local_port\\\":null,\\\"vxlan_remote_port\\\":null,\\\"vxlan_smac\\\":null,\\\"vxlan_dmac\\\":null,\\\"vxlan_qinq_outer_vlan_id\\\":null,\\\"vxlan_qinq_outer_vlan_pri\\\":null,\\\"vxlan_qinq_inner_vlan_id\\\":null,\\\"vxlan_qinq_inner_vlan_pri\\\":null,\\\"gre_ip\\\":null,\\\"gre_netmask\\\":null,\\\"gre_local_ip\\\":null,\\\"gre_src_ip\\\":null,\\\"gre_keyword_verify\\\":null,\\\"gre_mtu\\\":null,\\\"gre_keepalive_cycle\\\":null,\\\"gre_keepalive_num\\\":null,\\\"udproute_local_ip\\\":null,\\\"udproute_remote_ip\\\":null,\\\"udproute_local_port\\\":null,\\\"udproute_remote_port\\\":null,\\\"dns_type\\\":\\\"1\\\",\\\"dns_host_file\\\":null,\\\"dns_server_ip\\\":null,\\\"dns_standby_server_ip\\\":null,\\\"ipv4_tos_type\\\":\\\"0\\\",\\\"ipv4_tos\\\":\\\"0\\\",\\\"ipv4_tos_interval\\\":null,\\\"ipv4_tos2\\\":\\\"0\\\",\\\"ipv4_tos_time\\\":null,\\\"ipv4_tos2_time\\\":null,\\\"mac_config_enable\\\":\\\"0\\\",\\\"mac_config_prefix\\\":null,\\\"peer_mac_config_prefix\\\":null,\\\"enabled_vlan_ip\\\":\\\"0\\\",\\\"ipsec_static\\\":\\\"0\\\",\\\"ipsec_static_local_gw_hop\\\":\\\"0\\\",\\\"ipsec_static_remote_gw_hop\\\":\\\"0\\\",\\\"ipsec_static_sip_hop\\\":\\\"0\\\",\\\"ipsec_static_dip_hop\\\":\\\"0\\\",\\\"ipsec_static_in_esp_spi_random\\\":\\\"0\\\",\\\"ipsec_static_in_esp_iv_random\\\":\\\"0\\\",\\\"ipsec_static_in_enc_str_random\\\":\\\"0\\\",\\\"ipsec_static_in_auth_str_random\\\":\\\"0\\\",\\\"ipsec_static_in_padding_str_random\\\":\\\"0\\\",\\\"ipsec_static_out_esp_spi_random\\\":\\\"0\\\",\\\"ipsec_static_out_esp_iv_random\\\":\\\"0\\\",\\\"ipsec_static_out_enc_str_random\\\":\\\"0\\\",\\\"ipsec_static_out_auth_str_random\\\":\\\"0\\\",\\\"ipsec_static_out_padding_str_random\\\":\\\"0\\\",\\\"ipsec_static_calculate_delay_enable\\\":\\\"0\\\",\\\"remote_access\\\":\\\"0\\\",\\\"ipsec_verify_id\\\":\\\"0\\\",\\\"ipsec_frag_enabled\\\":\\\"0\\\",\\\"ext_sequence\\\":\\\"0\\\",\\\"pfs_dh_group\\\":\\\"0\\\",\\\"nat_traversal\\\":\\\"0\\\",\\\"branch_access\\\":\\\"0\\\",\\\"branch_access_remote_gw_jump\\\":\\\"0\\\",\\\"branch_access_src_jump\\\":\\\"0\\\",\\\"branch_access_dest_jump\\\":\\\"0\\\",\\\"ipsec_modify_enabled\\\":\\\"0\\\",\\\"ipsec_modify_python_log_enable\\\":\\\"0\\\",\\\"ipsec_modify_async_enable\\\":\\\"0\\\",\\\"ipsec_modify_recaculate_length\\\":\\\"0\\\",\\\"ipsec_modify_padding_enable\\\":\\\"0\\\",\\\"ipsec_modify_spi\\\":\\\"0\\\",\\\"enabled_tunnel_vlan\\\":\\\"0\\\",\\\"tunnel_srv6_enable\\\":\\\"0\\\",\\\"srv6_qinq_vlan_enable\\\":\\\"0\\\",\\\"vxlan_enable\\\":\\\"0\\\",\\\"vxlan_frag_enable\\\":\\\"0\\\",\\\"vxlan_qinq_vlan_enable\\\":\\\"0\\\",\\\"enabled_gre_vpn\\\":\\\"0\\\",\\\"gre_tunnel_verify\\\":\\\"0\\\",\\\"enabled_gre_keepalive\\\":\\\"0\\\",\\\"enabled_udproute\\\":\\\"0\\\",\\\"pppoe_session\\\":\\\"0\\\",\\\"eth_mpls_srv\\\":\\\"0\\\",\\\"srv_isakmp_id\\\":\\\"ISAKMPID\\\"}}\",\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/229/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/229/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/228",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/228/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/228/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/228/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/228",
    "id": 2566949409,
    "node_id": "I_kwDOKY_97s6ZAIoh",
    "number": 228,
    "title": "[BUG: pip install mistral_inference: ModuleNotFoundError: No module named 'torch'",
    "user": {
      "login": "chrisstankevitz",
      "id": 3683521,
      "node_id": "MDQ6VXNlcjM2ODM1MjE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/3683521?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/chrisstankevitz",
      "html_url": "https://github.com/chrisstankevitz",
      "followers_url": "https://api.github.com/users/chrisstankevitz/followers",
      "following_url": "https://api.github.com/users/chrisstankevitz/following{/other_user}",
      "gists_url": "https://api.github.com/users/chrisstankevitz/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/chrisstankevitz/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/chrisstankevitz/subscriptions",
      "organizations_url": "https://api.github.com/users/chrisstankevitz/orgs",
      "repos_url": "https://api.github.com/users/chrisstankevitz/repos",
      "events_url": "https://api.github.com/users/chrisstankevitz/events{/privacy}",
      "received_events_url": "https://api.github.com/users/chrisstankevitz/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2024-10-04T17:53:18Z",
    "updated_at": "2024-10-18T19:14:49Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\r\n\r\n```shell\r\n(mistral) C:\\Work\\2024-10-04_mistral>python -VV\r\nPython 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]\r\n```\r\n\r\n\r\n### Pip Freeze\r\n\r\n```shell\r\n(mistral) C:\\Work\\2024-10-04_mistral>pip freeze\r\n\r\n```\r\n\r\n\r\n### Reproduction Steps\r\n\r\n1. Buy a new computer\r\n2. Install Windows 10 22H2\r\n3. Install `python-3.12.6-amd64.exe` (select option to add python to path)\r\n4. Run these commands:\r\n   1. `python -m venv mistral`\r\n   1. `mistral\\Scripts\\activate.bat`\r\n   1. `pip install --upgrade pip`\r\n   2. `pip install mistral_inference`\r\n\r\n### Expected Behavior\r\n\r\npython package \"mistral_inference\" should be installed.\r\n\r\n### Additional Context\r\n\r\nThis fails during installation of xformers with \"no module named 'torch'\".\r\n\r\n```\r\nC:\\Work\\2024-10-04_mistral>python -m venv mistral\r\n\r\nC:\\Work\\2024-10-04_mistral>mistral\\Scripts\\activate.bat\r\n\r\n(mistral) C:\\Work\\2024-10-04_mistral>pip install --upgrade pip\r\nRequirement already satisfied: pip in c:\\work\\2024-10-04_mistral\\mistral\\lib\\site-packages (24.2)\r\n\r\n(mistral) C:\\Work\\2024-10-04_mistral>pip install mistral_inference\r\nCollecting mistral_inference\r\n  Using cached mistral_inference-1.4.0-py3-none-any.whl.metadata (14 kB)\r\nCollecting fire>=0.6.0 (from mistral_inference)\r\n  Using cached fire-0.7.0.tar.gz (87 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting mistral_common>=1.4.0 (from mistral_inference)\r\n  Using cached mistral_common-1.4.4-py3-none-any.whl.metadata (4.6 kB)\r\nCollecting pillow>=10.3.0 (from mistral_inference)\r\n  Using cached pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\r\nCollecting safetensors>=0.4.0 (from mistral_inference)\r\n  Using cached safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\r\nCollecting simple-parsing>=0.1.5 (from mistral_inference)\r\n  Using cached simple_parsing-0.1.6-py3-none-any.whl.metadata (7.3 kB)\r\nCollecting xformers>=0.0.24 (from mistral_inference)\r\n  Using cached xformers-0.0.28.post1.tar.gz (7.8 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  \u00d7 Getting requirements to build wheel did not run successfully.\r\n  \u2502 exit code: 1\r\n  \u2570\u2500> [20 lines of output]\r\n      Traceback (most recent call last):\r\n        File \"C:\\Work\\2024-10-04_mistral\\mistral\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\r\n          main()\r\n        File \"C:\\Work\\2024-10-04_mistral\\mistral\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\r\n          json_out['return_val'] = hook(**hook_input['kwargs'])\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Work\\2024-10-04_mistral\\mistral\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\r\n          return hook(config_settings)\r\n                 ^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\cstankevitz\\AppData\\Local\\Temp\\pip-build-env-fwupzqhw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 332, in get_requires_for_build_wheel\r\n          return self._get_build_requires(config_settings, requirements=[])\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\cstankevitz\\AppData\\Local\\Temp\\pip-build-env-fwupzqhw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 302, in _get_build_requires\r\n          self.run_setup()\r\n        File \"C:\\Users\\cstankevitz\\AppData\\Local\\Temp\\pip-build-env-fwupzqhw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 503, in run_setup\r\n          super().run_setup(setup_script=setup_script)\r\n        File \"C:\\Users\\cstankevitz\\AppData\\Local\\Temp\\pip-build-env-fwupzqhw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 318, in run_setup\r\n          exec(code, locals())\r\n        File \"<string>\", line 24, in <module>\r\n      ModuleNotFoundError: No module named 'torch'\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n\u00d7 Getting requirements to build wheel did not run successfully.\r\n\u2502 exit code: 1\r\n\u2570\u2500> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n\r\n(mistral) C:\\Work\\2024-10-04_mistral>\r\n```\r\n\r\n### Suggested Solutions\r\n\r\nPerhaps mistral_inference should require torch?  Or perhaps xformers should require torch?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/228/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/228/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/227",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/227/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/227/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/227/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/227",
    "id": 2552526680,
    "node_id": "I_kwDOKY_97s6YJHdY",
    "number": 227,
    "title": "Pixtral-12B tokenizer error - special_token_policy=IGNORE does not ignore special tokens in decoding",
    "user": {
      "login": "OmriKaduri",
      "id": 7421460,
      "node_id": "MDQ6VXNlcjc0MjE0NjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7421460?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/OmriKaduri",
      "html_url": "https://github.com/OmriKaduri",
      "followers_url": "https://api.github.com/users/OmriKaduri/followers",
      "following_url": "https://api.github.com/users/OmriKaduri/following{/other_user}",
      "gists_url": "https://api.github.com/users/OmriKaduri/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/OmriKaduri/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/OmriKaduri/subscriptions",
      "organizations_url": "https://api.github.com/users/OmriKaduri/orgs",
      "repos_url": "https://api.github.com/users/OmriKaduri/repos",
      "events_url": "https://api.github.com/users/OmriKaduri/events{/privacy}",
      "received_events_url": "https://api.github.com/users/OmriKaduri/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-09-27T10:02:28Z",
    "updated_at": "2024-09-27T10:02:28Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nDecoding `tokens` that contain special tokens ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) is not allowed. \r\nEither make sure `tokens` do not include any special tokens or, if you want to decode `tokens` that includes special tokens, change the tokenizer's special token policy to IGNORE or KEEP:\n```\n\n\n### Pip Freeze\n\n```shell\nmistral_common==1.4.2\r\nmistral_inference==1.4.0\n```\n\n\n### Reproduction Steps\n\ntokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tekken.json\")\r\ntokenizer.special_token_policy = SpecialTokenPolicy.IGNORE\r\n\r\nresult = tokenizer.decode(tokens)\r\n\r\nWhen tokens are special tokens (Like 0), the bug will occur\r\n\n\n### Expected Behavior\n\nIgnore the special tokens\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/227/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/227/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/226",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/226/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/226/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/226/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/226",
    "id": 2552191142,
    "node_id": "PR_kwDOKY_97s584eEx",
    "number": 226,
    "title": "Update transformer.py",
    "user": {
      "login": "siwer",
      "id": 9460782,
      "node_id": "MDQ6VXNlcjk0NjA3ODI=",
      "avatar_url": "https://avatars.githubusercontent.com/u/9460782?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/siwer",
      "html_url": "https://github.com/siwer",
      "followers_url": "https://api.github.com/users/siwer/followers",
      "following_url": "https://api.github.com/users/siwer/following{/other_user}",
      "gists_url": "https://api.github.com/users/siwer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/siwer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/siwer/subscriptions",
      "organizations_url": "https://api.github.com/users/siwer/orgs",
      "repos_url": "https://api.github.com/users/siwer/repos",
      "events_url": "https://api.github.com/users/siwer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/siwer/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-09-27T07:15:59Z",
    "updated_at": "2024-09-27T07:15:59Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/226",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/226",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/226.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/226.patch",
      "merged_at": null
    },
    "body": "Proposed fix for issue #225",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/226/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/226/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/225",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/225/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/225/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/225/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/225",
    "id": 2550052754,
    "node_id": "I_kwDOKY_97s6X_reS",
    "number": 225,
    "title": "[BUG: RuntimeError: Boolean value of Tensor with more than one value is ambiguous]",
    "user": {
      "login": "siwer",
      "id": 9460782,
      "node_id": "MDQ6VXNlcjk0NjA3ODI=",
      "avatar_url": "https://avatars.githubusercontent.com/u/9460782?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/siwer",
      "html_url": "https://github.com/siwer",
      "followers_url": "https://api.github.com/users/siwer/followers",
      "following_url": "https://api.github.com/users/siwer/following{/other_user}",
      "gists_url": "https://api.github.com/users/siwer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/siwer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/siwer/subscriptions",
      "organizations_url": "https://api.github.com/users/siwer/orgs",
      "repos_url": "https://api.github.com/users/siwer/repos",
      "events_url": "https://api.github.com/users/siwer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/siwer/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-09-26T09:33:53Z",
    "updated_at": "2024-09-26T14:02:56Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\r\n\r\n```shell\r\nFile \"/opt/anaconda/envs/transformers/lib/python3.11/site-packages/mistral_inference/transformer.py\", line 162, in forward_partial\r\n    if self.vision_encoder is not None and images:\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nRuntimeError: Boolean value of Tensor with more than one value is ambiguous\r\n```\r\n\r\n\r\n### Pip Freeze\r\n\r\n```shell\r\naiohappyeyeballs @ file:///croot/aiohappyeyeballs_1725434011349/work\r\naiohttp @ file:///croot/aiohttp_1725527756643/work\r\naiosignal @ file:///tmp/build/80754af9/aiosignal_1637843061372/work\r\nannotated-types==0.7.0\r\nattrs @ file:///croot/attrs_1695717823297/work\r\nBottleneck @ file:///croot/bottleneck_1707864210935/work\r\nBrotli @ file:///work/ci_py311/brotli-split_1676830125088/work\r\ncertifi @ file:///croot/certifi_1725551672989/work/certifi\r\ncffi @ file:///croot/cffi_1700254295673/work\r\ncharset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work\r\ncryptography @ file:///croot/cryptography_1702070282333/work\r\ndatasets @ file:///croot/datasets_1716911606380/work\r\ndill @ file:///croot/dill_1715094664823/work\r\ndocstring_parser==0.16\r\nfilelock @ file:///croot/filelock_1700591183607/work\r\nfire==0.6.0\r\nfrozenlist @ file:///croot/frozenlist_1698702560391/work\r\nfsspec @ file:///croot/fsspec_1714461537038/work\r\ngmpy2 @ file:///work/ci_py311/gmpy2_1676839849213/work\r\nhuggingface_hub @ file:///croot/huggingface_hub_1724853938404/work\r\nidna @ file:///work/ci_py311/idna_1676822698822/work\r\nJinja2 @ file:///work/ci_py311/jinja2_1676823587943/work\r\njsonschema==4.23.0\r\njsonschema-specifications==2023.12.1\r\nMarkupSafe @ file:///croot/markupsafe_1704205993651/work\r\nmistral_common==1.4.3\r\nmistral_inference==1.4.0\r\nmkl-fft @ file:///croot/mkl_fft_1695058164594/work\r\nmkl-random @ file:///croot/mkl_random_1695059800811/work\r\nmkl-service==2.4.0\r\nmpmath @ file:///croot/mpmath_1690848262763/work\r\nmultidict @ file:///croot/multidict_1701096859099/work\r\nmultiprocess @ file:///croot/multiprocess_1692294385131/work\r\nnetworkx @ file:///croot/networkx_1690561992265/work\r\nnumexpr @ file:///croot/numexpr_1696515281613/work\r\nnumpy @ file:///croot/numpy_and_numpy_base_1704311704800/work/dist/numpy-1.26.3-cp311-cp311-linux_x86_64.whl#sha256=10a078151ecec16bafb535f7487635217625fa06536dec8509e514648c78d626\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==9.1.0.70\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-nccl-cu12==2.20.5\r\nnvidia-nvjitlink-cu12==12.6.68\r\nnvidia-nvtx-cu12==12.1.105\r\nopencv-python-headless==4.10.0.84\r\npackaging @ file:///croot/packaging_1720101850331/work\r\npandas @ file:///croot/pandas_1718308974269/work/dist/pandas-2.2.2-cp311-cp311-linux_x86_64.whl#sha256=3c7ce50f9f519c785bd4cdb28a0ca71f85a541f3d27b25aa9da770f953e7f2e9\r\npillow==10.4.0\r\npyarrow @ file:///croot/pyarrow_1721664224170/work/python\r\npycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\r\npydantic==2.9.2\r\npydantic_core==2.23.4\r\npyOpenSSL @ file:///croot/pyopenssl_1690223430423/work\r\nPySocks @ file:///work/ci_py311/pysocks_1676822712504/work\r\npython-dateutil @ file:///croot/python-dateutil_1716495738603/work\r\npytz @ file:///croot/pytz_1713974312559/work\r\nPyYAML @ file:///croot/pyyaml_1698096049011/work\r\nreferencing==0.35.1\r\nregex @ file:///croot/regex_1723064389032/work\r\nrequests @ file:///croot/requests_1690400202158/work\r\nrpds-py==0.20.0\r\nsafetensors @ file:///croot/safetensors_1724853960118/work\r\nsentencepiece==0.2.0\r\nsimple-parsing==0.1.6\r\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\r\nsympy @ file:///croot/sympy_1701397643339/work\r\ntermcolor==2.4.0\r\ntiktoken==0.7.0\r\ntokenizers @ file:///croot/tokenizers_1721139552427/work\r\ntorch==2.4.1\r\ntorchaudio==2.1.2\r\ntorchvision==0.16.2\r\ntqdm @ file:///croot/tqdm_1724853939799/work\r\ntransformers @ file:///home/conda/feedstock_root/build_artifacts/transformers_1724403320167/work\r\ntriton==3.0.0\r\ntyping_extensions @ file:///croot/typing_extensions_1715268824938/work\r\ntzdata @ file:///croot/python-tzdata_1690578112552/work\r\nurllib3 @ file:///croot/urllib3_1698257533958/work\r\nxformers==0.0.28.post1\r\nxxhash @ file:///work/ci_py311/python-xxhash_1676842384694/work\r\nyarl @ file:///croot/yarl_1725976495189/work\r\n```\r\n\r\n\r\n### Reproduction Steps\r\n\r\nRunning forward_partial() with Pixtral led to the above mentioned issue. See the code below for my script\r\n```\r\nimport torch\r\nfrom pathlib import Path\r\nfrom mistral_inference.transformer import Transformer\r\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\r\nfrom mistral_common.protocol.instruct.messages import UserMessage, TextChunk, ImageURLChunk\r\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\r\n\r\nmistral_models_path = Path.home().joinpath('mistral_models', 'Pixtral')\r\ntokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tekken.json\")\r\nmodel = Transformer.from_folder(mistral_models_path,device=\"cuda:0\")\r\n\r\n# Run the model \r\nurl = \"https://huggingface.co/datasets/patrickvonplaten/random_img/resolve/main/yosemite.png\"\r\nprompt = \"Describe the image.\"\r\n\r\ncompletion_request = ChatCompletionRequest(messages=[UserMessage(content=[ImageURLChunk(image_url=url), TextChunk(text=prompt)])])\r\n\r\nencoded = tokenizer.encode_chat_completion(completion_request)\r\n\r\nimages = encoded.images\r\ntokens = encoded.tokens\r\n\r\ntokens = torch.tensor(tokens).to(model.device)\r\nimages = torch.cuda.BFloat16Tensor(images).to(model.device)\r\n\r\nwith torch.no_grad():\r\n    res = model.forward_partial(input_ids=tokens,seqlens=[len(tokens)],images=images)\r\n```\r\n\r\n### Expected Behavior\r\n\r\nExpected model.forward_partial() to output the vector representations of the input tokens\r\n\r\n### Additional Context\r\n\r\n_No response_\r\n\r\n### Suggested Solutions\r\n\r\nChange line 162 in mistral-inference/blob/main/src/mistral_inference/transformer.py\r\n\r\ncurrent:\r\n`if self.vision_encoder is not None and images:`\r\n\r\nproposed solution:\r\n`if self.vision_encoder is not None and images is not None:`\r\n\r\nThis led to the code to functioning properly",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/225/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/225/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/224",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/224/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/224/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/224/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/224",
    "id": 2546236141,
    "node_id": "I_kwDOKY_97s6XxHrt",
    "number": 224,
    "title": "[BUG: Cannot build on Mac M1 Silicion",
    "user": {
      "login": "timspannzilliz",
      "id": 171198611,
      "node_id": "U_kgDOCjRIkw",
      "avatar_url": "https://avatars.githubusercontent.com/u/171198611?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timspannzilliz",
      "html_url": "https://github.com/timspannzilliz",
      "followers_url": "https://api.github.com/users/timspannzilliz/followers",
      "following_url": "https://api.github.com/users/timspannzilliz/following{/other_user}",
      "gists_url": "https://api.github.com/users/timspannzilliz/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timspannzilliz/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timspannzilliz/subscriptions",
      "organizations_url": "https://api.github.com/users/timspannzilliz/orgs",
      "repos_url": "https://api.github.com/users/timspannzilliz/repos",
      "events_url": "https://api.github.com/users/timspannzilliz/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timspannzilliz/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-09-24T19:41:04Z",
    "updated_at": "2025-01-08T05:52:03Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nNote: This error originates from the build backend, and is likely not a problem with poetry but with xformers (0.0.26.post1) not supporting PEP 517 builds. You can verify this by running 'pip wheel --no-cache-dir --use-pep517 \"xformers (==0.0.26.post1)\"'.\n```\n\n\n### Pip Freeze\n\n```shell\n(milvusvenv) (base) timothyspann@tspannmac mistral-inference % pip freeze\r\nabsl-py==2.1.0\r\naccelerate==0.33.0\r\naiofiles==24.1.0\r\naiohappyeyeballs==2.4.0\r\naiohttp==3.10.5\r\naiolimiter==1.1.0\r\naiosignal==1.3.1\r\nairllm==2.9\r\nalembic==1.13.2\r\naltair==5.4.1\r\nannotated-types==0.6.0\r\nanthropic==0.28.1\r\nantlr4-python3-runtime==4.9.3\r\nanyio==4.4.0\r\nappdirs==1.4.4\r\nappnope==0.1.4\r\nargcomplete==3.5.0\r\nargon2-cffi==23.1.0\r\nargon2-cffi-bindings==21.2.0\r\narrow==1.3.0\r\narxiv==2.1.3\r\nasgiref==3.8.1\r\nassemblyai==0.26.0\r\nastra-assistants==2.1.0.18\r\nastrapy==1.4.1\r\nasttokens==2.4.1\r\nasync-lru==2.0.4\r\nasyncer==0.0.5\r\nattrs==24.2.0\r\naudioread==3.0.1\r\nAuthlib==1.3.2\r\nazure-core==1.30.1\r\nazure-storage-blob==12.20.0\r\nBabel==2.15.0\r\nbackoff==2.2.1\r\nbce-python-sdk==0.9.21\r\nbcrypt==4.0.1\r\nbeautifulsoup4==4.12.3\r\nbidict==0.23.1\r\nbitsandbytes==0.42.0\r\nblack==21.4b2\r\nbleach==6.1.0\r\nblinker==1.8.2\r\nblis==0.7.11\r\nbokeh==3.4.3\r\nboto3==1.34.162\r\nbotocore==1.34.162\r\nbreadability==0.1.20\r\nBrotli==1.1.0\r\nbs4==0.0.2\r\nbuild==1.2.1\r\ncachetools==5.5.0\r\ncassandra-driver==3.29.1\r\ncassio==0.1.8\r\ncatalogue==2.0.10\r\ncattrs==24.1.0\r\ncertifi==2024.8.30\r\ncffi==1.16.0\r\nchameleon @ git+https://github.com/facebookresearch/chameleon.git@dbbe47fdbc7a3cc4982ae931fea75e227262e70a\r\nchardet==5.2.0\r\ncharset-normalizer==3.3.2\r\nchroma-hnswlib==0.7.3\r\nchromadb==0.4.24\r\nchunkit==0.2.8\r\nclevercsv==0.8.2\r\nclick==8.1.7\r\nclip @ git+https://github.com/openai/CLIP.git@a1d071733d7111c9c014f024669f959182114e33\r\ncloudpathlib==0.18.1\r\ncloudpickle==3.0.0\r\ncohere==5.9.0\r\ncolorama==0.4.6\r\ncolorcet==3.1.0\r\ncoloredlogs==15.0.1\r\ncolorlog==6.8.2\r\ncomm==0.2.2\r\ncomposio_core==0.5.13\r\ncomposio_langchain==0.5.13\r\nconfection==0.1.5\r\ncontourpy==1.2.1\r\ncoolname==2.2.0\r\ncrewai==0.36.1\r\ncrewai-tools==0.4.26\r\ncryptography==42.0.7\r\ncycler==0.12.1\r\ncymem==2.0.8\r\ndacite==1.7.0\r\ndataclasses-json==0.6.5\r\ndatacommons-pandas==0.0.3\r\ndatasets==3.0.0\r\ndebugpy==1.8.1\r\ndecorator==5.1.1\r\ndeepdiff==7.0.1\r\ndefusedxml==0.7.1\r\nDeprecated==1.2.14\r\ndeprecation==2.1.0\r\ndetectron2 @ git+https://github.com/facebookresearch/detectron2.git@82a57ce0b70057685962b352535147d9a8118578\r\ndill==0.3.8\r\ndirtyjson==1.0.8\r\ndiscord.py==2.4.0\r\ndiskcache==5.6.3\r\ndistro==1.9.0\r\ndnspython==2.6.1\r\ndocker==7.1.0\r\ndocopt==0.6.2\r\ndocstring_parser==0.16\r\ndocx2txt==0.8\r\ndspy-ai==2.4.14\r\nduckdb==1.0.0\r\ne2b==0.17.2a52\r\ne2b-code-interpreter==0.0.10\r\neasyocr==1.7.1\r\necdsa==0.19.0\r\neinops==0.8.0\r\nelastic-transport==8.15.0\r\nelasticsearch==8.15.0\r\nemail_validator==2.2.0\r\nembedchain==0.1.121\r\nemoji==2.12.1\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\r\nencodec==0.1.1\r\nenvirons==9.5.0\r\net-xmlfile==1.1.0\r\nexecuting==2.0.1\r\nfaiss-cpu==1.8.0.post1\r\nfake-useragent==1.5.1\r\nFaker==28.4.1\r\nfastapi==0.111.0\r\nfastapi-cli==0.0.4\r\nfastavro==1.9.5\r\nfastjsonschema==2.19.1\r\nfeedparser==6.0.11\r\nfiftyone==0.24.1\r\nfiftyone-brain==0.16.1\r\nfiftyone-desktop==0.34.1\r\nfiftyone_db==1.1.5\r\nfilelock==3.16.0\r\nfiletype==1.2.0\r\nfirecrawl-py==0.0.16\r\n-e git+https://github.com/FlagOpen/FlagEmbedding.git@399d12f3e238f7d5c82c86939691f195041e0159#egg=FlagEmbedding\r\nFLAML==2.2.0\r\nFlask==3.0.3\r\nFlask-SocketIO==5.3.6\r\nflatbuffers==24.3.25\r\nfonttools==4.51.0\r\nfqdn==1.5.1\r\nfrozendict==2.4.4\r\nfrozenlist==1.4.1\r\nfsspec==2024.6.1\r\nftfy==6.2.3\r\nfuncy==2.0\r\nfuture==1.0.0\r\nfvcore==0.1.5.post20221221\r\ngeomet==0.2.1.post1\r\ngitdb==4.0.11\r\nGitPython==3.1.43\r\nglob2==0.7\r\ngoogle-ai-generativelanguage==0.6.6\r\ngoogle-api-core==2.19.2\r\ngoogle-api-python-client==2.143.0\r\ngoogle-auth==2.34.0\r\ngoogle-auth-httplib2==0.2.0\r\ngoogle-auth-oauthlib==1.2.1\r\ngoogle-cloud-aiplatform==1.64.0\r\ngoogle-cloud-bigquery==3.25.0\r\ngoogle-cloud-core==2.4.1\r\ngoogle-cloud-resource-manager==1.12.5\r\ngoogle-cloud-storage==2.18.2\r\ngoogle-crc32c==1.6.0\r\ngoogle-generativeai==0.7.2\r\ngoogle-resumable-media==2.7.2\r\ngoogle_search_results==2.4.2\r\ngoogleapis-common-protos==1.65.0\r\ngotrue==2.8.0\r\ngptcache==0.1.44\r\ngql==3.5.0\r\ngrandalf==0.8\r\ngraphql-core==3.2.3\r\ngreenlet==3.0.3\r\ngroq==0.11.0\r\ngrpc-google-iam-v1==0.13.1\r\ngrpcio==1.63.0\r\ngrpcio-health-checking==1.62.3\r\ngrpcio-status==1.62.3\r\ngrpcio-tools==1.62.3\r\ngtfs-realtime-bindings==1.0.0\r\ngunicorn==22.0.0\r\nh11==0.14.0\r\nh2==4.1.0\r\nhaystack-ai==2.5.0\r\nhaystack-experimental==0.1.1\r\nholoviews==1.19.1\r\nhpack==4.0.0\r\nhtml2text==2024.2.26\r\nhtml5lib==1.1\r\nhttpcore==1.0.5\r\nhttplib2==0.22.0\r\nhttptools==0.6.1\r\nhttpx==0.27.2\r\nhttpx-sse==0.4.0\r\nhuggingface-hub==0.24.7\r\nhumanfriendly==10.0\r\nhumanize==4.10.0\r\nhvplot==0.10.0\r\nhydra-core==1.3.2\r\nHypercorn==0.17.3\r\nhyperframe==6.0.1\r\nidna==3.8\r\nijson==3.3.0\r\nimageio==2.34.1\r\nimportlib_metadata==7.1.0\r\nimportlib_resources==6.4.4\r\ninflate64==1.0.0\r\ninflection==0.5.1\r\niniconfig==2.0.0\r\ninstructor==1.3.3\r\niopath==0.1.9\r\nipykernel==6.29.4\r\nipython==8.24.0\r\nipywidgets==8.1.3\r\nisodate==0.6.1\r\nisoduration==20.11.0\r\nitsdangerous==2.2.0\r\njaraco.context==6.0.1\r\njedi==0.19.1\r\nJinja2==3.1.4\r\njiter==0.4.2\r\njmespath==1.0.1\r\njoblib==1.4.2\r\njq==1.8.0\r\njson5==0.9.25\r\njson_repair==0.25.3\r\njsonlines==4.0.0\r\njsonpatch==1.33\r\njsonpath-python==1.0.6\r\njsonpointer==2.4\r\njsonref==1.1.0\r\njsonschema==4.22.0\r\njsonschema-specifications==2023.12.1\r\njupyter-events==0.10.0\r\njupyter-lsp==2.2.5\r\njupyter_client==8.6.1\r\njupyter_core==5.7.2\r\njupyter_server==2.14.0\r\njupyter_server_terminals==0.5.3\r\njupyterlab==4.1.8\r\njupyterlab_pygments==0.3.0\r\njupyterlab_server==2.27.1\r\njupyterlab_widgets==3.0.11\r\nkaleido==0.2.1\r\nkiwisolver==1.4.5\r\nkubernetes==30.1.0\r\nlancedb==0.5.7\r\nlangchain==0.2.15\r\nlangchain-anthropic==0.1.23\r\nlangchain-astradb==0.3.3\r\nlangchain-aws==0.1.17\r\nlangchain-chroma==0.1.3\r\nlangchain-cohere==0.1.9\r\nlangchain-community==0.2.15\r\nlangchain-core==0.2.37\r\nlangchain-experimental==0.0.61\r\nlangchain-google-calendar-tools==0.0.1\r\nlangchain-google-community==1.0.7\r\nlangchain-google-genai==1.0.8\r\nlangchain-google-vertexai==1.0.7\r\nlangchain-groq==0.1.6\r\nlangchain-huggingface==0.0.3\r\nlangchain-milvus==0.1.4\r\nlangchain-mistralai==0.1.10\r\nlangchain-mongodb==0.1.8\r\nlangchain-nvidia-ai-endpoints==0.1.6\r\nlangchain-openai==0.1.22\r\nlangchain-pinecone==0.1.2\r\nlangchain-text-splitters==0.2.2\r\nlangchainhub==0.1.21\r\nlangcodes==3.4.0\r\nlangdetect==1.0.9\r\nlangflow==1.0.17\r\nlangflow-base==0.0.95\r\nlangfuse==2.50.3\r\nlanggraph==0.2.15\r\nlanggraph-checkpoint==1.0.8\r\nlangserve==0.2.2\r\nlangsmith==0.1.99\r\nlanguage_data==1.2.0\r\nlangwatch==0.1.24\r\nlayoutparser==0.3.4\r\nlazy-imports==0.3.1\r\nlazy_loader==0.4\r\nlibrosa==0.10.2.post1\r\nlinkify-it-py==2.0.3\r\nlitellm==1.44.16\r\nllama-cloud==0.0.15\r\nllama-index==0.11.12\r\nllama-index-agent-openai==0.3.4\r\nllama-index-cli==0.3.1\r\nllama-index-core==0.11.12\r\nllama-index-embeddings-huggingface==0.3.1\r\nllama-index-embeddings-ollama==0.3.0\r\nllama-index-embeddings-openai==0.2.5\r\nllama-index-indices-managed-llama-cloud==0.3.0\r\nllama-index-legacy==0.9.48\r\nllama-index-llms-anthropic==0.3.0\r\nllama-index-llms-ollama==0.3.1\r\nllama-index-llms-openai==0.2.9\r\nllama-index-multi-modal-llms-openai==0.2.0\r\nllama-index-program-openai==0.2.0\r\nllama-index-question-gen-openai==0.2.0\r\nllama-index-readers-file==0.2.0\r\nllama-index-readers-llama-parse==0.3.0\r\nllama-index-readers-milvus==0.2.0\r\nllama-index-vector-stores-milvus==0.2.4\r\nllama-parse==0.5.6\r\nllamaindex-py-client==0.1.19\r\nllvmlite==0.43.0\r\nloguru==0.7.2\r\nlsprotocol==2023.0.1\r\nlxml==5.2.1\r\nmagicattr==0.1.6\r\nMako==1.3.5\r\nmarisa-trie==1.2.0\r\nMarkdown==3.7\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.5\r\nmarshmallow==3.22.0\r\nmatplotlib==3.8.4\r\nmatplotlib-inline==0.1.7\r\nmdit-plain==1.0.1\r\nmdit-py-plugins==0.4.1\r\nmdurl==0.1.2\r\nmem0ai==0.0.20\r\nmetal_sdk==2.5.1\r\nmetaphor-python==0.1.23\r\nmilvus-haystack==0.0.10\r\nmilvus-lite==2.4.10\r\nmilvus-model==0.2.3\r\nminijinja==2.0.1\r\nminio==7.2.8\r\nmistral_common==1.4.3\r\nmistune==3.0.2\r\nmmh3==4.1.0\r\nmongoengine==0.24.2\r\nmonotonic==1.6\r\nmore-itertools==10.3.0\r\nmotor==3.5.1\r\nmpmath==1.3.0\r\nmsgpack==1.0.8\r\nmultidict==6.1.0\r\nmultiprocess==0.70.16\r\nmultitasking==0.0.11\r\nmultivolumefile==0.2.3\r\nmurmurhash==1.0.10\r\nmutagen==1.47.0\r\nmypy-extensions==1.0.0\r\nnanoid==2.0.0\r\nnarwhals==1.5.5\r\nnbclient==0.10.0\r\nnbconvert==7.16.4\r\nnbformat==5.10.4\r\nnest-asyncio==1.6.0\r\nnetworkx==3.3\r\nninja==1.11.1.1\r\nnltk==3.9.1\r\nnodeenv==1.9.1\r\nnotebook_shim==0.2.4\r\nnumba==0.60.0\r\nnumexpr==2.10.1\r\nnumpy==1.26.4\r\noauthlib==3.2.2\r\nollama==0.3.1\r\nollama-haystack==0.0.7\r\nomegaconf==2.3.0\r\nonnxruntime==1.18.0\r\nopenai==1.44.0\r\nopencv-python==4.10.0.84\r\nopencv-python-headless==4.10.0.84\r\nopenpyxl==3.1.5\r\nopentelemetry-api==1.25.0\r\nopentelemetry-exporter-otlp-proto-common==1.25.0\r\nopentelemetry-exporter-otlp-proto-grpc==1.25.0\r\nopentelemetry-exporter-otlp-proto-http==1.25.0\r\nopentelemetry-exporter-prometheus==0.46b0\r\nopentelemetry-instrumentation==0.46b0\r\nopentelemetry-instrumentation-asgi==0.46b0\r\nopentelemetry-instrumentation-fastapi==0.46b0\r\nopentelemetry-proto==1.25.0\r\nopentelemetry-sdk==1.25.0\r\nopentelemetry-semantic-conventions==0.46b0\r\nopentelemetry-util-http==0.46b0\r\noptimum==1.21.2\r\noptuna==4.0.0\r\nordered-set==4.1.0\r\norjson==3.10.0\r\noutcome==1.3.0.post0\r\noverrides==7.7.0\r\npackaging==24.1\r\npandas==2.2.2\r\npandocfilters==1.5.1\r\npanel==1.4.5\r\nparam==2.1.1\r\nparameterized==0.9.0\r\nparamiko==3.4.1\r\nparso==0.8.4\r\npasslib==1.7.4\r\npathspec==0.12.1\r\npdf2image==1.17.0\r\npdf2img==0.1.2\r\npdfminer.six==20231228\r\npdfplumber==0.11.4\r\npeewee==3.17.6\r\npeft==0.12.0\r\npexpect==4.9.0\r\npgvector==0.2.5\r\nphidata==2.4.22\r\npillow==10.4.0\r\npinecone-client==3.2.2\r\npinecone-plugin-inference==1.0.3\r\npinecone-plugin-interface==0.0.7\r\nplatformdirs==4.2.1\r\nplotly==5.24.0\r\npluggy==1.5.0\r\npooch==1.8.2\r\nportalocker==2.10.1\r\npostgrest==0.16.11\r\nposthog==3.5.0\r\npprintpp==0.4.0\r\npreshed==3.0.9\r\npriority==2.0.0\r\nprometheus_client==0.20.0\r\nprompt-toolkit==3.0.43\r\nproto-plus==1.24.0\r\nprotobuf==4.25.5\r\npsutil==5.9.8\r\npsycopg==3.1.9\r\npsycopg2-binary==2.9.9\r\nptyprocess==0.7.0\r\npulsar-client==3.5.0\r\npure-eval==0.2.2\r\npy==1.11.0\r\npy-cpuinfo==9.0.0\r\npy7zr==0.22.0\r\npyarrow==15.0.2\r\npyarrow-hotfix==0.6\r\npyasn1==0.6.0\r\npyasn1_modules==0.4.0\r\npyautogen==0.2.35\r\npybcj==1.0.2\r\npyclipper==1.3.0.post5\r\npycocotools==2.0.8\r\npycountry==24.6.1\r\npycparser==2.22\r\npycryptodome==3.20.0\r\npycryptodomex==3.20.0\r\npydantic==2.8.2\r\npydantic-settings==2.3.4\r\npydantic_core==2.20.1\r\npydash==8.0.3\r\npydeck==0.9.1\r\npydot==3.0.1\r\nPygments==2.18.0\r\nPyJWT==2.9.0\r\npylance==0.9.18\r\npymilvus==2.4.6\r\npymongo==4.8.0\r\nPyNaCl==1.5.0\r\npyopensky==2.9\r\npyparsing==3.1.2\r\npypdf==4.2.0\r\nPyPDF2==3.0.1\r\npypdfium2==4.30.0\r\npyperclip==1.9.0\r\nPyPika==0.48.9\r\npyppmd==1.1.0\r\npyproject-toml==0.0.10\r\npyproject_hooks==1.1.0\r\npyright==1.1.379\r\npysbd==0.3.4\r\nPysher==1.0.8\r\nPySocks==1.7.1\r\npytest==8.3.2\r\npython-bidi==0.6.0\r\npython-dateutil==2.9.0.post0\r\npython-docx==1.1.2\r\npython-dotenv==1.0.1\r\npython-engineio==4.9.1\r\npython-iso639==2024.4.27\r\npython-jose==3.3.0\r\npython-json-logger==2.0.7\r\npython-lsp-jsonrpc==1.1.2\r\npython-magic==0.4.27\r\npython-multipart==0.0.7\r\npython-pptx==0.6.23\r\npython-socketio==5.11.3\r\npytube==15.0.0\r\npytz==2024.2\r\npyviz_comms==3.0.3\r\nPyYAML==6.0.2\r\npyzmq==26.0.3\r\npyzstd==0.16.1\r\nqdrant-client==1.11.1\r\nqianfan==0.3.5\r\nqwen-vl-utils==0.0.4\r\nradient==2024.8.19\r\nragas==0.1.16\r\nrapidfuzz==3.9.6\r\nrarfile==4.2\r\nratelimiter==1.2.0.post0\r\nrealtime==2.0.2\r\nreferencing==0.35.1\r\nregex==2024.9.11\r\nrequests==2.32.3\r\nrequests-futures==1.0.1\r\nrequests-oauthlib==2.0.0\r\nrequests-toolbelt==1.0.0\r\nretry==0.9.2\r\nretrying==1.3.4\r\nrfc3339-validator==0.1.4\r\nrfc3986-validator==0.1.1\r\nrich==13.7.1\r\nrpds-py==0.18.1\r\nrsa==4.9\r\nrss2newsletter==1.0.5\r\nruff==0.6.3\r\nrule-based-retrieval==0.1.4\r\ns3transfer==0.10.1\r\nsafetensors==0.4.5\r\nschema==0.7.7\r\nscikit-image==0.23.2\r\nscikit-learn==1.5.1\r\nscipy==1.13.0\r\nseaborn==0.13.2\r\nselenium==4.24.0\r\nsemver==3.0.2\r\nSend2Trash==1.8.3\r\nsentence-transformers==3.0.1\r\nsentencepiece==0.2.0\r\nsentry-sdk==2.13.0\r\nsetuptools==74.1.2\r\nsgmllib3k==1.0.0\r\nshapely==2.0.6\r\nshellingham==1.5.4\r\nsherlock-project==0.15.0\r\nsimple-websocket==1.0.0\r\nsix==1.16.0\r\nslack_bolt==1.20.0\r\nslack_sdk==3.27.2\r\nsmart-open==7.0.4\r\nsmmap==5.0.1\r\nsniffio==1.3.1\r\nsortedcontainers==2.4.0\r\nsoundfile==0.12.1\r\nsoupsieve==2.5\r\nsoxr==0.5.0\r\nspacy==3.7.6\r\nspacy-legacy==3.0.12\r\nspacy-loggers==1.0.5\r\nspider-client==0.0.27\r\nSQLAlchemy==2.0.34\r\nsqlmodel==0.0.18\r\nsrsly==2.4.8\r\nsse-starlette==0.10.3\r\nsseclient-py==1.8.0\r\nst-milvus-connection==0.0.4\r\nstack-data==0.6.3\r\nstarlette==0.37.2\r\nstem==1.8.2\r\nstorage3==0.7.7\r\nstrawberry-graphql==0.138.1\r\nstreamlit==1.38.0\r\nStrEnum==0.4.15\r\nstriprtf==0.0.26\r\nstructlog==24.4.0\r\nsumy==0.11.0\r\nsuno-bark @ git+https://github.com/suno-ai/bark.git@f4f32d4cd480dfec1c245d258174bc9bde3c2148\r\nsupabase==2.7.4\r\nsupafunc==0.5.1\r\nsympy==1.13.2\r\ntabulate==0.9.0\r\ntavily-python==0.4.0\r\ntenacity==8.3.0\r\ntensorboard==2.17.1\r\ntensorboard-data-server==0.7.2\r\ntermcolor==2.4.0\r\nterminado==0.18.1\r\ntexttable==1.7.0\r\nthinc==8.2.5\r\nthreadpoolctl==3.5.0\r\ntifffile==2024.5.3\r\ntiktoken==0.7.0\r\ntimm==1.0.9\r\ntinycss2==1.3.0\r\ntokenizers==0.19.1\r\ntoml==0.10.2\r\ntomli==2.0.1\r\ntorch==2.4.0\r\ntorchaudio==2.4.0\r\ntorchvision==0.19.0\r\ntornado==6.4\r\ntqdm==4.66.5\r\ntraitlets==5.14.3\r\ntransformers==4.44.2\r\ntree-sitter==0.23.0\r\ntree-sitter-python==0.23.2\r\ntrino==0.329.0\r\ntrio==0.26.2\r\ntrio-websocket==0.11.1\r\ntyper==0.12.3\r\ntypes-cachetools==5.5.0.20240820\r\ntypes-python-dateutil==2.9.0.20240316\r\ntypes-requests==2.32.0.20240712\r\ntyping-inspect==0.9.0\r\ntyping_extensions==4.12.2\r\ntzdata==2024.1\r\ntzlocal==5.2\r\nuc-micro-py==1.0.3\r\nujson==5.10.0\r\nultralytics==8.2.82\r\nultralytics-thop==2.0.5\r\nuncurl==0.0.11\r\nuniversal-analytics-python3==1.1.1\r\nunstructured==0.14.10\r\nunstructured-client==0.25.5\r\nupstash-vector==0.4.0\r\nuri-template==1.3.0\r\nuritemplate==4.1.1\r\nurllib3==2.2.3\r\nuuid6==2024.1.12\r\nuvicorn==0.30.1\r\nuvloop==0.19.0\r\nvalidators==0.33.0\r\nvoxel51-eta==0.12.7\r\nwasabi==1.1.3\r\nwatchdog==5.0.2\r\nwatchfiles==0.22.0\r\nwcwidth==0.2.13\r\nweasel==0.4.1\r\nweaviate-client==4.7.1\r\nwebcolors==1.13\r\nwebencodings==0.5.1\r\nwebsocket-client==1.8.0\r\nwebsockets==12.0\r\nWerkzeug==3.0.4\r\nwheel==0.44.0\r\nwidgetsnbextension==4.0.11\r\nwikipedia==1.4.0\r\nWikipedia-API==0.6.0\r\nwolframalpha==5.1.3\r\nwrapt==1.16.0\r\nwsproto==1.2.0\r\nxformer==1.0.1\r\nxformers==0.0.23\r\nXlsxWriter==3.2.0\r\nxmltodict==0.13.0\r\nxxhash==3.5.0\r\nxyzservices==2024.6.0\r\nyacs==0.1.8\r\nyarl==1.11.1\r\nyfinance==0.2.43\r\nyoutube-transcript-api==0.6.2\r\nyt-dlp==2024.8.6\r\nzep-python==2.0.0rc6\r\nzipp==3.20.1\n```\n\n\n### Reproduction Steps\n\npoetry install\r\n\r\nor \r\npip3 install mistral_inference\n\n### Expected Behavior\n\ncompile and work\n\n### Additional Context\n\nIt fails on build of xformers\r\n\r\nenv/lib/python3.12/site-packages/torch/include/THC -I/Users/timothyspann/Downloads/code/milvusvenv/include -I/opt/homebrew/opt/python@3.12/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c -c /private/var/folders/c2/6wq9klzn19d97gvw8f8j1jdr0000gn/T/pip-install-p9bq7hp4/xformers_6ffdc41865e543c99f124e7bdc9bacd2/xformers/csrc/attention/sddmm.cpp -o /private/var/folders/c2/6wq9klzn19d97gvw8f8j1jdr0000gn/T/pip-install-p9bq7hp4/xformers_6ffdc41865e543c99f124e7bdc9bacd2/build/temp.macosx-13.0-arm64-cpython-312/xformers/csrc/attention/sddmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_clang\"' '-DPYBIND11_STDLIB=\"_libcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1002\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n      clang: error: unsupported option '-fopenmp'\r\n      ninja: build stopped: subcommand failed.\r\n      Traceback (most recent call last):\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 2105, in _run_ninja_build\r\n          subprocess.run(\r\n        File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py\", line 571, in run\r\n          raise CalledProcessError(retcode, process.args,\r\n      subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\r\n\r\n      The above exception was the direct cause of the following exception:\r\n\r\n      Traceback (most recent call last):\r\n        File \"<string>\", line 2, in <module>\r\n        File \"<pip-setuptools-caller>\", line 34, in <module>\r\n        File \"/private/var/folders/c2/6wq9klzn19d97gvw8f8j1jdr0000gn/T/pip-install-p9bq7hp4/xformers_6ffdc41865e543c99f124e7bdc9bacd2/setup.py\", line 680, in <module>\r\n          setuptools.setup(\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/__init__.py\", line 117, in setup\r\n          return distutils.core.setup(**attrs)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 184, in setup\r\n          return run_commands(dist)\r\n                 ^^^^^^^^^^^^^^^^^^\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 200, in run_commands\r\n          dist.run_commands()\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 954, in run_commands\r\n          self.run_command(cmd)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/dist.py\", line 950, in run_command\r\n          super().run_command(command)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 973, in run_command\r\n          cmd_obj.run()\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/command/bdist_wheel.py\", line 384, in run\r\n          self.run_command(\"build\")\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\r\n          self.distribution.run_command(command)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/dist.py\", line 950, in run_command\r\n          super().run_command(command)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 973, in run_command\r\n          cmd_obj.run()\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/command/build.py\", line 135, in run\r\n          self.run_command(cmd_name)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\r\n          self.distribution.run_command(command)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/dist.py\", line 950, in run_command\r\n          super().run_command(command)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 973, in run_command\r\n          cmd_obj.run()\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/command/build_ext.py\", line 98, in run\r\n          _build_ext.run(self)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 359, in run\r\n          self.build_extensions()\r\n        File \"/private/var/folders/c2/6wq9klzn19d97gvw8f8j1jdr0000gn/T/pip-install-p9bq7hp4/xformers_6ffdc41865e543c99f124e7bdc9bacd2/setup.py\", line 637, in build_extensions\r\n          super().build_extensions()\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 866, in build_extensions\r\n          build_ext.build_extensions(self)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 476, in build_extensions\r\n          self._build_extensions_serial()\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 502, in _build_extensions_serial\r\n          self.build_extension(ext)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/command/build_ext.py\", line 263, in build_extension\r\n          _build_ext.build_extension(self, ext)\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 557, in build_extension\r\n          objects = self.compiler.compile(\r\n                    ^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 679, in unix_wrap_ninja_compile\r\n          _write_ninja_file_and_compile_objects(\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1785, in _write_ninja_file_and_compile_objects\r\n          _run_ninja_build(\r\n        File \"/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 2121, in _run_ninja_build\r\n          raise RuntimeError(message) from e\r\n      RuntimeError: Error compiling objects for extension\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for xformers\r\n  Running setup.py clean for xformers\r\nFailed to build xformers\r\nERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/224/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/224/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/223",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/223/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/223/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/223/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/223",
    "id": 2539665987,
    "node_id": "PR_kwDOKY_97s58NuCl",
    "number": 223,
    "title": "Update README.md",
    "user": {
      "login": "devendrachaplot",
      "id": 1102621,
      "node_id": "MDQ6VXNlcjExMDI2MjE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1102621?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/devendrachaplot",
      "html_url": "https://github.com/devendrachaplot",
      "followers_url": "https://api.github.com/users/devendrachaplot/followers",
      "following_url": "https://api.github.com/users/devendrachaplot/following{/other_user}",
      "gists_url": "https://api.github.com/users/devendrachaplot/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/devendrachaplot/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/devendrachaplot/subscriptions",
      "organizations_url": "https://api.github.com/users/devendrachaplot/orgs",
      "repos_url": "https://api.github.com/users/devendrachaplot/repos",
      "events_url": "https://api.github.com/users/devendrachaplot/events{/privacy}",
      "received_events_url": "https://api.github.com/users/devendrachaplot/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-09-20T20:56:17Z",
    "updated_at": "2024-09-20T22:12:46Z",
    "closed_at": "2024-09-20T22:12:46Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/223",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/223",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/223.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/223.patch",
      "merged_at": "2024-09-20T22:12:46Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/223/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/223/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/222",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/222/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/222/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/222/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/222",
    "id": 2539180325,
    "node_id": "I_kwDOKY_97s6XWNEl",
    "number": 222,
    "title": "[BUG: AttributeError: module 'torch.library' has no attribute 'custom_op'",
    "user": {
      "login": "mruhlmannGit",
      "id": 160583848,
      "node_id": "U_kgDOCZJQqA",
      "avatar_url": "https://avatars.githubusercontent.com/u/160583848?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mruhlmannGit",
      "html_url": "https://github.com/mruhlmannGit",
      "followers_url": "https://api.github.com/users/mruhlmannGit/followers",
      "following_url": "https://api.github.com/users/mruhlmannGit/following{/other_user}",
      "gists_url": "https://api.github.com/users/mruhlmannGit/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mruhlmannGit/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mruhlmannGit/subscriptions",
      "organizations_url": "https://api.github.com/users/mruhlmannGit/orgs",
      "repos_url": "https://api.github.com/users/mruhlmannGit/repos",
      "events_url": "https://api.github.com/users/mruhlmannGit/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mruhlmannGit/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-09-20T16:13:32Z",
    "updated_at": "2024-09-20T16:13:32Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython -vv\n```\n\n\n### Pip Freeze\n\n```shell\nPip freeze\n```\n\n\n### Reproduction Steps\n\n docker build -t llm-mistral7b .\r\n \r\n With the right dockerfile\n\n### Expected Behavior\n\nin dockerfile, pytorch version is 2.1.1 and custom_op needs version >=2.4.0. Seems dockerfile is outdated.\n\n### Additional Context\n\ndocker run -it llm-mistral7b /bin/bash\r\nThe HF_TOKEN environment variable is not set or empty, not logging to Hugging Face.\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\r\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\r\n  File \"/usr/lib/python3.10/runpy.py\", line 110, in _get_module_details\r\n    __import__(pkg_name)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/__init__.py\", line 3, in <module>\r\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/arg_utils.py\", line 11, in <module>\r\n    from vllm.config import (CacheConfig, ConfigFormat, DecodingConfig,\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/config.py\", line 12, in <module>\r\n    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/model_executor/__init__.py\", line 1, in <module>\r\n    from vllm.model_executor.parameter import (BasevLLMParameter,\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/model_executor/parameter.py\", line 7, in <module>\r\n    from vllm.distributed import get_tensor_model_parallel_rank\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/distributed/__init__.py\", line 1, in <module>\r\n    from .communication_op import *\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/distributed/communication_op.py\", line 6, in <module>\r\n    from .parallel_state import get_tp_group\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/distributed/parallel_state.py\", line 98, in <module>\r\n    @torch.library.custom_op(\"vllm::inplace_all_reduce\", mutates_args=[\"tensor\"])\r\nAttributeError: module 'torch.library' has no attribute 'custom_op'\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/222/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/222/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/221",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/221/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/221/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/221/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/221",
    "id": 2539153825,
    "node_id": "I_kwDOKY_97s6XWGmh",
    "number": 221,
    "title": "[BUG: RuntimeError: Couldn't instantiate class <class 'mistral_inference.args.TransformerArgs'> using init args dict_keys(['dim', 'n_layers', 'vocab_size', 'model_type'])",
    "user": {
      "login": "NM5035",
      "id": 147505733,
      "node_id": "U_kgDOCMrCRQ",
      "avatar_url": "https://avatars.githubusercontent.com/u/147505733?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/NM5035",
      "html_url": "https://github.com/NM5035",
      "followers_url": "https://api.github.com/users/NM5035/followers",
      "following_url": "https://api.github.com/users/NM5035/following{/other_user}",
      "gists_url": "https://api.github.com/users/NM5035/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/NM5035/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/NM5035/subscriptions",
      "organizations_url": "https://api.github.com/users/NM5035/orgs",
      "repos_url": "https://api.github.com/users/NM5035/repos",
      "events_url": "https://api.github.com/users/NM5035/events{/privacy}",
      "received_events_url": "https://api.github.com/users/NM5035/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-09-20T15:57:33Z",
    "updated_at": "2024-09-20T15:57:33Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.10\n```\n\n\n### Pip Freeze\n\n```shell\nabsl-py==1.4.0\r\naccelerate==0.34.2\r\naiohappyeyeballs==2.4.0\r\naiohttp==3.10.5\r\naiosignal==1.3.1\r\nalabaster==0.7.16\r\nalbucore==0.0.15\r\nalbumentations==1.4.15\r\naltair==4.2.2\r\nannotated-types==0.7.0\r\nanyio==3.7.1\r\nargon2-cffi==23.1.0\r\nargon2-cffi-bindings==21.2.0\r\narray_record==0.5.1\r\narviz==0.19.0\r\nastropy==6.1.3\r\nastropy-iers-data==0.2024.9.16.0.32.21\r\nastunparse==1.6.3\r\nasync-timeout==4.0.3\r\natpublic==4.1.0\r\nattrs==24.2.0\r\naudioread==3.0.1\r\nautograd==1.7.0\r\nbabel==2.16.0\r\nbackcall==0.2.0\r\nbeautifulsoup4==4.12.3\r\nbidict==0.23.1\r\nbigframes==1.17.0\r\nbigquery-magics==0.2.0\r\nbleach==6.1.0\r\nblinker==1.4\r\nblis==0.7.11\r\nblosc2==2.0.0\r\nbokeh==3.4.3\r\nbqplot==0.12.43\r\nbranca==0.7.2\r\nbuild==1.2.2\r\nCacheControl==0.14.0\r\ncachetools==5.5.0\r\ncatalogue==2.0.10\r\ncausal-conv1d==1.4.0\r\ncertifi==2024.8.30\r\ncffi==1.17.1\r\nchardet==5.2.0\r\ncharset-normalizer==3.3.2\r\nchex==0.1.86\r\nclarabel==0.9.0\r\nclick==8.1.7\r\ncloudpathlib==0.19.0\r\ncloudpickle==2.2.1\r\ncmake==3.30.3\r\ncmdstanpy==1.2.4\r\ncolorcet==3.1.0\r\ncolorlover==0.3.0\r\ncolour==0.1.5\r\ncommunity==1.0.0b1\r\nconfection==0.1.5\r\ncons==0.4.6\r\ncontextlib2==21.6.0\r\ncontourpy==1.3.0\r\ncryptography==43.0.1\r\ncuda-python==12.2.1\r\ncudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.4.1-cp310-cp310-manylinux_2_28_x86_64.whl#sha256=57366e7ef09dc63e0b389aff20df6c37d91e2790065861ee31a4720149f5b694\r\ncufflinks==0.17.3\r\ncupy-cuda12x==12.2.0\r\ncvxopt==1.3.2\r\ncvxpy==1.5.3\r\ncycler==0.12.1\r\ncymem==2.0.8\r\nCython==3.0.11\r\ndask==2024.8.0\r\ndatascience==0.17.6\r\ndb-dtypes==1.3.0\r\ndbus-python==1.2.18\r\ndebugpy==1.6.6\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\ndistributed==2024.8.0\r\ndistro==1.7.0\r\ndlib==19.24.2\r\ndm-tree==0.1.8\r\ndocstring_parser==0.16\r\ndocutils==0.18.1\r\ndopamine_rl==4.0.9\r\nduckdb==1.1.0\r\nearthengine-api==1.0.0\r\neasydict==1.13\r\necos==2.0.14\r\neditdistance==0.8.1\r\neerepr==0.0.4\r\neinops==0.8.0\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\r\nentrypoints==0.4\r\net-xmlfile==1.1.0\r\netils==1.9.4\r\netuples==0.3.9\r\neval_type_backport==0.2.0\r\nexceptiongroup==1.2.2\r\nfastai==2.7.17\r\nfastcore==1.7.8\r\nfastdownload==0.0.7\r\nfastjsonschema==2.20.0\r\nfastprogress==1.0.3\r\nfastrlock==0.8.2\r\nfilelock==3.16.0\r\nfire==0.6.0\r\nfirebase-admin==6.5.0\r\nFlask==2.2.5\r\nflatbuffers==24.3.25\r\nflax==0.8.4\r\nfolium==0.17.0\r\nfonttools==4.53.1\r\nfrozendict==2.4.4\r\nfrozenlist==1.4.1\r\nfsspec==2024.6.1\r\nfuture==1.0.0\r\ngast==0.6.0\r\ngcsfs==2024.6.1\r\nGDAL==3.6.4\r\ngdown==5.1.0\r\ngeemap==0.34.1\r\ngensim==4.3.3\r\ngeocoder==1.38.1\r\ngeographiclib==2.0\r\ngeopandas==1.0.1\r\ngeopy==2.4.1\r\ngin-config==0.5.0\r\nglob2==0.7\r\ngoogle==2.0.3\r\ngoogle-ai-generativelanguage==0.6.6\r\ngoogle-api-core==2.19.2\r\ngoogle-api-python-client==2.137.0\r\ngoogle-auth==2.27.0\r\ngoogle-auth-httplib2==0.2.0\r\ngoogle-auth-oauthlib==1.2.1\r\ngoogle-cloud-aiplatform==1.66.0\r\ngoogle-cloud-bigquery==3.25.0\r\ngoogle-cloud-bigquery-connection==1.15.5\r\ngoogle-cloud-bigquery-storage==2.26.0\r\ngoogle-cloud-bigtable==2.26.0\r\ngoogle-cloud-core==2.4.1\r\ngoogle-cloud-datastore==2.19.0\r\ngoogle-cloud-firestore==2.16.1\r\ngoogle-cloud-functions==1.16.5\r\ngoogle-cloud-iam==2.15.2\r\ngoogle-cloud-language==2.13.4\r\ngoogle-cloud-pubsub==2.23.1\r\ngoogle-cloud-resource-manager==1.12.5\r\ngoogle-cloud-storage==2.8.0\r\ngoogle-cloud-translate==3.15.5\r\ngoogle-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz#sha256=e86f433b6968bdd1e17b9e4cf8e0b4f105b3f6a409ffcd410336d06853a81096\r\ngoogle-crc32c==1.6.0\r\ngoogle-generativeai==0.7.2\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==2.7.2\r\ngoogleapis-common-protos==1.65.0\r\ngoogledrivedownloader==0.4\r\ngraphviz==0.20.3\r\ngreenlet==3.1.0\r\ngrpc-google-iam-v1==0.13.1\r\ngrpcio==1.64.1\r\ngrpcio-status==1.48.2\r\ngspread==6.0.2\r\ngspread-dataframe==3.3.1\r\ngym==0.25.2\r\ngym-notices==0.0.8\r\nh5netcdf==1.3.0\r\nh5py==3.11.0\r\nholidays==0.57\r\nholoviews==1.19.1\r\nhtml5lib==1.1\r\nhttpimport==1.4.0\r\nhttplib2==0.22.0\r\nhuggingface-hub==0.24.7\r\nhumanize==4.10.0\r\nhyperopt==0.2.7\r\nibis-framework==8.0.0\r\nidna==3.10\r\nimageio==2.35.1\r\nimageio-ffmpeg==0.5.1\r\nimagesize==1.4.1\r\nimbalanced-learn==0.12.3\r\nimgaug==0.4.0\r\nimmutabledict==4.2.0\r\nimportlib_metadata==8.5.0\r\nimportlib_resources==6.4.5\r\nimutils==0.5.4\r\ninflect==7.4.0\r\niniconfig==2.0.0\r\nintel-cmplr-lib-ur==2024.2.1\r\nintel-openmp==2024.2.1\r\nipyevents==2.0.2\r\nipyfilechooser==0.6.0\r\nipykernel==5.5.6\r\nipyleaflet==0.19.2\r\nipyparallel==8.8.0\r\nipython==7.34.0\r\nipython-genutils==0.2.0\r\nipython-sql==0.5.0\r\nipytree==0.2.2\r\nipywidgets==7.7.1\r\nitsdangerous==2.2.0\r\njax==0.4.26\r\njaxlib @ https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.26+cuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl#sha256=813cf1fe3e7ca4dbf5327d6e7b4fc8521e92d8bba073ee645ae0d5d036a25750\r\njeepney==0.7.1\r\njellyfish==1.1.0\r\njieba==0.42.1\r\nJinja2==3.1.4\r\njoblib==1.4.2\r\njsonpickle==3.3.0\r\njsonschema==4.23.0\r\njsonschema-specifications==2023.12.1\r\njupyter-client==6.1.12\r\njupyter-console==6.1.0\r\njupyter-leaflet==0.19.2\r\njupyter-server==1.24.0\r\njupyter_core==5.7.2\r\njupyterlab_pygments==0.3.0\r\njupyterlab_widgets==3.0.13\r\nkaggle==1.6.17\r\nkagglehub==0.2.9\r\nkeras==3.4.1\r\nkeyring==23.5.0\r\nkiwisolver==1.4.7\r\nlangcodes==3.4.0\r\nlanguage_data==1.2.0\r\nlaunchpadlib==1.10.16\r\nlazr.restfulclient==0.14.4\r\nlazr.uri==1.0.6\r\nlazy_loader==0.4\r\nlibclang==18.1.1\r\nlibrosa==0.10.2.post1\r\nlightgbm==4.5.0\r\nlinkify-it-py==2.0.3\r\nllvmlite==0.43.0\r\nlocket==1.0.0\r\nlogical-unification==0.4.6\r\nlxml==4.9.4\r\nmamba-ssm==2.2.2\r\nmarisa-trie==1.2.0\r\nMarkdown==3.7\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.5\r\nmatplotlib==3.7.1\r\nmatplotlib-inline==0.1.7\r\nmatplotlib-venn==1.1.1\r\nmdit-py-plugins==0.4.2\r\nmdurl==0.1.2\r\nminiKanren==1.0.3\r\nmissingno==0.5.2\r\nmistral_common==1.4.2\r\nmistral_inference==1.4.0\r\nmistune==0.8.4\r\nmizani==0.11.4\r\nmkl==2024.2.2\r\nml-dtypes==0.4.1\r\nmlxtend==0.23.1\r\nmore-itertools==10.5.0\r\nmoviepy==1.0.3\r\nmpmath==1.3.0\r\nmsgpack==1.0.8\r\nmultidict==6.1.0\r\nmultipledispatch==1.0.0\r\nmultitasking==0.0.11\r\nmurmurhash==1.0.10\r\nmusic21==9.1.0\r\nnamex==0.0.8\r\nnatsort==8.4.0\r\nnbclassic==1.1.0\r\nnbclient==0.10.0\r\nnbconvert==6.5.4\r\nnbformat==5.10.4\r\nnest-asyncio==1.6.0\r\nnetworkx==3.3\r\nnibabel==5.2.1\r\nninja==1.11.1.1\r\nnltk==3.8.1\r\nnotebook==6.5.5\r\nnotebook_shim==0.2.4\r\nnumba==0.60.0\r\nnumexpr==2.10.1\r\nnumpy==1.26.4\r\nnvidia-nccl-cu12==2.23.4\r\nnvtx==0.2.10\r\noauth2client==4.1.3\r\noauthlib==3.2.2\r\nopencv-contrib-python==4.10.0.84\r\nopencv-python==4.10.0.84\r\nopencv-python-headless==4.10.0.84\r\nopenpyxl==3.1.5\r\nopt-einsum==3.3.0\r\noptax==0.2.2\r\noptree==0.12.1\r\norbax-checkpoint==0.6.4\r\nosqp==0.6.7.post0\r\npackaging==24.1\r\npandas==2.1.4\r\npandas-datareader==0.10.0\r\npandas-gbq==0.23.1\r\npandas-stubs==2.1.4.231227\r\npandocfilters==1.5.1\r\npanel==1.4.5\r\nparam==2.1.1\r\nparso==0.8.4\r\nparsy==2.1\r\npartd==1.4.2\r\npathlib==1.0.1\r\npatsy==0.5.6\r\npeewee==3.17.6\r\npexpect==4.9.0\r\npickleshare==0.7.5\r\npillow==10.4.0\r\npip-tools==7.4.1\r\nplatformdirs==4.3.4\r\nplotly==5.15.0\r\nplotnine==0.13.6\r\npluggy==1.5.0\r\npolars==1.6.0\r\npooch==1.8.2\r\nportpicker==1.5.2\r\nprefetch_generator==1.0.3\r\npreshed==3.0.9\r\nprettytable==3.11.0\r\nproglog==0.1.10\r\nprogressbar2==4.5.0\r\nprometheus_client==0.20.0\r\npromise==2.3\r\nprompt_toolkit==3.0.47\r\nprophet==1.1.5\r\nproto-plus==1.24.0\r\nprotobuf==3.20.3\r\npsutil==5.9.5\r\npsycopg2==2.9.9\r\nptyprocess==0.7.0\r\npy-cpuinfo==9.0.0\r\npy4j==0.10.9.7\r\npyarrow==14.0.2\r\npyarrow-hotfix==0.6\r\npyasn1==0.6.1\r\npyasn1_modules==0.4.1\r\npycocotools==2.0.8\r\npycparser==2.22\r\npydantic==2.9.2\r\npydantic_core==2.23.4\r\npydata-google-auth==1.8.2\r\npydot==3.0.1\r\npydot-ng==2.0.0\r\npydotplus==2.0.2\r\nPyDrive==1.3.1\r\nPyDrive2==1.20.0\r\npyerfa==2.0.1.4\r\npygame==2.6.0\r\nPygments==2.18.0\r\nPyGObject==3.42.1\r\nPyJWT==2.9.0\r\npymc==5.16.2\r\npymystem3==0.2.0\r\npynvjitlink-cu12==0.3.0\r\npyogrio==0.9.0\r\nPyOpenGL==3.1.7\r\npyOpenSSL==24.2.1\r\npyparsing==3.1.4\r\npyperclip==1.9.0\r\npyproj==3.6.1\r\npyproject_hooks==1.1.0\r\npyshp==2.3.1\r\nPySocks==1.7.1\r\npytensor==2.25.4\r\npytest==7.4.4\r\npython-apt==2.4.0\r\npython-box==7.2.0\r\npython-dateutil==2.8.2\r\npython-louvain==0.16\r\npython-slugify==8.0.4\r\npython-utils==3.8.2\r\npytz==2024.2\r\npyviz_comms==3.0.3\r\nPyYAML==6.0.2\r\npyzmq==24.0.1\r\nqdldl==0.1.7.post4\r\nratelim==0.1.6\r\nreferencing==0.35.1\r\nregex==2024.9.11\r\nrequests==2.32.3\r\nrequests-oauthlib==1.3.1\r\nrequirements-parser==0.9.0\r\nrich==13.8.1\r\nrmm-cu12==24.4.0\r\nrpds-py==0.20.0\r\nrpy2==3.4.2\r\nrsa==4.9\r\nsafetensors==0.4.5\r\nscikit-image==0.23.2\r\nscikit-learn==1.3.2\r\nscipy==1.13.1\r\nscooby==0.10.0\r\nscs==3.2.7\r\nseaborn==0.13.1\r\nSecretStorage==3.3.1\r\nSend2Trash==1.8.3\r\nsentencepiece==0.2.0\r\nshapely==2.0.6\r\nshellingham==1.5.4\r\nsimple-parsing==0.1.6\r\nsix==1.16.0\r\nsklearn-pandas==2.2.0\r\nsmart-open==7.0.4\r\nsniffio==1.3.1\r\nsnowballstemmer==2.2.0\r\nsortedcontainers==2.4.0\r\nsoundfile==0.12.1\r\nsoupsieve==2.6\r\nsoxr==0.5.0.post1\r\nspacy==3.7.6\r\nspacy-legacy==3.0.12\r\nspacy-loggers==1.0.5\r\nSphinx==5.0.2\r\nsphinxcontrib-applehelp==2.0.0\r\nsphinxcontrib-devhelp==2.0.0\r\nsphinxcontrib-htmlhelp==2.1.0\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==2.0.0\r\nsphinxcontrib-serializinghtml==2.0.0\r\nSQLAlchemy==2.0.35\r\nsqlglot==20.11.0\r\nsqlparse==0.5.1\r\nsrsly==2.4.8\r\nstanio==0.5.1\r\nstatsmodels==0.14.3\r\nStrEnum==0.4.15\r\nsympy==1.13.2\r\ntables==3.8.0\r\ntabulate==0.9.0\r\ntbb==2021.13.1\r\ntblib==3.0.0\r\ntenacity==9.0.0\r\ntensorboard==2.17.0\r\ntensorboard-data-server==0.7.2\r\ntensorflow==2.17.0\r\ntensorflow-datasets==4.9.6\r\ntensorflow-hub==0.16.1\r\ntensorflow-io-gcs-filesystem==0.37.1\r\ntensorflow-metadata==1.15.0\r\ntensorflow-probability==0.24.0\r\ntensorstore==0.1.65\r\ntermcolor==2.4.0\r\nterminado==0.18.1\r\ntext-unidecode==1.3\r\ntextblob==0.17.1\r\ntf-slim==1.1.0\r\ntf_keras==2.17.0\r\nthinc==8.2.5\r\nthreadpoolctl==3.5.0\r\ntifffile==2024.8.30\r\ntiktoken==0.7.0\r\ntinycss2==1.3.0\r\ntokenizers==0.19.1\r\ntoml==0.10.2\r\ntomli==2.0.1\r\ntoolz==0.12.1\r\ntorch @ https://download.pytorch.org/whl/cu121_full/torch-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=f3ed9a2b7f8671b2b32a2f036d1b81055eb3ad9b18ba43b705aa34bae4289e1a\r\ntorchaudio @ https://download.pytorch.org/whl/cu121_full/torchaudio-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=da8c87c80a1c1376a48dc33eef30b03bbdf1df25a05bd2b1c620b8811c7b19be\r\ntorchsummary==1.5.1\r\ntorchvision @ https://download.pytorch.org/whl/cu121_full/torchvision-0.19.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=b8cc4bf381b75522995b601e07a1b433b5fd925dc3e34a7fa6cd22f449d65379\r\ntornado==6.3.3\r\ntqdm==4.66.5\r\ntraitlets==5.7.1\r\ntraittypes==0.2.1\r\ntransformers==4.44.2\r\ntriton==3.0.0\r\ntweepy==4.14.0\r\ntypeguard==4.3.0\r\ntyper==0.12.5\r\ntypes-pytz==2024.2.0.20240913\r\ntypes-setuptools==75.1.0.20240917\r\ntyping_extensions==4.12.2\r\ntzdata==2024.1\r\ntzlocal==5.2\r\nuc-micro-py==1.0.3\r\nuritemplate==4.1.1\r\nurllib3==2.0.7\r\nvega-datasets==0.9.0\r\nwadllib==1.3.6\r\nwasabi==1.1.3\r\nwcwidth==0.2.13\r\nweasel==0.4.1\r\nwebcolors==24.8.0\r\nwebencodings==0.5.1\r\nwebsocket-client==1.8.0\r\nWerkzeug==3.0.4\r\nwidgetsnbextension==3.6.9\r\nwordcloud==1.9.3\r\nwrapt==1.16.0\r\nxarray==2024.9.0\r\nxarray-einstats==0.7.0\r\nxformers==0.0.28.post1\r\nxgboost==2.1.1\r\nxlrd==2.0.1\r\nxyzservices==2024.9.0\r\nyarl==1.11.1\r\nyellowbrick==1.5\r\nyfinance==0.2.43\r\nzict==3.0.0\r\nzipp==3.20.2\n```\n\n\n### Reproduction Steps\n\n1. I install pip install mamba_ssm causal-conv1d\r\n2. Apply the [Fix issue 496 #501]: https://github.com/state-spaces/mamba/pull/501\r\n3. Load this model locally in content diredctory in colab env : mistralai/Mamba-Codestral-7B-v0.1\r\n4. Use Mamba-Codestral-7B in inference\r\n```python\r\nfrom mistral_inference.transformer import Transformer\r\nfrom mistral_inference.generate import generate\r\n\r\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\r\nfrom mistral_common.protocol.instruct.messages import UserMessage\r\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\r\n\r\n# load tokenizer\r\nmistral_tokenizer = MistralTokenizer.from_file(\"/content/mistral_models/mamba-codestral/tokenizer.model.v3\")\r\n# chat completion request\r\ncompletion_request = ChatCompletionRequest(messages=[UserMessage(content=\"Write a sample of C code.\")])\r\n# encode message\r\ntokens = mistral_tokenizer.encode_chat_completion(completion_request).tokens\r\n# load model\r\nmodel = Transformer.from_folder(\"/content/mistral_models/mamba-codestral\")\r\n# generate results\r\nout_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=mistral_tokenizer.instruct_tokenizer.tokenizer.eos_id)\r\n# decode generated tokens\r\nresult = mistral_tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\r\nprint(result)\r\n```\r\n5. got this error\r\n```Shell\r\nWARNING:simple_parsing.helpers.serialization.serializable:Couldn't find the field 'head_dim' in the dict with keys ['dim', 'n_layers', 'vocab_size', 'n_groups', 'rms_norm', 'residual_in_fp32', 'fused_add_norm', 'pad_vocab_size_multiple', 'tie_embeddings', 'model_type']\r\nWARNING:simple_parsing.helpers.serialization.serializable:Couldn't find the field 'hidden_dim' in the dict with keys ['dim', 'n_layers', 'vocab_size', 'n_groups', 'rms_norm', 'residual_in_fp32', 'fused_add_norm', 'pad_vocab_size_multiple', 'tie_embeddings', 'model_type']\r\nWARNING:simple_parsing.helpers.serialization.serializable:Couldn't find the field 'n_heads' in the dict with keys ['dim', 'n_layers', 'vocab_size', 'n_groups', 'rms_norm', 'residual_in_fp32', 'fused_add_norm', 'pad_vocab_size_multiple', 'tie_embeddings', 'model_type']\r\nWARNING:simple_parsing.helpers.serialization.serializable:Couldn't find the field 'n_kv_heads' in the dict with keys ['dim', 'n_layers', 'vocab_size', 'n_groups', 'rms_norm', 'residual_in_fp32', 'fused_add_norm', 'pad_vocab_size_multiple', 'tie_embeddings', 'model_type']\r\nWARNING:simple_parsing.helpers.serialization.serializable:Couldn't find the field 'norm_eps' in the dict with keys ['dim', 'n_layers', 'vocab_size', 'n_groups', 'rms_norm', 'residual_in_fp32', 'fused_add_norm', 'pad_vocab_size_multiple', 'tie_embeddings', 'model_type']\r\nWARNING:simple_parsing.helpers.serialization.serializable:Dropping extra args {'n_groups': 8, 'rms_norm': True, 'residual_in_fp32': True, 'fused_add_norm': True, 'pad_vocab_size_multiple': 1, 'tie_embeddings': False}\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n[/usr/local/lib/python3.10/dist-packages/simple_parsing/helpers/serialization/serializable.py](https://localhost:8080/#) in from_dict(cls, d, drop_extra_fields)\r\n    896     try:\r\n--> 897         instance = cls(**init_args)  # type: ignore\r\n    898     except TypeError as e:\r\n\r\nTypeError: TransformerArgs.__init__() missing 5 required positional arguments: 'head_dim', 'hidden_dim', 'n_heads', 'n_kv_heads', and 'norm_eps'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nRuntimeError                              Traceback (most recent call last)\r\n3 frames\r\n[<ipython-input-3-8c814f063ac4>](https://localhost:8080/#) in <cell line: 17>()\r\n     15 tokens = mistral_tokenizer.encode_chat_completion(completion_request).tokens\r\n     16 # load model\r\n---> 17 model = Transformer.from_folder(\"/content/mistral_models/mamba-codestral\")\r\n     18 # generate results\r\n     19 out_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=mistral_tokenizer.instruct_tokenizer.tokenizer.eos_id)\r\n\r\n[/usr/local/lib/python3.10/dist-packages/mistral_inference/transformer.py](https://localhost:8080/#) in from_folder(folder, max_batch_size, num_pipeline_ranks, device, dtype)\r\n    260     ) -> \"Transformer\":\r\n    261         with open(Path(folder) / \"params.json\", \"r\") as f:\r\n--> 262             model_args = TransformerArgs.from_dict(json.load(f))\r\n    263         model_args.max_batch_size = max_batch_size\r\n    264         if num_pipeline_ranks > 1:\r\n\r\n[/usr/local/lib/python3.10/dist-packages/simple_parsing/helpers/serialization/serializable.py](https://localhost:8080/#) in from_dict(cls, obj, drop_extra_fields)\r\n    252         Passing `drop_extra_fields=False` forces the above-mentioned behaviour.\r\n    253         \"\"\"\r\n--> 254         return from_dict(cls, obj, drop_extra_fields=drop_extra_fields)\r\n    255 \r\n    256     def dump(self, fp: IO[str], dump_fn: DumpFn = json.dump) -> None:\r\n\r\n[/usr/local/lib/python3.10/dist-packages/simple_parsing/helpers/serialization/serializable.py](https://localhost:8080/#) in from_dict(cls, d, drop_extra_fields)\r\n    898     except TypeError as e:\r\n    899         # raise RuntimeError(f\"Couldn't instantiate class {cls} using init args {init_args}.\")\r\n--> 900         raise RuntimeError(\r\n    901             f\"Couldn't instantiate class {cls} using init args {init_args.keys()}: {e}\"\r\n    902         )\r\n\r\nRuntimeError: Couldn't instantiate class <class 'mistral_inference.args.TransformerArgs'> using init args dict_keys(['dim', 'n_layers', 'vocab_size', 'model_type']): TransformerArgs.__init__() missing 5 required positional arguments: 'head_dim', 'hidden_dim', 'n_heads', 'n_kv_heads', and 'norm_eps'\r\n```\r\n\n\n### Expected Behavior\n\nExpect the answer from the mamba-codestral to my query\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/221/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/221/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/220",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/220/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/220/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/220/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/220",
    "id": 2539103202,
    "node_id": "I_kwDOKY_97s6XV6Pi",
    "number": 220,
    "title": "[BUG: TypeError: generate_mamba() takes 2 positional arguments but 3 positional arguments were given",
    "user": {
      "login": "NM5035",
      "id": 147505733,
      "node_id": "U_kgDOCMrCRQ",
      "avatar_url": "https://avatars.githubusercontent.com/u/147505733?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/NM5035",
      "html_url": "https://github.com/NM5035",
      "followers_url": "https://api.github.com/users/NM5035/followers",
      "following_url": "https://api.github.com/users/NM5035/following{/other_user}",
      "gists_url": "https://api.github.com/users/NM5035/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/NM5035/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/NM5035/subscriptions",
      "organizations_url": "https://api.github.com/users/NM5035/orgs",
      "repos_url": "https://api.github.com/users/NM5035/repos",
      "events_url": "https://api.github.com/users/NM5035/events{/privacy}",
      "received_events_url": "https://api.github.com/users/NM5035/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-09-20T15:31:01Z",
    "updated_at": "2025-06-13T08:45:09Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\r\n\r\n```shell\r\nPython 3.10\r\n```\r\n\r\n\r\n### Pip Freeze\r\n\r\n```shell\r\nabsl-py==1.4.0\r\naccelerate==0.34.2\r\naiohappyeyeballs==2.4.0\r\naiohttp==3.10.5\r\naiosignal==1.3.1\r\nalabaster==0.7.16\r\nalbucore==0.0.15\r\nalbumentations==1.4.15\r\naltair==4.2.2\r\nannotated-types==0.7.0\r\nanyio==3.7.1\r\nargon2-cffi==23.1.0\r\nargon2-cffi-bindings==21.2.0\r\narray_record==0.5.1\r\narviz==0.19.0\r\nastropy==6.1.3\r\nastropy-iers-data==0.2024.9.16.0.32.21\r\nastunparse==1.6.3\r\nasync-timeout==4.0.3\r\natpublic==4.1.0\r\nattrs==24.2.0\r\naudioread==3.0.1\r\nautograd==1.7.0\r\nbabel==2.16.0\r\nbackcall==0.2.0\r\nbeautifulsoup4==4.12.3\r\nbidict==0.23.1\r\nbigframes==1.17.0\r\nbigquery-magics==0.2.0\r\nbleach==6.1.0\r\nblinker==1.4\r\nblis==0.7.11\r\nblosc2==2.0.0\r\nbokeh==3.4.3\r\nbqplot==0.12.43\r\nbranca==0.7.2\r\nbuild==1.2.2\r\nCacheControl==0.14.0\r\ncachetools==5.5.0\r\ncatalogue==2.0.10\r\ncausal-conv1d==1.4.0\r\ncertifi==2024.8.30\r\ncffi==1.17.1\r\nchardet==5.2.0\r\ncharset-normalizer==3.3.2\r\nchex==0.1.86\r\nclarabel==0.9.0\r\nclick==8.1.7\r\ncloudpathlib==0.19.0\r\ncloudpickle==2.2.1\r\ncmake==3.30.3\r\ncmdstanpy==1.2.4\r\ncolorcet==3.1.0\r\ncolorlover==0.3.0\r\ncolour==0.1.5\r\ncommunity==1.0.0b1\r\nconfection==0.1.5\r\ncons==0.4.6\r\ncontextlib2==21.6.0\r\ncontourpy==1.3.0\r\ncryptography==43.0.1\r\ncuda-python==12.2.1\r\ncudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.4.1-cp310-cp310-manylinux_2_28_x86_64.whl#sha256=57366e7ef09dc63e0b389aff20df6c37d91e2790065861ee31a4720149f5b694\r\ncufflinks==0.17.3\r\ncupy-cuda12x==12.2.0\r\ncvxopt==1.3.2\r\ncvxpy==1.5.3\r\ncycler==0.12.1\r\ncymem==2.0.8\r\nCython==3.0.11\r\ndask==2024.8.0\r\ndatascience==0.17.6\r\ndb-dtypes==1.3.0\r\ndbus-python==1.2.18\r\ndebugpy==1.6.6\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\ndistributed==2024.8.0\r\ndistro==1.7.0\r\ndlib==19.24.2\r\ndm-tree==0.1.8\r\ndocstring_parser==0.16\r\ndocutils==0.18.1\r\ndopamine_rl==4.0.9\r\nduckdb==1.1.0\r\nearthengine-api==1.0.0\r\neasydict==1.13\r\necos==2.0.14\r\neditdistance==0.8.1\r\neerepr==0.0.4\r\neinops==0.8.0\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\r\nentrypoints==0.4\r\net-xmlfile==1.1.0\r\netils==1.9.4\r\netuples==0.3.9\r\neval_type_backport==0.2.0\r\nexceptiongroup==1.2.2\r\nfastai==2.7.17\r\nfastcore==1.7.8\r\nfastdownload==0.0.7\r\nfastjsonschema==2.20.0\r\nfastprogress==1.0.3\r\nfastrlock==0.8.2\r\nfilelock==3.16.0\r\nfire==0.6.0\r\nfirebase-admin==6.5.0\r\nFlask==2.2.5\r\nflatbuffers==24.3.25\r\nflax==0.8.4\r\nfolium==0.17.0\r\nfonttools==4.53.1\r\nfrozendict==2.4.4\r\nfrozenlist==1.4.1\r\nfsspec==2024.6.1\r\nfuture==1.0.0\r\ngast==0.6.0\r\ngcsfs==2024.6.1\r\nGDAL==3.6.4\r\ngdown==5.1.0\r\ngeemap==0.34.1\r\ngensim==4.3.3\r\ngeocoder==1.38.1\r\ngeographiclib==2.0\r\ngeopandas==1.0.1\r\ngeopy==2.4.1\r\ngin-config==0.5.0\r\nglob2==0.7\r\ngoogle==2.0.3\r\ngoogle-ai-generativelanguage==0.6.6\r\ngoogle-api-core==2.19.2\r\ngoogle-api-python-client==2.137.0\r\ngoogle-auth==2.27.0\r\ngoogle-auth-httplib2==0.2.0\r\ngoogle-auth-oauthlib==1.2.1\r\ngoogle-cloud-aiplatform==1.66.0\r\ngoogle-cloud-bigquery==3.25.0\r\ngoogle-cloud-bigquery-connection==1.15.5\r\ngoogle-cloud-bigquery-storage==2.26.0\r\ngoogle-cloud-bigtable==2.26.0\r\ngoogle-cloud-core==2.4.1\r\ngoogle-cloud-datastore==2.19.0\r\ngoogle-cloud-firestore==2.16.1\r\ngoogle-cloud-functions==1.16.5\r\ngoogle-cloud-iam==2.15.2\r\ngoogle-cloud-language==2.13.4\r\ngoogle-cloud-pubsub==2.23.1\r\ngoogle-cloud-resource-manager==1.12.5\r\ngoogle-cloud-storage==2.8.0\r\ngoogle-cloud-translate==3.15.5\r\ngoogle-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz#sha256=e86f433b6968bdd1e17b9e4cf8e0b4f105b3f6a409ffcd410336d06853a81096\r\ngoogle-crc32c==1.6.0\r\ngoogle-generativeai==0.7.2\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==2.7.2\r\ngoogleapis-common-protos==1.65.0\r\ngoogledrivedownloader==0.4\r\ngraphviz==0.20.3\r\ngreenlet==3.1.0\r\ngrpc-google-iam-v1==0.13.1\r\ngrpcio==1.64.1\r\ngrpcio-status==1.48.2\r\ngspread==6.0.2\r\ngspread-dataframe==3.3.1\r\ngym==0.25.2\r\ngym-notices==0.0.8\r\nh5netcdf==1.3.0\r\nh5py==3.11.0\r\nholidays==0.57\r\nholoviews==1.19.1\r\nhtml5lib==1.1\r\nhttpimport==1.4.0\r\nhttplib2==0.22.0\r\nhuggingface-hub==0.24.7\r\nhumanize==4.10.0\r\nhyperopt==0.2.7\r\nibis-framework==8.0.0\r\nidna==3.10\r\nimageio==2.35.1\r\nimageio-ffmpeg==0.5.1\r\nimagesize==1.4.1\r\nimbalanced-learn==0.12.3\r\nimgaug==0.4.0\r\nimmutabledict==4.2.0\r\nimportlib_metadata==8.5.0\r\nimportlib_resources==6.4.5\r\nimutils==0.5.4\r\ninflect==7.4.0\r\niniconfig==2.0.0\r\nintel-cmplr-lib-ur==2024.2.1\r\nintel-openmp==2024.2.1\r\nipyevents==2.0.2\r\nipyfilechooser==0.6.0\r\nipykernel==5.5.6\r\nipyleaflet==0.19.2\r\nipyparallel==8.8.0\r\nipython==7.34.0\r\nipython-genutils==0.2.0\r\nipython-sql==0.5.0\r\nipytree==0.2.2\r\nipywidgets==7.7.1\r\nitsdangerous==2.2.0\r\njax==0.4.26\r\njaxlib @ https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.26+cuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl#sha256=813cf1fe3e7ca4dbf5327d6e7b4fc8521e92d8bba073ee645ae0d5d036a25750\r\njeepney==0.7.1\r\njellyfish==1.1.0\r\njieba==0.42.1\r\nJinja2==3.1.4\r\njoblib==1.4.2\r\njsonpickle==3.3.0\r\njsonschema==4.23.0\r\njsonschema-specifications==2023.12.1\r\njupyter-client==6.1.12\r\njupyter-console==6.1.0\r\njupyter-leaflet==0.19.2\r\njupyter-server==1.24.0\r\njupyter_core==5.7.2\r\njupyterlab_pygments==0.3.0\r\njupyterlab_widgets==3.0.13\r\nkaggle==1.6.17\r\nkagglehub==0.2.9\r\nkeras==3.4.1\r\nkeyring==23.5.0\r\nkiwisolver==1.4.7\r\nlangcodes==3.4.0\r\nlanguage_data==1.2.0\r\nlaunchpadlib==1.10.16\r\nlazr.restfulclient==0.14.4\r\nlazr.uri==1.0.6\r\nlazy_loader==0.4\r\nlibclang==18.1.1\r\nlibrosa==0.10.2.post1\r\nlightgbm==4.5.0\r\nlinkify-it-py==2.0.3\r\nllvmlite==0.43.0\r\nlocket==1.0.0\r\nlogical-unification==0.4.6\r\nlxml==4.9.4\r\nmamba-ssm==2.2.2\r\nmarisa-trie==1.2.0\r\nMarkdown==3.7\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.5\r\nmatplotlib==3.7.1\r\nmatplotlib-inline==0.1.7\r\nmatplotlib-venn==1.1.1\r\nmdit-py-plugins==0.4.2\r\nmdurl==0.1.2\r\nminiKanren==1.0.3\r\nmissingno==0.5.2\r\nmistral_common==1.4.2\r\nmistral_inference==1.4.0\r\nmistune==0.8.4\r\nmizani==0.11.4\r\nmkl==2024.2.2\r\nml-dtypes==0.4.1\r\nmlxtend==0.23.1\r\nmore-itertools==10.5.0\r\nmoviepy==1.0.3\r\nmpmath==1.3.0\r\nmsgpack==1.0.8\r\nmultidict==6.1.0\r\nmultipledispatch==1.0.0\r\nmultitasking==0.0.11\r\nmurmurhash==1.0.10\r\nmusic21==9.1.0\r\nnamex==0.0.8\r\nnatsort==8.4.0\r\nnbclassic==1.1.0\r\nnbclient==0.10.0\r\nnbconvert==6.5.4\r\nnbformat==5.10.4\r\nnest-asyncio==1.6.0\r\nnetworkx==3.3\r\nnibabel==5.2.1\r\nninja==1.11.1.1\r\nnltk==3.8.1\r\nnotebook==6.5.5\r\nnotebook_shim==0.2.4\r\nnumba==0.60.0\r\nnumexpr==2.10.1\r\nnumpy==1.26.4\r\nnvidia-nccl-cu12==2.23.4\r\nnvtx==0.2.10\r\noauth2client==4.1.3\r\noauthlib==3.2.2\r\nopencv-contrib-python==4.10.0.84\r\nopencv-python==4.10.0.84\r\nopencv-python-headless==4.10.0.84\r\nopenpyxl==3.1.5\r\nopt-einsum==3.3.0\r\noptax==0.2.2\r\noptree==0.12.1\r\norbax-checkpoint==0.6.4\r\nosqp==0.6.7.post0\r\npackaging==24.1\r\npandas==2.1.4\r\npandas-datareader==0.10.0\r\npandas-gbq==0.23.1\r\npandas-stubs==2.1.4.231227\r\npandocfilters==1.5.1\r\npanel==1.4.5\r\nparam==2.1.1\r\nparso==0.8.4\r\nparsy==2.1\r\npartd==1.4.2\r\npathlib==1.0.1\r\npatsy==0.5.6\r\npeewee==3.17.6\r\npexpect==4.9.0\r\npickleshare==0.7.5\r\npillow==10.4.0\r\npip-tools==7.4.1\r\nplatformdirs==4.3.4\r\nplotly==5.15.0\r\nplotnine==0.13.6\r\npluggy==1.5.0\r\npolars==1.6.0\r\npooch==1.8.2\r\nportpicker==1.5.2\r\nprefetch_generator==1.0.3\r\npreshed==3.0.9\r\nprettytable==3.11.0\r\nproglog==0.1.10\r\nprogressbar2==4.5.0\r\nprometheus_client==0.20.0\r\npromise==2.3\r\nprompt_toolkit==3.0.47\r\nprophet==1.1.5\r\nproto-plus==1.24.0\r\nprotobuf==3.20.3\r\npsutil==5.9.5\r\npsycopg2==2.9.9\r\nptyprocess==0.7.0\r\npy-cpuinfo==9.0.0\r\npy4j==0.10.9.7\r\npyarrow==14.0.2\r\npyarrow-hotfix==0.6\r\npyasn1==0.6.1\r\npyasn1_modules==0.4.1\r\npycocotools==2.0.8\r\npycparser==2.22\r\npydantic==2.9.2\r\npydantic_core==2.23.4\r\npydata-google-auth==1.8.2\r\npydot==3.0.1\r\npydot-ng==2.0.0\r\npydotplus==2.0.2\r\nPyDrive==1.3.1\r\nPyDrive2==1.20.0\r\npyerfa==2.0.1.4\r\npygame==2.6.0\r\nPygments==2.18.0\r\nPyGObject==3.42.1\r\nPyJWT==2.9.0\r\npymc==5.16.2\r\npymystem3==0.2.0\r\npynvjitlink-cu12==0.3.0\r\npyogrio==0.9.0\r\nPyOpenGL==3.1.7\r\npyOpenSSL==24.2.1\r\npyparsing==3.1.4\r\npyperclip==1.9.0\r\npyproj==3.6.1\r\npyproject_hooks==1.1.0\r\npyshp==2.3.1\r\nPySocks==1.7.1\r\npytensor==2.25.4\r\npytest==7.4.4\r\npython-apt==2.4.0\r\npython-box==7.2.0\r\npython-dateutil==2.8.2\r\npython-louvain==0.16\r\npython-slugify==8.0.4\r\npython-utils==3.8.2\r\npytz==2024.2\r\npyviz_comms==3.0.3\r\nPyYAML==6.0.2\r\npyzmq==24.0.1\r\nqdldl==0.1.7.post4\r\nratelim==0.1.6\r\nreferencing==0.35.1\r\nregex==2024.9.11\r\nrequests==2.32.3\r\nrequests-oauthlib==1.3.1\r\nrequirements-parser==0.9.0\r\nrich==13.8.1\r\nrmm-cu12==24.4.0\r\nrpds-py==0.20.0\r\nrpy2==3.4.2\r\nrsa==4.9\r\nsafetensors==0.4.5\r\nscikit-image==0.23.2\r\nscikit-learn==1.3.2\r\nscipy==1.13.1\r\nscooby==0.10.0\r\nscs==3.2.7\r\nseaborn==0.13.1\r\nSecretStorage==3.3.1\r\nSend2Trash==1.8.3\r\nsentencepiece==0.2.0\r\nshapely==2.0.6\r\nshellingham==1.5.4\r\nsimple-parsing==0.1.6\r\nsix==1.16.0\r\nsklearn-pandas==2.2.0\r\nsmart-open==7.0.4\r\nsniffio==1.3.1\r\nsnowballstemmer==2.2.0\r\nsortedcontainers==2.4.0\r\nsoundfile==0.12.1\r\nsoupsieve==2.6\r\nsoxr==0.5.0.post1\r\nspacy==3.7.6\r\nspacy-legacy==3.0.12\r\nspacy-loggers==1.0.5\r\nSphinx==5.0.2\r\nsphinxcontrib-applehelp==2.0.0\r\nsphinxcontrib-devhelp==2.0.0\r\nsphinxcontrib-htmlhelp==2.1.0\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==2.0.0\r\nsphinxcontrib-serializinghtml==2.0.0\r\nSQLAlchemy==2.0.35\r\nsqlglot==20.11.0\r\nsqlparse==0.5.1\r\nsrsly==2.4.8\r\nstanio==0.5.1\r\nstatsmodels==0.14.3\r\nStrEnum==0.4.15\r\nsympy==1.13.2\r\ntables==3.8.0\r\ntabulate==0.9.0\r\ntbb==2021.13.1\r\ntblib==3.0.0\r\ntenacity==9.0.0\r\ntensorboard==2.17.0\r\ntensorboard-data-server==0.7.2\r\ntensorflow==2.17.0\r\ntensorflow-datasets==4.9.6\r\ntensorflow-hub==0.16.1\r\ntensorflow-io-gcs-filesystem==0.37.1\r\ntensorflow-metadata==1.15.0\r\ntensorflow-probability==0.24.0\r\ntensorstore==0.1.65\r\ntermcolor==2.4.0\r\nterminado==0.18.1\r\ntext-unidecode==1.3\r\ntextblob==0.17.1\r\ntf-slim==1.1.0\r\ntf_keras==2.17.0\r\nthinc==8.2.5\r\nthreadpoolctl==3.5.0\r\ntifffile==2024.8.30\r\ntiktoken==0.7.0\r\ntinycss2==1.3.0\r\ntokenizers==0.19.1\r\ntoml==0.10.2\r\ntomli==2.0.1\r\ntoolz==0.12.1\r\ntorch @ https://download.pytorch.org/whl/cu121_full/torch-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=f3ed9a2b7f8671b2b32a2f036d1b81055eb3ad9b18ba43b705aa34bae4289e1a\r\ntorchaudio @ https://download.pytorch.org/whl/cu121_full/torchaudio-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=da8c87c80a1c1376a48dc33eef30b03bbdf1df25a05bd2b1c620b8811c7b19be\r\ntorchsummary==1.5.1\r\ntorchvision @ https://download.pytorch.org/whl/cu121_full/torchvision-0.19.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=b8cc4bf381b75522995b601e07a1b433b5fd925dc3e34a7fa6cd22f449d65379\r\ntornado==6.3.3\r\ntqdm==4.66.5\r\ntraitlets==5.7.1\r\ntraittypes==0.2.1\r\ntransformers==4.44.2\r\ntriton==3.0.0\r\ntweepy==4.14.0\r\ntypeguard==4.3.0\r\ntyper==0.12.5\r\ntypes-pytz==2024.2.0.20240913\r\ntypes-setuptools==75.1.0.20240917\r\ntyping_extensions==4.12.2\r\ntzdata==2024.1\r\ntzlocal==5.2\r\nuc-micro-py==1.0.3\r\nuritemplate==4.1.1\r\nurllib3==2.0.7\r\nvega-datasets==0.9.0\r\nwadllib==1.3.6\r\nwasabi==1.1.3\r\nwcwidth==0.2.13\r\nweasel==0.4.1\r\nwebcolors==24.8.0\r\nwebencodings==0.5.1\r\nwebsocket-client==1.8.0\r\nWerkzeug==3.0.4\r\nwidgetsnbextension==3.6.9\r\nwordcloud==1.9.3\r\nwrapt==1.16.0\r\nxarray==2024.9.0\r\nxarray-einstats==0.7.0\r\nxformers==0.0.28.post1\r\nxgboost==2.1.1\r\nxlrd==2.0.1\r\nxyzservices==2024.9.0\r\nyarl==1.11.1\r\nyellowbrick==1.5\r\nyfinance==0.2.43\r\nzict==3.0.0\r\nzipp==3.20.2\r\n```\r\n\r\n\r\n### Reproduction Steps\r\n\r\n1. I install pip install mamba_ssm causal-conv1d\r\n2. Apply the [Fix issue 496 #501]: https://github.com/state-spaces/mamba/pull/501\r\n3. Load this model locally in content diredctory in colab env : mistralai/Mamba-Codestral-7B-v0.1\r\n4. mistral-chat ./mistral_models/mamba-codestral --instruct --max_tokens 256\r\n5. Prompt: \r\n6. expect answer from the model but got this error:\r\n\r\n/content# mistral-chat ./mistral_models/mamba-codestral --instruct --max_tokens 256\r\nPrompt: Hi\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/mistral-chat\", line 8, in <module>\r\n    sys.exit(mistral_chat())\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/main.py\", line 259, in mistral_chat\r\n    fire.Fire(interactive)\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 143, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 477, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 693, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/main.py\", line 172, in interactive\r\n    generated_tokens, _ = generate_fn(  # type: ignore[operator]\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\r\n    return func(*args, **kwargs)\r\nTypeError: generate_mamba() takes 2 positional arguments but 3 positional arguments (and 3 keyword-only arguments) were given\r\n\r\n### Expected Behavior\r\n\r\nI expect an answer from the model once entering a prompt but got the error described above\r\n\r\n### Additional Context\r\nOnce I installed mistral_inference to explore the inference of mistralai/Mamba-Codestral-7B-v0.1 using Misral-Chat CLI \r\n\r\n_No response_\r\n\r\n### Suggested Solutions\r\n\r\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/220/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/220/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/219",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/219/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/219/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/219/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/219",
    "id": 2537672690,
    "node_id": "PR_kwDOKY_97s58G55s",
    "number": 219,
    "title": "Pixtral 12B",
    "user": {
      "login": "devendrachaplot",
      "id": 1102621,
      "node_id": "MDQ6VXNlcjExMDI2MjE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1102621?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/devendrachaplot",
      "html_url": "https://github.com/devendrachaplot",
      "followers_url": "https://api.github.com/users/devendrachaplot/followers",
      "following_url": "https://api.github.com/users/devendrachaplot/following{/other_user}",
      "gists_url": "https://api.github.com/users/devendrachaplot/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/devendrachaplot/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/devendrachaplot/subscriptions",
      "organizations_url": "https://api.github.com/users/devendrachaplot/orgs",
      "repos_url": "https://api.github.com/users/devendrachaplot/repos",
      "events_url": "https://api.github.com/users/devendrachaplot/events{/privacy}",
      "received_events_url": "https://api.github.com/users/devendrachaplot/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-09-20T02:04:29Z",
    "updated_at": "2024-09-20T07:45:01Z",
    "closed_at": "2024-09-20T07:45:01Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/219",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/219",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/219.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/219.patch",
      "merged_at": "2024-09-20T07:45:01Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/219/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/219/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/218",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/218/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/218/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/218/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/218",
    "id": 2533972152,
    "node_id": "PR_kwDOKY_97s576g_i",
    "number": 218,
    "title": "[fix] Correctly pass mask in TransformerBlock.forward in transformer_layers.py",
    "user": {
      "login": "MarcSzafraniec",
      "id": 13677476,
      "node_id": "MDQ6VXNlcjEzNjc3NDc2",
      "avatar_url": "https://avatars.githubusercontent.com/u/13677476?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/MarcSzafraniec",
      "html_url": "https://github.com/MarcSzafraniec",
      "followers_url": "https://api.github.com/users/MarcSzafraniec/followers",
      "following_url": "https://api.github.com/users/MarcSzafraniec/following{/other_user}",
      "gists_url": "https://api.github.com/users/MarcSzafraniec/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/MarcSzafraniec/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/MarcSzafraniec/subscriptions",
      "organizations_url": "https://api.github.com/users/MarcSzafraniec/orgs",
      "repos_url": "https://api.github.com/users/MarcSzafraniec/repos",
      "events_url": "https://api.github.com/users/MarcSzafraniec/events{/privacy}",
      "received_events_url": "https://api.github.com/users/MarcSzafraniec/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-09-18T14:53:37Z",
    "updated_at": "2024-09-18T15:28:45Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/218",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/218",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/218.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/218.patch",
      "merged_at": null
    },
    "body": "The attention mask was not passed correctly to the `Attention` in `TransformerBlock.forward`.\r\n\r\nOne problem it caused was that when passing two images in the image encoder, the attention would be done on all images at the same time, thus taking more resources and returning an incorrect result.\r\n\r\nThis PR fixes this problem.\r\nTested by passing two images separately to the encoder, and checking that passing them as a batch gives \"almost\" the same thing.\r\nAlso tested on classic vision benchmarks where the results were very low (and inference very slow), now considerably better:\r\nImageNet KNN:\r\n- was 7.27% accuracy and took 5h\r\n- now is 63.79% accuracy and takes 35 min (8.6 times faster)\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/218/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/218/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/217",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/217/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/217/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/217/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/217",
    "id": 2524619651,
    "node_id": "PR_kwDOKY_97s57bFyy",
    "number": 217,
    "title": "Pixtral",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-09-13T11:36:53Z",
    "updated_at": "2024-09-13T12:46:35Z",
    "closed_at": "2024-09-13T12:46:35Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/217",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/217",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/217.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/217.patch",
      "merged_at": "2024-09-13T12:46:35Z"
    },
    "body": "Add Pixtral",
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/217/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/217/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/216",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/216/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/216/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/216/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/216",
    "id": 2491911499,
    "node_id": "PR_kwDOKY_97s55s4fC",
    "number": 216,
    "title": "Fix device error when using cuda device other than cuda:0",
    "user": {
      "login": "cornzz",
      "id": 39997278,
      "node_id": "MDQ6VXNlcjM5OTk3Mjc4",
      "avatar_url": "https://avatars.githubusercontent.com/u/39997278?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cornzz",
      "html_url": "https://github.com/cornzz",
      "followers_url": "https://api.github.com/users/cornzz/followers",
      "following_url": "https://api.github.com/users/cornzz/following{/other_user}",
      "gists_url": "https://api.github.com/users/cornzz/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cornzz/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cornzz/subscriptions",
      "organizations_url": "https://api.github.com/users/cornzz/orgs",
      "repos_url": "https://api.github.com/users/cornzz/repos",
      "events_url": "https://api.github.com/users/cornzz/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cornzz/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-08-28T12:13:12Z",
    "updated_at": "2024-08-29T11:17:24Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/216",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/216",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/216.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/216.patch",
      "merged_at": null
    },
    "body": "Fixes https://github.com/mistralai/mistral-inference/issues/215\r\n\r\nAttention bias was being created on cuda:0 regardless of the selected cuda device as the correct device was not being passed to `from_seqlens()` in `BufferCache.get_input_metadata()`",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/216/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/216/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/215",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/215/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/215/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/215/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/215",
    "id": 2491837370,
    "node_id": "I_kwDOKY_97s6Uhmu6",
    "number": 215,
    "title": "[BUG] Device error when running on other cuda device than cuda:0 ",
    "user": {
      "login": "cornzz",
      "id": 39997278,
      "node_id": "MDQ6VXNlcjM5OTk3Mjc4",
      "avatar_url": "https://avatars.githubusercontent.com/u/39997278?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cornzz",
      "html_url": "https://github.com/cornzz",
      "followers_url": "https://api.github.com/users/cornzz/followers",
      "following_url": "https://api.github.com/users/cornzz/following{/other_user}",
      "gists_url": "https://api.github.com/users/cornzz/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cornzz/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cornzz/subscriptions",
      "organizations_url": "https://api.github.com/users/cornzz/orgs",
      "repos_url": "https://api.github.com/users/cornzz/repos",
      "events_url": "https://api.github.com/users/cornzz/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cornzz/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-08-28T11:36:23Z",
    "updated_at": "2024-08-28T12:14:53Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\r\n\r\n```shell\r\nPython 3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]\r\n```\r\n\r\n\r\n### Pip Freeze\r\n<details>\r\n  <summary>conda env export</summary>\r\n\r\n```shell\r\nname: test\r\nchannels:\r\n  - defaults\r\ndependencies:\r\n  - _libgcc_mutex=0.1=main\r\n  - _openmp_mutex=5.1=1_gnu\r\n  - asttokens=2.0.5=pyhd3eb1b0_0\r\n  - bzip2=1.0.8=h5eee18b_6\r\n  - ca-certificates=2024.7.2=h06a4308_0\r\n  - comm=0.2.1=py311h06a4308_0\r\n  - debugpy=1.6.7=py311h6a678d5_0\r\n  - decorator=5.1.1=pyhd3eb1b0_0\r\n  - executing=0.8.3=pyhd3eb1b0_0\r\n  - ipykernel=6.28.0=py311h06a4308_0\r\n  - ipython=8.25.0=py311h06a4308_0\r\n  - jedi=0.19.1=py311h06a4308_0\r\n  - jupyter_client=8.6.0=py311h06a4308_0\r\n  - jupyter_core=5.7.2=py311h06a4308_0\r\n  - ld_impl_linux-64=2.38=h1181459_1\r\n  - libffi=3.4.4=h6a678d5_1\r\n  - libgcc-ng=11.2.0=h1234567_1\r\n  - libgomp=11.2.0=h1234567_1\r\n  - libsodium=1.0.18=h7b6447c_0\r\n  - libstdcxx-ng=11.2.0=h1234567_1\r\n  - libuuid=1.41.5=h5eee18b_0\r\n  - matplotlib-inline=0.1.6=py311h06a4308_0\r\n  - ncurses=6.4=h6a678d5_0\r\n  - nest-asyncio=1.6.0=py311h06a4308_0\r\n  - openssl=3.0.14=h5eee18b_0\r\n  - packaging=24.1=py311h06a4308_0\r\n  - parso=0.8.3=pyhd3eb1b0_0\r\n  - pexpect=4.8.0=pyhd3eb1b0_3\r\n  - pip=24.2=py311h06a4308_0\r\n  - platformdirs=3.10.0=py311h06a4308_0\r\n  - prompt-toolkit=3.0.43=py311h06a4308_0\r\n  - prompt_toolkit=3.0.43=hd3eb1b0_0\r\n  - ptyprocess=0.7.0=pyhd3eb1b0_2\r\n  - pure_eval=0.2.2=pyhd3eb1b0_0\r\n  - pygments=2.15.1=py311h06a4308_1\r\n  - python=3.11.9=h955ad1f_0\r\n  - python-dateutil=2.9.0post0=py311h06a4308_2\r\n  - pyzmq=25.1.2=py311h6a678d5_0\r\n  - readline=8.2=h5eee18b_0\r\n  - setuptools=72.1.0=py311h06a4308_0\r\n  - six=1.16.0=pyhd3eb1b0_1\r\n  - sqlite=3.45.3=h5eee18b_0\r\n  - stack_data=0.2.0=pyhd3eb1b0_0\r\n  - tk=8.6.14=h39e8969_0\r\n  - tornado=6.4.1=py311h5eee18b_0\r\n  - traitlets=5.14.3=py311h06a4308_0\r\n  - typing_extensions=4.11.0=py311h06a4308_0\r\n  - wcwidth=0.2.5=pyhd3eb1b0_0\r\n  - wheel=0.43.0=py311h06a4308_0\r\n  - xz=5.4.6=h5eee18b_1\r\n  - zeromq=4.3.5=h6a678d5_0\r\n  - zlib=1.2.13=h5eee18b_1\r\n  - pip:\r\n      - accelerate==0.33.0\r\n      - aiohappyeyeballs==2.4.0\r\n      - aiohttp==3.10.5\r\n      - aiosignal==1.3.1\r\n      - annotated-types==0.7.0\r\n      - anyio==4.4.0\r\n      - attrs==24.2.0\r\n      - certifi==2024.7.4\r\n      - charset-normalizer==3.3.2\r\n      - click==8.1.7\r\n      - datasets==2.21.0\r\n      - dill==0.3.8\r\n      - distro==1.9.0\r\n      - docstring-parser==0.16\r\n      - evaluate==0.4.2\r\n      - filelock==3.15.4\r\n      - fire==0.6.0\r\n      - frozenlist==1.4.1\r\n      - fsspec==2024.6.1\r\n      - fuzzywuzzy==0.18.0\r\n      - h11==0.14.0\r\n      - httpcore==1.0.5\r\n      - httpx==0.27.1\r\n      - huggingface-hub==0.24.5\r\n      - idna==3.7\r\n      - jieba==0.42.1\r\n      - jinja2==3.1.4\r\n      - jiter==0.5.0\r\n      - joblib==1.4.2\r\n      - jsonschema==4.23.0\r\n      - jsonschema-specifications==2023.12.1\r\n      - llmlingua==0.2.2\r\n      - markupsafe==2.1.5\r\n      - mistral-common==1.3.4\r\n      - mistral-inference==1.3.1\r\n      - mpmath==1.3.0\r\n      - multidict==6.0.5\r\n      - multiprocess==0.70.16\r\n      - networkx==3.3\r\n      - nltk==3.8.1\r\n      - numpy==1.26.4\r\n      - nvidia-cublas-cu12==12.1.3.1\r\n      - nvidia-cuda-cupti-cu12==12.1.105\r\n      - nvidia-cuda-nvrtc-cu12==12.1.105\r\n      - nvidia-cuda-runtime-cu12==12.1.105\r\n      - nvidia-cudnn-cu12==9.1.0.70\r\n      - nvidia-cufft-cu12==11.0.2.54\r\n      - nvidia-curand-cu12==10.3.2.106\r\n      - nvidia-cusolver-cu12==11.4.5.107\r\n      - nvidia-cusparse-cu12==12.1.0.106\r\n      - nvidia-nccl-cu12==2.20.5\r\n      - nvidia-nvjitlink-cu12==12.6.20\r\n      - nvidia-nvtx-cu12==12.1.105\r\n      - openai==1.42.0\r\n      - pandas==2.2.2\r\n      - psutil==6.0.0\r\n      - pyarrow==17.0.0\r\n      - pydantic==2.8.2\r\n      - pydantic-core==2.20.1\r\n      - pytz==2024.1\r\n      - pyyaml==6.0.2\r\n      - referencing==0.35.1\r\n      - regex==2024.7.24\r\n      - requests==2.32.3\r\n      - rouge==1.0.1\r\n      - rpds-py==0.20.0\r\n      - safetensors==0.4.4\r\n      - sentencepiece==0.2.0\r\n      - simple-parsing==0.1.5\r\n      - sniffio==1.3.1\r\n      - sympy==1.13.2\r\n      - termcolor==2.4.0\r\n      - tiktoken==0.7.0\r\n      - tokenizers==0.19.1\r\n      - torch==2.4.0\r\n      - tqdm==4.66.5\r\n      - transformers==4.44.0\r\n      - triton==3.0.0\r\n      - typing-extensions==4.12.2\r\n      - tzdata==2024.1\r\n      - urllib3==2.2.2\r\n      - xformers==0.0.27.post2\r\n      - xxhash==3.5.0\r\n      - yarl==1.9.4\r\nprefix: /home/test\r\n```\r\n\r\n</details>\r\n\r\n### Reproduction Steps\r\n\r\n```python\r\nfrom mistral_inference.transformer import Transformer\r\nfrom mistral_inference.generate import generate\r\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\r\n\r\nmodel = Transformer.from_folder(\"./models/mistral-7B-v0.1\", device=\"cuda:7\")\r\ntokenizer = MistralTokenizer.from_file(\"./models/mistral-7B-v0.1/tokenizer.model\").instruct_tokenizer.tokenizer\r\n\r\nprompt = \"What is the capital of germany? Answer:\"\r\ntokens = tokenizer.encode(prompt, bos=True, eos=False)\r\nout_tokens, logprobs = generate([tokens], model, max_tokens=50, temperature=0)\r\nresult = tokenizer.decode(out_tokens[0])\r\n```\r\n\r\n### Expected Behavior\r\n\r\nI am getting the following error when trying to run above code:\r\n\r\n```\r\nValueError: Attention bias and Query/Key/Value should be on the same device\r\n  query.device: cuda:7\r\n  attn_bias   : cuda:0\r\n```\r\n\r\nThis seems related to https://github.com/facebookresearch/xformers/issues/1064, couldn't figure out why this happens yet...\r\n\r\n### Additional Context\r\n\r\n<details>\r\n  <summary>Stack trace</summary>\r\n\r\n```\r\nFile \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/mistral_inference/generate.py\", line 82, in generate                       \r\n    prelogits = model.forward(                                                                                                                           \r\n                ^^^^^^^^^^^^^^                                                                                                                           \r\n  File \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/mistral_inference/transformer.py\", line 276, in forward                    \r\n    h = self.forward_partial(input_ids, seqlens, cache=cache)                                                                                            \r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                                                                            \r\n  File \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/mistral_inference/transformer.py\", line 258, in forward_partial            \r\n    h = layer(h, freqs_cis, cache_view)                                                                                                                  \r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                                                                                                  \r\n  File \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl              \r\n    return self._call_impl(*args, **kwargs)                                                                                                              \r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                                                                                              \r\n  File \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl                      \r\n    return forward_call(*args, **kwargs)                                                                                                                 \r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                                                                                                 \r\n  File \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/mistral_inference/transformer.py\", line 156, in forward                    \r\n    r = self.attention.forward(self.attention_norm(x), freqs_cis, cache)                                                                                 \r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                                                                 \r\n  File \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/mistral_inference/transformer.py\", line 100, in forward                    \r\n    output = memory_efficient_attention(xq, key, val, None if cache is None else cache.mask)                                                             \r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                                             \r\n  File \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py\", line 276, in memory_efficient_attention    \r\n    return _memory_efficient_attention(                                                                                                                  \r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                                                                                                  \r\n  File \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py\", line 395, in _memory_efficient_attention   \r\n    return _memory_efficient_attention_forward(                                                                                                          \r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                                                                                          \r\n  File \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py\", line 411, in _memory_efficient_attention_for\r\nward                                                                                                                                                     \r\n    inp.validate_inputs()                                                                                                                                \r\n  File \"/home/test/miniconda3/envs/test/lib/python3.11/site-packages/xformers/ops/fmha/common.py\", line 145, in validate_inputs                 \r\n    raise ValueError(\r\nValueError: Attention bias and Query/Key/Value should be on the same device\r\n  query.device: cuda:7\r\n  attn_bias   : cuda:0\r\n```\r\n\r\n</details>\r\n\r\n### Suggested Solutions\r\n\r\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/215/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/215/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/214",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/214/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/214/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/214/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/214",
    "id": 2478493719,
    "node_id": "PR_kwDOKY_97s55Akii",
    "number": 214,
    "title": "Fix generation not concluding when eos was hit for each prompt",
    "user": {
      "login": "cornzz",
      "id": 39997278,
      "node_id": "MDQ6VXNlcjM5OTk3Mjc4",
      "avatar_url": "https://avatars.githubusercontent.com/u/39997278?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cornzz",
      "html_url": "https://github.com/cornzz",
      "followers_url": "https://api.github.com/users/cornzz/followers",
      "following_url": "https://api.github.com/users/cornzz/following{/other_user}",
      "gists_url": "https://api.github.com/users/cornzz/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cornzz/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cornzz/subscriptions",
      "organizations_url": "https://api.github.com/users/cornzz/orgs",
      "repos_url": "https://api.github.com/users/cornzz/repos",
      "events_url": "https://api.github.com/users/cornzz/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cornzz/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-08-21T16:39:13Z",
    "updated_at": "2024-08-22T07:11:00Z",
    "closed_at": "2024-08-22T07:11:00Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/214",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/214",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/214.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/214.patch",
      "merged_at": "2024-08-22T07:11:00Z"
    },
    "body": "Fixes https://github.com/mistralai/mistral-inference/issues/180\r\n\r\nThe operation should be an OR, not XOR, since we do not want to change `is_finished` back to `False` once we encounter another eos token.\r\n\r\nExample why this change is needed:\r\n```python\r\nimport torch\r\ntokens = [\r\n    [28782,   28734,  28723,  13,     13,     5660],\r\n    [8430,    28723,  13,     13,     3195,   349]\r\n]\r\neos_id = 13\r\n\r\nis_finished = torch.tensor([False for _ in range(len(tokens))])\r\nfor a, b in zip(*tokens):\r\n    next_token = torch.tensor([[a, b]])\r\n    print(\" --- \\t\", next_token)\r\n    print(\"before:\\t\", is_finished)\r\n    is_finished = is_finished ^ (next_token == eos_id).cpu()\r\n    print(\"after:\\t\", is_finished, \"\\n\")\r\n    if is_finished.all():\r\n        print(\"finished!\")\r\n        break\r\n```\r\n\r\n<details>\r\n  <summary>Output</summary>\r\n\r\n```\r\n --- \t tensor([[28782,  8430]])\r\nbefore:\t tensor([False, False])\r\nafter:\t tensor([[False, False]]) \r\n\r\n --- \t tensor([[28734, 28723]])\r\nbefore:\t tensor([[False, False]])\r\nafter:\t tensor([[False, False]]) \r\n\r\n --- \t tensor([[28723,    13]])\r\nbefore:\t tensor([[False, False]])\r\nafter:\t tensor([[False,  True]]) \r\n\r\n --- \t tensor([[13, 13]])\r\nbefore:\t tensor([[False,  True]])\r\nafter:\t tensor([[ True, False]]) \r\n\r\n --- \t tensor([[  13, 3195]])\r\nbefore:\t tensor([[ True, False]])\r\nafter:\t tensor([[False, False]]) \r\n\r\n --- \t tensor([[5660,  349]])\r\nbefore:\t tensor([[False, False]])\r\nafter:\t tensor([[False, False]]) \r\n```\r\n</details>\r\n\r\nWith OR instead of XOR:\r\n```python\r\nimport torch\r\ntokens = [\r\n    [28782,   28734,  28723,  13,     13,     5660],\r\n    [8430,    28723,  13,     13,     3195,   349]\r\n]\r\neos_id = 13\r\n\r\nis_finished = torch.tensor([False for _ in range(len(tokens))])\r\nfor a, b in zip(*tokens):\r\n    next_token = torch.tensor([[a, b]])\r\n    print(\" --- \\t\", next_token)\r\n    print(\"before:\\t\", is_finished)\r\n    is_finished = is_finished | (next_token == eos_id).cpu()\r\n    print(\"after:\\t\", is_finished, \"\\n\")\r\n    if is_finished.all():\r\n        print(\"finished!\")\r\n        break\r\n```\r\n\r\n<details>\r\n<summary>Output:</summary>\r\n\r\n```\r\n --- \t tensor([[28782,  8430]])\r\nbefore:\t tensor([False, False])\r\nafter:\t tensor([[False, False]]) \r\n\r\n --- \t tensor([[28734, 28723]])\r\nbefore:\t tensor([[False, False]])\r\nafter:\t tensor([[False, False]]) \r\n\r\n --- \t tensor([[28723,    13]])\r\nbefore:\t tensor([[False, False]])\r\nafter:\t tensor([[False,  True]]) \r\n\r\n --- \t tensor([[13, 13]])\r\nbefore:\t tensor([[False,  True]])\r\nafter:\t tensor([[True, True]]) \r\n\r\nfinished!\r\n```\r\n</details>",
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/214/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/214/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/213",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/213/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/213/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/213/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/213",
    "id": 2477415185,
    "node_id": "I_kwDOKY_97s6TqlsR",
    "number": 213,
    "title": "[BUG: Mamba-Codestral-7B-v0.1  Internal Triton PTX codegen error:  Ptx assembly aborted due to errors",
    "user": {
      "login": "andretisch",
      "id": 48943433,
      "node_id": "MDQ6VXNlcjQ4OTQzNDMz",
      "avatar_url": "https://avatars.githubusercontent.com/u/48943433?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/andretisch",
      "html_url": "https://github.com/andretisch",
      "followers_url": "https://api.github.com/users/andretisch/followers",
      "following_url": "https://api.github.com/users/andretisch/following{/other_user}",
      "gists_url": "https://api.github.com/users/andretisch/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/andretisch/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/andretisch/subscriptions",
      "organizations_url": "https://api.github.com/users/andretisch/orgs",
      "repos_url": "https://api.github.com/users/andretisch/repos",
      "events_url": "https://api.github.com/users/andretisch/events{/privacy}",
      "received_events_url": "https://api.github.com/users/andretisch/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-08-21T08:28:12Z",
    "updated_at": "2024-11-29T04:22:57Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n```\n\n\n### Pip Freeze\n\n```shell\nabsl-py==2.1.0\r\naccelerate==0.29.3\r\naiohttp==3.9.5\r\naiosignal==1.3.1\r\nalbucore==0.0.5\r\nalbumentations==1.4.0\r\nale-py==0.7.5\r\nannotated-types==0.6.0\r\nanyio==4.3.0\r\naqlm==1.1.6\r\nargon2-cffi==23.1.0\r\nargon2-cffi-bindings==21.2.0\r\narrow==1.3.0\r\nastroid==3.2.2\r\nasttokens==2.4.1\r\nastunparse==1.6.3\r\nasync-lru==2.0.4\r\nasync-timeout==4.0.3\r\nasyncio==3.4.3\r\nattrs==23.2.0\r\nAutomat==20.2.0\r\nautopep8==2.0.4\r\nAutoROM==0.4.2\r\nAutoROM.accept-rom-license==0.6.1\r\nBabel==2.14.0\r\nbcrypt==3.2.0\r\nbeautifulsoup4==4.12.3\r\nbitsandbytes==0.43.1\r\nbleach==6.1.0\r\nblinker==1.4\r\ncachetools==5.3.3\r\ncausal-conv1d==1.4.0\r\ncertifi==2024.2.2\r\ncffi==1.16.0\r\nchardet==4.0.0\r\ncharset-normalizer==3.3.2\r\nclick==8.0.3\r\ncloud-init==24.1.3\r\ncloudpickle==3.0.0\r\ncmake==3.30.2\r\ncolorama==0.4.4\r\ncoloredlogs==15.0.1\r\ncomm==0.2.2\r\ncommand-not-found==0.3\r\nconfigobj==5.0.6\r\nconstantly==15.1.0\r\ncontourpy==1.2.1\r\ncraft-text-detector @ git+https://github.com/ria-com/craft-text-detector.git@0734fc81fbe9705cffa6d13c71d2ba240b20b422\r\ncryptography==3.4.8\r\ncycler==0.12.1\r\nCython==3.0.10\r\ndataclasses-json==0.6.4\r\ndatasets==2.19.1\r\ndbus-python==1.2.18\r\ndebugpy==1.8.1\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\ndill==0.3.8\r\ndiskcache==5.6.3\r\ndistlib==0.3.8\r\ndistro==1.7.0\r\ndistro-info==1.1+ubuntu0.2\r\ndnspython==2.1.0\r\ndocstring-to-markdown==0.15\r\ndocstring_parser==0.16\r\neinops==0.8.0\r\nexceptiongroup==1.2.1\r\nexecuting==2.0.1\r\nfaiss-cpu==1.8.0\r\nfastapi==0.112.0\r\nfastjsonschema==2.19.1\r\nfilelock==3.14.0\r\nfire==0.6.0\r\nflake8==7.0.0\r\nflatbuffers==24.3.25\r\nfonttools==4.51.0\r\nfqdn==1.5.1\r\nfrozenlist==1.4.1\r\nfsspec==2024.3.1\r\ngast==0.5.4\r\ngdown==5.2.0\r\ngevent==24.2.1\r\ngigachain==0.1.16\r\ngigachain-community==0.0.33.1\r\ngigachain-core==0.1.43.1\r\ngigachain-text-splitters==0.0.1\r\ngigachat==0.1.23\r\ngitdb==4.0.11\r\nGitPython==3.1.18\r\ngoogle-auth==2.29.0\r\ngoogle-auth-oauthlib==1.2.0\r\ngoogle-pasta==0.2.0\r\ngpg==1.16.0\r\ngreenlet==3.0.3\r\ngrpcio==1.62.0\r\ngym==0.25.2\r\ngym-notices==0.0.8\r\nh11==0.14.0\r\nh5py==3.10.0\r\nhttpcore==1.0.5\r\nhttplib2==0.20.2\r\nhttptools==0.6.1\r\nhttpx==0.27.0\r\nhuggingface-hub==0.24.5\r\nhumanfriendly==10.0\r\nhyperlink==21.0.0\r\nidna==3.6\r\nimageio==2.34.1\r\nimageio-ffmpeg==0.5.1\r\nimgaug==0.4.0\r\nimportlib_metadata==8.0.0\r\nimportlib_resources==6.4.0\r\nincremental==21.3.0\r\ninteregular==0.3.3\r\nipykernel==6.29.4\r\nipython==8.23.0\r\nipywidgets==8.1.2\r\nisoduration==20.11.0\r\nisort==5.13.2\r\njedi==0.19.1\r\njeepney==0.7.1\r\nJinja2==3.1.4\r\njoblib==1.4.0\r\njson5==0.9.25\r\njsonpatch==1.33\r\njsonpickle==3.0.4\r\njsonpointer==2.0\r\njsonschema==4.21.1\r\njsonschema-specifications==2023.12.1\r\njupyter==1.0.0\r\njupyter-console==6.6.3\r\njupyter-events==0.10.0\r\njupyter-lsp==2.2.5\r\njupyter_client==8.6.1\r\njupyter_core==5.7.2\r\njupyter_server==2.14.0\r\njupyter_server_terminals==0.5.3\r\njupyterlab==4.1.6\r\njupyterlab-language-pack-ru-RU==4.1.post2\r\njupyterlab-lsp==5.1.0\r\njupyterlab_pygments==0.3.0\r\njupyterlab_server==2.27.0\r\njupyterlab_widgets==3.0.10\r\njupyterthemes==0.20.0\r\nkeras==2.15.0\r\nkeyring==23.5.0\r\nkiwisolver==1.4.5\r\nlangsmith==0.1.50\r\nlapx==0.5.9\r\nlark==1.2.1\r\nlaunchpadlib==1.10.16\r\nlazr.restfulclient==0.14.4\r\nlazr.uri==1.0.6\r\nlazy_loader==0.4\r\nlesscpy==0.15.1\r\nlibclang==18.1.1\r\nlightning-utilities==0.11.2\r\nllvmlite==0.43.0\r\nlm-format-enforcer==0.10.3\r\nlxml==5.2.1\r\nmamba-ssm==2.2.2\r\nMarkdown==3.6\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.5\r\nmarshmallow==3.21.1\r\nmatplotlib==3.9.0\r\nmatplotlib-inline==0.1.7\r\nmccabe==0.7.0\r\nmdurl==0.1.2\r\nmistral_common==1.3.4\r\nmistral_inference==1.3.1\r\nmistune==3.0.2\r\nml-dtypes==0.2.0\r\nmodelhub-client @ git+https://github.com/ria-com/modelhub-client.git@d155a12e1c32a0a65b98c911f1e9e8786d02d93f\r\nmore-itertools==8.10.0\r\nmoviepy==1.0.3\r\nmpmath==1.3.0\r\nmsgpack==1.0.8\r\nmultidict==6.0.5\r\nmultiprocess==0.70.16\r\nmypy-extensions==1.0.0\r\nnamex==0.0.8\r\nnbclient==0.10.0\r\nnbconvert==7.16.3\r\nnbformat==5.10.4\r\nnest-asyncio==1.6.0\r\nnetifaces==0.11.0\r\nnetworkx==3.3\r\nninja==1.11.1.1\r\nnotebook==7.1.3\r\nnotebook_shim==0.2.4\r\nnumba==0.60.0\r\nnumpy==1.26.4\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==9.1.0.70\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-ml-py==12.555.43\r\nnvidia-nccl-cu12==2.20.5\r\nnvidia-nvjitlink-cu12==12.5.40\r\nnvidia-nvtx-cu12==12.1.105\r\noauthlib==3.2.0\r\nonnx==1.15.0\r\nonnx2pytorch==0.4.1\r\nonnxruntime-gpu==1.18.1\r\nopenai==1.23.3\r\nopencv-python==4.9.0.80\r\nopencv-python-headless==4.9.0.80\r\nopt-einsum==3.3.0\r\noptree==0.11.0\r\norjson==3.10.1\r\noutlines==0.0.46\r\noverrides==7.7.0\r\npackaging==24.0\r\npandas==2.2.2\r\npandocfilters==1.5.1\r\nparso==0.8.4\r\npexpect==4.8.0\r\npillow==10.3.0\r\nplatformdirs==4.2.0\r\npluggy==1.5.0\r\nply==3.11\r\npretty-errors==1.2.25\r\nproglog==0.1.10\r\nprometheus-fastapi-instrumentator==7.0.0\r\nprometheus_client==0.20.0\r\nprompt-toolkit==3.0.43\r\nprotobuf==3.20.3\r\npsutil==5.9.8\r\nptyprocess==0.7.0\r\npure-eval==0.2.2\r\npy-cpuinfo==9.0.0\r\npyairports==2.1.1\r\npyarrow==16.1.0\r\npyarrow-hotfix==0.6\r\npyasn1==0.5.1\r\npyasn1-modules==0.3.0\r\npycocotools==2.0.7\r\npycodestyle==2.11.1\r\npycountry==24.6.1\r\npycparser==2.22\r\npydantic==2.7.1\r\npydantic_core==2.18.2\r\npydocstyle==6.3.0\r\npydot==2.0.0\r\npyflakes==3.2.0\r\nPygments==2.17.2\r\nPyGObject==3.42.1\r\nPyHamcrest==2.0.2\r\nPyJWT==2.3.0\r\npylint==3.2.5\r\npyOpenSSL==21.0.0\r\npyparsing==3.1.2\r\npyrsistent==0.18.1\r\npyserial==3.5\r\nPySocks==1.7.1\r\npyTelegramBotAPI==4.17.0\r\npython-apt==2.4.0+ubuntu3\r\npython-dateutil==2.9.0.post0\r\npython-debian==0.1.43+ubuntu1.1\r\npython-dotenv==1.0.1\r\npython-json-logger==2.0.7\r\npython-lsp-jsonrpc==1.1.2\r\npython-lsp-server==1.11.0\r\npython-magic==0.4.24\r\npytoolconfig==1.3.1\r\npytorch-lightning==1.8.6\r\nPyTurboJPEG @ git+https://github.com/lilohuang/PyTurboJPEG.git@c9a4973ab48e1e3d421881f76d8b1b2a22669fd2\r\npytz==2024.1\r\nPyVirtualDisplay==3.0\r\nPyYAML==6.0.1\r\npyzmq==26.0.2\r\nqtconsole==5.5.1\r\nQtPy==2.4.1\r\nqudida==0.0.4\r\nray==2.34.0\r\nreferencing==0.34.0\r\nregex==2024.4.16\r\nrequests==2.32.2\r\nrequests-oauthlib==2.0.0\r\nrequests-toolbelt==0.9.1\r\nrfc3339-validator==0.1.4\r\nrfc3986-validator==0.1.1\r\nrich==13.7.1\r\nrope==1.13.0\r\nrpds-py==0.18.0\r\nrsa==4.9\r\nsafetensors==0.4.3\r\nscikit-image==0.23.2\r\nscikit-learn==1.4.2\r\nscipy==1.13.0\r\nscreen-resolution-extra==0.0.0\r\nseaborn==0.13.2\r\nSecretStorage==3.3.1\r\nSend2Trash==1.8.3\r\nsentence-transformers==2.7.0\r\nsentencepiece==0.2.0\r\nsentry-sdk==2.1.1\r\nservice-identity==18.1.0\r\nshapely==2.0.4\r\nsimple_parsing==0.1.5\r\nsix==1.16.0\r\nsmmap==5.0.1\r\nsniffio==1.3.1\r\nsnowballstemmer==2.2.0\r\nsos==4.5.6\r\nsoupsieve==2.5\r\nSQLAlchemy==2.0.29\r\nssh-import-id==5.11\r\nstack-data==0.6.3\r\nstarlette==0.37.2\r\nsympy==1.12\r\nsystemd-python==234\r\ntenacity==8.2.3\r\ntensorboard==2.15.2\r\ntensorboard-data-server==0.7.2\r\ntensorboardX==2.6.2.2\r\ntensorflow==2.15.0.post1\r\ntensorflow-estimator==2.15.0\r\ntensorflow-io-gcs-filesystem==0.36.0\r\ntensorrt==10.0.1\r\ntensorrt-cu12==10.0.1\r\ntensorrt-cu12-bindings==10.0.1\r\ntensorrt-cu12-libs==10.0.1\r\ntermcolor==2.4.0\r\nterminado==0.18.1\r\ntf2onnx==1.16.1\r\nthop==0.1.1.post2209072238\r\nthreadpoolctl==3.4.0\r\ntifffile==2024.5.10\r\ntiktoken==0.7.0\r\ntinycss2==1.2.1\r\ntokenizers==0.19.1\r\ntomli==2.0.1\r\ntomlkit==0.12.5\r\ntorch==2.4.0\r\ntorchaudio==2.4.0+cu124\r\ntorchmetrics==1.4.0\r\ntorchvision==0.19.0\r\ntornado==6.4\r\ntqdm==4.66.4\r\ntraitlets==5.14.3\r\ntransformers==4.44.0\r\ntriton==3.0.0\r\nTwisted==22.1.0\r\ntypeguard==4.2.1\r\ntypes-python-dateutil==2.9.0.20240316\r\ntyping-inspect==0.9.0\r\ntyping_extensions==4.11.0\r\ntzdata==2024.1\r\nubuntu-drivers-common==0.0.0\r\nubuntu-pro-client==8001\r\nufw==0.36.1\r\nujson==5.10.0\r\nultralytics==8.2.19\r\nunattended-upgrades==0.1\r\nuri-template==1.3.0\r\nurllib3==2.2.1\r\nuvicorn==0.30.6\r\nuvloop==0.19.0\r\nvirtualenv==20.25.3\r\nvllm==0.5.4\r\nvllm-flash-attn==2.6.1\r\nwadllib==1.3.6\r\nwatchfiles==0.23.0\r\nwcwidth==0.2.13\r\nwebcolors==1.13\r\nwebencodings==0.5.1\r\nwebsocket-client==1.7.0\r\nwebsockets==12.0\r\nWerkzeug==3.0.2\r\nwhatthepatch==1.0.5\r\nwidgetsnbextension==4.0.10\r\nwrapt==1.14.1\r\nxformers==0.0.27.post2\r\nxkit==0.0.0\r\nxvfbwrapper==0.2.9\r\nxxhash==3.4.1\r\nyapf==0.40.2\r\nyarl==1.9.4\r\nzipp==1.0.0\r\nzope.event==5.0\r\nzope.interface==5.4.0\n```\n\n\n### Reproduction Steps\n\n```python\r\nfrom mistral_inference.main import *\r\n\r\ndemo('models/Mamba-Codestral-7B-v0.1')\r\n```\n\n### Expected Behavior\n\nJust generated output answer\n\n### Additional Context\n\nHi. I tried run demo function with model mistralai/Mamba-Codestral-7B-v0.1.  I use torch 2.4.0 and CUDA 12.4 on Nvidia Tesla P40. \r\nHow I understand triton have some problem with bf16 on P40. But early I was loading llama in bf16. \r\n\r\n```bash\r\n---------------------------------------------------------------------------\r\nCalledProcessError                        Traceback (most recent call last)\r\nFile ~/.local/lib/python3.10/site-packages/triton/backends/nvidia/compiler.py:292, in CUDABackend.make_cubin(src, metadata, opt, capability)\r\n    291 try:\r\n--> 292     subprocess.run(cmd, shell=True, check=True)\r\n    293 except subprocess.CalledProcessError as e:\r\n\r\nFile /usr/lib/python3.10/subprocess.py:526, in run(input, capture_output, timeout, check, *popenargs, **kwargs)\r\n    525     if check and retcode:\r\n--> 526         raise CalledProcessError(retcode, process.args,\r\n    527                                  output=stdout, stderr=stderr)\r\n    528 return CompletedProcess(process.args, retcode, stdout, stderr)\r\n\r\nCalledProcessError: Command '/home/andrew/.local/lib/python3.10/site-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_61 /tmp/tmpxqf2tngx.ptx -o /tmp/tmpxqf2tngx.ptx.o 2> /tmp/tmpbh62k9ys.log' returned non-zero exit status 255.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nRuntimeError                              Traceback (most recent call last)\r\nCell In[1], line 4\r\n      1 import torch\r\n      2 from mistral_inference.main import *\r\n----> 4 demo('models/Mamba-Codestral-7B-v0.1')\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mistral_inference/main.py:185, in demo(model_path, max_tokens, temperature, lora_path)\r\n    178     warnings.warn(\r\n    179         \"Batched generation is not correctly supported at the moment and therefore might lead to worse results \"\r\n    180         \"as compared to non-batched generation. \"\r\n    181         \"See https://github.com/state-spaces/mamba/issues/66#issuecomment-1862349718 for more information.\"\r\n    182     )\r\n    183     encoded_prompts = pad_and_convert_to_tensor(encoded_prompts, mistral_tokenizer.instruct_tokenizer.BOS)  # type: ignore[attr-defined]\r\n--> 185 generated_tokens, _logprobs = generate_fn(\r\n    186     encoded_prompts,\r\n    187     model,  # type: ignore[arg-type]\r\n    188     max_tokens=max_tokens,\r\n    189     temperature=temperature,\r\n    190     eos_id=tokenizer.eos_id,\r\n    191 )\r\n    193 generated_words = []\r\n    194 for i, x in enumerate(generated_tokens):\r\n\r\nFile ~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116, in context_decorator.<locals>.decorate_context(*args, **kwargs)\r\n    113 @functools.wraps(func)\r\n    114 def decorate_context(*args, **kwargs):\r\n    115     with ctx_factory():\r\n--> 116         return func(*args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mistral_inference/generate.py:21, in generate_mamba(encoded_prompts, model, max_tokens, temperature, chunk_size, eos_id)\r\n     10 @torch.inference_mode()\r\n     11 def generate_mamba(\r\n     12     encoded_prompts: List[List[int]],\r\n   (...)\r\n     18     eos_id: Optional[int] = None,\r\n     19 ) -> Tuple[List[List[int]], List[List[float]]]:\r\n     20     input_ids = torch.tensor(encoded_prompts, device=model.device)\r\n---> 21     output = model.model.generate(\r\n     22         input_ids=input_ids,\r\n     23         max_length=input_ids.shape[-1] + max_tokens,\r\n     24         cg=True,\r\n     25         return_dict_in_generate=True,\r\n     26         output_scores=True,\r\n     27         enable_timing=False,\r\n     28         eos_token_id=eos_id,\r\n     29         temperature=temperature,\r\n     30         top_p=0.8,\r\n     31     )\r\n     32     generated_tokens = output.sequences[:, input_ids.shape[-1] :].tolist()\r\n     34     _logprobs: List[List[float]] = [[] for _ in range(len(generated_tokens))]\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mamba_ssm/utils/generation.py:260, in GenerationMixin.generate(self, input_ids, max_length, top_k, top_p, min_p, temperature, return_dict_in_generate, output_scores, **kwargs)\r\n    248 def generate(\r\n    249     self,\r\n    250     input_ids,\r\n   (...)\r\n    258     **kwargs,\r\n    259 ):\r\n--> 260     output = decode(\r\n    261         input_ids, self, max_length, top_k=top_k, top_p=top_p, min_p = min_p, temperature=temperature, **kwargs\r\n    262     )\r\n    263     if not output_scores:\r\n    264         output.scores = None\r\n\r\nFile ~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116, in context_decorator.<locals>.decorate_context(*args, **kwargs)\r\n    113 @functools.wraps(func)\r\n    114 def decorate_context(*args, **kwargs):\r\n    115     with ctx_factory():\r\n--> 116         return func(*args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mamba_ssm/utils/generation.py:160, in decode(input_ids, model, max_length, top_k, top_p, min_p, temperature, repetition_penalty, eos_token_id, teacher_outputs, vocab_size, cg, enable_timing, streamer)\r\n    158 if not hasattr(model, \"_decoding_cache\"):\r\n    159     model._decoding_cache = None\r\n--> 160 model._decoding_cache = update_graph_cache(\r\n    161     model,\r\n    162     model._decoding_cache,\r\n    163     batch_size,\r\n    164     seqlen_og,\r\n    165     max_length,\r\n    166 )\r\n    167 inference_params = model._decoding_cache.inference_params\r\n    168 inference_params.reset(max_length, batch_size)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116, in context_decorator.<locals>.decorate_context(*args, **kwargs)\r\n    113 @functools.wraps(func)\r\n    114 def decorate_context(*args, **kwargs):\r\n    115     with ctx_factory():\r\n--> 116         return func(*args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mamba_ssm/utils/generation.py:321, in update_graph_cache(model, cache, batch_size, seqlen_og, max_seqlen, decoding_seqlens, dtype, n_warmups)\r\n    319 for decoding_seqlen in decoding_seqlens:\r\n    320     if (batch_size, decoding_seqlen) not in cache.callables:\r\n--> 321         cache.callables[batch_size, decoding_seqlen] = capture_graph(\r\n    322             model,\r\n    323             cache.inference_params,\r\n    324             batch_size,\r\n    325             max_seqlen,\r\n    326             decoding_seqlen=decoding_seqlen,\r\n    327             mempool=cache.mempool,\r\n    328             n_warmups=n_warmups,\r\n    329         )\r\n    331 def dispatch(input_ids, position_ids, seqlen):\r\n    332     batch_size, decoding_seqlen = input_ids.shape[:2]\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mamba_ssm/utils/generation.py:355, in capture_graph(model, inference_params, batch_size, max_seqlen, decoding_seqlen, mempool, n_warmups)\r\n    353 with torch.cuda.stream(s):\r\n    354     for _ in range(n_warmups):\r\n--> 355         logits = model(\r\n    356             input_ids,\r\n    357             position_ids=position_ids,\r\n    358             inference_params=inference_params,\r\n    359             num_last_tokens=decoding_seqlen,\r\n    360         ).logits\r\n    361     s.synchronize()\r\n    362     # This might be needed for correctness if we run with NCCL_GRAPH_MIXING_SUPPORT=0,\r\n    363     # which requires that graph launch and non-captured launch to not overlap (I think,\r\n    364     # that's how I interpret the documentation). I'm not sure if this is required.\r\n\r\nFile ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553, in Module._wrapped_call_impl(self, *args, **kwargs)\r\n   1551     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\r\n   1552 else:\r\n-> 1553     return self._call_impl(*args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562, in Module._call_impl(self, *args, **kwargs)\r\n   1557 # If we don't have any hooks, we want to skip the rest of the logic in\r\n   1558 # this function, and just call forward.\r\n   1559 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\r\n   1560         or _global_backward_pre_hooks or _global_backward_hooks\r\n   1561         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1562     return forward_call(*args, **kwargs)\r\n   1564 try:\r\n   1565     result = None\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mamba_ssm/models/mixer_seq_simple.py:279, in MambaLMHeadModel.forward(self, input_ids, position_ids, inference_params, num_last_tokens, **mixer_kwargs)\r\n    274 def forward(self, input_ids, position_ids=None, inference_params=None, num_last_tokens=0, **mixer_kwargs):\r\n    275     \"\"\"\r\n    276     \"position_ids\" is just to be compatible with Transformer generation. We don't use it.\r\n    277     num_last_tokens: if > 0, only return the logits for the last n tokens\r\n    278     \"\"\"\r\n--> 279     hidden_states = self.backbone(input_ids, inference_params=inference_params, **mixer_kwargs)\r\n    280     if num_last_tokens > 0:\r\n    281         hidden_states = hidden_states[:, -num_last_tokens:]\r\n\r\nFile ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553, in Module._wrapped_call_impl(self, *args, **kwargs)\r\n   1551     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\r\n   1552 else:\r\n-> 1553     return self._call_impl(*args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562, in Module._call_impl(self, *args, **kwargs)\r\n   1557 # If we don't have any hooks, we want to skip the rest of the logic in\r\n   1558 # this function, and just call forward.\r\n   1559 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\r\n   1560         or _global_backward_pre_hooks or _global_backward_hooks\r\n   1561         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1562     return forward_call(*args, **kwargs)\r\n   1564 try:\r\n   1565     result = None\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mamba_ssm/models/mixer_seq_simple.py:194, in MixerModel.forward(self, input_ids, inference_params, **mixer_kwargs)\r\n    192 residual = None\r\n    193 for layer in self.layers:\r\n--> 194     hidden_states, residual = layer(\r\n    195         hidden_states, residual, inference_params=inference_params, **mixer_kwargs\r\n    196     )\r\n    197 if not self.fused_add_norm:\r\n    198     residual = (hidden_states + residual) if residual is not None else hidden_states\r\n\r\nFile ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553, in Module._wrapped_call_impl(self, *args, **kwargs)\r\n   1551     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\r\n   1552 else:\r\n-> 1553     return self._call_impl(*args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562, in Module._call_impl(self, *args, **kwargs)\r\n   1557 # If we don't have any hooks, we want to skip the rest of the logic in\r\n   1558 # this function, and just call forward.\r\n   1559 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\r\n   1560         or _global_backward_pre_hooks or _global_backward_hooks\r\n   1561         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1562     return forward_call(*args, **kwargs)\r\n   1564 try:\r\n   1565     result = None\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mamba_ssm/modules/block.py:57, in Block.forward(self, hidden_states, residual, inference_params, **mixer_kwargs)\r\n     55         residual = residual.to(torch.float32)\r\n     56 else:\r\n---> 57     hidden_states, residual = layer_norm_fn(\r\n     58         hidden_states,\r\n     59         self.norm.weight,\r\n     60         self.norm.bias,\r\n     61         residual=residual,\r\n     62         prenorm=True,\r\n     63         residual_in_fp32=self.residual_in_fp32,\r\n     64         eps=self.norm.eps,\r\n     65         is_rms_norm=isinstance(self.norm, RMSNorm)\r\n     66     )\r\n     67 hidden_states = self.mixer(hidden_states, inference_params=inference_params, **mixer_kwargs)\r\n     69 if self.mlp is not None:\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mamba_ssm/ops/triton/layer_norm.py:902, in layer_norm_fn(x, weight, bias, residual, x1, weight1, bias1, eps, dropout_p, rowscale, prenorm, residual_in_fp32, is_rms_norm, return_dropout_mask)\r\n    886 def layer_norm_fn(\r\n    887     x,\r\n    888     weight,\r\n   (...)\r\n    900     return_dropout_mask=False,\r\n    901 ):\r\n--> 902     return LayerNormFn.apply(\r\n    903         x,\r\n    904         weight,\r\n    905         bias,\r\n    906         residual,\r\n    907         x1,\r\n    908         weight1,\r\n    909         bias1,\r\n    910         eps,\r\n    911         dropout_p,\r\n    912         rowscale,\r\n    913         prenorm,\r\n    914         residual_in_fp32,\r\n    915         is_rms_norm,\r\n    916         return_dropout_mask,\r\n    917     )\r\n\r\nFile ~/.local/lib/python3.10/site-packages/torch/autograd/function.py:574, in Function.apply(cls, *args, **kwargs)\r\n    571 if not torch._C._are_functorch_transforms_active():\r\n    572     # See NOTE: [functorch vjp and autograd interaction]\r\n    573     args = _functorch.utils.unwrap_dead_wrappers(args)\r\n--> 574     return super().apply(*args, **kwargs)  # type: ignore[misc]\r\n    576 if not is_setup_ctx_defined:\r\n    577     raise RuntimeError(\r\n    578         \"In order to use an autograd.Function with functorch transforms \"\r\n    579         \"(vmap, grad, jvp, jacrev, ...), it must override the setup_context \"\r\n    580         \"staticmethod. For more details, please see \"\r\n    581         \"https://pytorch.org/docs/main/notes/extending.func.html\"\r\n    582     )\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mamba_ssm/ops/triton/layer_norm.py:775, in LayerNormFn.forward(ctx, x, weight, bias, residual, x1, weight1, bias1, eps, dropout_p, rowscale, prenorm, residual_in_fp32, is_rms_norm, return_dropout_mask)\r\n    769     rowscale = rowscale.reshape(-1).contiguous()\r\n    770 residual_dtype = (\r\n    771     residual.dtype\r\n    772     if residual is not None\r\n    773     else (torch.float32 if residual_in_fp32 else None)\r\n    774 )\r\n--> 775 y, y1, mean, rstd, residual_out, seeds, dropout_mask, dropout_mask1 = _layer_norm_fwd(\r\n    776     x,\r\n    777     weight,\r\n    778     bias,\r\n    779     eps,\r\n    780     residual,\r\n    781     x1,\r\n    782     weight1,\r\n    783     bias1,\r\n    784     dropout_p=dropout_p,\r\n    785     rowscale=rowscale,\r\n    786     residual_dtype=residual_dtype,\r\n    787     is_rms_norm=is_rms_norm,\r\n    788     return_dropout_mask=return_dropout_mask,\r\n    789 )\r\n    790 ctx.save_for_backward(\r\n    791     residual_out, weight, bias, weight1, bias1, rowscale, seeds, mean, rstd\r\n    792 )\r\n    793 ctx.x_shape_og = x_shape_og\r\n\r\nFile ~/.local/lib/python3.10/site-packages/mamba_ssm/ops/triton/layer_norm.py:369, in _layer_norm_fwd(x, weight, bias, eps, residual, x1, weight1, bias1, dropout_p, rowscale, out_dtype, residual_dtype, is_rms_norm, return_dropout_mask)\r\n    367     raise RuntimeError(\"This layer norm doesn't support feature dim >= 64KB.\")\r\n    368 with torch.cuda.device(x.device.index):\r\n--> 369     _layer_norm_fwd_1pass_kernel[(M,)](\r\n    370         x,\r\n    371         y,\r\n    372         weight,\r\n    373         bias,\r\n    374         residual,\r\n    375         x1,\r\n    376         weight1,\r\n    377         bias1,\r\n    378         y1,\r\n    379         residual_out,\r\n    380         rowscale,\r\n    381         seeds,\r\n    382         dropout_mask,\r\n    383         mean,\r\n    384         rstd,\r\n    385         x.stride(0),\r\n    386         y.stride(0),\r\n    387         residual.stride(0) if residual is not None else 0,\r\n    388         residual_out.stride(0) if residual_out is not None else 0,\r\n    389         x1.stride(0) if x1 is not None else 0,\r\n    390         y1.stride(0) if y1 is not None else 0,\r\n    391         M,\r\n    392         N,\r\n    393         eps,\r\n    394         dropout_p,\r\n    395         is_rms_norm,\r\n    396         BLOCK_N,\r\n    397         residual is not None,\r\n    398         residual_out is not None,\r\n    399         bias is not None,\r\n    400         dropout_p > 0.0,\r\n    401         dropout_mask is not None,\r\n    402         rowscale is not None,\r\n    403     )\r\n    404 # residual_out is None if residual is None and residual_dtype == input_dtype and dropout_p == 0.0\r\n    405 if dropout_mask is not None and x1 is not None:\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/runtime/jit.py:345, in KernelInterface.__getitem__.<locals>.<lambda>(*args, **kwargs)\r\n    339 def __getitem__(self, grid) -> T:\r\n    340     \"\"\"\r\n    341     A JIT function is launched with: fn[grid](*args, **kwargs).\r\n    342     Hence JITFunction.__getitem__ returns a callable proxy that\r\n    343     memorizes the grid.\r\n    344     \"\"\"\r\n--> 345     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py:156, in Autotuner.run(self, *args, **kwargs)\r\n    154 pruned_configs = self.prune_configs(kwargs)\r\n    155 bench_start = time.time()\r\n--> 156 timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\r\n    157 bench_end = time.time()\r\n    158 self.bench_time = bench_end - bench_start\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py:156, in <dictcomp>(.0)\r\n    154 pruned_configs = self.prune_configs(kwargs)\r\n    155 bench_start = time.time()\r\n--> 156 timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\r\n    157 bench_end = time.time()\r\n    158 self.bench_time = bench_end - bench_start\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py:133, in Autotuner._bench(self, config, *args, **meta)\r\n    131             bench_res = do_bench_cudagraph(kernel_call, rep=self.num_reps, return_mode=\"median\")\r\n    132         return bench_res\r\n--> 133     return do_bench(kernel_call, warmup=self.num_warmups, rep=self.num_reps, quantiles=(0.5, 0.2, 0.8))\r\n    134 except (OutOfResources, CompileTimeAssertionFailure):\r\n    135     return float(\"inf\") if self.use_cuda_graph else [float(\"inf\"), float(\"inf\"), float(\"inf\")]\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/testing.py:103, in do_bench(fn, warmup, rep, grad_to_none, quantiles, fast_flush, return_mode)\r\n    100 assert return_mode in [\"min\", \"max\", \"mean\", \"median\"]\r\n    101 import torch\r\n--> 103 fn()\r\n    104 torch.cuda.synchronize()\r\n    106 # We maintain a buffer of 256 MB that we clear\r\n    107 # before each kernel call to make sure that the L2\r\n    108 # doesn't contain any input data before the run\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py:114, in Autotuner._bench.<locals>.kernel_call()\r\n    112 self.pre_hook(args)\r\n    113 try:\r\n--> 114     self.fn.run(\r\n    115         *args,\r\n    116         **current,\r\n    117     )\r\n    118 except Exception as e:\r\n    119     try:\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py:338, in Heuristics.run(self, *args, **kwargs)\r\n    336 for v, heur in self.values.items():\r\n    337     kwargs[v] = heur({**dict(zip(self.arg_names, args)), **kwargs})\r\n--> 338 return self.fn.run(*args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py:338, in Heuristics.run(self, *args, **kwargs)\r\n    336 for v, heur in self.values.items():\r\n    337     kwargs[v] = heur({**dict(zip(self.arg_names, args)), **kwargs})\r\n--> 338 return self.fn.run(*args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py:338, in Heuristics.run(self, *args, **kwargs)\r\n    336 for v, heur in self.values.items():\r\n    337     kwargs[v] = heur({**dict(zip(self.arg_names, args)), **kwargs})\r\n--> 338 return self.fn.run(*args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/runtime/jit.py:662, in JITFunction.run(self, grid, warmup, *args, **kwargs)\r\n    660     # compile the kernel\r\n    661     src = self.ASTSource(self, signature, constants, configs[0])\r\n--> 662     kernel = self.compile(\r\n    663         src,\r\n    664         target=target,\r\n    665         options=options.__dict__,\r\n    666     )\r\n    667     self.cache[device][key] = kernel\r\n    669 # Check that used global values have not changed.\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/compiler/compiler.py:282, in compile(src, target, options)\r\n    280 use_ttgir_loc = os.environ.get(\"USE_TTGIR_LOC\", \"0\") == \"1\"\r\n    281 for ext, compile_ir in list(stages.items())[first_stage:]:\r\n--> 282     next_module = compile_ir(module, metadata)\r\n    283     ir_filename = f\"{src.name}.{ext}\"\r\n    284     metadata_group[ir_filename] = fn_cache_manager.put(next_module, ir_filename)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/backends/nvidia/compiler.py:320, in CUDABackend.add_stages.<locals>.<lambda>(src, metadata)\r\n    318 stages[\"llir\"] = lambda src, metadata: self.make_llir(src, metadata, options, self.capability)\r\n    319 stages[\"ptx\"] = lambda src, metadata: self.make_ptx(src, metadata, options, self.capability)\r\n--> 320 stages[\"cubin\"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.capability)\r\n\r\nFile ~/.local/lib/python3.10/site-packages/triton/backends/nvidia/compiler.py:297, in CUDABackend.make_cubin(src, metadata, opt, capability)\r\n    295     log = log_file.read()\r\n    296 if e.returncode == 255:\r\n--> 297     raise RuntimeError(f'Internal Triton PTX codegen error: \\n{log}')\r\n    298 elif e.returncode == 128 + signal.SIGSEGV:\r\n    299     raise RuntimeError(\r\n    300         f'Please run `ptxas {fsrc.name}` to confirm that this is a bug in `ptxas`\\n{log}')\r\n\r\nRuntimeError: Internal Triton PTX codegen error: \r\nptxas /tmp/tmpxqf2tngx.ptx, line 579; error   : Feature '.bf16' requires .target sm_80 or higher\r\nptxas /tmp/tmpxqf2tngx.ptx, line 579; error   : Feature 'cvt with .f32.bf16' requires .target sm_80 or higher\r\nptxas /tmp/tmpxqf2tngx.ptx, line 582; error   : Feature '.bf16' requires .target sm_80 or higher\r\nptxas /tmp/tmpxqf2tngx.ptx, line 582; error   : Feature 'cvt with .f32.bf16' requires .target sm_80 or higher\r\nptxas /tmp/tmpxqf2tngx.ptx, line 585; error   : Feature '.bf16' requires ......\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/213/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/213/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/212",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/212/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/212/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/212/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/212",
    "id": 2467348354,
    "node_id": "I_kwDOKY_97s6TEL-C",
    "number": 212,
    "title": "[Feat] Add streaming support to Codestral Mamba",
    "user": {
      "login": "xNul",
      "id": 894305,
      "node_id": "MDQ6VXNlcjg5NDMwNQ==",
      "avatar_url": "https://avatars.githubusercontent.com/u/894305?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/xNul",
      "html_url": "https://github.com/xNul",
      "followers_url": "https://api.github.com/users/xNul/followers",
      "following_url": "https://api.github.com/users/xNul/following{/other_user}",
      "gists_url": "https://api.github.com/users/xNul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/xNul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/xNul/subscriptions",
      "organizations_url": "https://api.github.com/users/xNul/orgs",
      "repos_url": "https://api.github.com/users/xNul/repos",
      "events_url": "https://api.github.com/users/xNul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/xNul/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-08-15T03:59:49Z",
    "updated_at": "2024-08-15T03:59:49Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nN/A\n```\n\n\n### Pip Freeze\n\n```shell\nN/A\n```\n\n\n### Reproduction Steps\n\nN/A\n\n### Expected Behavior\n\nN/A\n\n### Additional Context\n\nN/A\n\n### Suggested Solutions\n\n`mamba-ssm` has added streaming support for the Mamba architecture Codestral Mamba uses via the [`streamer`](https://github.com/state-spaces/mamba/blob/62db608da60f6fc790b8ed9f4b3225e95ca15fde/mamba_ssm/utils/generation.py#L135) parameter which can be passed as an argument in this function call: https://github.com/mistralai/mistral-inference/blob/337e3db62ea185d7acf1a83c57a6e25a4bb60b26/src/mistral_inference/generate.py#L21 So now it should be pretty easy to implement streaming support for Codestral Mamba in `mistral-inference`.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/212/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/212/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/211",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/211/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/211/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/211/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/211",
    "id": 2462769363,
    "node_id": "PR_kwDOKY_97s54M62p",
    "number": 211,
    "title": "Update README.md",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-08-13T08:46:38Z",
    "updated_at": "2024-08-14T15:47:53Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/211",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/211",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/211.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/211.patch",
      "merged_at": null
    },
    "body": null,
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/211/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/211/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/210",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/210/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/210/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/210/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/210",
    "id": 2459785676,
    "node_id": "I_kwDOKY_97s6SnVnM",
    "number": 210,
    "title": "[BUG: rate limit exceeded on basic examples",
    "user": {
      "login": "AlbertoMQ",
      "id": 58190042,
      "node_id": "MDQ6VXNlcjU4MTkwMDQy",
      "avatar_url": "https://avatars.githubusercontent.com/u/58190042?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AlbertoMQ",
      "html_url": "https://github.com/AlbertoMQ",
      "followers_url": "https://api.github.com/users/AlbertoMQ/followers",
      "following_url": "https://api.github.com/users/AlbertoMQ/following{/other_user}",
      "gists_url": "https://api.github.com/users/AlbertoMQ/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AlbertoMQ/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AlbertoMQ/subscriptions",
      "organizations_url": "https://api.github.com/users/AlbertoMQ/orgs",
      "repos_url": "https://api.github.com/users/AlbertoMQ/repos",
      "events_url": "https://api.github.com/users/AlbertoMQ/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AlbertoMQ/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-08-11T22:19:23Z",
    "updated_at": "2024-08-11T22:19:23Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.11.9 (main, Apr  6 2024, 17:59:24) [GCC 9.4.0]\n```\n\n\n### Pip Freeze\n\n```shell\naiohappyeyeballs==2.3.5\r\naiohttp==3.10.3\r\naiosignal==1.3.1\r\nannotated-types==0.7.0\r\nanyio==4.4.0\r\nattrs==24.2.0\r\ncertifi==2024.7.4\r\ncharset-normalizer==3.3.2\r\ndataclasses-json==0.6.7\r\nfaiss-cpu==1.8.0.post1\r\nfilelock==3.15.4\r\nfrozenlist==1.4.1\r\nfsspec==2024.6.1\r\ngreenlet==3.0.3\r\nh11==0.14.0\r\nhttpcore==1.0.5\r\nhttpx==0.27.0\r\nhttpx-sse==0.4.0\r\nhuggingface-hub==0.24.5\r\nidna==3.7\r\njsonpatch==1.33\r\njsonpath-python==1.0.6\r\njsonpointer==3.0.0\r\nlangchain==0.2.12\r\nlangchain-community==0.2.11\r\nlangchain-core==0.2.29\r\nlangchain-mistralai==0.1.12\r\nlangchain-text-splitters==0.2.2\r\nlangsmith==0.1.99\r\nmarshmallow==3.21.3\r\nmistralai==1.0.0\r\nmultidict==6.0.5\r\nmypy-extensions==1.0.0\r\nnumpy==1.26.4\r\norjson==3.10.7\r\npackaging==24.1\r\npydantic==2.8.2\r\npydantic_core==2.20.1\r\npython-dateutil==2.9.0.post0\r\nPyYAML==6.0.2\r\nregex==2024.7.24\r\nrequests==2.32.3\r\nsafetensors==0.4.4\r\nsix==1.16.0\r\nsniffio==1.3.1\r\nSQLAlchemy==2.0.32\r\ntenacity==8.5.0\r\ntokenizers==0.19.1\r\ntqdm==4.66.5\r\ntransformers==4.44.0\r\ntyping-inspect==0.9.0\r\ntyping_extensions==4.12.2\r\nurllib3==2.2.2\r\nyarl==1.9.4\n```\n\n\n### Reproduction Steps\n\nRun everything exactly as detailed in https://docs.mistral.ai/guides/rag/\n\n### Expected Behavior\n\nI expect to not have a rate limit exceeded error on a provided example.\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/210/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/210/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/209",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/209/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/209/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/209/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/209",
    "id": 2458772544,
    "node_id": "PR_kwDOKY_97s53_kIW",
    "number": 209,
    "title": "add Makefile",
    "user": {
      "login": "bionicles",
      "id": 24532336,
      "node_id": "MDQ6VXNlcjI0NTMyMzM2",
      "avatar_url": "https://avatars.githubusercontent.com/u/24532336?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bionicles",
      "html_url": "https://github.com/bionicles",
      "followers_url": "https://api.github.com/users/bionicles/followers",
      "following_url": "https://api.github.com/users/bionicles/following{/other_user}",
      "gists_url": "https://api.github.com/users/bionicles/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bionicles/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bionicles/subscriptions",
      "organizations_url": "https://api.github.com/users/bionicles/orgs",
      "repos_url": "https://api.github.com/users/bionicles/repos",
      "events_url": "https://api.github.com/users/bionicles/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bionicles/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-08-09T23:05:00Z",
    "updated_at": "2024-08-09T23:06:18Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/209",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/209",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/209.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/209.patch",
      "merged_at": null
    },
    "body": "this Makefile enables developers to download and extract three Mistral open source models with a single word: `make`\r\n\r\nModels included:\r\n- codestral-mamba-7b-v0-1\r\n- mistral-7b-v0-3\r\n- mathstral-7b-v0-1\r\n\r\nNote: there would still be some additional setup needed, specifically to [tell the mistral-chat CLI where to find the models](https://github.com/mistralai/mistral-inference/tree/main?tab=readme-ov-file#usage)\r\n\r\nIf it's helpful, I can help update the README to show how to use the makefile\r\nWe can also have the makefile install and run the cli\r\nWe can even make it idempotently add `mistral-models` to the `$PATH` by adding code to their `profile` (example: https://github.com/bionicles/tree_plus/blob/main/tree_plus_src/scripts/alias_tree_plus.sh)\r\n\r\ninlined here and lightly modified to save you a click\r\n```sh\r\n#!/bin/bash\r\n\r\n# set your RC_FILE to .bashrc if you use bash \r\n# or set it to .zshrc if you use zsh\r\nRC_FILE=~/.bash_profile # where the aliases will be added\r\n\r\n# Function to idempotently add an alias if it doesn't exist in RC_FILE\r\nadd_alias() {\r\n    grep -qF \"alias $1=\\\"$2\\\"\" $RC_FILE || echo \"alias $1=\\\"$2\\\"\" >> $RC_FILE\r\n}\r\n\r\n# Add alias\r\nadd_alias mc mistral-chat \r\n```\r\n\r\nah here's another nice script chunk that would enable the one above to automatically add a line to the user's profile which would indicate the path to find the mistral_models\r\n\r\n```sh\r\nexport DEBUG=true\r\n\r\n# ensure lines are added to a file only once\r\nfunction idempotent_add_line_to_file() {\r\n  local line=\"$1\"\r\n  local file=\"$2\"\r\n  # Check if the line already exists in the file\r\n  if grep -Fxq \"$line\" \"$file\"; then\r\n    ${DEBUG:=false} && echo \"DEBUG(idempotent_add_line_to_file) line '$line' already in '$file'\"\r\n  else\r\n    echo \"$line\" >> \"$file\"\r\n    echo \"DEBUG(idempotent_add_line_to_file) SCRIPT_DIR: $SCRIPT_DIR\"\r\n    echo \"The line '$line' was added to '$file'\"\r\n  fi\r\n}\r\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\r\necho \"DEBUG(idempotent_add_line_to_file) SCRIPT_DIR: $SCRIPT_DIR\"\r\nidempotent_add_line_to_file \"export MISTRAL_MODELS_PATH=$SCRIPT_DIR/mistral_models\" \"$HOME/$RC_FILE\"\r\nexport -f idempotent_add_line_to_file\r\n```\r\nkey idea: it only adds the line once, so it won't keep re-adding it\r\n\r\ncould enable mistral to install local terminal utilities more easily without needing to tell people to tinker with their path too much\r\n\r\nAnyway: TLDR - make it easier to download the models, and this description contains a couple of bash fragments to make it even easier",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/209/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/209/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/208",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/208/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/208/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/208/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/208",
    "id": 2455652897,
    "node_id": "PR_kwDOKY_97s531GNG",
    "number": 208,
    "title": "Fix wrong link",
    "user": {
      "login": "arch-btw",
      "id": 57669023,
      "node_id": "MDQ6VXNlcjU3NjY5MDIz",
      "avatar_url": "https://avatars.githubusercontent.com/u/57669023?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/arch-btw",
      "html_url": "https://github.com/arch-btw",
      "followers_url": "https://api.github.com/users/arch-btw/followers",
      "following_url": "https://api.github.com/users/arch-btw/following{/other_user}",
      "gists_url": "https://api.github.com/users/arch-btw/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/arch-btw/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/arch-btw/subscriptions",
      "organizations_url": "https://api.github.com/users/arch-btw/orgs",
      "repos_url": "https://api.github.com/users/arch-btw/repos",
      "events_url": "https://api.github.com/users/arch-btw/events{/privacy}",
      "received_events_url": "https://api.github.com/users/arch-btw/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-08-08T12:18:19Z",
    "updated_at": "2024-08-08T12:43:43Z",
    "closed_at": "2024-08-08T12:43:43Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/208",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/208",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/208.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/208.patch",
      "merged_at": "2024-08-08T12:43:43Z"
    },
    "body": "Fix wrong link",
    "closed_by": {
      "login": "pandora-s-git",
      "id": 128635000,
      "node_id": "U_kgDOB6rQeA",
      "avatar_url": "https://avatars.githubusercontent.com/u/128635000?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pandora-s-git",
      "html_url": "https://github.com/pandora-s-git",
      "followers_url": "https://api.github.com/users/pandora-s-git/followers",
      "following_url": "https://api.github.com/users/pandora-s-git/following{/other_user}",
      "gists_url": "https://api.github.com/users/pandora-s-git/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pandora-s-git/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pandora-s-git/subscriptions",
      "organizations_url": "https://api.github.com/users/pandora-s-git/orgs",
      "repos_url": "https://api.github.com/users/pandora-s-git/repos",
      "events_url": "https://api.github.com/users/pandora-s-git/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pandora-s-git/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/208/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/208/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/207",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/207/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/207/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/207/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/207",
    "id": 2444794089,
    "node_id": "I_kwDOKY_97s6RuJjp",
    "number": 207,
    "title": "[BUG:  config.json in mamba-codestral-7B-v0.1 is error",
    "user": {
      "login": "Fly-Pluche",
      "id": 73021377,
      "node_id": "MDQ6VXNlcjczMDIxMzc3",
      "avatar_url": "https://avatars.githubusercontent.com/u/73021377?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Fly-Pluche",
      "html_url": "https://github.com/Fly-Pluche",
      "followers_url": "https://api.github.com/users/Fly-Pluche/followers",
      "following_url": "https://api.github.com/users/Fly-Pluche/following{/other_user}",
      "gists_url": "https://api.github.com/users/Fly-Pluche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Fly-Pluche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Fly-Pluche/subscriptions",
      "organizations_url": "https://api.github.com/users/Fly-Pluche/orgs",
      "repos_url": "https://api.github.com/users/Fly-Pluche/repos",
      "events_url": "https://api.github.com/users/Fly-Pluche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Fly-Pluche/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-08-02T11:51:40Z",
    "updated_at": "2024-08-05T07:30:10Z",
    "closed_at": "2024-08-05T07:30:10Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n```\n\n\n### Pip Freeze\n\n```shell\naccelerate==0.33.0\r\naddict==2.4.0\r\nannotated-types==0.7.0\r\napex @ file:///data2/apex\r\nasttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work\r\nastunparse==1.6.3\r\nattrs==23.1.0\r\nbackcall @ file:///home/ktietz/src/ci/backcall_1611930011877/work\r\nbeautifulsoup4 @ file:///croot/beautifulsoup4-split_1681493039619/work\r\nbitsandbytes==0.41.2\r\nblinker==1.7.0\r\nboltons @ file:///croot/boltons_1677628692245/work\r\nbrotlipy==0.7.0\r\ncertifi @ file:///croot/certifi_1690232220950/work/certifi\r\ncffi @ file:///croot/cffi_1670423208954/work\r\nchardet @ file:///home/builder/ci_310/chardet_1640804867535/work\r\ncharset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work\r\nclick==8.1.7\r\nconda @ file:///croot/conda_1696257509808/work\r\nconda-build @ file:///croot/conda-build_1696257509796/work\r\nconda-content-trust @ file:///croot/conda-content-trust_1693490622020/work\r\nconda-libmamba-solver @ file:///croot/conda-libmamba-solver_1691418897561/work/src\r\nconda-package-handling @ file:///croot/conda-package-handling_1690999929514/work\r\nconda_index @ file:///croot/conda-index_1695310357675/work\r\nconda_package_streaming @ file:///croot/conda-package-streaming_1690987966409/work\r\ncontourpy==1.2.0\r\ncoverage==7.6.0\r\ncpm-kernels @ file:///data2/package_build/cpm_kernels\r\ncryptography @ file:///croot/cryptography_1694444244250/work\r\ncycler==0.12.1\r\nCython==3.0.6\r\ndecorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work\r\ndnspython==2.4.2\r\ndocstring_parser==0.16\r\neinops==0.7.0\r\neventlet==0.36.1\r\nexceptiongroup @ file:///croot/exceptiongroup_1668714342571/work\r\nexecuting @ file:///opt/conda/conda-bld/executing_1646925071911/work\r\nexpecttest==0.1.6\r\nfilelock @ file:///croot/filelock_1672387128942/work\r\nfire==0.6.0\r\nflash-attn==2.3.6\r\nFlask==3.0.0\r\nfonttools==4.45.1\r\nfsspec==2023.9.2\r\ngmpy2 @ file:///tmp/build/80754af9/gmpy2_1645455533097/work\r\ngoogle==3.0.0\r\ngreenlet==3.0.3\r\ngrpcio==1.59.3\r\ngrpcio-tools==1.59.3\r\nhuggingface-hub==0.24.5\r\nhypothesis==6.87.1\r\nidna @ file:///croot/idna_1666125576474/work\r\nipython @ file:///croot/ipython_1694181358621/work\r\nitsdangerous==2.1.2\r\njedi @ file:///tmp/build/80754af9/jedi_1644315229345/work\r\nJinja2 @ file:///croot/jinja2_1666908132255/work\r\njoblib==1.3.2\r\njsonpatch @ file:///tmp/build/80754af9/jsonpatch_1615747632069/work\r\njsonpointer==2.1\r\njsonschema==4.21.1\r\njsonschema-specifications==2023.12.1\r\nkiwisolver==1.4.5\r\nlibarchive-c @ file:///tmp/build/80754af9/python-libarchive-c_1617780486945/work\r\nlibmambapy @ file:///croot/mamba-split_1685993156657/work/libmambapy\r\nlinecache2==1.0.0\r\nMarkupSafe @ file:///opt/conda/conda-bld/markupsafe_1654597864307/work\r\nmatplotlib==3.8.2\r\nmatplotlib-inline @ file:///opt/conda/conda-bld/matplotlib-inline_1662014470464/work\r\nmistral_common==1.3.3\r\nmistral_inference==1.3.1\r\nmkl-fft @ file:///croot/mkl_fft_1695058164594/work\r\nmkl-random @ file:///croot/mkl_random_1695059800811/work\r\nmkl-service==2.4.0\r\nmodelscope==1.16.0\r\nmore-itertools @ file:///tmp/build/80754af9/more-itertools_1637733554872/work\r\nmpmath @ file:///croot/mpmath_1690848262763/work\r\nnetworkx @ file:///croot/networkx_1690561992265/work\r\nninja==1.11.1.1\r\nnumpy @ file:///croot/numpy_and_numpy_base_1695830428084/work/dist/numpy-1.26.0-cp310-cp310-linux_x86_64.whl#sha256=fc2732718bc9e06a7b702492cb4f5afffe9671083930452d894377bf563464a3\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==9.1.0.70\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-nccl-cu12==2.20.5\r\nnvidia-nvjitlink-cu12==12.6.20\r\nnvidia-nvtx-cu12==12.1.105\r\npackaging==23.2\r\npandas==2.2.2\r\nparso @ file:///opt/conda/conda-bld/parso_1641458642106/work\r\npexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work\r\npickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work\r\nPillow @ file:///croot/pillow_1695134008276/work\r\npkginfo @ file:///croot/pkginfo_1679431160147/work\r\npluggy @ file:///tmp/build/80754af9/pluggy_1648024709248/work\r\nprompt-toolkit @ file:///croot/prompt-toolkit_1672387306916/work\r\nprotobuf==4.25.1\r\npsutil @ file:///opt/conda/conda-bld/psutil_1656431268089/work\r\nptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work\r\npycosat @ file:///croot/pycosat_1666805502580/work\r\npycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\r\npydantic==2.6.1\r\npydantic_core==2.16.2\r\nPygments @ file:///croot/pygments_1684279966437/work\r\npyOpenSSL @ file:///croot/pyopenssl_1690223430423/work\r\npyparsing==3.1.1\r\nPySocks @ file:///home/builder/ci_310/pysocks_1640793678128/work\r\npython-dateutil==2.8.2\r\npython-etcd==0.4.5\r\npytz @ file:///croot/pytz_1695131579487/work\r\nPyYAML @ file:///croot/pyyaml_1670514731622/work\r\nreferencing==0.35.1\r\nregex==2023.10.3\r\nrequests @ file:///croot/requests_1690400202158/work\r\nrpds-py==0.19.1\r\nruamel.yaml @ file:///croot/ruamel.yaml_1666304550667/work\r\nruamel.yaml.clib @ file:///croot/ruamel.yaml.clib_1666302247304/work\r\nsafetensors==0.4.3\r\nscikit-learn==1.3.2\r\nscipy==1.11.4\r\nsentencepiece==0.2.0\r\nsimple_parsing==0.1.5\r\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\r\nsortedcontainers==2.4.0\r\nsoupsieve @ file:///croot/soupsieve_1696347547217/work\r\nstack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work\r\nsympy @ file:///croot/sympy_1668202399572/work\r\ntermcolor==2.4.0\r\nthreadpoolctl==3.2.0\r\ntiktoken==0.7.0\r\ntokenizers==0.19.1\r\ntomli @ file:///opt/conda/conda-bld/tomli_1657175507142/work\r\ntoolz @ file:///croot/toolz_1667464077321/work\r\ntorch==2.4.0\r\ntorchaudio==2.1.0\r\ntorchelastic==0.2.2\r\ntorchvision==0.16.0\r\ntqdm @ file:///croot/tqdm_1679561862951/work\r\ntraceback2==1.4.0\r\ntraitlets @ file:///croot/traitlets_1671143879854/work\r\ntransformers==4.42.4\r\ntree-sitter==0.20.4\r\ntriton==3.0.0\r\ntruststore @ file:///croot/truststore_1695244293384/work\r\ntypes-dataclasses==0.6.6\r\ntyping_extensions==4.12.2\r\ntzdata==2024.1\r\nunittest2==1.1.0\r\nurllib3 @ file:///croot/urllib3_1686163155763/work\r\nwcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\r\nWerkzeug==3.0.1\r\nxformers==0.0.27.post2\r\nzstandard @ file:///croot/zstandard_1677013143055/work\n```\n\n\n### Reproduction Steps\n\n``` python\r\n\r\n\r\nfrom mistral_inference.transformer import Transformer\r\nfrom mistral_inference.generate import generate\r\n\r\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\r\nfrom mistral_common.protocol.instruct.messages import UserMessage\r\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\r\n\r\n\r\nmodel_id = \"/gxkj/models/mamba-codestral-7B-v0.1/tokenizer.model.v3\"\r\n\r\n# load tokenizer\r\nmistral_tokenizer = MistralTokenizer.from_file(model_id)\r\n# chat completion request\r\ncompletion_request = ChatCompletionRequest(messages=[UserMessage(content=\"Explain Machine Learning to me in a nutshell.\")])\r\n# encode message\r\ntokens = mistral_tokenizer.encode_chat_completion(completion_request).tokens\r\n# load model\r\nmodel = \"/gxkj/models/mamba-codestral-7B-v0.1\"\r\n\r\nmodel = Transformer.from_folder(model)\r\n# generate results\r\nout_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=mistral_tokenizer.instruct_tokenizer.tokenizer.eos_id)\r\n# decode generated tokens\r\nresult = mistral_tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\r\nprint(result)\r\n```\r\n\r\n![image](https://github.com/user-attachments/assets/ab4c4cac-3f1c-4f0a-840d-1ecd0fec2f1c)\r\n\n\n### Expected Behavior\n\nconfig.json is error.\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": {
      "login": "Fly-Pluche",
      "id": 73021377,
      "node_id": "MDQ6VXNlcjczMDIxMzc3",
      "avatar_url": "https://avatars.githubusercontent.com/u/73021377?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Fly-Pluche",
      "html_url": "https://github.com/Fly-Pluche",
      "followers_url": "https://api.github.com/users/Fly-Pluche/followers",
      "following_url": "https://api.github.com/users/Fly-Pluche/following{/other_user}",
      "gists_url": "https://api.github.com/users/Fly-Pluche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Fly-Pluche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Fly-Pluche/subscriptions",
      "organizations_url": "https://api.github.com/users/Fly-Pluche/orgs",
      "repos_url": "https://api.github.com/users/Fly-Pluche/repos",
      "events_url": "https://api.github.com/users/Fly-Pluche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Fly-Pluche/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/207/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/207/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/206",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/206/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/206/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/206/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/206",
    "id": 2432758736,
    "node_id": "I_kwDOKY_97s6RAPPQ",
    "number": 206,
    "title": "[BUG: ImportError: cannot import name 'Transformer' from 'mistral_inference.model' (/usr/local/lib/python3.10/dist-packages/mistral_inference/model.py)",
    "user": {
      "login": "rabeeqasem",
      "id": 44259257,
      "node_id": "MDQ6VXNlcjQ0MjU5MjU3",
      "avatar_url": "https://avatars.githubusercontent.com/u/44259257?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rabeeqasem",
      "html_url": "https://github.com/rabeeqasem",
      "followers_url": "https://api.github.com/users/rabeeqasem/followers",
      "following_url": "https://api.github.com/users/rabeeqasem/following{/other_user}",
      "gists_url": "https://api.github.com/users/rabeeqasem/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rabeeqasem/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rabeeqasem/subscriptions",
      "organizations_url": "https://api.github.com/users/rabeeqasem/orgs",
      "repos_url": "https://api.github.com/users/rabeeqasem/repos",
      "events_url": "https://api.github.com/users/rabeeqasem/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rabeeqasem/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 9,
    "created_at": "2024-07-26T18:16:20Z",
    "updated_at": "2024-08-05T08:16:11Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n```\n\n\n### Pip Freeze\n\n```shell\nabsl-py==1.4.0\r\naccelerate==0.32.1\r\naiohttp==3.9.5\r\naiosignal==1.3.1\r\nalabaster==0.7.16\r\nalbumentations==1.3.1\r\naltair==4.2.2\r\nannotated-types==0.7.0\r\nanyio==3.7.1\r\nargon2-cffi==23.1.0\r\nargon2-cffi-bindings==21.2.0\r\narray_record==0.5.1\r\narviz==0.15.1\r\nastropy==5.3.4\r\nastunparse==1.6.3\r\nasync-timeout==4.0.3\r\natpublic==4.1.0\r\nattrs==23.2.0\r\naudioread==3.0.1\r\nautograd==1.6.2\r\nBabel==2.15.0\r\nbackcall==0.2.0\r\nbeautifulsoup4==4.12.3\r\nbidict==0.23.1\r\nbigframes==1.11.1\r\nbleach==6.1.0\r\nblinker==1.4\r\nblis==0.7.11\r\nblosc2==2.0.0\r\nbokeh==3.3.4\r\nbqplot==0.12.43\r\nbranca==0.7.2\r\nbuild==1.2.1\r\nCacheControl==0.14.0\r\ncachetools==5.4.0\r\ncatalogue==2.0.10\r\ncertifi==2024.7.4\r\ncffi==1.16.0\r\nchardet==5.2.0\r\ncharset-normalizer==3.3.2\r\nchex==0.1.86\r\nclarabel==0.9.0\r\ncleo==2.1.0\r\nclick==8.1.7\r\nclick-plugins==1.1.1\r\ncligj==0.7.2\r\ncloudpathlib==0.18.1\r\ncloudpickle==2.2.1\r\ncmake==3.27.9\r\ncmdstanpy==1.2.4\r\ncolorcet==3.1.0\r\ncolorlover==0.3.0\r\ncolour==0.1.5\r\ncommunity==1.0.0b1\r\nconfection==0.1.5\r\ncons==0.4.6\r\ncontextlib2==21.6.0\r\ncontourpy==1.2.1\r\ncrashtest==0.4.1\r\ncryptography==43.0.0\r\ncuda-python==12.2.1\r\ncudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.4.1-cp310-cp310-manylinux_2_28_x86_64.whl#sha256=57366e7ef09dc63e0b389aff20df6c37d91e2790065861ee31a4720149f5b694\r\ncufflinks==0.17.3\r\ncupy-cuda12x==12.2.0\r\ncvxopt==1.3.2\r\ncvxpy==1.5.2\r\ncycler==0.12.1\r\ncymem==2.0.8\r\nCython==3.0.10\r\ndask==2023.8.1\r\ndatascience==0.17.6\r\ndb-dtypes==1.2.0\r\ndbus-python==1.2.18\r\ndebugpy==1.6.6\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\ndistlib==0.3.8\r\ndistributed==2023.8.1\r\ndistro==1.7.0\r\ndlib==19.24.4\r\ndm-tree==0.1.8\r\ndocstring_parser==0.16\r\ndocutils==0.18.1\r\ndopamine_rl==4.0.9\r\nduckdb==0.10.3\r\ndulwich==0.21.7\r\nearthengine-api==0.1.412\r\neasydict==1.13\r\necos==2.0.14\r\neditdistance==0.6.2\r\neerepr==0.0.4\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\r\nentrypoints==0.4\r\net-xmlfile==1.1.0\r\netils==1.7.0\r\netuples==0.3.9\r\nexceptiongroup==1.2.2\r\nfastai==2.7.15\r\nfastcore==1.5.54\r\nfastdownload==0.0.7\r\nfastjsonschema==2.20.0\r\nfastprogress==1.0.3\r\nfastrlock==0.8.2\r\nfilelock==3.15.4\r\nfiona==1.9.6\r\nfire==0.6.0\r\nfirebase-admin==5.3.0\r\nFlask==2.2.5\r\nflatbuffers==24.3.25\r\nflax==0.8.4\r\nfolium==0.14.0\r\nfonttools==4.53.1\r\nfrozendict==2.4.4\r\nfrozenlist==1.4.1\r\nfsspec==2023.6.0\r\nfuture==0.18.3\r\ngast==0.6.0\r\ngcsfs==2023.6.0\r\nGDAL==3.6.4\r\ngdown==5.1.0\r\ngeemap==0.33.1\r\ngensim==4.3.3\r\ngeocoder==1.38.1\r\ngeographiclib==2.0\r\ngeopandas==0.13.2\r\ngeopy==2.3.0\r\ngin-config==0.5.0\r\nglob2==0.7\r\ngoogle==2.0.3\r\ngoogle-ai-generativelanguage==0.6.6\r\ngoogle-api-core==2.19.1\r\ngoogle-api-python-client==2.137.0\r\ngoogle-auth==2.27.0\r\ngoogle-auth-httplib2==0.2.0\r\ngoogle-auth-oauthlib==1.2.1\r\ngoogle-cloud-aiplatform==1.59.0\r\ngoogle-cloud-bigquery==3.25.0\r\ngoogle-cloud-bigquery-connection==1.15.4\r\ngoogle-cloud-bigquery-storage==2.25.0\r\ngoogle-cloud-bigtable==2.25.0\r\ngoogle-cloud-core==2.4.1\r\ngoogle-cloud-datastore==2.19.0\r\ngoogle-cloud-firestore==2.16.1\r\ngoogle-cloud-functions==1.16.4\r\ngoogle-cloud-iam==2.15.1\r\ngoogle-cloud-language==2.13.4\r\ngoogle-cloud-pubsub==2.22.0\r\ngoogle-cloud-resource-manager==1.12.4\r\ngoogle-cloud-storage==2.8.0\r\ngoogle-cloud-translate==3.15.4\r\ngoogle-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz#sha256=b8deedac71ff3db3b2e77e0b24edc5d10e65cee289f242ec5bff06d7583b32e8\r\ngoogle-crc32c==1.5.0\r\ngoogle-generativeai==0.7.2\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==2.7.1\r\ngoogleapis-common-protos==1.63.2\r\ngoogledrivedownloader==0.4\r\ngraphviz==0.20.3\r\ngreenlet==3.0.3\r\ngrpc-google-iam-v1==0.13.1\r\ngrpcio==1.64.1\r\ngrpcio-status==1.48.2\r\ngspread==6.0.2\r\ngspread-dataframe==3.3.1\r\ngym==0.25.2\r\ngym-notices==0.0.8\r\nh5netcdf==1.3.0\r\nh5py==3.9.0\r\nholidays==0.53\r\nholoviews==1.17.1\r\nhtml5lib==1.1\r\nhttpimport==1.3.1\r\nhttplib2==0.22.0\r\nhuggingface-hub==0.23.5\r\nhumanize==4.7.0\r\nhyperopt==0.2.7\r\nibis-framework==8.0.0\r\nidna==3.7\r\nimageio==2.31.6\r\nimageio-ffmpeg==0.5.1\r\nimagesize==1.4.1\r\nimbalanced-learn==0.10.1\r\nimgaug==0.4.0\r\nimmutabledict==4.2.0\r\nimportlib_metadata==8.0.0\r\nimportlib_resources==6.4.0\r\nimutils==0.5.4\r\ninflect==7.0.0\r\niniconfig==2.0.0\r\ninstaller==0.7.0\r\nintel-openmp==2023.2.4\r\nipyevents==2.0.2\r\nipyfilechooser==0.6.0\r\nipykernel==5.5.6\r\nipyleaflet==0.18.2\r\nipyparallel==8.8.0\r\nipython==7.34.0\r\nipython-genutils==0.2.0\r\nipython-sql==0.5.0\r\nipytree==0.2.2\r\nipywidgets==7.7.1\r\nitsdangerous==2.2.0\r\njaraco.classes==3.4.0\r\njax==0.4.26\r\njaxlib @ https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.26+cuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl#sha256=813cf1fe3e7ca4dbf5327d6e7b4fc8521e92d8bba073ee645ae0d5d036a25750\r\njeepney==0.7.1\r\njellyfish==1.0.4\r\njieba==0.42.1\r\nJinja2==3.1.4\r\njoblib==1.4.2\r\njsonpickle==3.2.2\r\njsonschema==4.21.1\r\njsonschema-specifications==2023.12.1\r\njupyter-client==6.1.12\r\njupyter-console==6.1.0\r\njupyter-server==1.24.0\r\njupyter_core==5.7.2\r\njupyterlab_pygments==0.3.0\r\njupyterlab_widgets==3.0.11\r\nkaggle==1.6.14\r\nkagglehub==0.2.8\r\nkeras==2.15.0\r\nkeyring==24.3.1\r\nkiwisolver==1.4.5\r\nlangcodes==3.4.0\r\nlanguage_data==1.2.0\r\nlaunchpadlib==1.10.16\r\nlazr.restfulclient==0.14.4\r\nlazr.uri==1.0.6\r\nlazy_loader==0.4\r\nlibclang==18.1.1\r\nlibrosa==0.10.2.post1\r\nlightgbm==4.1.0\r\nlinkify-it-py==2.0.3\r\nllvmlite==0.41.1\r\nlocket==1.0.0\r\nlogical-unification==0.4.6\r\nlxml==4.9.4\r\nmalloy==2023.1067\r\nmarisa-trie==1.2.0\r\nMarkdown==3.6\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.5\r\nmatplotlib==3.7.1\r\nmatplotlib-inline==0.1.7\r\nmatplotlib-venn==0.11.10\r\nmdit-py-plugins==0.4.1\r\nmdurl==0.1.2\r\nminiKanren==1.0.3\r\nmissingno==0.5.2\r\nmistral_common==1.3.3\r\nmistral_inference==1.3.1\r\nmistune==0.8.4\r\nmizani==0.9.3\r\nmkl==2023.2.0\r\nml-dtypes==0.2.0\r\nmlxtend==0.22.0\r\nmore-itertools==10.1.0\r\nmoviepy==1.0.3\r\nmpmath==1.3.0\r\nmsgpack==1.0.8\r\nmultidict==6.0.5\r\nmultipledispatch==1.0.0\r\nmultitasking==0.0.11\r\nmurmurhash==1.0.10\r\nmusic21==9.1.0\r\nnatsort==8.4.0\r\nnbclassic==1.1.0\r\nnbclient==0.10.0\r\nnbconvert==6.5.4\r\nnbformat==5.10.4\r\nnest-asyncio==1.6.0\r\nnetworkx==3.3\r\nnibabel==4.0.2\r\nnltk==3.8.1\r\nnotebook==6.5.5\r\nnotebook_shim==0.2.4\r\nnumba==0.58.1\r\nnumexpr==2.10.1\r\nnumpy==1.25.2\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==8.9.2.26\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-nccl-cu12==2.19.3\r\nnvidia-nvjitlink-cu12==12.5.82\r\nnvidia-nvtx-cu12==12.1.105\r\nnvtx==0.2.10\r\noauth2client==4.1.3\r\noauthlib==3.2.2\r\nopencv-contrib-python==4.8.0.76\r\nopencv-python==4.8.0.76\r\nopencv-python-headless==4.10.0.84\r\nopenpyxl==3.1.5\r\nopt-einsum==3.3.0\r\noptax==0.2.2\r\norbax-checkpoint==0.4.4\r\nosqp==0.6.2.post8\r\npackaging==24.1\r\npandas==2.0.3\r\npandas-datareader==0.10.0\r\npandas-gbq==0.19.2\r\npandas-stubs==2.0.3.230814\r\npandocfilters==1.5.1\r\npanel==1.3.8\r\nparam==2.1.1\r\nparso==0.8.4\r\nparsy==2.1\r\npartd==1.4.2\r\npathlib==1.0.1\r\npatsy==0.5.6\r\npeewee==3.17.6\r\npexpect==4.9.0\r\npickleshare==0.7.5\r\nPillow==9.4.0\r\npip-tools==7.4.1\r\npkginfo==1.11.1\r\nplatformdirs==4.2.2\r\nplotly==5.15.0\r\nplotnine==0.12.4\r\npluggy==1.5.0\r\npoetry==1.8.3\r\npoetry-core==1.9.0\r\npoetry-plugin-export==1.8.0\r\npolars==0.20.2\r\npooch==1.8.2\r\nportpicker==1.5.2\r\nprefetch_generator==1.0.3\r\npreshed==3.0.9\r\nprettytable==3.10.2\r\nproglog==0.1.10\r\nprogressbar2==4.2.0\r\nprometheus_client==0.20.0\r\npromise==2.3\r\nprompt_toolkit==3.0.47\r\nprophet==1.1.5\r\nproto-plus==1.24.0\r\nprotobuf==3.20.3\r\npsutil==5.9.5\r\npsycopg2==2.9.9\r\nptyprocess==0.7.0\r\npy-cpuinfo==9.0.0\r\npy4j==0.10.9.7\r\npyarrow==14.0.2\r\npyarrow-hotfix==0.6\r\npyasn1==0.6.0\r\npyasn1_modules==0.4.0\r\npycocotools==2.0.8\r\npycparser==2.22\r\npydantic==2.6.1\r\npydantic_core==2.16.2\r\npydata-google-auth==1.8.2\r\npydot==1.4.2\r\npydot-ng==2.0.0\r\npydotplus==2.0.2\r\nPyDrive==1.3.1\r\nPyDrive2==1.6.3\r\npyerfa==2.0.1.4\r\npygame==2.6.0\r\nPygments==2.16.1\r\nPyGObject==3.42.1\r\nPyJWT==2.3.0\r\npymc==5.10.4\r\npymystem3==0.2.0\r\npynvjitlink-cu12==0.3.0\r\nPyOpenGL==3.1.7\r\npyOpenSSL==24.2.1\r\npyparsing==3.1.2\r\npyperclip==1.9.0\r\npyproj==3.6.1\r\npyproject_hooks==1.1.0\r\npyshp==2.3.1\r\nPySocks==1.7.1\r\npytensor==2.18.6\r\npytest==7.4.4\r\npython-apt==2.4.0\r\npython-box==7.2.0\r\npython-dateutil==2.8.2\r\npython-louvain==0.16\r\npython-slugify==8.0.4\r\npython-utils==3.8.2\r\npytz==2023.4\r\npyviz_comms==3.0.2\r\nPyWavelets==1.6.0\r\nPyYAML==6.0.1\r\npyzmq==24.0.1\r\nqdldl==0.1.7.post4\r\nqudida==0.0.4\r\nrapidfuzz==3.9.4\r\nratelim==0.1.6\r\nreferencing==0.35.1\r\nregex==2024.5.15\r\nrequests==2.31.0\r\nrequests-oauthlib==1.3.1\r\nrequests-toolbelt==1.0.0\r\nrequirements-parser==0.9.0\r\nrich==13.7.1\r\nrmm-cu12==24.4.0\r\nrpds-py==0.19.0\r\nrpy2==3.4.2\r\nrsa==4.9\r\nsafetensors==0.4.3\r\nscikit-image==0.19.3\r\nscikit-learn==1.2.2\r\nscipy==1.11.4\r\nscooby==0.10.0\r\nscs==3.2.6\r\nseaborn==0.13.1\r\nSecretStorage==3.3.1\r\nSend2Trash==1.8.3\r\nsentencepiece==0.2.0\r\nshapely==2.0.5\r\nshellingham==1.5.4\r\nsimple_parsing==0.1.5\r\nsix==1.16.0\r\nsklearn-pandas==2.2.0\r\nsmart-open==7.0.4\r\nsniffio==1.3.1\r\nsnowballstemmer==2.2.0\r\nsortedcontainers==2.4.0\r\nsoundfile==0.12.1\r\nsoupsieve==2.5\r\nsoxr==0.3.7\r\nspacy==3.7.5\r\nspacy-legacy==3.0.12\r\nspacy-loggers==1.0.5\r\nSphinx==5.0.2\r\nsphinxcontrib-applehelp==1.0.8\r\nsphinxcontrib-devhelp==1.0.6\r\nsphinxcontrib-htmlhelp==2.0.6\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.8\r\nsphinxcontrib-serializinghtml==1.1.10\r\nSQLAlchemy==2.0.31\r\nsqlglot==20.11.0\r\nsqlparse==0.5.1\r\nsrsly==2.4.8\r\nstanio==0.5.1\r\nstatsmodels==0.14.2\r\nStrEnum==0.4.15\r\nsympy==1.13.1\r\ntables==3.8.0\r\ntabulate==0.9.0\r\ntbb==2021.13.0\r\ntblib==3.0.0\r\ntenacity==8.5.0\r\ntensorboard==2.15.2\r\ntensorboard-data-server==0.7.2\r\ntensorflow @ https://storage.googleapis.com/colab-tf-builds-public-09h6ksrfwbb9g9xv/tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=a2ec79931350b378c1ef300ca836b52a55751acb71a433582508a07f0de57c42\r\ntensorflow-datasets==4.9.6\r\ntensorflow-estimator==2.15.0\r\ntensorflow-gcs-config==2.15.0\r\ntensorflow-hub==0.16.1\r\ntensorflow-io-gcs-filesystem==0.37.1\r\ntensorflow-metadata==1.15.0\r\ntensorflow-probability==0.23.0\r\ntensorstore==0.1.45\r\ntermcolor==2.4.0\r\nterminado==0.18.1\r\ntext-unidecode==1.3\r\ntextblob==0.17.1\r\ntf-slim==1.1.0\r\ntf_keras==2.15.1\r\nthinc==8.2.5\r\nthreadpoolctl==3.5.0\r\ntifffile==2024.7.21\r\ntiktoken==0.7.0\r\ntinycss2==1.3.0\r\ntokenizers==0.19.1\r\ntoml==0.10.2\r\ntomli==2.0.1\r\ntomlkit==0.13.0\r\ntoolz==0.12.1\r\ntorch==2.2.0\r\ntorchaudio @ https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=0b423f4ae3356f11f6723e8c77208ac3f9361a4f941e4cc08d86c32c137594bc\r\ntorchsummary==1.5.1\r\ntorchtext==0.18.0\r\ntorchvision @ https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=e95ba5a2c616939281e01babf11664d6d1725e81bba57ef81f81c3e57e4d4151\r\ntornado==6.3.3\r\ntqdm==4.66.4\r\ntraitlets==5.7.1\r\ntraittypes==0.2.1\r\ntransformers==4.42.4\r\ntriton==2.2.0\r\ntrove-classifiers==2024.7.2\r\ntweepy==4.14.0\r\ntyper==0.12.3\r\ntypes-pytz==2024.1.0.20240417\r\ntypes-setuptools==71.1.0.20240724\r\ntyping_extensions==4.12.2\r\ntzdata==2024.1\r\ntzlocal==5.2\r\nuc-micro-py==1.0.3\r\nuritemplate==4.1.1\r\nurllib3==2.0.7\r\nvega-datasets==0.9.0\r\nvirtualenv==20.26.3\r\nwadllib==1.3.6\r\nwasabi==1.1.3\r\nwcwidth==0.2.13\r\nweasel==0.4.1\r\nwebcolors==24.6.0\r\nwebencodings==0.5.1\r\nwebsocket-client==1.8.0\r\nWerkzeug==3.0.3\r\nwidgetsnbextension==3.6.7\r\nwordcloud==1.9.3\r\nwrapt==1.14.1\r\nxarray==2023.7.0\r\nxarray-einstats==0.7.0\r\nxformers==0.0.24\r\nxgboost==2.0.3\r\nxlrd==2.0.1\r\nxyzservices==2024.6.0\r\nyarl==1.9.4\r\nyellowbrick==1.5\r\nyfinance==0.2.41\r\nzict==3.0.0\r\nzipp==3.19.2\n```\n\n\n### Reproduction Steps\n\n1. installed it as documentation !pip install mistral-inference\r\n2. import it from mistral_inference.model import Transformer\r\n\n\n### Expected Behavior\n\ni have a proplem when im importing mistral_inference when i finedtuned the mistral model based on this official [repo](https://github.com/mistralai/mistral-finetune) but when im try to do an inferance using the mistral_inference it gives me this error \r\n```\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n[<ipython-input-2-21d900f74e3e>](https://localhost:8080/#) in <cell line: 1>()\r\n----> 1 from mistral_inference.model import Transformer\r\n      2 from mistral_inference.generate import generate\r\n      3 \r\n      4 from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\r\n      5 from mistral_common.protocol.instruct.messages import UserMessage\r\n\r\nImportError: cannot import name 'Transformer' from 'mistral_inference.model' (/usr/local/lib/python3.10/dist-packages/mistral_inference/model.py)\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: If your import is failing due to a missing package, you can\r\nmanually install dependencies using either !pip or !apt.\r\n\r\nTo view examples of installing some common dependencies, click the\r\n\"Open Examples\" button below.\r\n---------------------------------------------------------------------------\r\n```\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/206/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/206/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/205",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/205/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/205/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/205/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/205",
    "id": 2431298478,
    "node_id": "I_kwDOKY_97s6Q6quu",
    "number": 205,
    "title": "[BUG: Could not find consolidated.00.pth or consolidated.safetensors in Mistral model path but mistralai/Mistral-Large-Instruct-2407 surely not contains it ",
    "user": {
      "login": "ShadowTeamCN",
      "id": 11573254,
      "node_id": "MDQ6VXNlcjExNTczMjU0",
      "avatar_url": "https://avatars.githubusercontent.com/u/11573254?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ShadowTeamCN",
      "html_url": "https://github.com/ShadowTeamCN",
      "followers_url": "https://api.github.com/users/ShadowTeamCN/followers",
      "following_url": "https://api.github.com/users/ShadowTeamCN/following{/other_user}",
      "gists_url": "https://api.github.com/users/ShadowTeamCN/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ShadowTeamCN/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ShadowTeamCN/subscriptions",
      "organizations_url": "https://api.github.com/users/ShadowTeamCN/orgs",
      "repos_url": "https://api.github.com/users/ShadowTeamCN/repos",
      "events_url": "https://api.github.com/users/ShadowTeamCN/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ShadowTeamCN/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 11,
    "created_at": "2024-07-26T02:38:28Z",
    "updated_at": "2025-06-05T09:26:00Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n```\n\n\n### Pip Freeze\n\n```shell\naccelerate==0.32.1\r\naiohttp==3.9.5\r\naiosignal==1.3.1\r\nannotated-types==0.7.0\r\nanyio==4.4.0\r\nargon2-cffi==23.1.0\r\nargon2-cffi-bindings==21.2.0\r\narrow==1.3.0\r\nasttokens==2.4.1\r\nasync-lru==2.0.4\r\nasync-timeout==4.0.3\r\nattrs==23.2.0\r\nBabel==2.15.0\r\nbeautifulsoup4==4.12.3\r\nbitsandbytes==0.43.1\r\nbleach==6.1.0\r\nblinker==1.8.2\r\ncertifi==2024.7.4\r\ncffi==1.16.0\r\ncharset-normalizer==3.3.2\r\nclick==8.1.7\r\ncloudpickle==3.0.0\r\ncmake==3.30.0\r\ncomm==0.2.2\r\ncos-python-sdk-v5==1.9.30\r\ncoscmd==1.8.6.31\r\ncrcmod==1.7\r\ndatasets==2.20.0\r\nDateTime==5.5\r\ndbus-python==1.2.18\r\ndebugpy==1.8.2\r\ndecorator==5.1.1\r\ndeepspeed==0.14.4\r\ndefusedxml==0.7.1\r\ndill==0.3.8\r\ndiskcache==5.6.3\r\ndistro==1.7.0\r\ndnspython==2.6.1\r\ndocstring_parser==0.16\r\neinops==0.8.0\r\nemail_validator==2.2.0\r\net-xmlfile==1.1.0\r\nexceptiongroup==1.2.2\r\nexecuting==2.0.1\r\nfastapi==0.111.1\r\nfastapi-cli==0.0.4\r\nfastjsonschema==2.20.0\r\nfilelock==3.15.4\r\nfire==0.6.0\r\nflash-attn==2.6.1\r\nFlask==3.0.3\r\nfqdn==1.5.1\r\nfrozenlist==1.4.1\r\nfsspec==2024.5.0\r\nh11==0.14.0\r\nhjson==3.1.0\r\nhttpcore==1.0.5\r\nhttptools==0.6.1\r\nhttpx==0.27.0\r\nhuggingface-hub==0.24.0\r\nidna==3.7\r\ninteregular==0.3.3\r\nipykernel==6.29.5\r\nipython==8.26.0\r\nipywidgets==8.1.3\r\nisoduration==20.11.0\r\nitsdangerous==2.2.0\r\njedi==0.19.1\r\njieba==0.42.1\r\nJinja2==3.1.4\r\njson5==0.9.25\r\njsonlines==4.0.0\r\njsonpointer==3.0.0\r\njsonschema==4.21.1\r\njsonschema-specifications==2023.12.1\r\njupyter==1.0.0\r\njupyter-console==6.6.3\r\njupyter-events==0.10.0\r\njupyter-lsp==2.2.5\r\njupyter_client==8.6.2\r\njupyter_core==5.7.2\r\njupyter_server==2.14.2\r\njupyter_server_terminals==0.5.3\r\njupyterlab==4.2.3\r\njupyterlab_pygments==0.3.0\r\njupyterlab_server==2.27.3\r\njupyterlab_widgets==3.0.11\r\njupytext==1.16.3\r\nlark==1.1.9\r\nllvmlite==0.43.0\r\nlm-format-enforcer==0.10.3\r\nloguru==0.7.2\r\nlxml==5.2.2\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.5\r\nmatplotlib-inline==0.1.7\r\nmdit-py-plugins==0.4.1\r\nmdurl==0.1.2\r\nmistral_common==1.3.3\r\nmistral_inference==1.3.1\r\nmistune==3.0.2\r\nmpmath==1.3.0\r\nmsgpack==1.0.8\r\nmultidict==6.0.5\r\nmultiprocess==0.70.16\r\nnbclient==0.10.0\r\nnbconvert==7.16.4\r\nnbformat==5.10.4\r\nnest-asyncio==1.6.0\r\nnetworkx==3.3\r\nninja==1.11.1.1\r\nnotebook==7.2.1\r\nnotebook_shim==0.2.4\r\nnumba==0.60.0\r\nnumpy==1.26.4\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==8.9.2.26\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-ml-py==12.555.43\r\nnvidia-nccl-cu12==2.20.5\r\nnvidia-nvjitlink-cu12==12.5.82\r\nnvidia-nvtx-cu12==12.1.105\r\nopenai==1.35.15\r\nopencc-python-reimplemented==0.1.7\r\nopenpyxl==3.1.5\r\noutlines==0.0.46\r\noverrides==7.7.0\r\npackaging==24.1\r\npandarallel==1.6.5\r\npandas==2.2.2\r\npandocfilters==1.5.1\r\nparso==0.8.4\r\npeft==0.11.1\r\npexpect==4.9.0\r\npillow==10.4.0\r\nplatformdirs==4.2.2\r\nprettytable==3.10.2\r\nprometheus-fastapi-instrumentator==7.0.0\r\nprometheus_client==0.20.0\r\nprompt_toolkit==3.0.47\r\nprotobuf==5.27.2\r\npsutil==6.0.0\r\nptyprocess==0.7.0\r\npure-eval==0.2.2\r\npy-cpuinfo==9.0.0\r\npyairports==2.1.1\r\npyarrow==17.0.0\r\npyarrow-hotfix==0.6\r\npycountry==24.6.1\r\npycparser==2.22\r\npycryptodome==3.20.0\r\npydantic==2.6.1\r\npydantic_core==2.16.2\r\nPygments==2.18.0\r\nPyGObject==3.42.1\r\npypinyin==0.51.0\r\npython-dateutil==2.9.0.post0\r\npython-dotenv==1.0.1\r\npython-json-logger==2.0.7\r\npython-multipart==0.0.9\r\npytz==2024.1\r\nPyYAML==6.0.1\r\npyzmq==26.0.3\r\nqtconsole==5.5.2\r\nQtPy==2.4.1\r\nray==2.32.0\r\nreferencing==0.35.1\r\nregex==2024.5.15\r\nrequests==2.32.3\r\nrfc3339-validator==0.1.4\r\nrfc3986-validator==0.1.1\r\nrich==13.7.1\r\nrpds-py==0.19.0\r\nsafetensors==0.4.3\r\nSend2Trash==1.8.3\r\nsentencepiece==0.2.0\r\nshellingham==1.5.4\r\nsimple_parsing==0.1.5\r\nsix==1.16.0\r\nsniffio==1.3.1\r\nsoupsieve==2.5\r\nssh-import-id==5.11\r\nstack-data==0.6.3\r\nstarlette==0.37.2\r\nsympy==1.13.0\r\ntencentcloud-sdk-python==3.0.955\r\ntermcolor==2.4.0\r\nterminado==0.18.1\r\ntikit==1.7.9.240628\r\ntiktoken==0.7.0\r\ntinycss2==1.3.0\r\ntokenizers==0.19.1\r\ntomli==2.0.1\r\ntorch==2.3.1\r\ntorchvision==0.18.1\r\ntornado==6.4.1\r\ntqdm==4.66.4\r\ntraitlets==5.14.3\r\ntransformers==4.42.4\r\ntriton==2.3.1\r\ntyper==0.12.3\r\ntypes-python-dateutil==2.9.0.20240316\r\ntyping_extensions==4.12.2\r\ntzdata==2024.1\r\nuri-template==1.3.0\r\nurllib3==2.2.2\r\nuvicorn==0.30.1\r\nuvloop==0.19.0\r\nvllm==0.5.2\r\nvllm-flash-attn==2.5.9.post1\r\nwatchfiles==0.22.0\r\nwcwidth==0.2.13\r\nwebcolors==24.6.0\r\nwebencodings==0.5.1\r\nwebsocket-client==1.8.0\r\nwebsockets==12.0\r\nWerkzeug==3.0.3\r\nwidgetsnbextension==4.0.11\r\nxformers==0.0.27\r\nXlsxWriter==3.2.0\r\nxmltodict==0.13.0\r\nxxhash==3.4.1\r\nyarl==1.9.4\r\nzope.interface==6.4.post2\n```\n\n\n### Reproduction Steps\n\nfrom mistral_inference.transformer import Transformer\r\nfrom mistral_inference.generate import generate\r\n\r\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\r\nfrom mistral_common.protocol.instruct.messages import UserMessage\r\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\r\n\r\nmistral_models_path='/path/to/Mistral-Large-Instruct-2407/'\r\ntokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tokenizer.model.v3\")\r\nmodel = Transformer.from_folder(mistral_models_path)\r\n\n\n### Expected Behavior\n\nload model successfully\n\n### Additional Context\n\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\nCell In[3], line 10\r\n      8 mistral_models_path='/home/tione/notebook/PretrainModelStore/Mistral-Large-Instruct-2407/'\r\n      9 tokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tokenizer.model.v3\")\r\n---> 10 model = Transformer.from_folder(mistral_models_path)\r\n\r\nFile /usr/local/lib/python3.10/dist-packages/mistral_inference/transformer.py:353, in Transformer.from_folder(folder, max_batch_size, num_pipeline_ranks, device, dtype)\r\n    350 pt_model_file = Path(folder) / \"consolidated.00.pth\"\r\n    351 safetensors_model_file = Path(folder) / \"consolidated.safetensors\"\r\n--> 353 assert (\r\n    354     pt_model_file.exists() or safetensors_model_file.exists()\r\n    355 ), f\"Make sure either {pt_model_file} or {safetensors_model_file} exists\"\r\n    356 assert not (\r\n    357     pt_model_file.exists() and safetensors_model_file.exists()\r\n    358 ), f\"Both {pt_model_file} and {safetensors_model_file} cannot exist\"\r\n    360 if pt_model_file.exists():\r\n\r\nAssertionError: Make sure either /home/tione/notebook/PretrainModelStore/Mistral-Large-Instruct-2407/consolidated.00.pth or /home/tione/notebook/PretrainModelStore/Mistral-Large-Instruct-2407/consolidated.safetensors exists\n\n### Suggested Solutions\n\nI think the model file check script check the wrong file name:\r\n```\r\n        pt_model_file = Path(folder) / \"consolidated.00.pth\"\r\n        safetensors_model_file = Path(folder) / \"consolidated.safetensors\"\r\n\r\n        assert (\r\n            pt_model_file.exists() or safetensors_model_file.exists()\r\n        ), f\"Make sure either {pt_model_file} or {safetensors_model_file} exists\"\r\n        assert not (\r\n            pt_model_file.exists() and safetensors_model_file.exists()\r\n        ), f\"Both {pt_model_file} and {safetensors_model_file} cannot exist\"\r\n```",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/205/reactions",
      "total_count": 2,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 2
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/205/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/204",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/204/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/204/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/204/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/204",
    "id": 2427876790,
    "node_id": "PR_kwDOKY_97s52W4Ka",
    "number": 204,
    "title": "README newline ",
    "user": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-24T15:25:29Z",
    "updated_at": "2024-07-24T15:28:50Z",
    "closed_at": "2024-07-24T15:28:50Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/204",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/204",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/204.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/204.patch",
      "merged_at": "2024-07-24T15:28:50Z"
    },
    "body": null,
    "closed_by": {
      "login": "lerela",
      "id": 7956811,
      "node_id": "MDQ6VXNlcjc5NTY4MTE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7956811?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lerela",
      "html_url": "https://github.com/lerela",
      "followers_url": "https://api.github.com/users/lerela/followers",
      "following_url": "https://api.github.com/users/lerela/following{/other_user}",
      "gists_url": "https://api.github.com/users/lerela/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lerela/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lerela/subscriptions",
      "organizations_url": "https://api.github.com/users/lerela/orgs",
      "repos_url": "https://api.github.com/users/lerela/repos",
      "events_url": "https://api.github.com/users/lerela/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lerela/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/204/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/204/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/203",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/203/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/203/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/203/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/203",
    "id": 2427870542,
    "node_id": "PR_kwDOKY_97s52W2zf",
    "number": 203,
    "title": "Mistral Large 2 release",
    "user": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-24T15:22:22Z",
    "updated_at": "2024-07-24T15:24:57Z",
    "closed_at": "2024-07-24T15:24:57Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/203",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/203",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/203.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/203.patch",
      "merged_at": "2024-07-24T15:24:57Z"
    },
    "body": null,
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/203/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/203/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/202",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/202/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/202/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/202/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/202",
    "id": 2424522964,
    "node_id": "I_kwDOKY_97s6Qg0jU",
    "number": 202,
    "title": "[BUG: ModuleNotFoundError: No module named 'mistral_inference.transformer' \u200b",
    "user": {
      "login": "yafangwang9",
      "id": 92705719,
      "node_id": "U_kgDOBYaTtw",
      "avatar_url": "https://avatars.githubusercontent.com/u/92705719?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/yafangwang9",
      "html_url": "https://github.com/yafangwang9",
      "followers_url": "https://api.github.com/users/yafangwang9/followers",
      "following_url": "https://api.github.com/users/yafangwang9/following{/other_user}",
      "gists_url": "https://api.github.com/users/yafangwang9/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/yafangwang9/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/yafangwang9/subscriptions",
      "organizations_url": "https://api.github.com/users/yafangwang9/orgs",
      "repos_url": "https://api.github.com/users/yafangwang9/repos",
      "events_url": "https://api.github.com/users/yafangwang9/events{/privacy}",
      "received_events_url": "https://api.github.com/users/yafangwang9/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 6,
    "created_at": "2024-07-23T07:55:11Z",
    "updated_at": "2024-08-15T15:48:02Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nfrom mistral_inference.transformer import Transformer\r\nfrom mistral_inference.generate import generate\r\n\r\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\r\nfrom mistral_common.protocol.instruct.messages import UserMessage\r\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\r\n\r\ntokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tekken.json\")\r\nmodel = Transformer.from_folder(mistral_models_path)\r\n\r\nprompt = \"How expensive would it be to ask a window cleaner to clean all windows in Paris. Make a reasonable guess in US Dollar.\"\r\n\r\ncompletion_request = ChatCompletionRequest(messages=[UserMessage(content=prompt)])\r\n\r\ntokens = tokenizer.encode_chat_completion(completion_request).tokens\r\n\r\nout_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.35, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\r\nresult = tokenizer.decode(out_tokens[0])\r\n\r\nprint(result)\n```\n\n\n### Pip Freeze\n\n```shell\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\nInput In [3], in <cell line: 1>()\r\n----> 1 from mistral_inference.transformer import Transformer\r\n      2 from mistral_inference.generate import generate\r\n      4 from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\r\n\r\nModuleNotFoundError: No module named 'mistral_inference.transformer'\n```\n\n\n### Reproduction Steps\n\nI use Mistral_inference for mistral-nemo \uff0cgot this issue\n\n### Expected Behavior\n\nhttps://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/202/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/202/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/201",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/201/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/201/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/201/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/201",
    "id": 2424479296,
    "node_id": "PR_kwDOKY_97s52LWzj",
    "number": 201,
    "title": "Update README.md",
    "user": {
      "login": "RahulMR42",
      "id": 23480999,
      "node_id": "MDQ6VXNlcjIzNDgwOTk5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23480999?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/RahulMR42",
      "html_url": "https://github.com/RahulMR42",
      "followers_url": "https://api.github.com/users/RahulMR42/followers",
      "following_url": "https://api.github.com/users/RahulMR42/following{/other_user}",
      "gists_url": "https://api.github.com/users/RahulMR42/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/RahulMR42/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/RahulMR42/subscriptions",
      "organizations_url": "https://api.github.com/users/RahulMR42/orgs",
      "repos_url": "https://api.github.com/users/RahulMR42/repos",
      "events_url": "https://api.github.com/users/RahulMR42/events{/privacy}",
      "received_events_url": "https://api.github.com/users/RahulMR42/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-23T07:31:53Z",
    "updated_at": "2024-07-23T07:48:12Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/201",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/201",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/201.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/201.patch",
      "merged_at": null
    },
    "body": null,
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/201/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/201/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/200",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/200/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/200/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/200/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/200",
    "id": 2422288588,
    "node_id": "I_kwDOKY_97s6QYTDM",
    "number": 200,
    "title": "[BUG: ModuleNotFoundError: No module named 'triton']",
    "user": {
      "login": "MaxAkbar",
      "id": 13856299,
      "node_id": "MDQ6VXNlcjEzODU2Mjk5",
      "avatar_url": "https://avatars.githubusercontent.com/u/13856299?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/MaxAkbar",
      "html_url": "https://github.com/MaxAkbar",
      "followers_url": "https://api.github.com/users/MaxAkbar/followers",
      "following_url": "https://api.github.com/users/MaxAkbar/following{/other_user}",
      "gists_url": "https://api.github.com/users/MaxAkbar/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/MaxAkbar/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/MaxAkbar/subscriptions",
      "organizations_url": "https://api.github.com/users/MaxAkbar/orgs",
      "repos_url": "https://api.github.com/users/MaxAkbar/repos",
      "events_url": "https://api.github.com/users/MaxAkbar/events{/privacy}",
      "received_events_url": "https://api.github.com/users/MaxAkbar/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2024-07-22T08:38:30Z",
    "updated_at": "2024-07-23T01:58:42Z",
    "closed_at": "2024-07-23T00:57:25Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n```\n\n\n### Pip Freeze\n\n```shell\nannotated-types==0.7.0\r\nasttokens==2.4.1\r\nattrs==23.2.0\r\nBrotli @ file:///C:/b/abs_3d36mno480/croot/brotli-split_1714483178642/work\r\ncertifi @ file:///C:/b/abs_7bbxxprxir/croot/certifi_1720453609121/work/certifi\r\ncharset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work\r\ncolorama==0.4.6\r\ncomm==0.2.0\r\ndebugpy==1.8.0\r\ndecorator==5.1.1\r\ndocstring_parser==0.16\r\nexecuting==2.0.1\r\nfilelock @ file:///C:/b/abs_f2gie28u58/croot/filelock_1700591233643/work\r\nfire==0.6.0\r\nfsspec==2024.6.1\r\ngmpy2 @ file:///C:/ci_311/gmpy2_1677743390134/work\r\nhuggingface-hub==0.24.0\r\nidna @ file:///C:/b/abs_aad84bnnw5/croot/idna_1714398896795/work\r\nintel-openmp==2021.4.0\r\nipython==8.18.1\r\njedi==0.19.1\r\nJinja2 @ file:///C:/b/abs_92fccttino/croot/jinja2_1716993447201/work\r\njsonschema==4.21.1\r\njsonschema-specifications==2023.12.1\r\njupyter_client==8.6.0\r\njupyter_core==5.5.0\r\nMarkupSafe @ file:///C:/b/abs_ecfdqh67b_/croot/markupsafe_1704206030535/work\r\nmatplotlib-inline==0.1.6\r\nmistral_common==1.3.3\r\nmistral_inference==1.3.1\r\nmkl==2021.4.0\r\nmkl-fft==1.3.1\r\nmkl-random @ file:///C:/ci_311/mkl_random_1676481991689/work\r\nmkl-service==2.4.0\r\nmpmath @ file:///C:/b/abs_7833jrbiox/croot/mpmath_1690848321154/work\r\nnetworkx @ file:///C:/b/abs_36fmumtynt/croot/networkx_1720002497414/work\r\nnumpy @ file:///C:/b/abs_54abayvc9j/croot/numpy_and_numpy_base_1682520598361/work\r\npackaging==24.1\r\nparso==0.8.3\r\npillow @ file:///C:/b/abs_32o8er3uqp/croot/pillow_1721059447598/work\r\nplatformdirs==4.0.0\r\nprompt-toolkit==3.0.41\r\npure-eval==0.2.2\r\npydantic==2.6.1\r\npydantic_core==2.16.2\r\nPySocks @ file:///C:/ci_311/pysocks_1676425991111/work\r\nPyYAML @ file:///C:/b/abs_782o3mbw7z/croot/pyyaml_1698096085010/work\r\npyzmq==25.1.1\r\nreferencing==0.35.1\r\nregex==2024.5.15\r\nrequests @ file:///C:/b/abs_9c5n24p1y7/croot/requests_1716902867639/work\r\nrpds-py==0.19.0\r\nsafetensors==0.4.3\r\nsentencepiece==0.2.0\r\nsimple_parsing==0.1.5\r\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\r\nstack-data==0.6.3\r\nsympy @ file:///C:/b/abs_82njkonm7f/croot/sympy_1701397685028/work\r\ntbb==2021.13.0\r\ntermcolor==2.4.0\r\ntiktoken==0.7.0\r\ntokenizers==0.19.1\r\ntorch==2.3.1\r\ntorchaudio==2.3.1\r\ntorchvision==0.18.1\r\ntornado==6.4\r\ntqdm==4.66.4\r\ntraitlets==5.14.0\r\ntransformers==4.42.4\r\ntyping_extensions @ file:///C:/b/abs_0as9mdbkfl/croot/typing_extensions_1715268906610/work\r\nurllib3 @ file:///C:/b/abs_a7hvzm4y95/croot/urllib3_1718912661242/work\r\nwin-inet-pton @ file:///C:/ci_311/win_inet_pton_1676425458225/work\r\nxformers==0.0.27\n```\n\n\n### Reproduction Steps\n\n1. Download the model from [Mistral-7B-Instruct-v0.3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3/discussions/8) on windows 11 system with python 3.11.9 with nvidia RTX 3090.\r\n2. Create Conda environment \r\n3. Run the following code in a python file with updated path to the model path:\r\n```\r\nfrom mistral_inference.model import Transformer\r\nfrom mistral_inference.generate import generate\r\n\r\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\r\nfrom mistral_common.protocol.instruct.messages import UserMessage\r\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\r\n\r\n\r\ntokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tokenizer.model.v3\")\r\nmodel = Transformer.from_folder(mistral_models_path)\r\n\r\ncompletion_request = ChatCompletionRequest(messages=[UserMessage(content=\"Explain Machine Learning to me in a nutshell.\")])\r\n\r\ntokens = tokenizer.encode_chat_completion(completion_request).tokens\r\n\r\nout_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\r\nresult = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\r\n\r\nprint(result)\r\n```\r\n\r\nActual Result: \r\nA matching Triton is not available, some optimizations will not be enabled\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\\\-----\\anaconda3\\envs\\mistral\\Lib\\site-packages\\xformers\\__init__.py\", line 57, in _is_triton_available\r\n    import triton  # noqa\r\n    ^^^^^^^^^^^^^\r\nModuleNotFoundError: No module named 'triton'\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\\\-----\\source\\repos\\Mistral-7B-Instruct-v0.3\\simplechat.py\", line 1, in <module>\r\n    from mistral_inference.model import Transformer\r\nImportError: cannot import name 'Transformer' from 'mistral_inference.model' (C:\\Users\\\\-----\\anaconda3\\envs\\mistral\\Lib\\site-packages\\mistral_inference\\model.py)\n\n### Expected Behavior\n\nResponse from the model.\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": {
      "login": "MaxAkbar",
      "id": 13856299,
      "node_id": "MDQ6VXNlcjEzODU2Mjk5",
      "avatar_url": "https://avatars.githubusercontent.com/u/13856299?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/MaxAkbar",
      "html_url": "https://github.com/MaxAkbar",
      "followers_url": "https://api.github.com/users/MaxAkbar/followers",
      "following_url": "https://api.github.com/users/MaxAkbar/following{/other_user}",
      "gists_url": "https://api.github.com/users/MaxAkbar/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/MaxAkbar/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/MaxAkbar/subscriptions",
      "organizations_url": "https://api.github.com/users/MaxAkbar/orgs",
      "repos_url": "https://api.github.com/users/MaxAkbar/repos",
      "events_url": "https://api.github.com/users/MaxAkbar/events{/privacy}",
      "received_events_url": "https://api.github.com/users/MaxAkbar/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/200/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/200/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/199",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/199/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/199/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/199/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/199",
    "id": 2420993567,
    "node_id": "PR_kwDOKY_97s51_iEJ",
    "number": 199,
    "title": "Improve mistral inference",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-20T17:48:13Z",
    "updated_at": "2024-08-05T11:17:08Z",
    "closed_at": "2024-08-05T11:17:08Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/199",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/199",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/199.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/199.patch",
      "merged_at": "2024-08-05T11:17:08Z"
    },
    "body": "Improve as per comments here: https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407/discussions/12",
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/199/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/199/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/198",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/198/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/198/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/198/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/198",
    "id": 2420543407,
    "node_id": "PR_kwDOKY_97s51-AqJ",
    "number": 198,
    "title": "Update README.md",
    "user": {
      "login": "bhargavyagnik",
      "id": 41851612,
      "node_id": "MDQ6VXNlcjQxODUxNjEy",
      "avatar_url": "https://avatars.githubusercontent.com/u/41851612?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bhargavyagnik",
      "html_url": "https://github.com/bhargavyagnik",
      "followers_url": "https://api.github.com/users/bhargavyagnik/followers",
      "following_url": "https://api.github.com/users/bhargavyagnik/following{/other_user}",
      "gists_url": "https://api.github.com/users/bhargavyagnik/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bhargavyagnik/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bhargavyagnik/subscriptions",
      "organizations_url": "https://api.github.com/users/bhargavyagnik/orgs",
      "repos_url": "https://api.github.com/users/bhargavyagnik/repos",
      "events_url": "https://api.github.com/users/bhargavyagnik/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bhargavyagnik/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-20T04:04:44Z",
    "updated_at": "2024-08-05T10:18:02Z",
    "closed_at": "2024-08-05T10:18:02Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/198",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/198",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/198.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/198.patch",
      "merged_at": "2024-08-05T10:18:02Z"
    },
    "body": "Changes to the new Nemo model usage example. (Path variable and tar file)\r\nThese changes were left out from PR #195 by @patrickvonplaten ",
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/198/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/198/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/197",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/197/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/197/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/197/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/197",
    "id": 2419183618,
    "node_id": "I_kwDOKY_97s6QMdAC",
    "number": 197,
    "title": "[BUG] Transformer.from_folder() does not load the model on multiple GPU",
    "user": {
      "login": "Cerrix",
      "id": 7694393,
      "node_id": "MDQ6VXNlcjc2OTQzOTM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7694393?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Cerrix",
      "html_url": "https://github.com/Cerrix",
      "followers_url": "https://api.github.com/users/Cerrix/followers",
      "following_url": "https://api.github.com/users/Cerrix/following{/other_user}",
      "gists_url": "https://api.github.com/users/Cerrix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Cerrix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Cerrix/subscriptions",
      "organizations_url": "https://api.github.com/users/Cerrix/orgs",
      "repos_url": "https://api.github.com/users/Cerrix/repos",
      "events_url": "https://api.github.com/users/Cerrix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Cerrix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2024-07-19T15:13:24Z",
    "updated_at": "2024-10-28T13:51:22Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\nPython 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n```\n\n\n### Pip Freeze\n\n```shell\nabsl-py @ file:///home/conda/feedstock_root/build_artifacts/absl-py_1705494584803/work\r\naccelerate==0.32.1\r\naiobotocore @ file:///home/conda/feedstock_root/build_artifacts/aiobotocore_1719300089447/work\r\naiohttp @ file:///home/conda/feedstock_root/build_artifacts/aiohttp_1713964853148/work\r\naioitertools @ file:///home/conda/feedstock_root/build_artifacts/aioitertools_1663521246073/work\r\naiosignal @ file:///home/conda/feedstock_root/build_artifacts/aiosignal_1667935791922/work\r\naiosqlite @ file:///home/conda/feedstock_root/build_artifacts/aiosqlite_1682491975081/work\r\naltair @ file:///home/conda/feedstock_root/build_artifacts/altair-split_1711824856061/work\r\namazon-q-developer-jupyterlab-ext @ file:///home/conda/feedstock_root/build_artifacts/amazon-q-developer-jupyterlab-ext_1718654116006/work\r\namazon-sagemaker-sql-editor @ file:///home/conda/feedstock_root/build_artifacts/amazon_sagemaker_sql_editor_1718780416454/work\r\namazon-sagemaker-sql-execution @ file:///home/conda/feedstock_root/build_artifacts/amazon-sagemaker-sql-execution_1713045672980/work\r\namazon-sagemaker-sql-magic @ file:///home/conda/feedstock_root/build_artifacts/amazon-sagemaker-sql-magic_1718780032766/work\r\namazon_sagemaker_jupyter_ai_q_developer @ file:///home/conda/feedstock_root/build_artifacts/amazon-sagemaker-jupyter-ai-q-developer_1718767262338/work\r\namazon_sagemaker_jupyter_scheduler @ file:///home/conda/feedstock_root/build_artifacts/amazon-sagemaker-jupyter-scheduler_1718040900290/work\r\nannotated-types==0.7.0\r\nansi2html @ file:///home/conda/feedstock_root/build_artifacts/ansi2html_1703532389991/work\r\nansicolors @ file:///home/conda/feedstock_root/build_artifacts/ansicolors_1661653730566/work\r\nantlr4-python3-runtime @ file:///home/conda/feedstock_root/build_artifacts/antlr-python-runtime-meta_1638309185939/work\r\nanyio @ file:///home/conda/feedstock_root/build_artifacts/anyio_1717693030552/work\r\narchspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1708969572489/work\r\nargon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1692818318753/work\r\nargon2-cffi-bindings @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi-bindings_1695386546427/work\r\narrow @ file:///home/conda/feedstock_root/build_artifacts/arrow_1696128962909/work\r\nasn1crypto @ file:///home/conda/feedstock_root/build_artifacts/asn1crypto_1647369152656/work\r\nastroid @ file:///home/conda/feedstock_root/build_artifacts/astroid_1716193690567/work\r\nasttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work\r\nastunparse @ file:///home/conda/feedstock_root/build_artifacts/astunparse_1610696312422/work\r\nasync-lru @ file:///home/conda/feedstock_root/build_artifacts/async-lru_1690563019058/work\r\nasync-timeout @ file:///home/conda/feedstock_root/build_artifacts/async-timeout_1691763562544/work\r\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1704011227531/work\r\nautogluon @ file:///home/conda/feedstock_root/build_artifacts/autogluon_1714773683092/work/autogluon\r\nautogluon.common @ file:///home/conda/feedstock_root/build_artifacts/autogluon.common_1714694238466/work/common\r\nautogluon.core @ file:///home/conda/feedstock_root/build_artifacts/autogluon.core_1714752967231/work/core\r\nautogluon.features @ file:///home/conda/feedstock_root/build_artifacts/autogluon.features_1714697569882/work/features\r\nautogluon.multimodal @ file:///home/conda/feedstock_root/build_artifacts/autogluon.multimodal_1714763188950/work/multimodal\r\nautogluon.tabular @ file:///home/conda/feedstock_root/build_artifacts/autogluon.tabular_1714759714895/work/tabular\r\nautogluon.timeseries @ file:///home/conda/feedstock_root/build_artifacts/autogluon.timeseries_1714764748604/work/timeseries\r\nautopep8 @ file:///home/conda/feedstock_root/build_artifacts/autopep8_1693061251004/work\r\nautovizwidget @ file:///home/conda/feedstock_root/build_artifacts/autovizwidget_1694633627542/work\r\naws-embedded-metrics @ file:///home/conda/feedstock_root/build_artifacts/aws-embedded-metrics_1696355834319/work\r\naws-glue-sessions @ file:///home/conda/feedstock_root/build_artifacts/aws-glue-sessions_1716530167930/work\r\nBabel @ file:///home/conda/feedstock_root/build_artifacts/babel_1702422572539/work\r\nbcrypt @ file:///home/conda/feedstock_root/build_artifacts/bcrypt_1715971615809/work\r\nbeautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1705564648255/work\r\nbinaryornot==0.4.4\r\nbleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1696630167146/work\r\nblinker @ file:///home/conda/feedstock_root/build_artifacts/blinker_1715091184126/work\r\nblis @ file:///home/conda/feedstock_root/build_artifacts/cython-blis_1696148805003/work\r\nboltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1711936407380/work\r\nboto3 @ file:///home/conda/feedstock_root/build_artifacts/boto3_1718954179215/work\r\nbotocore @ file:///home/conda/feedstock_root/build_artifacts/botocore_1718937901137/work\r\nBrotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1687884021435/work\r\ncached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\r\ncachetools @ file:///home/conda/feedstock_root/build_artifacts/cachetools_1708987703938/work\r\ncatalogue @ file:///home/conda/feedstock_root/build_artifacts/catalogue_1695626339626/work\r\ncatboost @ https://pypi.org/packages/cp310/c/catboost/catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl#sha256=a92da61e95919b03d611045f0f3373799deec6f8192d7d1211714a21ff0da65e\r\ncertifi @ file:///home/conda/feedstock_root/build_artifacts/certifi_1718025014955/work/certifi\r\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001684923/work\r\nchardet @ file:///home/conda/feedstock_root/build_artifacts/chardet_1695468598188/work\r\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1698833585322/work\r\nclick @ file:///home/conda/feedstock_root/build_artifacts/click_1692311806742/work\r\ncloudpathlib @ file:///home/conda/feedstock_root/build_artifacts/cloudpathlib-meta_1697837790453/work\r\ncloudpickle @ file:///home/conda/feedstock_root/build_artifacts/cloudpickle_1674202310934/work\r\ncolorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\r\ncomm @ file:///home/conda/feedstock_root/build_artifacts/comm_1710320294760/work\r\nconda @ file:///home/conda/feedstock_root/build_artifacts/conda_1701731572133/work\r\nconda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1706566000184/work/src\r\nconda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1717678605937/work\r\nconda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1717678526951/work\r\nconfection @ file:///home/conda/feedstock_root/build_artifacts/confection_1701179074719/work\r\ncontextlib2 @ file:///home/conda/feedstock_root/build_artifacts/contextlib2_1624848568296/work\r\ncontourpy @ file:///home/conda/feedstock_root/build_artifacts/contourpy_1712429905637/work\r\ncookiecutter @ file:///home/conda/feedstock_root/build_artifacts/cookiecutter_1708608886262/work\r\ncroniter @ file:///home/conda/feedstock_root/build_artifacts/croniter_1686929181238/work\r\ncryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography-split_1717559422169/work\r\ncycler @ file:///home/conda/feedstock_root/build_artifacts/cycler_1696677705766/work\r\ncymem @ file:///home/conda/feedstock_root/build_artifacts/cymem_1695443485440/work\r\ncytoolz @ file:///home/conda/feedstock_root/build_artifacts/cytoolz_1706897049115/work\r\ndash @ file:///home/conda/feedstock_root/build_artifacts/dash_1718251139044/work\r\ndask @ file:///home/conda/feedstock_root/build_artifacts/dask-core_1718917774609/work\r\ndataclasses-json @ file:///home/conda/feedstock_root/build_artifacts/dataclasses-json_1717969336599/work\r\ndatasets @ file:///home/conda/feedstock_root/build_artifacts/datasets_1717425882640/work\r\ndebugpy @ file:///home/conda/feedstock_root/build_artifacts/debugpy_1707444420542/work\r\ndecorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\r\ndeepmerge @ file:///home/conda/feedstock_root/build_artifacts/deepmerge_1702941685750/work\r\ndefusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\r\ndill @ file:///home/conda/feedstock_root/build_artifacts/dill_1706434688412/work\r\ndiskcache @ file:///home/conda/feedstock_root/build_artifacts/diskcache_1693471346238/work\r\ndistributed @ file:///home/conda/feedstock_root/build_artifacts/distributed_1718922226295/work\r\ndistro @ file:///home/conda/feedstock_root/build_artifacts/distro_1704321475663/work\r\ndocker @ file:///home/conda/feedstock_root/build_artifacts/docker-py_1716508870406/work\r\ndocstring-to-markdown @ file:///home/conda/feedstock_root/build_artifacts/docstring-to-markdown_1708563025188/work\r\ndocstring_parser==0.16\r\nentrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\r\nevaluate @ file:///home/conda/feedstock_root/build_artifacts/evaluate_1697442180934/work\r\nexceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1704921103267/work\r\nexecuting @ file:///home/conda/feedstock_root/build_artifacts/executing_1698579936712/work\r\nfaiss==1.7.4\r\nfastai @ file:///home/conda/feedstock_root/build_artifacts/fastai_1714277957289/work\r\nfastapi @ file:///home/conda/feedstock_root/build_artifacts/fastapi_1714446803450/work\r\nfastcore @ file:///home/conda/feedstock_root/build_artifacts/fastcore_1719152646370/work\r\nfastdownload @ file:///home/conda/feedstock_root/build_artifacts/fastdownload_1675782504990/work\r\nfastjsonschema @ file:///home/conda/feedstock_root/build_artifacts/python-fastjsonschema_1718477020893/work/dist\r\nfastprogress @ file:///home/conda/feedstock_root/build_artifacts/fastprogress_1658690818839/work\r\nfilelock @ file:///home/conda/feedstock_root/build_artifacts/filelock_1719088281970/work\r\nfire==0.6.0\r\nflake8 @ file:///home/conda/feedstock_root/build_artifacts/flake8_1704483779980/work\r\nFlask @ file:///home/conda/feedstock_root/build_artifacts/flask_1712667726126/work\r\nflatbuffers @ file:///home/conda/feedstock_root/build_artifacts/python-flatbuffers_1711466727397/work\r\nfonttools @ file:///home/conda/feedstock_root/build_artifacts/fonttools_1717209196293/work\r\nfqdn @ file:///home/conda/feedstock_root/build_artifacts/fqdn_1638810296540/work/dist\r\nfrozenlist @ file:///home/conda/feedstock_root/build_artifacts/frozenlist_1702645481127/work\r\nfsspec @ file:///home/conda/feedstock_root/build_artifacts/fsspec_1686342280219/work\r\nfuture @ file:///home/conda/feedstock_root/build_artifacts/future_1708610096684/work\r\ngast @ file:///home/conda/feedstock_root/build_artifacts/gast_1688368721366/work\r\ngdown @ file:///home/conda/feedstock_root/build_artifacts/gdown_1715510831822/work\r\ngitdb @ file:///home/conda/feedstock_root/build_artifacts/gitdb_1697791558612/work\r\nGitPython @ file:///home/conda/feedstock_root/build_artifacts/gitpython_1711991025291/work\r\ngluonts @ file:///home/conda/feedstock_root/build_artifacts/gluonts_1697634602503/work\r\ngmpy2 @ file:///home/conda/feedstock_root/build_artifacts/gmpy2_1715527283764/work\r\ngoogle-auth @ file:///home/conda/feedstock_root/build_artifacts/google-auth_1717749192251/work\r\ngoogle-auth-oauthlib @ file:///home/conda/feedstock_root/build_artifacts/google-auth-oauthlib_1688235217226/work\r\ngoogle-pasta==0.2.0\r\ngraphviz @ file:///home/conda/feedstock_root/build_artifacts/python-graphviz_1711016462626/work\r\ngreenlet @ file:///home/conda/feedstock_root/build_artifacts/greenlet_1703201576006/work\r\ngrpcio @ file:///home/conda/feedstock_root/build_artifacts/grpc-split_1690942284331/work\r\ngssapi @ file:///home/conda/feedstock_root/build_artifacts/python-gssapi_1697143962561/work\r\nh11 @ file:///home/conda/feedstock_root/build_artifacts/h11_1664132893548/work\r\nh2 @ file:///home/conda/feedstock_root/build_artifacts/h2_1634280454336/work\r\nh5py @ file:///home/conda/feedstock_root/build_artifacts/h5py_1717664841189/work\r\nhdijupyterutils @ file:///home/conda/feedstock_root/build_artifacts/hdijupyterutils_1694633580855/work\r\nhpack==4.0.0\r\nhttpcore @ file:///home/conda/feedstock_root/build_artifacts/httpcore_1711596990900/work\r\nhttpx @ file:///home/conda/feedstock_root/build_artifacts/httpx_1708530890843/work\r\nhuggingface-hub==0.24.0\r\nhyperframe @ file:///home/conda/feedstock_root/build_artifacts/hyperframe_1619110129307/work\r\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1713279365350/work\r\nimagecodecs-lite @ file:///home/conda/feedstock_root/build_artifacts/imagecodecs-lite_1716011160511/work\r\nimageio @ file:///home/conda/feedstock_root/build_artifacts/imageio_1719234999090/work\r\nimportlib-metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1701625711742/work\r\nimportlib_resources @ file:///home/conda/feedstock_root/build_artifacts/importlib_resources_1711040877059/work\r\nipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1717717528849/work\r\nipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1717182742060/work\r\nipywidgets @ file:///home/conda/feedstock_root/build_artifacts/ipywidgets_1716897651763/work\r\nisoduration @ file:///home/conda/feedstock_root/build_artifacts/isoduration_1638811571363/work/dist\r\nisort @ file:///home/conda/feedstock_root/build_artifacts/isort_1702518492027/work\r\nitsdangerous @ file:///home/conda/feedstock_root/build_artifacts/itsdangerous_1713372668944/work\r\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work\r\nJinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1715127149914/work\r\njmespath @ file:///home/conda/feedstock_root/build_artifacts/jmespath_1655568249366/work\r\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1714665484399/work\r\njson5 @ file:///home/conda/feedstock_root/build_artifacts/json5_1712986206667/work\r\njsonpatch @ file:///home/conda/feedstock_root/build_artifacts/jsonpatch_1695536281965/work\r\njsonpath-ng @ file:///home/conda/feedstock_root/build_artifacts/jsonpath-ng_1705008192957/work\r\njsonpointer @ file:///home/conda/feedstock_root/build_artifacts/jsonpointer_1718283388110/work\r\njsonschema==4.21.1\r\njsonschema-specifications==2023.12.1\r\njupyter @ file:///home/conda/feedstock_root/build_artifacts/jupyter_1696255489086/work\r\njupyter-console @ file:///home/conda/feedstock_root/build_artifacts/jupyter_console_1678118109161/work\r\njupyter-dash @ file:///home/conda/feedstock_root/build_artifacts/jupyter-dash_1648919001274/work\r\njupyter-events @ file:///home/conda/feedstock_root/build_artifacts/jupyter_events_1690301630599/work\r\njupyter-lsp @ file:///home/conda/feedstock_root/build_artifacts/jupyter-lsp-meta_1712707420468/work/jupyter-lsp\r\njupyter-server-mathjax @ file:///home/conda/feedstock_root/build_artifacts/jupyter-server-mathjax_1672324512570/work\r\njupyter-ydoc @ file:///home/conda/feedstock_root/build_artifacts/jupyter_ydoc_1695982286089/work/dist\r\njupyter_ai @ file:///home/conda/feedstock_root/build_artifacts/jupyter-ai_1718999803192/work\r\njupyter_ai_magics @ file:///home/conda/feedstock_root/build_artifacts/jupyter-ai-magics_1718990665983/work\r\njupyter_client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1716472197302/work\r\njupyter_collaboration @ file:///home/conda/feedstock_root/build_artifacts/jupyter-collaboration_1691763294057/work\r\njupyter_core @ file:///home/conda/feedstock_root/build_artifacts/jupyter_core_1710257277185/work\r\njupyter_scheduler @ file:///home/conda/feedstock_root/build_artifacts/jupyter_scheduler_1717458331320/work\r\njupyter_server @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_1699289262408/work\r\njupyter_server_fileid @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_fileid_1714390608391/work\r\njupyter_server_proxy @ file:///home/conda/feedstock_root/build_artifacts/jupyter-server-proxy_1718130470839/work\r\njupyter_server_terminals @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_terminals_1710262634903/work\r\njupyterlab @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_1712586972478/work\r\njupyterlab-lsp @ file:///home/conda/feedstock_root/build_artifacts/jupyter-lsp-meta_1707098417706/work/jupyterlab-lsp\r\njupyterlab_git @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab-git_1707314297225/work\r\njupyterlab_nvdashboard==0.11.0\r\njupyterlab_pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1707149102966/work\r\njupyterlab_server @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_server_1690205927615/work\r\njupyterlab_widgets @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_widgets_1716891641122/work\r\nkeras @ file:///home/conda/feedstock_root/build_artifacts/keras_1698427100715/work/keras-2.14.0-py3-none-any.whl#sha256=d7429d1d2131cc7eb1f2ea2ec330227c7d9d38dab3dfdf2e78defee4ecc43fcd\r\nkiwisolver @ file:///home/conda/feedstock_root/build_artifacts/kiwisolver_1695379902431/work\r\nkrb5 @ file:///home/conda/feedstock_root/build_artifacts/pykrb5_1708557570437/work\r\nlangchain @ file:///home/conda/feedstock_root/build_artifacts/langchain_1708677218603/work\r\nlangchain-aws @ file:///home/conda/feedstock_root/build_artifacts/langchain-aws_1716564756966/work\r\nlangchain-community @ file:///home/conda/feedstock_root/build_artifacts/langchain-community_1715223770788/work\r\nlangchain-core @ file:///home/conda/feedstock_root/build_artifacts/langchain-core_1715060411785/work\r\nlangcodes @ file:///home/conda/feedstock_root/build_artifacts/langcodes_1714235526219/work\r\nlangsmith @ file:///home/conda/feedstock_root/build_artifacts/langsmith_1719286093638/work\r\nlanguage_data @ file:///home/conda/feedstock_root/build_artifacts/language-data_1714193818885/work\r\nlibmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1711394305528/work/libmambapy\r\nlightgbm @ file:///home/conda/feedstock_root/build_artifacts/lightgbm_1674563383654/work\r\nlightning-utilities @ file:///home/conda/feedstock_root/build_artifacts/lightning-utilities_1711597355069/work\r\nllvmlite==0.43.0\r\nlocket @ file:///home/conda/feedstock_root/build_artifacts/locket_1650660393415/work\r\nlxml @ file:///home/conda/feedstock_root/build_artifacts/lxml_1704590401168/work\r\nmarisa-trie @ file:///home/conda/feedstock_root/build_artifacts/marisa-trie_1706566476731/work\r\nMarkdown @ file:///home/conda/feedstock_root/build_artifacts/markdown_1710435156458/work\r\nmarkdown-it-py @ file:///home/conda/feedstock_root/build_artifacts/markdown-it-py_1686175045316/work\r\nMarkupSafe @ file:///home/conda/feedstock_root/build_artifacts/markupsafe_1706899921127/work\r\nmarshmallow @ file:///home/conda/feedstock_root/build_artifacts/marshmallow_1717665261177/work\r\nmatplotlib @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-suite_1715976200404/work\r\nmatplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1713250518406/work\r\nmccabe @ file:///home/conda/feedstock_root/build_artifacts/mccabe_1643049622439/work\r\nmdurl @ file:///home/conda/feedstock_root/build_artifacts/mdurl_1704317613764/work\r\nmenuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1718088294643/work\r\nmistral_common==1.3.1\r\nmistral_inference==1.3.0\r\nmistune @ file:///home/conda/feedstock_root/build_artifacts/mistune_1698947099619/work\r\nml-dtypes @ file:///home/conda/feedstock_root/build_artifacts/ml_dtypes_1695280938812/work\r\nmlforecast @ file:///home/conda/feedstock_root/build_artifacts/mlforecast_1684814678333/work\r\nmock @ file:///home/conda/feedstock_root/build_artifacts/mock_1689092066756/work\r\nmodel-index @ file:///home/conda/feedstock_root/build_artifacts/model-index_1674171417239/work\r\nmpmath @ file:///home/conda/feedstock_root/build_artifacts/mpmath_1678228039184/work\r\nmsgpack @ file:///home/conda/feedstock_root/build_artifacts/msgpack-python_1715670632672/work\r\nmultidict @ file:///home/conda/feedstock_root/build_artifacts/multidict_1707040698785/work\r\nmultiprocess @ file:///home/conda/feedstock_root/build_artifacts/multiprocess_1706514640841/work\r\nmunkres==1.1.4\r\nmurmurhash @ file:///home/conda/feedstock_root/build_artifacts/murmurhash_1695449783955/work\r\nmypy-extensions @ file:///home/conda/feedstock_root/build_artifacts/mypy_extensions_1675543315189/work\r\nnbclient @ file:///home/conda/feedstock_root/build_artifacts/nbclient_1710317608672/work\r\nnbconvert @ file:///home/conda/feedstock_root/build_artifacts/nbconvert-meta_1718135430380/work\r\nnbdime @ file:///home/conda/feedstock_root/build_artifacts/nbdime_1700575643650/work\r\nnbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1712238998817/work\r\nnest_asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1705850609492/work\r\nnetworkx @ file:///home/conda/feedstock_root/build_artifacts/networkx_1712540363324/work\r\nnlpaug @ file:///home/conda/feedstock_root/build_artifacts/nlpaug_1675088251829/work\r\nnltk @ file:///home/conda/feedstock_root/build_artifacts/nltk_1672696305909/work\r\nnose @ file:///home/conda/feedstock_root/build_artifacts/nose_1602434998960/work\r\nnotebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1713397707292/work\r\nnotebook_shim @ file:///home/conda/feedstock_root/build_artifacts/notebook-shim_1707957777232/work\r\nnptyping @ file:///home/conda/feedstock_root/build_artifacts/nptyping_1668652041379/work\r\nnumba @ file:///home/conda/feedstock_root/build_artifacts/numba_1718888013454/work\r\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1707225380409/work/dist/numpy-1.26.4-cp310-cp310-linux_x86_64.whl#sha256=51131fd8fc130cd168aecaf1bc0ea85f92e8ffebf211772ceb16ac2e7f10d7ca\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==8.9.2.26\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-nccl-cu12==2.20.5\r\nnvidia-nvjitlink-cu12==12.5.82\r\nnvidia-nvtx-cu12==12.1.105\r\noauthlib @ file:///home/conda/feedstock_root/build_artifacts/oauthlib_1666056362788/work\r\nomegaconf @ file:///home/conda/feedstock_root/build_artifacts/omegaconf_1669157093953/work\r\nopenmim @ file:///home/conda/feedstock_root/build_artifacts/openmim_1679406745319/work\r\nopt-einsum @ file:///home/conda/feedstock_root/build_artifacts/opt_einsum_1696448916724/work\r\nordered-set @ file:///home/conda/feedstock_root/build_artifacts/ordered-set_1643221357603/work\r\norjson @ file:///home/conda/feedstock_root/build_artifacts/orjson_1718073284999/work/target/wheels/orjson-3.10.4-cp310-cp310-linux_x86_64.whl#sha256=378a4c2ffd007c04573a2e6ae4e5718ef07b12724ff7309ca3b2ef0d27edbf06\r\noverrides @ file:///home/conda/feedstock_root/build_artifacts/overrides_1706394519472/work\r\npackaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1696202382185/work\r\npandas @ file:///home/conda/feedstock_root/build_artifacts/pandas_1702057131119/work\r\npandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\r\npapermill @ file:///home/conda/feedstock_root/build_artifacts/papermill_1714214592023/work\r\nparamiko @ file:///home/conda/feedstock_root/build_artifacts/paramiko_1703015906107/work\r\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1712320355065/work\r\npartd @ file:///home/conda/feedstock_root/build_artifacts/partd_1715026491486/work\r\npathos @ file:///home/conda/feedstock_root/build_artifacts/pathos_1706533117008/work\r\npatsy @ file:///home/conda/feedstock_root/build_artifacts/patsy_1704469236901/work\r\npexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1706113125309/work\r\npickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\r\npillow @ file:///home/conda/feedstock_root/build_artifacts/pillow_1718833719602/work\r\npkgutil_resolve_name @ file:///home/conda/feedstock_root/build_artifacts/pkgutil-resolve-name_1694617248815/work\r\nplatformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1715777629804/work\r\nplotly @ file:///home/conda/feedstock_root/build_artifacts/plotly_1714829923649/work\r\npluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1713667077545/work\r\nply @ file:///home/conda/feedstock_root/build_artifacts/ply_1712242996588/work\r\npox @ file:///home/conda/feedstock_root/build_artifacts/pox_1706431181924/work\r\nppft @ file:///home/conda/feedstock_root/build_artifacts/ppft_1706409481851/work\r\npreshed @ file:///home/conda/feedstock_root/build_artifacts/preshed_1695644760607/work\r\nprometheus_client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1707932675456/work\r\nprompt_toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1718047967974/work\r\nprotobuf==4.21.12\r\npsutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1705722392846/work\r\nptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\r\npure-sasl @ file:///home/conda/feedstock_root/build_artifacts/pure-sasl_1631890804823/work\r\npyarrow==12.0.1\r\npyarrow-hotfix @ file:///home/conda/feedstock_root/build_artifacts/pyarrow-hotfix_1700596371886/work\r\npyasn1 @ file:///home/conda/feedstock_root/build_artifacts/pyasn1_1713209357222/work\r\npyasn1_modules @ file:///home/conda/feedstock_root/build_artifacts/pyasn1-modules_1713209683338/work\r\nPyAthena @ file:///home/conda/feedstock_root/build_artifacts/pyathena_1716887874522/work\r\npycodestyle @ file:///home/conda/feedstock_root/build_artifacts/pycodestyle_1697202867721/work\r\npycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758174/work\r\npycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1711811537435/work\r\npydantic==2.6.1\r\npydantic_core==2.16.2\r\npydocstyle @ file:///home/conda/feedstock_root/build_artifacts/pydocstyle_1673997487070/work\r\npyflakes @ file:///home/conda/feedstock_root/build_artifacts/pyflakes_1704424584912/work\r\nPygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1714846767233/work\r\nPyHive @ file:///home/conda/feedstock_root/build_artifacts/pyhive_1692318104998/work\r\nPyJWT @ file:///home/conda/feedstock_root/build_artifacts/pyjwt_1706895065046/work\r\npylint @ file:///home/conda/feedstock_root/build_artifacts/pylint_1717705591781/work\r\nPyNaCl @ file:///home/conda/feedstock_root/build_artifacts/pynacl_1695544850803/work\r\npynvml==11.5.3\r\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1706660063483/work\r\npyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1709721012883/work\r\nPyQt5==5.15.9\r\nPyQt5-sip==12.12.2\r\npyrsistent @ file:///home/conda/feedstock_root/build_artifacts/pyrsistent_1698753827123/work\r\nPySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1661604839144/work\r\npyspnego @ file:///home/conda/feedstock_root/build_artifacts/pyspnego_1718198288313/work\r\npytesseract @ file:///home/conda/feedstock_root/build_artifacts/pytesseract_1647306555263/work\r\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1709299778482/work\r\npython-json-logger @ file:///home/conda/feedstock_root/build_artifacts/python-json-logger_1677079630776/work\r\npython-lsp-jsonrpc @ file:///home/conda/feedstock_root/build_artifacts/python-lsp-jsonrpc_1695528365348/work\r\npython-lsp-server @ file:///home/conda/feedstock_root/build_artifacts/python-lsp-server-meta_1711734797703/work\r\npython-slugify @ file:///home/conda/feedstock_root/build_artifacts/python-slugify-split_1707425621764/work\r\npytoolconfig @ file:///home/conda/feedstock_root/build_artifacts/pytoolconfig_1675124745143/work\r\npytorch-lightning @ file:///home/conda/feedstock_root/build_artifacts/pytorch-lightning_1694753701789/work\r\npytorch-metric-learning @ file:///home/conda/feedstock_root/build_artifacts/pytorch-metric-learning_1674962728780/work\r\npytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1680088766131/work\r\npyu2f @ file:///home/conda/feedstock_root/build_artifacts/pyu2f_1604248910016/work\r\nPyWavelets @ file:///home/conda/feedstock_root/build_artifacts/pywavelets_1695567558330/work\r\nPyYAML @ file:///home/conda/feedstock_root/build_artifacts/pyyaml_1695373428874/work\r\npyzmq @ file:///home/conda/feedstock_root/build_artifacts/pyzmq_1715024398995/work\r\nqtconsole @ file:///home/conda/feedstock_root/build_artifacts/qtconsole-base_1714942934316/work\r\nQtPy @ file:///home/conda/feedstock_root/build_artifacts/qtpy_1698112029416/work\r\nredshift_connector @ file:///home/conda/feedstock_root/build_artifacts/redshift_connector_1718898916124/work\r\nreferencing==0.35.1\r\nregex @ file:///home/conda/feedstock_root/build_artifacts/regex_1715828395057/work\r\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1717057054362/work\r\nrequests-kerberos @ file:///home/conda/feedstock_root/build_artifacts/requests-kerberos_1708339520234/work\r\nrequests-oauthlib @ file:///home/conda/feedstock_root/build_artifacts/requests-oauthlib_1711290127547/work\r\nresponses @ file:///home/conda/feedstock_root/build_artifacts/responses_1643839609465/work\r\nretrying==1.3.3\r\nrfc3339-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3339-validator_1638811747357/work\r\nrfc3986-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3986-validator_1598024191506/work\r\nrich @ file:///home/conda/feedstock_root/build_artifacts/rich-split_1709150387247/work/dist\r\nrope @ file:///home/conda/feedstock_root/build_artifacts/rope_1711296293824/work\r\nrpds-py==0.19.0\r\nrsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1658328885051/work\r\nruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1707298115475/work\r\nruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1707314473442/work\r\ns3transfer @ file:///home/conda/feedstock_root/build_artifacts/s3transfer_1719300139436/work\r\nsafetensors @ file:///home/conda/feedstock_root/build_artifacts/safetensors_1713253444440/work\r\nsagemaker @ file:///home/conda/feedstock_root/build_artifacts/sagemaker-python-sdk_1718975582923/work\r\nsagemaker-headless-execution-driver @ file:///home/conda/feedstock_root/build_artifacts/sagemaker-headless-execution-driver_1701485690453/work\r\nsagemaker-jupyterlab-emr-extension @ file:///home/conda/feedstock_root/build_artifacts/sagemaker-jupyterlab-emr-extension_1699459875830/work\r\nsagemaker-jupyterlab-extension @ file:///home/conda/feedstock_root/build_artifacts/sagemaker-jupyterlab-extension_1713553599180/work\r\nsagemaker-jupyterlab-extension-common @ file:///home/conda/feedstock_root/build_artifacts/sagemaker-jupyterlab-extension-common_1718653645629/work\r\nsagemaker-kernel-wrapper @ file:///home/conda/feedstock_root/build_artifacts/sagemaker-kernel-wrapper_1697451623569/work\r\nsagemaker-studio-analytics-extension @ file:///home/conda/feedstock_root/build_artifacts/sagemaker-studio-analytics-extension_1697836878634/work\r\nsagemaker-studio-sparkmagic-lib @ file:///home/conda/feedstock_root/build_artifacts/sagemaker-studio-sparkmagic-lib_1695149984387/work\r\nsasl==0.3.1\r\nschema @ file:///home/conda/feedstock_root/build_artifacts/schema_1714829163029/work\r\nscikit-image @ file:///home/conda/feedstock_root/build_artifacts/scikit-image_1667117143644/work\r\nscikit-learn @ file:///home/conda/feedstock_root/build_artifacts/scikit-learn_1715869161825/work\r\nSciPy @ file:///home/conda/feedstock_root/build_artifacts/scipy-split_1700812469549/work/dist/scipy-1.11.4-cp310-cp310-linux_x86_64.whl#sha256=136e231ccb8768e60c17ed60f2c2423262d3dfd8136f373e715db9dd77617e41\r\nscramp @ file:///home/conda/feedstock_root/build_artifacts/scramp_1667411948349/work\r\nSend2Trash @ file:///home/conda/feedstock_root/build_artifacts/send2trash_1712584999685/work\r\nsentencepiece==0.2.0\r\nseqeval @ file:///home/conda/feedstock_root/build_artifacts/seqeval_1607636513878/work\r\nshellingham @ file:///home/conda/feedstock_root/build_artifacts/shellingham_1698144360966/work\r\nsimpervisor @ file:///home/conda/feedstock_root/build_artifacts/simpervisor_1684441099342/work\r\nsimple_parsing==0.1.5\r\nsip @ file:///home/conda/feedstock_root/build_artifacts/sip_1697300428978/work\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\r\nsmart-open @ file:///home/conda/feedstock_root/build_artifacts/smart_open_split_1694066705667/work/dist\r\nsmdebug-rulesconfig @ file:///home/conda/feedstock_root/build_artifacts/smdebug-rulesconfig_1619805148199/work\r\nsmmap @ file:///home/conda/feedstock_root/build_artifacts/smmap_1634310307496/work\r\nsniffio @ file:///home/conda/feedstock_root/build_artifacts/sniffio_1708952932303/work\r\nsnowballstemmer @ file:///home/conda/feedstock_root/build_artifacts/snowballstemmer_1637143057757/work\r\nsnowflake-connector-python @ file:///home/conda/feedstock_root/build_artifacts/snowflake-connector-python_1719328315873/work\r\nsortedcontainers @ file:///home/conda/feedstock_root/build_artifacts/sortedcontainers_1621217038088/work\r\nsoupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1693929250441/work\r\nspacy @ file:///home/conda/feedstock_root/build_artifacts/spacy_1717591992814/work\r\nspacy-legacy @ file:///home/conda/feedstock_root/build_artifacts/spacy-legacy_1674550301837/work\r\nspacy-loggers @ file:///home/conda/feedstock_root/build_artifacts/spacy-loggers_1694527114282/work\r\nsparkmagic @ file:///home/conda/feedstock_root/build_artifacts/sparkmagic_1694633601704/work/sparkmagic\r\nSQLAlchemy==2.0.30\r\nsqlparse @ file:///home/conda/feedstock_root/build_artifacts/sqlparse_1715013953229/work\r\nsrsly @ file:///home/conda/feedstock_root/build_artifacts/srsly_1695653949688/work\r\nstack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work\r\nstarlette @ file:///home/conda/feedstock_root/build_artifacts/starlette-recipe_1709667058396/work\r\nstatsforecast @ file:///home/conda/feedstock_root/build_artifacts/statsforecast_1669882640898/work\r\nstatsmodels @ file:///home/conda/feedstock_root/build_artifacts/statsmodels_1715941214543/work\r\nsupervisor==4.2.5\r\nsympy @ file:///home/conda/feedstock_root/build_artifacts/sympy_1718625539893/work\r\ntabulate @ file:///home/conda/feedstock_root/build_artifacts/tabulate_1665138452165/work\r\ntblib @ file:///home/conda/feedstock_root/build_artifacts/tblib_1694702375735/work\r\ntenacity @ file:///home/conda/feedstock_root/build_artifacts/tenacity_1719315008981/work\r\ntensorboard @ file:///home/conda/feedstock_root/build_artifacts/tensorboard_1695917943728/work/tensorboard-2.14.1-py3-none-any.whl#sha256=3db108fb58f023b6439880e177743c5f1e703e9eeb5fb7d597871f949f85fd58\r\ntensorboard-data-server @ file:///home/conda/feedstock_root/build_artifacts/tensorboard-data-server_1695425366946/work/tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl#sha256=aa1f69b2111bb4309cc6277ac277c89a9f67d074aa666b96eebe7401a359e1d5\r\ntensorflow @ file:///home/conda/feedstock_root/build_artifacts/tensorflow-split_1699620173861/work/tensorflow_pkg/tensorflow-2.14.0-cp310-cp310-linux_x86_64.whl#sha256=a015dab8043172172ca4a754467c15209dcc02b420221cfcbc32ffa7e0c47fbd\r\ntensorflow-estimator @ file:///home/conda/feedstock_root/build_artifacts/tensorflow-split_1699620173861/work/tensorflow-estimator/wheel_dir/tensorflow_estimator-2.14.0-py2.py3-none-any.whl#sha256=f05e70bcc48452fdf9e473666558a4d4cf92833fa4f1411e17806326b41e6fb1\r\ntermcolor @ file:///home/conda/feedstock_root/build_artifacts/termcolor_1704357939450/work\r\nterminado @ file:///home/conda/feedstock_root/build_artifacts/terminado_1710262609923/work\r\ntext-unidecode @ file:///home/conda/feedstock_root/build_artifacts/text-unidecode_1694707102786/work\r\nthinc @ file:///home/conda/feedstock_root/build_artifacts/thinc_1715461684054/work\r\nthreadpoolctl @ file:///home/conda/feedstock_root/build_artifacts/threadpoolctl_1714400101435/work\r\nthrift @ file:///home/conda/feedstock_root/build_artifacts/thrift_1711156094832/work/lib/py\r\nthrift-sasl @ file:///home/conda/feedstock_root/build_artifacts/thrift_sasl_1664049052220/work\r\ntifffile @ file:///home/conda/feedstock_root/build_artifacts/tifffile_1591280222285/work\r\ntiktoken==0.7.0\r\ntimm @ file:///home/conda/feedstock_root/build_artifacts/timm_1708532402622/work\r\ntinycss2 @ file:///home/conda/feedstock_root/build_artifacts/tinycss2_1713974937325/work\r\ntokenizers @ file:///home/conda/feedstock_root/build_artifacts/tokenizers_1713402723682/work/bindings/python\r\ntoml @ file:///home/conda/feedstock_root/build_artifacts/toml_1604308577558/work\r\ntomli @ file:///home/conda/feedstock_root/build_artifacts/tomli_1644342247877/work\r\ntomlkit @ file:///home/conda/feedstock_root/build_artifacts/tomlkit_1715185399719/work\r\ntoolz @ file:///home/conda/feedstock_root/build_artifacts/toolz_1706112571092/work\r\ntorch==2.3.1\r\ntorchmetrics @ file:///home/conda/feedstock_root/build_artifacts/torchmetrics_1691516815780/work\r\ntorchvision @ file:///home/conda/feedstock_root/build_artifacts/torchvision-split_1699863652134/work\r\ntornado @ file:///home/conda/feedstock_root/build_artifacts/tornado_1717722796999/work\r\ntqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1714854870413/work\r\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1713535121073/work\r\ntransformers @ git+https://github.com/huggingface/transformers.git@22f888b3fab3d914882b8f44896a5658712f535c\r\ntriton==2.3.1\r\ntruststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\r\ntyper @ file:///home/conda/feedstock_root/build_artifacts/typer_1711217621866/work\r\ntypes-python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/types-python-dateutil_1710589910274/work\r\ntyping-inspect @ file:///home/conda/feedstock_root/build_artifacts/typing_inspect_1685820062773/work\r\ntyping-utils @ file:///home/conda/feedstock_root/build_artifacts/typing_utils_1622899189314/work\r\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1717802530399/work\r\ntypish @ file:///home/conda/feedstock_root/build_artifacts/typish_1628254486386/work\r\ntzdata @ file:///home/conda/feedstock_root/build_artifacts/python-tzdata_1707747584337/work\r\nujson @ file:///home/conda/feedstock_root/build_artifacts/ujson_1715783105793/work\r\nunicodedata2 @ file:///home/conda/feedstock_root/build_artifacts/unicodedata2_1695847980273/work\r\nuri-template @ file:///home/conda/feedstock_root/build_artifacts/uri-template_1688655812972/work/dist\r\nurllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1718728347128/work\r\nuvicorn @ file:///home/conda/feedstock_root/build_artifacts/uvicorn-split_1717404975401/work\r\nwasabi @ file:///home/conda/feedstock_root/build_artifacts/wasabi_1715409644734/work\r\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1704731205417/work\r\nweasel @ file:///home/conda/feedstock_root/build_artifacts/weasel_1699295455892/work\r\nwebcolors @ file:///home/conda/feedstock_root/build_artifacts/webcolors_1717667289718/work\r\nwebencodings @ file:///home/conda/feedstock_root/build_artifacts/webencodings_1694681268211/work\r\nwebsocket-client @ file:///home/conda/feedstock_root/build_artifacts/websocket-client_1713923384721/work\r\nWerkzeug @ file:///home/conda/feedstock_root/build_artifacts/werkzeug_1715000201436/work\r\nwhatthepatch @ file:///home/conda/feedstock_root/build_artifacts/whatthepatch_1683396758362/work\r\nwidgetsnbextension @ file:///home/conda/feedstock_root/build_artifacts/widgetsnbextension_1716891659446/work\r\nwindow_ops @ file:///home/conda/feedstock_root/build_artifacts/window-ops_1709587127407/work\r\nwrapt @ file:///home/conda/feedstock_root/build_artifacts/wrapt_1666806031361/work\r\nxformers==0.0.27\r\nxgboost==1.7.6\r\nxxhash @ file:///home/conda/feedstock_root/build_artifacts/python-xxhash_1696486308932/work\r\ny-py @ file:///home/conda/feedstock_root/build_artifacts/y-py_1696495053386/work\r\nyapf @ file:///home/conda/feedstock_root/build_artifacts/yapf_1690387939953/work\r\nyarl @ file:///home/conda/feedstock_root/build_artifacts/yarl_1705508292061/work\r\nypy-websocket @ file:///home/conda/feedstock_root/build_artifacts/ypy-websocket_1696470545029/work\r\nzict @ file:///home/conda/feedstock_root/build_artifacts/zict_1681770155528/work\r\nzipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1718013267051/work\r\nzstandard==0.22.0\n```\n\n\n### Reproduction Steps\n\nRunning the following code with a model such as Nemo Instruct (which can not be stored onto a single GPU): \r\n\r\n```\r\nfrom mistral_inference.transformer import Transformer\r\nfrom mistral_inference.generate import generate\r\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\r\nfrom mistral_common.protocol.instruct.messages import UserMessage\r\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\r\n\r\ntokenizer = MistralTokenizer.from_file(f\"{model_folder_name}/tekken.json\")\r\nmodel = Transformer.from_folder(model_folder_name)\r\n```\r\n\r\nlead to teh following error: \"OutOfMemoryError: CUDA out of memory. Tried to allocate 140.00 MiB. GPU\" \r\n\r\nThis is because, as you can see in the attached screenshot, it is loaded onto one single GPU\r\n<img width=\"1137\" alt=\"image\" src=\"https://github.com/user-attachments/assets/58410428-6944-4573-958e-f6ffb64c8685\">\r\n\r\nI looked for a parameter inside the Transformer python module but I don't see nothing to enable the multi-gpu inference.\r\n\r\nThank you so much\n\n### Expected Behavior\n\nI would expect to see the model loaded onto multiple GPUs automatically as in the screenshot \r\n<img width=\"1155\" alt=\"image\" src=\"https://github.com/user-attachments/assets/59ad1b48-cd57-4d27-8ac3-711d34c8c50e\">\r\n\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\nI would recommend to add a parameter such as the device_map parameter of Hugging Face Transformer library: https://huggingface.co/docs/transformers/main_classes/pipelines. Or distribute the model automatically",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/197/reactions",
      "total_count": 2,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/197/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/196",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/196/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/196/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/196/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/196",
    "id": 2418632115,
    "node_id": "I_kwDOKY_97s6QKWWz",
    "number": 196,
    "title": "[BUG:  mistralai/mamba-codestral-7B-v0.1 AttributeError: 'Mamba2' object has no attribute 'dconv'",
    "user": {
      "login": "s-natsubori",
      "id": 78010664,
      "node_id": "MDQ6VXNlcjc4MDEwNjY0",
      "avatar_url": "https://avatars.githubusercontent.com/u/78010664?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/s-natsubori",
      "html_url": "https://github.com/s-natsubori",
      "followers_url": "https://api.github.com/users/s-natsubori/followers",
      "following_url": "https://api.github.com/users/s-natsubori/following{/other_user}",
      "gists_url": "https://api.github.com/users/s-natsubori/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/s-natsubori/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/s-natsubori/subscriptions",
      "organizations_url": "https://api.github.com/users/s-natsubori/orgs",
      "repos_url": "https://api.github.com/users/s-natsubori/repos",
      "events_url": "https://api.github.com/users/s-natsubori/events{/privacy}",
      "received_events_url": "https://api.github.com/users/s-natsubori/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-07-19T11:02:51Z",
    "updated_at": "2025-06-13T08:40:43Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\r\n\r\n```shell\r\nPython 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\r\n```\r\n\r\n\r\n### Pip Freeze\r\n\r\n```shell\r\nabsl-py==2.0.0\r\naccelerate==0.28.0\r\naiohttp @ file:///rapids/aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=df72ac063b97837a80d80dec8d54c241af059cc9bb42c4de68bd5b61ceb37caa\r\naiorwlock==1.3.0\r\naiosignal @ file:///rapids/aiosignal-1.3.1-py3-none-any.whl#sha256=f8376fb07dd1e86a584e4fcdec80b36b7f81aac666ebc724e2c090300dd83b17\r\nannotated-types==0.5.0\r\nantlr4-python3-runtime==4.9.3\r\nanyio==4.4.0\r\napex @ file:///opt/pytorch/apex\r\nargilla==1.24.0\r\nargon2-cffi==23.1.0\r\nargon2-cffi-bindings==21.2.0\r\nasttokens==2.4.0\r\nastunparse==1.6.3\r\nasync-timeout @ file:///rapids/async_timeout-4.0.3-py3-none-any.whl#sha256=7405140ff1230c310e51dc27b3145b9092d659ce68ff733fb0cefe3ee42be028\r\nasyncio==3.4.3\r\nattrs==23.1.0\r\naudioread==3.0.1\r\nav==12.2.0\r\nbackcall==0.2.0\r\nbackoff==2.2.1\r\nbeautifulsoup4==4.12.2\r\nbleach==6.0.0\r\nblis==0.7.11\r\ncachetools==5.3.1\r\ncatalogue==2.0.10\r\ncausal-conv1d==1.4.0\r\ncertifi==2023.7.22\r\ncffi==1.16.0\r\ncharset-normalizer @ file:///rapids/charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=193cbc708ea3aca45e7221ae58f0fd63f933753a9bfb498a3b474878f12caaad\r\nclick @ file:///rapids/click-8.1.6-py3-none-any.whl#sha256=fa244bb30b3b5ee2cae3da8f55c9e5e0c0e86093306301fb418eb9dc40fbded5\r\ncloudpathlib==0.15.1\r\ncloudpickle @ file:///rapids/cloudpickle-2.2.1-py3-none-any.whl#sha256=61f594d1f4c295fa5cd9014ceb3a1fc4a70b0de1164b94fbc2d854ccba056f9f\r\ncmake==3.27.6\r\ncoloredlogs==15.0.1\r\ncomm==0.1.4\r\ncompel==2.0.2\r\nconfection==0.1.3\r\ncontourpy==1.1.1\r\ncontrolnet_aux==0.0.7\r\ncssselect==1.2.0\r\nctranslate2==4.3.1\r\ncubinlinker @ file:///rapids/cubinlinker-0.3.0%2B2.gce0680b-cp310-cp310-linux_x86_64.whl#sha256=8cff93be2d63d7db8f1d15fc72cf813abe3d8fd31c35be439e3fb6b7b4c89f76\r\ncuda-python @ file:///rapids/cuda_python-12.2.0rc5%2B5.g84845d1-cp310-cp310-linux_x86_64.whl#sha256=19bb8c6dd62e976182ff183aab18d2c9f0a698add93a1037f2cbaa5d0f739d9d\r\ncudf @ file:///rapids/cudf-23.8.0-cp310-cp310-linux_x86_64.whl#sha256=12228d0949a6be3a7a383262f77c37372d48e02e57c4d0b8ed3763ced4d26ccb\r\ncugraph @ file:///rapids/cugraph-23.8.0-cp310-cp310-linux_x86_64.whl#sha256=209757e66f1ef51a5bace52774f9fc5575cdc6a00e11287ca8f0be78f57a9661\r\ncugraph-dgl @ file:///rapids/cugraph_dgl-23.8.0-py3-none-any.whl#sha256=ef49cc4464b39aa686b97faa50186bd104cf965a7b7215c7ffb7b94011b6bcea\r\ncugraph-service-client @ file:///rapids/cugraph_service_client-23.8.0-py3-none-any.whl#sha256=54d3f0367285be37ed4166483e4402e71e6a4747fb55e5a32a6ca9abfe264cb5\r\ncugraph-service-server @ file:///rapids/cugraph_service_server-23.8.0-py3-none-any.whl#sha256=1fd5d70166ff9023c2b451f63e1a4a25c0e55e018811fc1549f52dffb7a422f6\r\ncuml @ file:///rapids/cuml-23.8.0-cp310-cp310-linux_x86_64.whl#sha256=f9209e5d1e2c765a4bc0b2955e4bc29016b9c4186b7e0512553f3fff879bf697\r\ncupy-cuda12x @ file:///rapids/cupy_cuda12x-12.1.0-cp310-cp310-linux_x86_64.whl#sha256=840d1f4560436be5aaa9b6071d4947a391ab8c7b4810f035fc7815d43c29ed6d\r\ncycler==0.12.1\r\ncymem==2.0.8\r\nCython==3.0.3\r\ndask @ file:///rapids/dask-2023.7.1-py3-none-any.whl#sha256=8ca3969805dd1cceee66f1138f103fba6fbaf22ba488f15b2382b4579ee39f02\r\ndask-cuda @ file:///rapids/dask_cuda-23.8.0-py3-none-any.whl#sha256=68d2bef0df1307a28a0306e3501d63e6d19994d8bbe5e5dccd8b0967bcca8d30\r\ndask-cudf @ file:///rapids/dask_cudf-23.8.0-py3-none-any.whl#sha256=8783c9089041462b8a4418d8645db2a7b2bc32c4c4b1800512f387d466ee1f16\r\ndataclasses-json==0.6.7\r\ndatasets==2.19.2\r\ndebugpy==1.8.0\r\ndecorator==5.1.1\r\ndefusedxml==0.7.1\r\nDeprecated==1.2.14\r\ndiffusers==0.29.0\r\ndill==0.3.8\r\ndiskcache==5.6.3\r\ndistributed @ file:///rapids/distributed-2023.7.1-py3-none-any.whl#sha256=1237f8ae11baa9f80070329a33f9d5af32da5c272a98bab088c9b0578c2d816e\r\ndistro==1.9.0\r\ndm-tree==0.1.8\r\ndocstring_parser==0.16\r\neinops==0.7.0\r\nexceptiongroup==1.1.3\r\nexecnet==2.0.2\r\nexecuting==2.0.0\r\nexpecttest==0.1.3\r\nfastapi==0.110.0\r\nfaster-whisper==1.0.2\r\nfastjsonschema==2.18.1\r\nfastrlock @ file:///rapids/fastrlock-0.8.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_24_x86_64.whl#sha256=d6c53abeae3f9a55b5c65824cec9df59159fa50e8fa800a5c6e8de42b2219c28\r\nfeedfinder2==0.0.4\r\nfeedparser==6.0.11\r\nffmpeg-python==0.2.0\r\nfilelock==3.12.4\r\nfire==0.6.0\r\nflash-attn @ https://github.com/Dao-AILab/flash-attention/releases/download/v2.5.9.post1/flash_attn-2.5.9.post1+cu122torch2.3cxx11abiFALSE-cp310-cp310-linux_x86_64.whl#sha256=5022ba11d48bf74926da9c16260f4ea2b9bb7f4e29bdb4bd6e1383ad1c55d16f\r\nflatbuffers==24.3.25\r\nfonttools==4.43.1\r\nfrozenlist @ file:///rapids/frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=6918d49b1f90821e93069682c06ffde41829c346c66b721e65a5c62b4bab0300\r\nfsspec @ file:///rapids/fsspec-2023.6.0-py3-none-any.whl#sha256=1cbad1faef3e391fba6dc005ae9b5bdcbf43005c9167ce78c915549c352c869a\r\nfugashi==1.3.1\r\nfuture==1.0.0\r\ngast==0.5.4\r\ngoogle-auth==2.23.2\r\ngoogle-auth-oauthlib==0.4.6\r\ngraphsurgeon @ file:///workspace/TensorRT-8.6.1.6/graphsurgeon/graphsurgeon-0.4.6-py2.py3-none-any.whl#sha256=0fbadaefbbe6e9920b9f814ae961c4a279be602812edf3ed7fb9cc6f8f4809fe\r\ngreenlet==3.0.3\r\ngrpcio==1.59.0\r\nh11==0.14.0\r\nhttpcore==1.0.5\r\nhttptools==0.6.1\r\nhttpx==0.26.0\r\nhuggingface-hub==0.24.0\r\nhumanfriendly==10.0\r\nhypothesis==5.35.1\r\nidna==3.4\r\nimageio==2.34.2\r\nimportlib-metadata @ file:///rapids/importlib_metadata-6.8.0-py3-none-any.whl#sha256=3ebb78df84a805d7698245025b975d9d67053cd94c79245ba4b3eb694abe68bb\r\niniconfig==2.0.0\r\nintel-openmp==2021.4.0\r\ninteregular==0.3.3\r\nipykernel==6.25.2\r\nipython==8.16.1\r\nipython-genutils==0.2.0\r\nja-sentence-segmenter==0.0.2\r\njedi==0.19.1\r\njieba3k==0.35.1\r\nJinja2==3.1.2\r\njoblib==1.3.2\r\njson5==0.9.14\r\njsonpatch==1.33\r\njsonpointer==3.0.0\r\njsonschema==4.21.1\r\njsonschema-specifications==2023.7.1\r\njupyter-tensorboard @ git+https://github.com/cliffwoolley/jupyter_tensorboard.git@ffa7e26138b82549453306e06b535a9ac36db17a\r\njupyter_client==8.3.1\r\njupyter_core==5.3.2\r\njupyterlab==2.3.2\r\njupyterlab-pygments==0.2.2\r\njupyterlab-server==1.2.0\r\njupytext==1.15.2\r\nkiwisolver==1.4.5\r\nlangchain==0.2.3\r\nlangchain-community==0.2.4\r\nlangchain-core==0.2.5\r\nlangchain-openai==0.1.8\r\nlangchain-text-splitters==0.2.1\r\nlangcodes==3.3.0\r\nlangsmith==0.1.92\r\nlark==1.1.9\r\nlazy_loader==0.4\r\nlibrosa==0.9.2\r\nllvmlite @ file:///rapids/llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=bbd5e82cc990e5a3e343a3bf855c26fdfe3bfae55225f00efd01c05bbda79918\r\nlm-format-enforcer==0.10.1\r\nlocket @ file:///rapids/locket-1.0.0-py2.py3-none-any.whl#sha256=b6c819a722f7b6bd955b80781788e4a66a55628b858d347536b7e81325a3a5e3\r\nlxml==5.2.1\r\nlxml_html_clean==0.1.1\r\n-e git+https://github.com/state-spaces/mamba@c0a00bd1808881831ddf43206c69362d4df90cf7#egg=mamba_ssm\r\nMarkdown==3.4.4\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.3\r\nmarshmallow==3.21.3\r\nmatplotlib==3.8.0\r\nmatplotlib-inline==0.1.6\r\nmdit-py-plugins==0.4.0\r\nmdurl==0.1.2\r\nmediapipe==0.10.8\r\nmistral_common==1.3.1\r\nmistral_inference==1.3.0\r\nmistune==3.0.2\r\nmkl==2021.1.1\r\nmkl-devel==2021.1.1\r\nmkl-include==2021.1.1\r\nmock==5.1.0\r\nmonotonic==1.6\r\nmpmath==1.3.0\r\nmsgpack @ file:///rapids/msgpack-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=e42b9594cc3bf4d838d67d6ed62b9e59e201862a25e9a157019e171fbe672dd3\r\nmultidict @ file:///rapids/multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=36c63aaa167f6c6b04ef2c85704e93af16c11d20de1d133e39de6a0e84582a93\r\nmultiprocess==0.70.16\r\nmurmurhash==1.0.10\r\nmypy-extensions==1.0.0\r\nnbclient==0.8.0\r\nnbconvert==7.9.2\r\nnbformat==5.9.2\r\nnest-asyncio==1.5.8\r\nnetworkx==3.3\r\nnewspaper3k==0.2.8\r\nninja==1.11.1.1\r\nnltk==3.8.1\r\nnotebook==6.4.10\r\nnumba @ file:///rapids/numba-0.57.1%2B1.g5fba9aa8f-cp310-cp310-linux_x86_64.whl#sha256=348d18dbb5ce363133fa7d033ae804b5440bf51778395f08b337a9ca6ac98e53\r\nnumpy==1.23.5\r\nnvfuser==0.0.20+gitunknown\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==8.9.2.26\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-dali-cuda120==1.30.0\r\nnvidia-ml-py==12.555.43\r\nnvidia-nccl-cu12==2.20.5\r\nnvidia-nvjitlink-cu12==12.5.82\r\nnvidia-nvtx-cu12==12.1.105\r\nnvidia-pyindex==1.0.9\r\nnvtx @ file:///rapids/nvtx-0.2.5-cp310-cp310-linux_x86_64.whl#sha256=b8024910cace4d07e6c9677eaf3be1b3e626fa1923ec6e3c7e5d3fdca053c9c9\r\noauthlib==3.2.2\r\nomegaconf==2.3.0\r\nonnx @ file:///opt/pytorch/pytorch/third_party/onnx\r\nonnxruntime==1.18.1\r\nopenai==1.35.15\r\nopencv @ file:///opencv-4.7.0/modules/python/package\r\nopencv-contrib-python==4.10.0.84\r\nopencv-python==4.10.0.84\r\norjson==3.10.6\r\noutlines==0.0.46\r\npackaging==23.2\r\npandas @ file:///rapids/pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=7a0a56cef15fd1586726dace5616db75ebcfec9179a3a55e78f72c5639fa2a23\r\npandocfilters==1.5.0\r\nparso==0.8.3\r\npartd @ file:///rapids/partd-1.4.0-py3-none-any.whl#sha256=7a63529348cf0dff14b986db641cd1b83c16b5cb9fc647c2851779db03282ef8\r\npathy==0.10.2\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==10.1.0\r\nplatformdirs==3.11.0\r\npluggy==1.3.0\r\nply @ file:///rapids/ply-3.11-py2.py3-none-any.whl#sha256=096f9b8350b65ebd2fd1346b12452efe5b9607f7482813ffca50c22722a807ce\r\npolygraphy==0.49.0\r\npooch==1.7.0\r\npreshed==3.0.9\r\nprettytable==3.9.0\r\nprometheus-fastapi-instrumentator==7.0.0\r\nprometheus_client==0.20.0\r\nprompt-toolkit==3.0.39\r\nprotobuf==3.20.3\r\npsutil @ file:///rapids/psutil-5.9.4-cp310-abi3-linux_x86_64.whl#sha256=e711cfad802fd4061d559d17e9f175e866551434c3418af2925881a3e5f3440e\r\nptxcompiler @ file:///rapids/ptxcompiler-0.8.1%2B1.g2cb1b35-cp310-cp310-linux_x86_64.whl#sha256=461049ad74511c8d923967e1826861a0d9a2bcee0cfcf3ebc338fc48b3ecc724\r\nptyprocess==0.7.0\r\npure-eval==0.2.2\r\npy-cpuinfo==9.0.0\r\npyairports==2.1.1\r\npyarrow==17.0.0\r\npyarrow-hotfix==0.6\r\npyasn1==0.5.0\r\npyasn1-modules==0.3.0\r\npybind11==2.11.1\r\npybind11-global==2.11.1\r\npycocotools @ git+https://github.com/nvidia/cocoapi.git@fa44301f7a8b3f95a9f2751d19bfd735b0f6c65d#subdirectory=PythonAPI\r\npycountry==24.6.1\r\npycparser==2.21\r\npydantic==2.6.1\r\npydantic_core==2.16.2\r\nPygments==2.16.1\r\npylibcugraph @ file:///rapids/pylibcugraph-23.8.0-cp310-cp310-linux_x86_64.whl#sha256=8327053f864ed56bf0d0d8fb69a2291ca1e044fa1f447e63b85b29bf72102c74\r\npylibcugraphops @ file:///rapids/pylibcugraphops-23.8.0-cp310-cp310-linux_x86_64.whl#sha256=17364a79cda63c9f6c62ef6f2bd37151a9e70539f6d60e43fb26ab40e163bba2\r\npylibraft @ file:///rapids/pylibraft-23.8.0-cp310-cp310-linux_x86_64.whl#sha256=f74580fec4d0e1603f9b3027da33d915ce07a37d2790c28b1d784d133e90a6d2\r\npynvml @ file:///rapids/pynvml-11.4.1-py3-none-any.whl#sha256=d27be542cd9d06558de18e2deffc8022ccd7355bc7382255d477038e7e424c6c\r\npyparsing==3.1.1\r\npytest==7.4.2\r\npytest-flakefinder==1.1.0\r\npytest-rerunfailures==12.0\r\npytest-shard==0.1.2\r\npytest-xdist==3.3.1\r\npython-dateutil==2.8.2\r\npython-dotenv==1.0.1\r\npython-hostlist==1.23.0\r\npython-multipart==0.0.9\r\npytorch-quantization==2.1.2\r\npytz @ file:///rapids/pytz-2023.3-py2.py3-none-any.whl#sha256=a151b3abb88eda1d4e34a9814df37de2a80e301e68ba0fd856fb9b46bfbbbffb\r\nPyYAML==6.0\r\npyzmq==25.1.1\r\nraft-dask @ file:///rapids/raft_dask-23.8.0-cp310-cp310-linux_x86_64.whl#sha256=9464bd2889aff217d63f2ff804f06328123119e72745399900315fc85f4d6b7e\r\nray==2.32.0\r\nredis==5.0.3\r\nreferencing==0.30.2\r\nregex==2023.10.3\r\nrequests==2.32.3\r\nrequests-file==2.1.0\r\nrequests-oauthlib==1.3.1\r\nresampy==0.4.2\r\nrich==13.7.1\r\nrmm @ file:///rapids/rmm-23.8.0-cp310-cp310-linux_x86_64.whl#sha256=11e3bc42ddfa51f8293ddb37fb006e4dd59fc20534e8f027b5453c8d00fa089f\r\nrpds-py==0.10.4\r\nrsa==4.9\r\nsafetensors==0.4.3\r\nscikit-image==0.24.0\r\nscikit-learn @ file:///rapids/scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=184a42842a4e698ffa4d849b6019de50a77a0aa24d26afa28fa49c9190bb144b\r\nscipy @ file:///rapids/scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=366a6a937110d80dca4f63b3f5b00cc89d36f678b2d124a01067b154e692bab1\r\nSend2Trash==1.8.2\r\nsentence-transformers==3.0.1\r\nsentencepiece==0.2.0\r\nsgmllib3k==1.0.0\r\nsimple_parsing==0.1.5\r\nsix==1.16.0\r\nsmart-open==6.4.0\r\nsniffio==1.3.1\r\nsortedcontainers==2.4.0\r\nsounddevice==0.4.7\r\nsoundfile==0.12.1\r\nsoupsieve==2.5\r\nspacy==3.7.1\r\nspacy-legacy==3.0.12\r\nspacy-loggers==1.0.5\r\nsphinx-glpi-theme==0.3\r\nSQLAlchemy==2.0.31\r\nsrsly==2.4.8\r\nstack-data==0.6.3\r\nstarlette==0.36.3\r\nsympy==1.12\r\ntabulate==0.9.0\r\ntbb==2021.10.0\r\ntblib @ file:///rapids/tblib-2.0.0-py3-none-any.whl#sha256=9100bfa016b047d5b980d66e7efed952fbd20bd85b56110aaf473cb97d18709a\r\ntenacity==8.5.0\r\ntensorboard==2.9.0\r\ntensorboard-data-server==0.6.1\r\ntensorboard-plugin-wit==1.8.1\r\ntensorrt @ file:///workspace/TensorRT-8.6.1.6/python/tensorrt-8.6.1-cp310-none-linux_x86_64.whl#sha256=2684b4772cb16088184266728a0668f5dac14e66f088c4ccff2096ccb222d74c\r\ntermcolor==2.4.0\r\nterminado==0.17.1\r\nthinc==8.2.1\r\nthread6==0.2.0\r\nthreadpoolctl==3.2.0\r\nthriftpy2 @ file:///rapids/thriftpy2-0.4.16-cp310-cp310-linux_x86_64.whl#sha256=3b41ffe57f0a10ee592e06b4843e37ae1bc7f0309a2478f0bf1368ede2ad4ed4\r\ntifffile==2024.7.2\r\ntiktoken==0.7.0\r\ntimm==1.0.7\r\ntinycss2==1.2.1\r\ntinysegmenter==0.3\r\ntldextract==5.1.2\r\ntokenizers==0.19.1\r\ntoml==0.10.2\r\ntomli==2.0.1\r\ntoolz @ file:///rapids/toolz-0.12.0-py3-none-any.whl#sha256=2059bd4148deb1884bb0eb770a3cde70e7f954cfbbdc2285f1f2de01fd21eb6f\r\ntorch==2.3.0\r\ntorch-tensorrt @ file:///opt/pytorch/torch_tensorrt/dist/torch_tensorrt-0.0.0-cp310-cp310-linux_x86_64.whl#sha256=239cc59958283c8fd764ec360b93adf63db94d231c6dbae3212736187d1c1f21\r\ntorchdata @ file:///opt/pytorch/data\r\ntorchtext @ file:///opt/pytorch/text\r\ntorchvision==0.18.0\r\ntornado==6.3.3\r\ntqdm==4.66.2\r\ntraitlets==5.9.0\r\ntransformers==4.42.4\r\ntreelite @ file:///rapids/treelite-3.2.0-cp310-cp310-linux_x86_64.whl#sha256=7627a3fed44ce1dda4c35ce707cca4b6108d74a661997c0451be59d03f2155ca\r\ntreelite-runtime @ file:///rapids/treelite_runtime-3.2.0-cp310-cp310-linux_x86_64.whl#sha256=085ec1ba71007d357ecebb493c490133c20778cd51d8662a0a10d1dc56b1623e\r\ntriton==2.3.0\r\ntyper==0.9.0\r\ntypes-dataclasses==0.6.6\r\ntyping==3.7.4.3\r\ntyping-inspect==0.9.0\r\ntyping_extensions==4.12.2\r\nucx-py @ file:///rapids/ucx_py-0.33.0-cp310-cp310-linux_x86_64.whl#sha256=55d9f5f80627ba1f00577fca41ecd6ab8c72cc518e392a078d108b7dbd809c1e\r\nuff @ file:///workspace/TensorRT-8.6.1.6/uff/uff-0.6.9-py2.py3-none-any.whl#sha256=618a3f812d491f0d3c4f2e38b99e03217ca37b206db14cee079f2bf681eb4fe3\r\nunidic-lite==1.0.8\r\nurllib3 @ file:///rapids/urllib3-1.26.16-py2.py3-none-any.whl#sha256=8d36afa7616d8ab714608411b4a3b13e58f463aee519024578e062e141dce20f\r\nuvicorn==0.30.1\r\nuvloop==0.19.0\r\nvllm==0.5.0\r\nvllm-flash-attn==2.5.9\r\nwasabi==1.1.2\r\nwatchfiles==0.22.0\r\nwcwidth==0.2.8\r\nweasel==0.3.2\r\nwebencodings==0.5.1\r\nwebsockets==12.0\r\nWerkzeug==3.0.0\r\nwrapt==1.14.1\r\nxdoctest==1.0.2\r\nxformers==0.0.26.post1\r\nxgboost @ file:///rapids/xgboost-1.7.5-cp310-cp310-linux_x86_64.whl#sha256=56f29fb999f8272bf8498ecbaf0659de4becf693b96a545f0e52f627270cf80d\r\nxxhash==3.4.1\r\nyarl @ file:///rapids/yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=891c0e3ec5ec881541f6c5113d8df0315ce5440e244a716b95f2525b7b9f3608\r\nzict @ file:///rapids/zict-3.0.0-py2.py3-none-any.whl#sha256=5796e36bd0e0cc8cf0fbc1ace6a68912611c1dbd74750a3f3026b9b9d6a327ae\r\nzipp @ file:///rapids/zipp-3.16.2-py3-none-any.whl#sha256=679e51dd4403591b2d6838a48de3d283f3d188412a9782faadf845f298736ba0\r\n```\r\n\r\n\r\n### Reproduction Steps\r\n\r\nmistral-chat $LLM_MODEL --instruct  --max_tokens 256\r\n$LLM_MODEL is mamba-codestral-7B-v0.1 folder\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/mistral-chat\", line 8, in <module>\r\n    sys.exit(mistral_chat())\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/main.py\", line 203, in mistral_chat\r\n    fire.Fire(interactive)\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 143, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 477, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 693, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/main.py\", line 117, in interactive\r\n    generated_tokens, _ = generate_fn(  # type: ignore[operator]\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/generate.py\", line 21, in generate_mamba\r\n    output = model.model.generate(\r\n  File \"/usr/local/setup/mamba/mamba_ssm/utils/generation.py\", line 260, in generate\r\n    output = decode(\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/setup/mamba/mamba_ssm/utils/generation.py\", line 221, in decode\r\n    scores.append(get_logits(sequences[-1], inference_params))\r\n  File \"/usr/local/setup/mamba/mamba_ssm/utils/generation.py\", line 184, in get_logits\r\n    logits = model(\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/usr/local/setup/mamba/mamba_ssm/models/mixer_seq_simple.py\", line 279, in forward\r\n    hidden_states = self.backbone(input_ids, inference_params=inference_params, **mixer_kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/usr/local/setup/mamba/mamba_ssm/models/mixer_seq_simple.py\", line 194, in forward\r\n    hidden_states, residual = layer(\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/usr/local/setup/mamba/mamba_ssm/modules/block.py\", line 67, in forward\r\n    hidden_states = self.mixer(hidden_states, inference_params=inference_params, **mixer_kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/usr/local/setup/mamba/mamba_ssm/modules/mamba2.py\", line 233, in forward\r\n    self.conv1d(xBC.transpose(1, 2)).transpose(1, 2)[:, -(self.dconv - 1):]\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1709, in __getattr__\r\n    raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\r\nAttributeError: 'Mamba2' object has no attribute 'dconv'. Did you mean: 'd_conv'?\r\n\r\n```\r\n\r\n### Expected Behavior\r\n\r\nchat output \r\n\r\n### Additional Context\r\n\r\nI install `mistral-inference ` and `causal-conv1d` from pip\r\n`mamba-ssm` build from [github ](https://github.com/state-spaces/mamba)source. (2.2.2 )\r\nbecause it raise Undefined Symbol Error.\r\n\r\n### Suggested Solutions\r\n\r\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/196/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/196/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/195",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/195/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/195/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/195/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/195",
    "id": 2416765237,
    "node_id": "PR_kwDOKY_97s51zIbe",
    "number": 195,
    "title": "Update README.md",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-18T15:44:32Z",
    "updated_at": "2024-07-18T15:52:41Z",
    "closed_at": "2024-07-18T15:52:40Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/195",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/195",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/195.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/195.patch",
      "merged_at": "2024-07-18T15:52:40Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/195/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/195/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/194",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/194/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/194/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/194/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/194",
    "id": 2416507498,
    "node_id": "PR_kwDOKY_97s51yTor",
    "number": 194,
    "title": "Update README",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-18T14:10:57Z",
    "updated_at": "2024-07-18T14:22:26Z",
    "closed_at": "2024-07-18T14:22:26Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/194",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/194",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/194.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/194.patch",
      "merged_at": "2024-07-18T14:22:25Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/194/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/194/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/193",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/193/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/193/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/193/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/193",
    "id": 2415819427,
    "node_id": "PR_kwDOKY_97s51wAXn",
    "number": 193,
    "title": "Tekken",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-18T09:15:31Z",
    "updated_at": "2024-07-18T13:14:56Z",
    "closed_at": "2024-07-18T13:14:56Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/193",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/193",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/193.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/193.patch",
      "merged_at": "2024-07-18T13:14:56Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/193/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/193/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/192",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/192/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/192/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/192/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/192",
    "id": 2412564766,
    "node_id": "I_kwDOKY_97s6PzNEe",
    "number": 192,
    "title": "[BUG: AssertionError: Mamba is not installed. Please install it using `pip install mamba-ssm`.",
    "user": {
      "login": "matbeedotcom",
      "id": 381356,
      "node_id": "MDQ6VXNlcjM4MTM1Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/381356?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/matbeedotcom",
      "html_url": "https://github.com/matbeedotcom",
      "followers_url": "https://api.github.com/users/matbeedotcom/followers",
      "following_url": "https://api.github.com/users/matbeedotcom/following{/other_user}",
      "gists_url": "https://api.github.com/users/matbeedotcom/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/matbeedotcom/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/matbeedotcom/subscriptions",
      "organizations_url": "https://api.github.com/users/matbeedotcom/orgs",
      "repos_url": "https://api.github.com/users/matbeedotcom/repos",
      "events_url": "https://api.github.com/users/matbeedotcom/events{/privacy}",
      "received_events_url": "https://api.github.com/users/matbeedotcom/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 9,
    "created_at": "2024-07-17T03:44:47Z",
    "updated_at": "2024-11-26T02:31:45Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\n\n```shell\n(codestral) \u279c  dev python -VV\r\nPython 3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]\n```\n\n\n### Pip Freeze\n\n```shell\n(codestral) \u279c  dev pip freeze\r\nabsl-py==2.1.0\r\naddict==2.4.0\r\nannotated-types==0.7.0\r\nantlr4-python3-runtime==4.9.3\r\napex @ file:///home/acidhax/dev/VisionLLM/VisionLLMv2/apex\r\nattrs==23.2.0\r\nbeautifulsoup4==4.12.3\r\nblack==24.4.2\r\nBrotli @ file:///croot/brotli-split_1714483155106/work\r\ncausal-conv1d==1.4.0\r\ncertifi @ file:///croot/certifi_1720453481653/work/certifi\r\ncharset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work\r\ncloudpickle==3.0.0\r\ncrowdposetools==2.0\r\nDCNv3==1.0\r\ndetectron2 @ git+https://github.com/facebookresearch/detectron2.git@e8806d607403cf0f2634d4c5ac464109fdc7d4af\r\ndocstring_parser==0.16\r\neinops==0.8.0\r\nfilelock @ file:///croot/filelock_1700591183607/work\r\nfire==0.6.0\r\nfsspec==2024.6.1\r\nfvcore==0.1.5.post20221221\r\ngdown==5.2.0\r\ngmpy2 @ file:///tmp/build/80754af9/gmpy2_1645455533097/work\r\ngrpcio==1.64.1\r\nhuggingface-hub==0.23.5\r\nhydra-core==1.3.2\r\nidna @ file:///croot/idna_1714398848350/work\r\nimportlib_metadata==7.1.0\r\niopath==0.1.9\r\nJinja2 @ file:///croot/jinja2_1716993405101/work\r\njsonschema==4.21.1\r\njsonschema-specifications==2023.12.1\r\nmamba-ssm==2.2.2\r\nMarkupSafe @ file:///croot/markupsafe_1704205993651/work\r\nmistral_common==1.2.1\r\nmistral_inference==1.2.0\r\nmkl-fft @ file:///croot/mkl_fft_1695058164594/work\r\nmkl-random @ file:///croot/mkl_random_1695059800811/work\r\nmkl-service==2.4.0\r\nmpmath @ file:///croot/mpmath_1690848262763/work\r\nMultiScaleDeformableAttention==1.0\r\nmypy-extensions==1.0.0\r\nnetworkx @ file:///croot/networkx_1720002482208/work\r\nninja==1.11.1.1\r\nnumpy @ file:///croot/numpy_and_numpy_base_1708638617955/work/dist/numpy-1.26.4-cp310-cp310-linux_x86_64.whl#sha256=d8cd837ed43e87f77e6efaa08e8de927ca030a1c9c5d04624432d6fb9a74a5ee\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==8.9.2.26\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-nccl-cu12==2.20.5\r\nnvidia-nvjitlink-cu12==12.5.82\r\nnvidia-nvtx-cu12==12.1.105\r\npackaging==24.1\r\npathspec==0.12.1\r\npillow @ file:///croot/pillow_1721059439630/work\r\nplatformdirs==4.2.2\r\nportalocker==2.8.2\r\npycocotools @ git+https://github.com/youtubevos/cocoapi.git@f24b5f58594adfe4f4c015bf49dbc819cc3be98f#subdirectory=PythonAPI\r\npydantic==2.6.1\r\npydantic_core==2.16.2\r\nPySocks==1.7.1\r\nPyYAML @ file:///croot/pyyaml_1698096049011/work\r\nreferencing==0.35.1\r\nregex==2024.5.15\r\nrequests @ file:///croot/requests_1716902831423/work\r\nrpds-py==0.19.0\r\nsafetensors==0.4.3\r\nsentencepiece==0.1.99\r\nsimple_parsing==0.1.5\r\nsix==1.16.0\r\nsoupsieve==2.5\r\nsympy @ file:///croot/sympy_1701397643339/work\r\ntensorboard-data-server==0.7.2\r\ntermcolor==2.4.0\r\ntokenizers==0.19.1\r\ntomli==2.0.1\r\ntorch==2.3.1\r\ntorchaudio==2.3.1\r\ntorchvision==0.18.1\r\ntqdm==4.66.4\r\ntransformers==4.42.4\r\ntriton==2.3.1\r\ntyping_extensions @ file:///croot/typing_extensions_1715268824938/work\r\nurllib3 @ file:///croot/urllib3_1718912636303/work\r\nWerkzeug==3.0.3\r\nxformers==0.0.27\r\nyacs==0.1.8\r\nyapf==0.40.2\r\nzipp==3.19.2\n```\n\n\n### Reproduction Steps\n\n```\r\n(codestral) \u279c  dev pip install mamba-ssm\r\nRequirement already satisfied: mamba-ssm in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (2.2.2)\r\nRequirement already satisfied: torch in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from mamba-ssm) (2.3.1)\r\nRequirement already satisfied: packaging in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from mamba-ssm) (24.1)\r\nRequirement already satisfied: ninja in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from mamba-ssm) (1.11.1.1)\r\nRequirement already satisfied: einops in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from mamba-ssm) (0.8.0)\r\nRequirement already satisfied: triton in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from mamba-ssm) (2.3.1)\r\nRequirement already satisfied: transformers in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from mamba-ssm) (4.42.4)\r\nRequirement already satisfied: filelock in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from torch->mamba-ssm) (3.13.1)\r\nRequirement already satisfied: typing-extensions>=4.8.0 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from torch->mamba-ssm) (4.11.0)\r\nRequirement already satisfied: sympy in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from torch->mamba-ssm) (1.12)\r\nRequirement already satisfied: networkx in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from torch->mamba-ssm) (3.3)\r\nRequirement already satisfied: jinja2 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from torch->mamba-ssm) (3.1.4)\r\nRequirement already satisfied: fsspec in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from torch->mamba-ssm) (2024.6.1)\r\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.23.5)\r\nRequirement already satisfied: numpy<2.0,>=1.17 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from transformers->mamba-ssm) (1.26.4)\r\nRequirement already satisfied: pyyaml>=5.1 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from transformers->mamba-ssm) (6.0.1)\r\nRequirement already satisfied: regex!=2019.12.17 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from transformers->mamba-ssm) (2024.5.15)\r\nRequirement already satisfied: requests in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from transformers->mamba-ssm) (2.32.2)\r\nRequirement already satisfied: safetensors>=0.4.1 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.4.3)\r\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.19.1)\r\nRequirement already satisfied: tqdm>=4.27 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from transformers->mamba-ssm) (4.66.4)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from jinja2->torch->mamba-ssm) (2.1.3)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (2.0.4)\r\nRequirement already satisfied: idna<4,>=2.5 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (3.7)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (2.2.2)\r\nRequirement already satisfied: certifi>=2017.4.17 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (2024.7.4)\r\nRequirement already satisfied: mpmath>=0.19 in /mnt/environments/miniconda3/envs/codestral/lib/python3.10/site-packages (from sympy->torch->mamba-ssm) (1.3.0)\r\n```\r\n\r\n```\r\n\r\n(codestral) \u279c  dev mistral-chat $HOME/7B_MAMBA_CODE --instruct --max_tokens 256\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/acidhax/miniconda3/envs/codestral/bin/mistral-chat\", line 8, in <module>\r\n    sys.exit(mistral_chat())\r\n  File \"/home/acidhax/miniconda3/envs/codestral/lib/python3.10/site-packages/mistral_inference/main.py\", line 201, in mistral_chat\r\n    fire.Fire(interactive)\r\n  File \"/home/acidhax/miniconda3/envs/codestral/lib/python3.10/site-packages/fire/core.py\", line 143, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/home/acidhax/miniconda3/envs/codestral/lib/python3.10/site-packages/fire/core.py\", line 477, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/home/acidhax/miniconda3/envs/codestral/lib/python3.10/site-packages/fire/core.py\", line 693, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n  File \"/home/acidhax/miniconda3/envs/codestral/lib/python3.10/site-packages/mistral_inference/main.py\", line 81, in interactive\r\n    model = model_cls.from_folder(Path(model_path), max_batch_size=3, num_pipeline_ranks=num_pipeline_ranks)\r\n  File \"/home/acidhax/miniconda3/envs/codestral/lib/python3.10/site-packages/mistral_inference/mamba.py\", line 75, in from_folder\r\n    model = Mamba(model_args)\r\n  File \"/home/acidhax/miniconda3/envs/codestral/lib/python3.10/site-packages/mistral_inference/mamba.py\", line 27, in __init__\r\n    assert _is_mamba_installed, \"Mamba is not installed. Please install it using `pip install mamba-ssm`.\"\r\nAssertionError: Mamba is not installed. Please install it using `pip install mamba-ssm`.\r\n\r\n```\r\n\r\n\n\n### Expected Behavior\n\nworking\n\n### Additional Context\n\n_No response_\n\n### Suggested Solutions\n\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/192/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/192/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/191",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/191/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/191/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/191/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/191",
    "id": 2411041029,
    "node_id": "PR_kwDOKY_97s51glmJ",
    "number": 191,
    "title": "Update hardcoded Mamba filenames",
    "user": {
      "login": "Wauplin",
      "id": 11801849,
      "node_id": "MDQ6VXNlcjExODAxODQ5",
      "avatar_url": "https://avatars.githubusercontent.com/u/11801849?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Wauplin",
      "html_url": "https://github.com/Wauplin",
      "followers_url": "https://api.github.com/users/Wauplin/followers",
      "following_url": "https://api.github.com/users/Wauplin/following{/other_user}",
      "gists_url": "https://api.github.com/users/Wauplin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Wauplin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Wauplin/subscriptions",
      "organizations_url": "https://api.github.com/users/Wauplin/orgs",
      "repos_url": "https://api.github.com/users/Wauplin/repos",
      "events_url": "https://api.github.com/users/Wauplin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Wauplin/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-07-16T12:41:10Z",
    "updated_at": "2024-07-16T13:25:34Z",
    "closed_at": "2024-07-16T13:25:33Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/191",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/191",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/191.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/191.patch",
      "merged_at": null
    },
    "body": "`mamba_ssm` has already hardcoded the filenames for the config and weights files in https://github.com/Wauplin/mamba/blob/33dc96c84926e58a392861d5ad9d2ee4f4f4a259/mamba_ssm/utils/hf.py. It uses the convention for the Hugging Face Hub which is usually `config.json` for config and `model.safetensors` for weights. This PR updates `mistral-inference` to comply with this and make the model loadable from `mamba_ssm` directly. It would require the filenames to be renamed on the HF Hub repo.\r\n\r\nThis change would also allow the download counter to work on the model page out of the box.",
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/191/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/191/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/190",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/190/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/190/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/190/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/190",
    "id": 2411028351,
    "node_id": "PR_kwDOKY_97s51gizY",
    "number": 190,
    "title": "Update README.md",
    "user": {
      "login": "Simontwice",
      "id": 74513955,
      "node_id": "MDQ6VXNlcjc0NTEzOTU1",
      "avatar_url": "https://avatars.githubusercontent.com/u/74513955?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Simontwice",
      "html_url": "https://github.com/Simontwice",
      "followers_url": "https://api.github.com/users/Simontwice/followers",
      "following_url": "https://api.github.com/users/Simontwice/following{/other_user}",
      "gists_url": "https://api.github.com/users/Simontwice/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Simontwice/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Simontwice/subscriptions",
      "organizations_url": "https://api.github.com/users/Simontwice/orgs",
      "repos_url": "https://api.github.com/users/Simontwice/repos",
      "events_url": "https://api.github.com/users/Simontwice/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Simontwice/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-16T12:35:09Z",
    "updated_at": "2024-07-16T18:49:35Z",
    "closed_at": "2024-07-16T18:49:35Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/190",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/190",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/190.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/190.patch",
      "merged_at": null
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/190/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/190/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/189",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/189/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/189/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/189/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/189",
    "id": 2410979772,
    "node_id": "PR_kwDOKY_97s51gYB6",
    "number": 189,
    "title": "Update README.md",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-16T12:10:21Z",
    "updated_at": "2024-07-16T12:35:32Z",
    "closed_at": "2024-07-16T12:35:32Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/189",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/189",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/189.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/189.patch",
      "merged_at": "2024-07-16T12:35:32Z"
    },
    "body": null,
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/189/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/189/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/188",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/188/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/188/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/188/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/188",
    "id": 2410883875,
    "node_id": "PR_kwDOKY_97s51gCvP",
    "number": 188,
    "title": "Add Mamba and Mathstral to README",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-16T11:17:17Z",
    "updated_at": "2024-07-16T11:59:35Z",
    "closed_at": "2024-07-16T11:59:35Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/188",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/188",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/188.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/188.patch",
      "merged_at": "2024-07-16T11:59:35Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/188/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/188/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/187",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/187/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/187/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/187/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/187",
    "id": 2410824856,
    "node_id": "PR_kwDOKY_97s51f1oD",
    "number": 187,
    "title": "Add mamba",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-07-16T10:45:05Z",
    "updated_at": "2024-07-16T11:04:34Z",
    "closed_at": "2024-07-16T11:04:33Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/187",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/187",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/187.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/187.patch",
      "merged_at": "2024-07-16T11:04:33Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/187/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/187/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/184",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/184/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/184/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/184/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/184",
    "id": 2363927431,
    "node_id": "PR_kwDOKY_97s5zC8z4",
    "number": 184,
    "title": "Update README.md",
    "user": {
      "login": "Simontwice",
      "id": 74513955,
      "node_id": "MDQ6VXNlcjc0NTEzOTU1",
      "avatar_url": "https://avatars.githubusercontent.com/u/74513955?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Simontwice",
      "html_url": "https://github.com/Simontwice",
      "followers_url": "https://api.github.com/users/Simontwice/followers",
      "following_url": "https://api.github.com/users/Simontwice/following{/other_user}",
      "gists_url": "https://api.github.com/users/Simontwice/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Simontwice/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Simontwice/subscriptions",
      "organizations_url": "https://api.github.com/users/Simontwice/orgs",
      "repos_url": "https://api.github.com/users/Simontwice/repos",
      "events_url": "https://api.github.com/users/Simontwice/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Simontwice/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-06-20T09:06:31Z",
    "updated_at": "2024-06-20T09:10:23Z",
    "closed_at": "2024-06-20T09:10:23Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/184",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/184",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/184.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/184.patch",
      "merged_at": "2024-06-20T09:10:23Z"
    },
    "body": null,
    "closed_by": {
      "login": "Simontwice",
      "id": 74513955,
      "node_id": "MDQ6VXNlcjc0NTEzOTU1",
      "avatar_url": "https://avatars.githubusercontent.com/u/74513955?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Simontwice",
      "html_url": "https://github.com/Simontwice",
      "followers_url": "https://api.github.com/users/Simontwice/followers",
      "following_url": "https://api.github.com/users/Simontwice/following{/other_user}",
      "gists_url": "https://api.github.com/users/Simontwice/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Simontwice/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Simontwice/subscriptions",
      "organizations_url": "https://api.github.com/users/Simontwice/orgs",
      "repos_url": "https://api.github.com/users/Simontwice/repos",
      "events_url": "https://api.github.com/users/Simontwice/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Simontwice/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/184/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/184/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/183",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/183/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/183/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/183/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/183",
    "id": 2359772412,
    "node_id": "PR_kwDOKY_97s5y0tpE",
    "number": 183,
    "title": "typo in ModelArgs class docstring.",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-06-18T12:41:47Z",
    "updated_at": "2024-06-18T16:17:18Z",
    "closed_at": "2024-06-18T16:17:18Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/183",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/183",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/183.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/183.patch",
      "merged_at": "2024-06-18T16:17:18Z"
    },
    "body": "Changed the word \"infered\" to \"inferred\" to fix a spelling mistake.",
    "closed_by": {
      "login": "pandora-s-git",
      "id": 128635000,
      "node_id": "U_kgDOB6rQeA",
      "avatar_url": "https://avatars.githubusercontent.com/u/128635000?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pandora-s-git",
      "html_url": "https://github.com/pandora-s-git",
      "followers_url": "https://api.github.com/users/pandora-s-git/followers",
      "following_url": "https://api.github.com/users/pandora-s-git/following{/other_user}",
      "gists_url": "https://api.github.com/users/pandora-s-git/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pandora-s-git/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pandora-s-git/subscriptions",
      "organizations_url": "https://api.github.com/users/pandora-s-git/orgs",
      "repos_url": "https://api.github.com/users/pandora-s-git/repos",
      "events_url": "https://api.github.com/users/pandora-s-git/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pandora-s-git/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/183/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 1,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/183/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/182",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/182/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/182/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/182/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/182",
    "id": 2359328480,
    "node_id": "I_kwDOKY_97s6MoH7g",
    "number": 182,
    "title": "[BUG:  Mistral 7B Instruct Models from Huggingface limited to 4096tokens?",
    "user": {
      "login": "MaxS3552284",
      "id": 97786931,
      "node_id": "U_kgDOBdQcMw",
      "avatar_url": "https://avatars.githubusercontent.com/u/97786931?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/MaxS3552284",
      "html_url": "https://github.com/MaxS3552284",
      "followers_url": "https://api.github.com/users/MaxS3552284/followers",
      "following_url": "https://api.github.com/users/MaxS3552284/following{/other_user}",
      "gists_url": "https://api.github.com/users/MaxS3552284/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/MaxS3552284/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/MaxS3552284/subscriptions",
      "organizations_url": "https://api.github.com/users/MaxS3552284/orgs",
      "repos_url": "https://api.github.com/users/MaxS3552284/repos",
      "events_url": "https://api.github.com/users/MaxS3552284/events{/privacy}",
      "received_events_url": "https://api.github.com/users/MaxS3552284/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 6014552425,
        "node_id": "LA_kwDOKY_97s8AAAABZn7JaQ",
        "url": "https://api.github.com/repos/mistralai/mistral-inference/labels/bug",
        "name": "bug",
        "color": "d73a4a",
        "default": true,
        "description": "Something isn't working"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-06-18T08:57:22Z",
    "updated_at": "2024-06-19T14:08:07Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Python -VV\r\n\r\n```shell\r\n---------------------------------------------------------------------------\r\nNameError                                 Traceback (most recent call last)\r\nCell In[29], line 1\r\n----> 1 python -VV\r\n\r\nNameError: name 'python' is not defined\r\n\r\nnot working in sagemaker studio notebook?\r\n```\r\n\r\n\r\n### Pip Freeze\r\n\r\n```shell\r\naiobotocore==2.13.0\r\naiohttp==3.9.5\r\naioitertools==0.11.0\r\naiosignal==1.3.1\r\nalabaster @ file:///home/conda/feedstock_root/build_artifacts/alabaster_1704848697227/work\r\nannotated-types @ file:///home/conda/feedstock_root/build_artifacts/annotated-types_1696634205638/work\r\nanyio @ file:///home/conda/feedstock_root/build_artifacts/anyio_1708355285029/work\r\nappdirs @ file:///home/conda/feedstock_root/build_artifacts/appdirs_1603108395799/work\r\narchspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1699370045702/work\r\nargon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1692818318753/work\r\nargon2-cffi-bindings @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi-bindings_1695386546427/work\r\narrow @ file:///home/conda/feedstock_root/build_artifacts/arrow_1696128962909/work\r\nasgiref @ file:///home/conda/feedstock_root/build_artifacts/asgiref_1711268871457/work\r\nastroid @ file:///home/conda/feedstock_root/build_artifacts/astroid_1695739484762/work\r\nastropy @ file:///home/conda/feedstock_root/build_artifacts/astropy_1711552963707/work\r\nastropy-iers-data @ file:///home/conda/feedstock_root/build_artifacts/astropy-iers-data_1713182991850/work\r\nasttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work\r\nasync-lru @ file:///home/conda/feedstock_root/build_artifacts/async-lru_1690563019058/work\r\nasync-timeout==4.0.3\r\natomicwrites @ file:///home/conda/feedstock_root/build_artifacts/atomicwrites_1657325823582/work\r\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1704011227531/work\r\nAuthlib==1.3.0\r\nAutomat @ file:///home/conda/feedstock_root/build_artifacts/automat_1667331175863/work\r\nautopep8 @ file:///home/conda/feedstock_root/build_artifacts/autopep8_1693061251004/work\r\nautovizwidget==0.20.4\r\nawscli==1.32.84\r\nBabel @ file:///home/conda/feedstock_root/build_artifacts/babel_1702422572539/work\r\nbcrypt @ file:///home/conda/feedstock_root/build_artifacts/bcrypt_1702663837948/work\r\nbeautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1705564648255/work\r\nbinaryornot==0.4.4\r\nblack @ file:///home/conda/feedstock_root/build_artifacts/black-recipe_1713169757064/work\r\nbleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1696630167146/work\r\nblinker @ file:///home/conda/feedstock_root/build_artifacts/blinker_1698890160476/work\r\nbokeh @ file:///home/conda/feedstock_root/build_artifacts/bokeh_1712901085037/work\r\nboltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1703154663129/work\r\nboto3==1.34.84\r\nbotocore==1.34.84\r\nBrotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1695989787169/work\r\nbrotlipy @ file:///home/conda/feedstock_root/build_artifacts/brotlipy_1695621686607/work\r\ncached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\r\ncertifi @ file:///home/conda/feedstock_root/build_artifacts/certifi_1707022139797/work/certifi\r\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001684923/work\r\nchardet @ file:///home/conda/feedstock_root/build_artifacts/chardet_1695468598188/work\r\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1698833585322/work\r\nclick @ file:///home/conda/feedstock_root/build_artifacts/click_1692311806742/work\r\ncloudpickle==2.2.1\r\ncolorama==0.4.4\r\ncolorcet @ file:///home/conda/feedstock_root/build_artifacts/colorcet_1709713288616/work\r\ncomm @ file:///home/conda/feedstock_root/build_artifacts/comm_1710320294760/work\r\nconda @ file:///home/conda/feedstock_root/build_artifacts/conda_1701731572133/work\r\nconda-content-trust @ file:///home/conda/feedstock_root/build_artifacts/conda-content-trust_1693490762241/work\r\nconda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1702406360642/work/src\r\nconda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1691048088238/work\r\nconda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1691009212940/work\r\nconstantly==15.1.0\r\ncontextlib2==21.6.0\r\ncontourpy @ file:///home/conda/feedstock_root/build_artifacts/contourpy_1712429905637/work\r\ncookiecutter @ file:///home/conda/feedstock_root/build_artifacts/cookiecutter_1708608886262/work\r\ncryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography-split_1708780263085/work\r\ncycler @ file:///home/conda/feedstock_root/build_artifacts/cycler_1696677705766/work\r\ncytoolz @ file:///home/conda/feedstock_root/build_artifacts/cytoolz_1706897049115/work\r\ndaal4py==2024.3.0\r\ndask @ file:///home/conda/feedstock_root/build_artifacts/dask-core_1712248465271/work\r\ndask-expr @ file:///home/conda/feedstock_root/build_artifacts/dask-expr_1712693819397/work\r\ndatasets==2.20.0\r\ndebugpy @ file:///home/conda/feedstock_root/build_artifacts/debugpy_1707444420542/work\r\ndecorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\r\ndefusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\r\ndiff-match-patch @ file:///home/conda/feedstock_root/build_artifacts/diff-match-patch_1683670697993/work\r\ndill @ file:///home/conda/feedstock_root/build_artifacts/dill_1706434688412/work\r\ndistributed @ file:///home/conda/feedstock_root/build_artifacts/distributed_1712327504625/work\r\ndistro @ file:///home/conda/feedstock_root/build_artifacts/distro_1675116244235/work\r\nDjango @ file:///home/conda/feedstock_root/build_artifacts/django_1712162937871/work\r\ndocker==6.1.3\r\ndocstring-to-markdown @ file:///home/conda/feedstock_root/build_artifacts/docstring-to-markdown_1708563025188/work\r\ndocutils==0.16\r\ndparse==0.6.4b0\r\nentrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\r\net-xmlfile @ file:///home/conda/feedstock_root/build_artifacts/et_xmlfile_1674664118162/work\r\nexceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1704921103267/work\r\nexecuting @ file:///home/conda/feedstock_root/build_artifacts/executing_1698579936712/work\r\nfastapi @ file:///home/conda/feedstock_root/build_artifacts/fastapi_1712541010133/work\r\nfastjsonschema @ file:///home/conda/feedstock_root/build_artifacts/python-fastjsonschema_1703780968325/work/dist\r\nfilelock==3.13.4\r\nflake8 @ file:///home/conda/feedstock_root/build_artifacts/flake8_1704483779980/work\r\nFlask @ file:///home/conda/feedstock_root/build_artifacts/flask_1692686107036/work\r\nfonttools @ file:///home/conda/feedstock_root/build_artifacts/fonttools_1712344558731/work\r\nfqdn @ file:///home/conda/feedstock_root/build_artifacts/fqdn_1638810296540/work/dist\r\nfrozenlist==1.4.1\r\nfsspec==2024.6.0\r\nfuture @ file:///home/conda/feedstock_root/build_artifacts/future_1708610096684/work\r\ngevent @ file:///home/conda/feedstock_root/build_artifacts/gevent_1696750251337/work\r\ngmpy2 @ file:///home/conda/feedstock_root/build_artifacts/gmpy2_1666808654411/work\r\ngoogle-pasta==0.2.0\r\ngreenlet @ file:///home/conda/feedstock_root/build_artifacts/greenlet_1703201576006/work\r\ngssapi @ file:///home/conda/feedstock_root/build_artifacts/python-gssapi_1697143962561/work\r\nh11 @ file:///home/conda/feedstock_root/build_artifacts/h11_1664132893548/work\r\nh2 @ file:///home/conda/feedstock_root/build_artifacts/h2_1634280454336/work\r\nh5py @ file:///home/conda/feedstock_root/build_artifacts/h5py_1712763600515/work\r\nhdijupyterutils==0.20.4\r\nholoviews @ file:///home/conda/feedstock_root/build_artifacts/holoviews_1707758049702/work\r\nhpack==4.0.0\r\nhttpcore @ file:///home/conda/feedstock_root/build_artifacts/httpcore_1711596990900/work\r\nhttpx @ file:///home/conda/feedstock_root/build_artifacts/httpx_1708530890843/work\r\nhuggingface-hub==0.23.4\r\nhyperframe @ file:///home/conda/feedstock_root/build_artifacts/hyperframe_1619110129307/work\r\nhyperlink @ file:///home/conda/feedstock_root/build_artifacts/hyperlink_1610092164190/work\r\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1701026962277/work\r\nimagecodecs @ file:///home/conda/feedstock_root/build_artifacts/imagecodecs_1712887497562/work\r\nimageio @ file:///home/conda/feedstock_root/build_artifacts/imageio_1707730027807/work\r\nimagesize @ file:///home/conda/feedstock_root/build_artifacts/imagesize_1656939531508/work\r\nimportlib-metadata==6.11.0\r\nimportlib_resources @ file:///home/conda/feedstock_root/build_artifacts/importlib_resources_1711040877059/work\r\nincremental @ file:///home/conda/feedstock_root/build_artifacts/incremental_1665859450441/work\r\ninflection @ file:///home/conda/feedstock_root/build_artifacts/inflection_1598089801258/work\r\niniconfig @ file:///home/conda/feedstock_root/build_artifacts/iniconfig_1673103042956/work\r\nintervaltree @ file:///home/conda/feedstock_root/build_artifacts/intervaltree_1683532206518/work\r\nipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1708996548741/work\r\nipython==8.23.0\r\nipython-genutils==0.2.0\r\nipywidgets @ file:///home/conda/feedstock_root/build_artifacts/ipywidgets_1631590360471/work\r\nisoduration @ file:///home/conda/feedstock_root/build_artifacts/isoduration_1638811571363/work/dist\r\nisort @ file:///home/conda/feedstock_root/build_artifacts/isort_1702518492027/work\r\nitsdangerous @ file:///home/conda/feedstock_root/build_artifacts/itsdangerous_1648147185463/work\r\njaraco.classes @ file:///home/conda/feedstock_root/build_artifacts/jaraco.classes_1712041970955/work\r\njaraco.context @ file:///home/conda/feedstock_root/build_artifacts/jaraco.context_1675258691127/work\r\njaraco.functools @ file:///home/conda/feedstock_root/build_artifacts/jaraco.functools_1701695162614/work\r\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work\r\njeepney @ file:///home/conda/feedstock_root/build_artifacts/jeepney_1649085214306/work\r\njellyfish @ file:///home/conda/feedstock_root/build_artifacts/jellyfish_1700261197714/work\r\nJinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1704966972576/work\r\njmespath==1.0.1\r\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1712597192451/work\r\njson5 @ file:///home/conda/feedstock_root/build_artifacts/json5_1712986206667/work\r\njsonpatch @ file:///home/conda/feedstock_root/build_artifacts/jsonpatch_1695536281965/work\r\njsonpointer @ file:///home/conda/feedstock_root/build_artifacts/jsonpointer_1695397238043/work\r\njsonschema @ file:///home/conda/feedstock_root/build_artifacts/jsonschema-meta_1705707496704/work\r\njsonschema-specifications @ file:///tmp/tmpkv1z7p57/src\r\njupyter @ file:///home/conda/feedstock_root/build_artifacts/jupyter_1696255489086/work\r\njupyter-console @ file:///home/conda/feedstock_root/build_artifacts/jupyter_console_1678118109161/work\r\njupyter-events @ file:///home/conda/feedstock_root/build_artifacts/jupyter_events_1710805637316/work\r\njupyter-lsp @ file:///home/conda/feedstock_root/build_artifacts/jupyter-lsp-meta_1712707420468/work/jupyter-lsp\r\njupyter_client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1673615989977/work\r\njupyter_core @ file:///home/conda/feedstock_root/build_artifacts/jupyter_core_1710257277185/work\r\njupyter_server @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_1712884210432/work\r\njupyter_server_terminals @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_terminals_1710262634903/work\r\njupyterlab @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_1712586972478/work\r\njupyterlab_pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1707149102966/work\r\njupyterlab_server @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_server-split_1712583928460/work\r\njupyterlab_widgets @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_widgets_1707421892171/work\r\nkeyring @ file:///home/conda/feedstock_root/build_artifacts/keyring_1712107862727/work\r\nkiwisolver @ file:///home/conda/feedstock_root/build_artifacts/kiwisolver_1695379902431/work\r\nkrb5 @ file:///home/conda/feedstock_root/build_artifacts/pykrb5_1708557570437/work\r\nlazy-object-proxy @ file:///home/conda/feedstock_root/build_artifacts/lazy-object-proxy_1702663550721/work\r\nlibmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1702310393080/work/libmambapy\r\nlief==0.14.1\r\nlinkify-it-py @ file:///home/conda/feedstock_root/build_artifacts/linkify-it-py_1707129103613/work\r\nllvmlite==0.42.0\r\nlocket @ file:///home/conda/feedstock_root/build_artifacts/locket_1650660393415/work\r\nlxml @ file:///home/conda/feedstock_root/build_artifacts/lxml_1704724217654/work\r\nlz4 @ file:///home/conda/feedstock_root/build_artifacts/lz4_1704831084136/work\r\nmamba @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1702310393080/work/mamba\r\nMarkdown @ file:///home/conda/feedstock_root/build_artifacts/markdown_1710435156458/work\r\nmarkdown-it-py @ file:///home/conda/feedstock_root/build_artifacts/markdown-it-py_1686175045316/work\r\nMarkupSafe @ file:///home/conda/feedstock_root/build_artifacts/markupsafe_1706899921127/work\r\nmarshmallow==3.21.1\r\nmatplotlib @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-suite_1712605966339/work\r\nmatplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1660814786464/work\r\nmccabe @ file:///home/conda/feedstock_root/build_artifacts/mccabe_1643049622439/work\r\nmdit-py-plugins @ file:///home/conda/feedstock_root/build_artifacts/mdit-py-plugins_1686175351422/work\r\nmdurl @ file:///home/conda/feedstock_root/build_artifacts/mdurl_1704317613764/work\r\nmenuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1702317041727/work\r\nmistune @ file:///home/conda/feedstock_root/build_artifacts/mistune_1673904152039/work\r\nmock @ file:///home/conda/feedstock_root/build_artifacts/mock_1689092066756/work\r\nmore-itertools @ file:///home/conda/feedstock_root/build_artifacts/more-itertools_1704738417589/work\r\nmpmath @ file:///home/conda/feedstock_root/build_artifacts/mpmath_1678228039184/work\r\nmsgpack @ file:///home/conda/feedstock_root/build_artifacts/msgpack-python_1700926504817/work\r\nmultidict==6.0.5\r\nmultiprocess==0.70.16\r\nmunkres==1.1.4\r\nmypy-extensions @ file:///home/conda/feedstock_root/build_artifacts/mypy_extensions_1675543315189/work\r\nnb_conda_kernels @ file:///home/conda/feedstock_root/build_artifacts/nb_conda_kernels_1708439411368/work\r\nnbclassic @ file:///home/conda/feedstock_root/build_artifacts/nbclassic_1683202081046/work\r\nnbclient @ file:///home/conda/feedstock_root/build_artifacts/nbclient_1710317608672/work\r\nnbconvert @ file:///home/conda/feedstock_root/build_artifacts/nbconvert-meta_1660222578365/work\r\nnbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1712238998817/work\r\nnest-asyncio==1.5.5\r\nnltk @ file:///home/conda/feedstock_root/build_artifacts/nltk_1672696305909/work\r\nnose @ file:///home/conda/feedstock_root/build_artifacts/nose_1602434998960/work\r\nnotebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1695225629675/work\r\nnotebook_shim @ file:///home/conda/feedstock_root/build_artifacts/notebook-shim_1707957777232/work\r\nnumba @ file:///home/conda/feedstock_root/build_artifacts/numba_1711475179870/work\r\nnumexpr @ file:///home/conda/feedstock_root/build_artifacts/numexpr_1707139868047/work\r\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1707225380409/work/dist/numpy-1.26.4-cp310-cp310-linux_x86_64.whl#sha256=51131fd8fc130cd168aecaf1bc0ea85f92e8ffebf211772ceb16ac2e7f10d7ca\r\nnumpydoc @ file:///home/conda/feedstock_root/build_artifacts/numpydoc_1711638311008/work\r\nopenpyxl @ file:///home/conda/feedstock_root/build_artifacts/openpyxl_1695464693876/work\r\noverrides @ file:///home/conda/feedstock_root/build_artifacts/overrides_1706394519472/work\r\npackaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1696202382185/work\r\npandas @ file:///home/conda/feedstock_root/build_artifacts/pandas_1712782027765/work\r\npandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\r\npanel @ file:///home/conda/feedstock_root/build_artifacts/panel_1712673484427/work\r\npapermill==2.5.0\r\nparam @ file:///home/conda/feedstock_root/build_artifacts/param_1711102884605/work\r\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1712320355065/work\r\npartd @ file:///home/conda/feedstock_root/build_artifacts/partd_1695667515973/work\r\npathos==0.3.2\r\npathspec @ file:///home/conda/feedstock_root/build_artifacts/pathspec_1702249949303/work\r\npatsy @ file:///home/conda/feedstock_root/build_artifacts/patsy_1704469236901/work\r\npexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1706113125309/work\r\npickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\r\npillow @ file:///home/conda/feedstock_root/build_artifacts/pillow_1712154467551/work\r\npkgutil_resolve_name @ file:///home/conda/feedstock_root/build_artifacts/pkgutil-resolve-name_1694617248815/work\r\nplatformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1701708255999/work\r\nplotly @ file:///home/conda/feedstock_root/build_artifacts/plotly_1708020413888/work\r\npluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1706116770704/work\r\nply @ file:///home/conda/feedstock_root/build_artifacts/ply_1712242996588/work\r\npox==0.3.4\r\nppft==1.7.6.8\r\nprometheus_client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1707932675456/work\r\nprompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1702399386289/work\r\nprotobuf==4.25.3\r\npsutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1705722392846/work\r\nptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\r\npure-sasl @ file:///home/conda/feedstock_root/build_artifacts/pure-sasl_1631890804823/work\r\npyarrow==15.0.2\r\npyarrow-hotfix @ file:///home/conda/feedstock_root/build_artifacts/pyarrow-hotfix_1700596371886/work\r\npyasn1 @ file:///home/conda/feedstock_root/build_artifacts/pyasn1_1713209357222/work\r\npyasn1_modules @ file:///home/conda/feedstock_root/build_artifacts/pyasn1-modules_1713209683338/work\r\npycodestyle @ file:///home/conda/feedstock_root/build_artifacts/pycodestyle_1697202867721/work\r\npycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758174/work\r\npycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\r\npydantic @ file:///home/conda/feedstock_root/build_artifacts/pydantic_1712899199321/work\r\npydantic_core @ file:///home/conda/feedstock_root/build_artifacts/pydantic-core_1712848713126/work\r\npydocstyle @ file:///home/conda/feedstock_root/build_artifacts/pydocstyle_1673997487070/work\r\npyerfa @ file:///home/conda/feedstock_root/build_artifacts/pyerfa_1712963310236/work\r\npyflakes @ file:///home/conda/feedstock_root/build_artifacts/pyflakes_1704424584912/work\r\npyfunctional==1.5.0\r\nPygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1700607939962/work\r\nPyHive @ file:///home/conda/feedstock_root/build_artifacts/pyhive_1692318104998/work\r\npylint @ file:///home/conda/feedstock_root/build_artifacts/pylint_1696171682664/work\r\npylint-venv @ file:///home/conda/feedstock_root/build_artifacts/pylint-venv_1698219336631/work\r\npyls-spyder @ file:///home/conda/feedstock_root/build_artifacts/pyls-spyder_1619747398504/work\r\npyodbc @ file:///home/conda/feedstock_root/build_artifacts/pyodbc_1707165112197/work\r\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1706660063483/work\r\npyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1709721012883/work\r\nPyQt5==5.15.9\r\nPyQt5-sip==12.12.2\r\nPyQtWebEngine==5.15.4\r\nPySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1661604839144/work\r\npyspnego @ file:///home/conda/feedstock_root/build_artifacts/pyspnego_1696277744607/work\r\npytest @ file:///home/conda/feedstock_root/build_artifacts/pytest_1709992573517/work\r\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1709299778482/work\r\npython-json-logger @ file:///home/conda/feedstock_root/build_artifacts/python-json-logger_1677079630776/work\r\npython-lsp-black @ file:///home/conda/feedstock_root/build_artifacts/python-lsp-black_1702956932456/work\r\npython-lsp-jsonrpc @ file:///home/conda/feedstock_root/build_artifacts/python-lsp-jsonrpc_1695528365348/work\r\npython-lsp-server @ file:///home/conda/feedstock_root/build_artifacts/python-lsp-server-meta_1710340750771/work\r\npython-slugify @ file:///home/conda/feedstock_root/build_artifacts/python-slugify-split_1707425621764/work\r\npytoolconfig @ file:///home/conda/feedstock_root/build_artifacts/pytoolconfig_1675124745143/work\r\npytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1706886791323/work\r\npyviz_comms @ file:///home/conda/feedstock_root/build_artifacts/pyviz_comms_1708965518207/work\r\npyxdg @ file:///home/conda/feedstock_root/build_artifacts/pyxdg_1654536799286/work\r\nPyYAML @ file:///home/conda/feedstock_root/build_artifacts/pyyaml_1695373428874/work\r\npyzmq @ file:///home/conda/feedstock_root/build_artifacts/pyzmq_1666828497229/work\r\nQDarkStyle @ file:///home/conda/feedstock_root/build_artifacts/qdarkstyle_1702957860620/work\r\nqstylizer @ file:///home/conda/feedstock_root/build_artifacts/qstylizer_1662244505808/work/dist/qstylizer-0.2.2-py2.py3-none-any.whl\r\nQtAwesome @ file:///home/conda/feedstock_root/build_artifacts/qtawesome_1678418951316/work\r\nqtconsole @ file:///home/conda/feedstock_root/build_artifacts/qtconsole-base_1700168901209/work\r\nQtPy @ file:///home/conda/feedstock_root/build_artifacts/qtpy_1698112029416/work\r\nreferencing @ file:///home/conda/feedstock_root/build_artifacts/referencing_1710763696991/work\r\nregex @ file:///home/conda/feedstock_root/build_artifacts/regex_1703393490683/work\r\nrequests==2.32.3\r\nrequests-kerberos @ file:///home/conda/feedstock_root/build_artifacts/requests-kerberos_1708339520234/work\r\nrfc3339-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3339-validator_1638811747357/work\r\nrfc3986-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3986-validator_1598024191506/work\r\nrich @ file:///home/conda/feedstock_root/build_artifacts/rich-split_1709150387247/work/dist\r\nrope @ file:///home/conda/feedstock_root/build_artifacts/rope_1711296293824/work\r\nrpds-py @ file:///home/conda/feedstock_root/build_artifacts/rpds-py_1707922703488/work\r\nrsa==4.7.2\r\nRtree @ file:///home/conda/feedstock_root/build_artifacts/rtree_1705697867335/work\r\nruamel-yaml-conda @ file:///home/conda/feedstock_root/build_artifacts/ruamel_yaml_1695546328261/work\r\nruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1699007337104/work\r\nruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1695996839082/work\r\ns3fs==2024.6.0\r\ns3transfer==0.10.1\r\nsafety-schemas==0.0.2\r\nsagemaker==2.223.0\r\nsagemaker-data-insights @ https://files.pythonhosted.org/packages/70/8b/7c964508afe1dc3535422df8383c022c762c1f1254acb68b29d26b33fe30/sagemaker_data_insights-0.3.3-py3-none-any.whl#sha256=b1368073adb0360c2bcee6edf011758c00ecfc0b1b1a8032f787618f87b9b1d0\r\nsagemaker-datawrangler @ https://files.pythonhosted.org/packages/6a/29/6d3da0518cbe72647b164bbdee23f4df3936cf5691fff9b29dc8714115ff/sagemaker_datawrangler-0.4.3-py3-none-any.whl#sha256=724467ef4c8204f2e6ecc6e5bc39a29dfe5b50657aec901becb7a7c207a06c25\r\nsagemaker-headless-execution-driver==0.0.13\r\nsagemaker-scikit-learn-extension==2.5.0\r\nsagemaker-studio-analytics-extension==0.0.20\r\nsagemaker-studio-sparkmagic-lib==0.1.4\r\nsasl==0.3.1\r\nschema==0.7.5\r\nscikit-learn @ file:///home/conda/feedstock_root/build_artifacts/scikit-learn_1712824576633/work\r\nscipy @ file:///home/conda/feedstock_root/build_artifacts/scipy-split_1712255231550/work/dist/scipy-1.13.0-cp310-cp310-linux_x86_64.whl#sha256=2d847580321887e90df63c23a59deb5edd129fd9b3b34ff76d61cc32872a00ac\r\nseaborn @ file:///home/conda/feedstock_root/build_artifacts/seaborn-split_1706340836595/work\r\nSecretStorage @ file:///home/conda/feedstock_root/build_artifacts/secretstorage_1695551734488/work\r\nSend2Trash @ file:///home/conda/feedstock_root/build_artifacts/send2trash_1712584999685/work\r\nservice-identity @ file:///home/conda/feedstock_root/build_artifacts/service-identity-build_1700936484042/work\r\nshellingham==1.5.4\r\nsip @ file:///home/conda/feedstock_root/build_artifacts/sip_1697300428978/work\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\r\nsmclarify==0.5\r\nsmdebug-rulesconfig==1.0.1\r\nsniffio @ file:///home/conda/feedstock_root/build_artifacts/sniffio_1708952932303/work\r\nsnowballstemmer @ file:///home/conda/feedstock_root/build_artifacts/snowballstemmer_1637143057757/work\r\nsortedcontainers @ file:///home/conda/feedstock_root/build_artifacts/sortedcontainers_1621217038088/work\r\nsoupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1693929250441/work\r\nsparkmagic @ file:///home/conda/feedstock_root/build_artifacts/sparkmagic_1675108208766/work/sparkmagic\r\nSphinx @ file:///home/conda/feedstock_root/build_artifacts/sphinx_1694647393084/work\r\nsphinxcontrib-applehelp @ file:///home/conda/feedstock_root/build_artifacts/sphinxcontrib-applehelp_1705126298355/work\r\nsphinxcontrib-devhelp @ file:///home/conda/feedstock_root/build_artifacts/sphinxcontrib-devhelp_1705126010477/work\r\nsphinxcontrib-htmlhelp @ file:///home/conda/feedstock_root/build_artifacts/sphinxcontrib-htmlhelp_1705118152391/work\r\nsphinxcontrib-jsmath @ file:///home/conda/feedstock_root/build_artifacts/sphinxcontrib-jsmath_1691604704163/work\r\nsphinxcontrib-qthelp @ file:///home/conda/feedstock_root/build_artifacts/sphinxcontrib-qthelp_1705126152907/work\r\nsphinxcontrib-serializinghtml @ file:///home/conda/feedstock_root/build_artifacts/sphinxcontrib-serializinghtml_1705118225549/work\r\nspyder @ file:///home/conda/feedstock_root/build_artifacts/spyder_1710687055121/work\r\nspyder-kernels @ file:///home/conda/feedstock_root/build_artifacts/spyder-kernels_1709087656711/work\r\nSQLAlchemy @ file:///home/conda/feedstock_root/build_artifacts/sqlalchemy_1711289771385/work\r\nsqlparse @ file:///home/conda/feedstock_root/build_artifacts/sqlparse_1681817562700/work\r\nstack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work\r\nstarlette @ file:///home/conda/feedstock_root/build_artifacts/starlette-recipe_1709667058396/work\r\nstatsmodels @ file:///home/conda/feedstock_root/build_artifacts/statsmodels_1702575356319/work\r\nsympy @ file:///home/conda/feedstock_root/build_artifacts/sympy_1684180540116/work\r\ntabulate @ file:///home/conda/feedstock_root/build_artifacts/tabulate_1665138452165/work\r\ntblib @ file:///home/conda/feedstock_root/build_artifacts/tblib_1702066284995/work\r\ntenacity @ file:///home/conda/feedstock_root/build_artifacts/tenacity_1692026804430/work\r\nterminado @ file:///home/conda/feedstock_root/build_artifacts/terminado_1710262609923/work\r\ntext-unidecode @ file:///home/conda/feedstock_root/build_artifacts/text-unidecode_1694707102786/work\r\ntextdistance @ file:///home/conda/feedstock_root/build_artifacts/textdistance_1663527496115/work\r\nthreadpoolctl @ file:///home/conda/feedstock_root/build_artifacts/threadpoolctl_1710943558485/work\r\nthree-merge @ file:///home/conda/feedstock_root/build_artifacts/three-merge_1595515817927/work\r\nthrift @ file:///home/conda/feedstock_root/build_artifacts/thrift_1711156094832/work/lib/py\r\nthrift-sasl @ file:///home/conda/feedstock_root/build_artifacts/thrift_sasl_1664049052220/work\r\ntinycss2 @ file:///home/conda/feedstock_root/build_artifacts/tinycss2_1666100256010/work\r\ntoml @ file:///home/conda/feedstock_root/build_artifacts/toml_1604308577558/work\r\ntomli @ file:///home/conda/feedstock_root/build_artifacts/tomli_1644342247877/work\r\ntomlkit @ file:///home/conda/feedstock_root/build_artifacts/tomlkit_1709043728182/work\r\ntoolz @ file:///home/conda/feedstock_root/build_artifacts/toolz_1706112571092/work\r\ntornado @ file:///home/conda/feedstock_root/build_artifacts/tornado_1708363098266/work\r\ntqdm==4.66.4\r\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1710254411456/work\r\ntruststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\r\nTwisted @ file:///home/conda/feedstock_root/build_artifacts/twisted_1709332269679/work\r\ntyper==0.12.3\r\ntypes-python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/types-python-dateutil_1710589910274/work\r\ntyping-utils @ file:///home/conda/feedstock_root/build_artifacts/typing_utils_1622899189314/work\r\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1712329955671/work\r\ntzdata @ file:///home/conda/feedstock_root/build_artifacts/python-tzdata_1707747584337/work\r\nuc-micro-py @ file:///home/conda/feedstock_root/build_artifacts/uc-micro-py_1707507364877/work\r\nujson @ file:///home/conda/feedstock_root/build_artifacts/ujson_1702256697606/work\r\nunicodedata2 @ file:///home/conda/feedstock_root/build_artifacts/unicodedata2_1695847980273/work\r\nuri-template @ file:///home/conda/feedstock_root/build_artifacts/uri-template_1688655812972/work/dist\r\nurllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1708239446578/work\r\nw3lib @ file:///home/conda/feedstock_root/build_artifacts/w3lib_1691236459676/work\r\nwatchdog @ file:///home/conda/feedstock_root/build_artifacts/watchdog_1707295131798/work\r\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1704731205417/work\r\nwebcolors @ file:///home/conda/feedstock_root/build_artifacts/webcolors_1679900785843/work\r\nwebencodings @ file:///home/conda/feedstock_root/build_artifacts/webencodings_1694681268211/work\r\nwebsocket-client @ file:///home/conda/feedstock_root/build_artifacts/websocket-client_1701630677416/work\r\nWerkzeug @ file:///home/conda/feedstock_root/build_artifacts/werkzeug_1699492457596/work\r\nwhatthepatch @ file:///home/conda/feedstock_root/build_artifacts/whatthepatch_1683396758362/work\r\nwidgetsnbextension @ file:///home/conda/feedstock_root/build_artifacts/widgetsnbextension_1637174134114/work\r\nwrapt @ file:///home/conda/feedstock_root/build_artifacts/wrapt_1699532811524/work\r\nwurlitzer @ file:///home/conda/feedstock_root/build_artifacts/wurlitzer_1669944596833/work\r\nxlrd @ file:///home/conda/feedstock_root/build_artifacts/xlrd_1610224409810/work\r\nxxhash==3.4.1\r\nxyzservices @ file:///home/conda/feedstock_root/build_artifacts/xyzservices_1712209912887/work\r\nyapf @ file:///home/conda/feedstock_root/build_artifacts/yapf_1690387939953/work\r\nyarl==1.9.4\r\nzict @ file:///home/conda/feedstock_root/build_artifacts/zict_1681770155528/work\r\nzipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1695255097490/work\r\nzope.event @ file:///home/conda/feedstock_root/build_artifacts/zope.event_1687705558811/work\r\nzope.interface @ file:///home/conda/feedstock_root/build_artifacts/zope.interface_1712940893298/work\r\nzstandard==0.22.0\r\nNote: you may need to restart the kernel to use updated packages.\r\n```\r\n\r\n\r\n### Reproduction Steps\r\n\r\nrecently i finetuned a Mistral 7B Instruct v0.3 model and deployed it on an AWS Sagemaker endpoint. But got errors like this during inference in the sagemaker studio notebook:\r\n\r\n\" Received client error (422) from primary with message \"{\"error\":\"Input validation error: inputs tokens + max_new_tokens must be <= 4096. Given: 877 inputs tokens and 4096 max_new_tokens\",\"error_type\":\"validation\"}\".\"\r\n\r\nWhich means I am limited to 4096 Tokens. But max. tokens should be the following: \r\nMistral 7B Instruct v0.1 = 8192 \r\nMistral 7B Instruct v0.2,v0.3 = 32k\r\n\r\nInput parameter were: \"parameters\": {\"max_new_tokens\": 4096, \"do_sample\": True} \r\n\r\nI also hosted the basemodels from huggingface on sagemaker endpoints and they all seem to be limited to 4096 tokens.\r\n\r\nDoes anyone know how to fix this?\r\n\r\n### Expected Behavior\r\n\r\nDuring inference the token limits should be far higher than 4k.\r\nUnder 4k inference works as intended.\r\n\r\n### Additional Context\r\n\r\nI got the code for deployment on AWS Sagemaker from here: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\r\n\r\n### Suggested Solutions\r\n\r\n_No response_",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/182/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/182/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/181",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/181/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/181/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/181/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/181",
    "id": 2355635458,
    "node_id": "PR_kwDOKY_97s5ymm8k",
    "number": 181,
    "title": "Correct grammatical error in markdown cells",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-06-16T10:05:27Z",
    "updated_at": "2024-06-16T10:05:27Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/181",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/181",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/181.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/181.patch",
      "merged_at": null
    },
    "body": "Fixed the grammatical error in the markdown cell by changing \"users location\" to the possessive \"user's location\".",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/181/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/181/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/180",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/180/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/180/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/180/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/180",
    "id": 2347464494,
    "node_id": "I_kwDOKY_97s6L63cu",
    "number": 180,
    "title": "Suggested improvement of eos logic in generate.py",
    "user": {
      "login": "vvatter",
      "id": 84607993,
      "node_id": "MDQ6VXNlcjg0NjA3OTkz",
      "avatar_url": "https://avatars.githubusercontent.com/u/84607993?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vvatter",
      "html_url": "https://github.com/vvatter",
      "followers_url": "https://api.github.com/users/vvatter/followers",
      "following_url": "https://api.github.com/users/vvatter/following{/other_user}",
      "gists_url": "https://api.github.com/users/vvatter/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vvatter/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vvatter/subscriptions",
      "organizations_url": "https://api.github.com/users/vvatter/orgs",
      "repos_url": "https://api.github.com/users/vvatter/repos",
      "events_url": "https://api.github.com/users/vvatter/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vvatter/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-06-11T23:26:23Z",
    "updated_at": "2024-08-22T07:11:01Z",
    "closed_at": "2024-08-22T07:11:01Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "https://github.com/mistralai/mistral-inference/blob/c24ac864ab623ca39bda4f48c334eed6e55f13a2/src/mistral_inference/generate.py#L91\r\n\r\nIn the generate() function of `generate.py`, there is some curious XOR logic for updating the boolean `is_finished` vector:\r\n```        \r\n        if eos_id is not None:\r\n            is_finished = is_finished ^ (next_token == eos_id).cpu()\r\n```\r\nEven once it reaches an eos token, Mistral likes to keep talking, so this means that if you are running large batches, the shortest response might hit eos and then generate another eos and flip back to `is_finished == False` before the longest response has finished, which will often keep happening up until you hit `max_tokens`. It seems to me that this should be an OR.\r\n\r\nAdditionally, the current approach allows tokens following an EOS to be included in outputs, which, since the tokenizer decodes EOS as an empty string, might contribute to confusing output sequences. This could potentially relate to the issues discussed in #149 .\r\n\r\nTo address both issues, I suggest the following modifications to ensure that `is_finished` remains `True` after encountering an eos token and to not return tokens after this point.\r\n```        \r\n        if eos_id is not None:\r\n            is_finished = is_finished | (next_token == eos_id).cpu()\r\n            next_token = next_token * (~is_finished).to(next_token.device)\r\n            next_token = next_token + eos_id * is_finished.to(next_token.device)\r\n```",
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/180/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/180/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/179",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/179/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/179/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/179/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/179",
    "id": 2341345138,
    "node_id": "PR_kwDOKY_97s5x2J9b",
    "number": 179,
    "title": "fix: typo in HF_TOKEN environment variable check message",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-06-08T01:28:29Z",
    "updated_at": "2024-06-10T08:41:39Z",
    "closed_at": "2024-06-10T08:41:39Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/179",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/179",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/179.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/179.patch",
      "merged_at": "2024-06-10T08:41:39Z"
    },
    "body": "Fixed a typo in the bash script that logs into Hugging Face using the HF_TOKEN environment variable. The message now correctly states \"The HF_TOKEN environment variable is set\" instead of \"The HF_TOKEN environment variable set\".",
    "closed_by": {
      "login": "pandora-s-git",
      "id": 128635000,
      "node_id": "U_kgDOB6rQeA",
      "avatar_url": "https://avatars.githubusercontent.com/u/128635000?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pandora-s-git",
      "html_url": "https://github.com/pandora-s-git",
      "followers_url": "https://api.github.com/users/pandora-s-git/followers",
      "following_url": "https://api.github.com/users/pandora-s-git/following{/other_user}",
      "gists_url": "https://api.github.com/users/pandora-s-git/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pandora-s-git/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pandora-s-git/subscriptions",
      "organizations_url": "https://api.github.com/users/pandora-s-git/orgs",
      "repos_url": "https://api.github.com/users/pandora-s-git/repos",
      "events_url": "https://api.github.com/users/pandora-s-git/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pandora-s-git/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/179/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/179/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/178",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/178/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/178/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/178/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/178",
    "id": 2340385481,
    "node_id": "PR_kwDOKY_97s5xy33z",
    "number": 178,
    "title": "Adding Issue/Bug template.",
    "user": {
      "login": "pandora-s-git",
      "id": 128635000,
      "node_id": "U_kgDOB6rQeA",
      "avatar_url": "https://avatars.githubusercontent.com/u/128635000?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pandora-s-git",
      "html_url": "https://github.com/pandora-s-git",
      "followers_url": "https://api.github.com/users/pandora-s-git/followers",
      "following_url": "https://api.github.com/users/pandora-s-git/following{/other_user}",
      "gists_url": "https://api.github.com/users/pandora-s-git/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pandora-s-git/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pandora-s-git/subscriptions",
      "organizations_url": "https://api.github.com/users/pandora-s-git/orgs",
      "repos_url": "https://api.github.com/users/pandora-s-git/repos",
      "events_url": "https://api.github.com/users/pandora-s-git/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pandora-s-git/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-06-07T12:52:57Z",
    "updated_at": "2024-06-17T08:26:04Z",
    "closed_at": "2024-06-17T08:26:04Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/178",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/178",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/178.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/178.patch",
      "merged_at": "2024-06-17T08:26:04Z"
    },
    "body": "Adds a template for issues and bugs, i've disabled blank issues for now.",
    "closed_by": {
      "login": "sophiamyang",
      "id": 39501859,
      "node_id": "MDQ6VXNlcjM5NTAxODU5",
      "avatar_url": "https://avatars.githubusercontent.com/u/39501859?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sophiamyang",
      "html_url": "https://github.com/sophiamyang",
      "followers_url": "https://api.github.com/users/sophiamyang/followers",
      "following_url": "https://api.github.com/users/sophiamyang/following{/other_user}",
      "gists_url": "https://api.github.com/users/sophiamyang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sophiamyang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sophiamyang/subscriptions",
      "organizations_url": "https://api.github.com/users/sophiamyang/orgs",
      "repos_url": "https://api.github.com/users/sophiamyang/repos",
      "events_url": "https://api.github.com/users/sophiamyang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sophiamyang/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/178/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/178/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/177",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/177/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/177/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/177/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/177",
    "id": 2338366846,
    "node_id": "PR_kwDOKY_97s5xr_mO",
    "number": 177,
    "title": "fix: typo in ModelArgs dataclass definition",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-06-06T14:10:37Z",
    "updated_at": "2024-06-06T14:10:37Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/177",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/177",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/177.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/177.patch",
      "merged_at": null
    },
    "body": "Corrected the misspelling of \"inferred\" in the ModelArgs dataclass definition.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/177/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/177/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/176",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/176/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/176/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/176/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/176",
    "id": 2338357055,
    "node_id": "PR_kwDOKY_97s5xr9ay",
    "number": 176,
    "title": "fix: typo in .gitignore file",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-06-06T14:06:22Z",
    "updated_at": "2024-06-06T14:06:22Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/176",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/176",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/176.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/176.patch",
      "merged_at": null
    },
    "body": "Corrected a typo in the .gitignore file. Changed \"infos\" to \"info\" for grammatical accuracy.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/176/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/176/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/175",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/175/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/175/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/175/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/175",
    "id": 2337357983,
    "node_id": "PR_kwDOKY_97s5xogg8",
    "number": 175,
    "title": "fixing type in README.md",
    "user": {
      "login": "didier-durand",
      "id": 2927957,
      "node_id": "MDQ6VXNlcjI5Mjc5NTc=",
      "avatar_url": "https://avatars.githubusercontent.com/u/2927957?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/didier-durand",
      "html_url": "https://github.com/didier-durand",
      "followers_url": "https://api.github.com/users/didier-durand/followers",
      "following_url": "https://api.github.com/users/didier-durand/following{/other_user}",
      "gists_url": "https://api.github.com/users/didier-durand/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/didier-durand/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/didier-durand/subscriptions",
      "organizations_url": "https://api.github.com/users/didier-durand/orgs",
      "repos_url": "https://api.github.com/users/didier-durand/repos",
      "events_url": "https://api.github.com/users/didier-durand/events{/privacy}",
      "received_events_url": "https://api.github.com/users/didier-durand/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-06-06T05:43:35Z",
    "updated_at": "2024-06-06T08:50:22Z",
    "closed_at": "2024-06-06T08:26:59Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/175",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/175",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/175.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/175.patch",
      "merged_at": "2024-06-06T08:26:59Z"
    },
    "body": "\"All models supports\" -> \"Al models support\" without \"s\" as subject is plural",
    "closed_by": {
      "login": "pandora-s-git",
      "id": 128635000,
      "node_id": "U_kgDOB6rQeA",
      "avatar_url": "https://avatars.githubusercontent.com/u/128635000?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pandora-s-git",
      "html_url": "https://github.com/pandora-s-git",
      "followers_url": "https://api.github.com/users/pandora-s-git/followers",
      "following_url": "https://api.github.com/users/pandora-s-git/following{/other_user}",
      "gists_url": "https://api.github.com/users/pandora-s-git/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pandora-s-git/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pandora-s-git/subscriptions",
      "organizations_url": "https://api.github.com/users/pandora-s-git/orgs",
      "repos_url": "https://api.github.com/users/pandora-s-git/repos",
      "events_url": "https://api.github.com/users/pandora-s-git/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pandora-s-git/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/175/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/175/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/174",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/174/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/174/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/174/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/174",
    "id": 2336826671,
    "node_id": "PR_kwDOKY_97s5xmtNQ",
    "number": 174,
    "title": "Fix: typo in ModelArgs: \"infered\" to \"inferred\"",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-06-05T21:01:10Z",
    "updated_at": "2024-06-06T08:56:19Z",
    "closed_at": "2024-06-06T08:56:19Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/174",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/174",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/174.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/174.patch",
      "merged_at": "2024-06-06T08:56:19Z"
    },
    "body": "Corrected a typographical error in the `ModelArgs` class of the inference script. The word \"infered\" was corrected to \"inferred\" in the comment regarding rotary embeddings.",
    "closed_by": {
      "login": "pandora-s-git",
      "id": 128635000,
      "node_id": "U_kgDOB6rQeA",
      "avatar_url": "https://avatars.githubusercontent.com/u/128635000?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pandora-s-git",
      "html_url": "https://github.com/pandora-s-git",
      "followers_url": "https://api.github.com/users/pandora-s-git/followers",
      "following_url": "https://api.github.com/users/pandora-s-git/following{/other_user}",
      "gists_url": "https://api.github.com/users/pandora-s-git/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pandora-s-git/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pandora-s-git/subscriptions",
      "organizations_url": "https://api.github.com/users/pandora-s-git/orgs",
      "repos_url": "https://api.github.com/users/pandora-s-git/repos",
      "events_url": "https://api.github.com/users/pandora-s-git/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pandora-s-git/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/174/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/174/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/173",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/173/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/173/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/173/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/173",
    "id": 2336819241,
    "node_id": "PR_kwDOKY_97s5xmriQ",
    "number": 173,
    "title": "fix: typo in LoRALoaderMixin: correct \"multipe\" to \"multiple\"",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-06-05T20:55:56Z",
    "updated_at": "2024-06-06T08:57:22Z",
    "closed_at": "2024-06-06T08:57:22Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/173",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/173",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/173.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/173.patch",
      "merged_at": "2024-06-06T08:57:22Z"
    },
    "body": "Corrected a typographical error in the `_load_lora_state_dict` method of the `LoRALoaderMixin` class. The word \"multipe\" was corrected to \"multiple\" in the assertion message that checks for consistent data types in the LoRA state dictionary.",
    "closed_by": {
      "login": "pandora-s-git",
      "id": 128635000,
      "node_id": "U_kgDOB6rQeA",
      "avatar_url": "https://avatars.githubusercontent.com/u/128635000?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pandora-s-git",
      "html_url": "https://github.com/pandora-s-git",
      "followers_url": "https://api.github.com/users/pandora-s-git/followers",
      "following_url": "https://api.github.com/users/pandora-s-git/following{/other_user}",
      "gists_url": "https://api.github.com/users/pandora-s-git/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pandora-s-git/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pandora-s-git/subscriptions",
      "organizations_url": "https://api.github.com/users/pandora-s-git/orgs",
      "repos_url": "https://api.github.com/users/pandora-s-git/repos",
      "events_url": "https://api.github.com/users/pandora-s-git/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pandora-s-git/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/173/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/173/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/172",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/172/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/172/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/172/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/172",
    "id": 2334458140,
    "node_id": "PR_kwDOKY_97s5xeh26",
    "number": 172,
    "title": "Fix: typo in error message for state_dict validation",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-06-04T22:12:36Z",
    "updated_at": "2024-06-06T10:12:27Z",
    "closed_at": "2024-06-06T10:12:27Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/172",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/172",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/172.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/172.patch",
      "merged_at": "2024-06-06T10:12:27Z"
    },
    "body": "Corrected a typo in the error message within the _load_lora_state_dict method of the LoRALoaderMixin class. The word \"multipe\" was changed to \"multiple\" to ensure clarity and accuracy in error reporting. This change improves the readability and professionalism of the codebase.",
    "closed_by": {
      "login": "pandora-s-git",
      "id": 128635000,
      "node_id": "U_kgDOB6rQeA",
      "avatar_url": "https://avatars.githubusercontent.com/u/128635000?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pandora-s-git",
      "html_url": "https://github.com/pandora-s-git",
      "followers_url": "https://api.github.com/users/pandora-s-git/followers",
      "following_url": "https://api.github.com/users/pandora-s-git/following{/other_user}",
      "gists_url": "https://api.github.com/users/pandora-s-git/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pandora-s-git/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pandora-s-git/subscriptions",
      "organizations_url": "https://api.github.com/users/pandora-s-git/orgs",
      "repos_url": "https://api.github.com/users/pandora-s-git/repos",
      "events_url": "https://api.github.com/users/pandora-s-git/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pandora-s-git/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/172/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/172/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/171",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/171/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/171/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/171/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/171",
    "id": 2334357771,
    "node_id": "PR_kwDOKY_97s5xeLqN",
    "number": 171,
    "title": "fix: Correct misspelling in ModelArgs docstring",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-06-04T20:58:19Z",
    "updated_at": "2024-06-06T10:14:46Z",
    "closed_at": "2024-06-06T10:14:46Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/171",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/171",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/171.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/171.patch",
      "merged_at": "2024-06-06T10:14:46Z"
    },
    "body": "- Fixed the misspelling of \"inferred\" in the ModelArgs docstring.\r\n- Changed \"infered\" to \"inferred\" to maintain proper spelling and clarity in the documentation.",
    "closed_by": {
      "login": "pandora-s-git",
      "id": 128635000,
      "node_id": "U_kgDOB6rQeA",
      "avatar_url": "https://avatars.githubusercontent.com/u/128635000?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pandora-s-git",
      "html_url": "https://github.com/pandora-s-git",
      "followers_url": "https://api.github.com/users/pandora-s-git/followers",
      "following_url": "https://api.github.com/users/pandora-s-git/following{/other_user}",
      "gists_url": "https://api.github.com/users/pandora-s-git/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pandora-s-git/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pandora-s-git/subscriptions",
      "organizations_url": "https://api.github.com/users/pandora-s-git/orgs",
      "repos_url": "https://api.github.com/users/pandora-s-git/repos",
      "events_url": "https://api.github.com/users/pandora-s-git/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pandora-s-git/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/171/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/171/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/170",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/170/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/170/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/170/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/170",
    "id": 2333665660,
    "node_id": "PR_kwDOKY_97s5xb0c3",
    "number": 170,
    "title": "Fix: grammar in installation instructions",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-06-04T14:17:49Z",
    "updated_at": "2024-06-04T14:17:49Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/170",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/170",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/170.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/170.patch",
      "merged_at": null
    },
    "body": "- Changed \"You will *use* a GPU to install\" to \"You will *need* a GPU to install\" for clarity.\r\n  - Justification: \"Need\" clearly indicates a requirement, improving user guidance.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/170/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/170/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/169",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/169/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/169/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/169/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/169",
    "id": 2329042880,
    "node_id": "I_kwDOKY_97s6K0l_A",
    "number": 169,
    "title": "speed up inference?",
    "user": {
      "login": "xxyp",
      "id": 25759236,
      "node_id": "MDQ6VXNlcjI1NzU5MjM2",
      "avatar_url": "https://avatars.githubusercontent.com/u/25759236?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/xxyp",
      "html_url": "https://github.com/xxyp",
      "followers_url": "https://api.github.com/users/xxyp/followers",
      "following_url": "https://api.github.com/users/xxyp/following{/other_user}",
      "gists_url": "https://api.github.com/users/xxyp/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/xxyp/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/xxyp/subscriptions",
      "organizations_url": "https://api.github.com/users/xxyp/orgs",
      "repos_url": "https://api.github.com/users/xxyp/repos",
      "events_url": "https://api.github.com/users/xxyp/events{/privacy}",
      "received_events_url": "https://api.github.com/users/xxyp/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-06-01T09:45:16Z",
    "updated_at": "2025-04-07T06:01:47Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "employing Codestral-22B-v0.1 by Mistral-inference, the speed seems slow.  there any methods to speed up the inference ?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/169/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/169/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/168",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/168/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/168/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/168/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/168",
    "id": 2325799854,
    "node_id": "PR_kwDOKY_97s5xBLn0",
    "number": 168,
    "title": "Update README.md",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-05-30T14:17:53Z",
    "updated_at": "2024-06-06T13:16:41Z",
    "closed_at": "2024-06-06T13:16:41Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/168",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/168",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/168.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/168.patch",
      "merged_at": "2024-06-06T13:16:41Z"
    },
    "body": "Updated codestral with new tokenizer, hence new checksum",
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/168/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/168/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/167",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/167/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/167/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/167/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/167",
    "id": 2325790065,
    "node_id": "PR_kwDOKY_97s5xBJfP",
    "number": 167,
    "title": "fix: Correct typo in classifier.ipynb from \"alborithm\" to \"algorithm\"",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-05-30T14:13:04Z",
    "updated_at": "2024-06-06T09:03:07Z",
    "closed_at": "2024-06-06T09:03:07Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/167",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/167",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/167.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/167.patch",
      "merged_at": "2024-06-06T09:03:07Z"
    },
    "body": "Corrected a typo in the markdown cell of the file classifier.ipynb where \"alborithm\" was incorrectly spelled. The correct term is \"algorithm\".",
    "closed_by": {
      "login": "pandora-s-git",
      "id": 128635000,
      "node_id": "U_kgDOB6rQeA",
      "avatar_url": "https://avatars.githubusercontent.com/u/128635000?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pandora-s-git",
      "html_url": "https://github.com/pandora-s-git",
      "followers_url": "https://api.github.com/users/pandora-s-git/followers",
      "following_url": "https://api.github.com/users/pandora-s-git/following{/other_user}",
      "gists_url": "https://api.github.com/users/pandora-s-git/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pandora-s-git/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pandora-s-git/subscriptions",
      "organizations_url": "https://api.github.com/users/pandora-s-git/orgs",
      "repos_url": "https://api.github.com/users/pandora-s-git/repos",
      "events_url": "https://api.github.com/users/pandora-s-git/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pandora-s-git/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/167/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/167/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/166",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/166/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/166/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/166/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/166",
    "id": 2324438357,
    "node_id": "PR_kwDOKY_97s5w8gLI",
    "number": 166,
    "title": "fix(README.md): correct verb agreement in model support statement",
    "user": {
      "login": "CharlesCNorton",
      "id": 135471798,
      "node_id": "U_kgDOCBMitg",
      "avatar_url": "https://avatars.githubusercontent.com/u/135471798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CharlesCNorton",
      "html_url": "https://github.com/CharlesCNorton",
      "followers_url": "https://api.github.com/users/CharlesCNorton/followers",
      "following_url": "https://api.github.com/users/CharlesCNorton/following{/other_user}",
      "gists_url": "https://api.github.com/users/CharlesCNorton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CharlesCNorton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CharlesCNorton/subscriptions",
      "organizations_url": "https://api.github.com/users/CharlesCNorton/orgs",
      "repos_url": "https://api.github.com/users/CharlesCNorton/repos",
      "events_url": "https://api.github.com/users/CharlesCNorton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CharlesCNorton/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-05-30T00:32:24Z",
    "updated_at": "2024-05-30T00:32:24Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/166",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/166",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/166.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/166.patch",
      "merged_at": null
    },
    "body": "Corrected \"supports\" to \"support\" in the sentence \"All of the listed models above supports function calling.\" This change ensures subject-verb agreement, as the subject \"All of the listed models\" is plural and requires the plural form of the verb \"support.\"",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/166/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/166/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/165",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/165/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/165/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/165/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/165",
    "id": 2323484758,
    "node_id": "PR_kwDOKY_97s5w5PBu",
    "number": 165,
    "title": "Update README.md",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-05-29T14:30:31Z",
    "updated_at": "2024-05-29T14:33:10Z",
    "closed_at": "2024-05-29T14:33:10Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/165",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/165",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/165.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/165.patch",
      "merged_at": "2024-05-29T14:33:10Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/165/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/165/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/164",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/164/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/164/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/164/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/164",
    "id": 2323359872,
    "node_id": "PR_kwDOKY_97s5w4zgB",
    "number": 164,
    "title": "Add codestral",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-05-29T13:36:47Z",
    "updated_at": "2024-05-29T14:29:11Z",
    "closed_at": "2024-05-29T14:29:11Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/164",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/164",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/164.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/164.patch",
      "merged_at": "2024-05-29T14:29:10Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/164/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/164/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/163",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/163/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/163/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/163/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/163",
    "id": 2320116424,
    "node_id": "I_kwDOKY_97s6KSirI",
    "number": 163,
    "title": "Using base model on GPU with no bfloat16",
    "user": {
      "login": "yichen0104",
      "id": 17027292,
      "node_id": "MDQ6VXNlcjE3MDI3Mjky",
      "avatar_url": "https://avatars.githubusercontent.com/u/17027292?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/yichen0104",
      "html_url": "https://github.com/yichen0104",
      "followers_url": "https://api.github.com/users/yichen0104/followers",
      "following_url": "https://api.github.com/users/yichen0104/following{/other_user}",
      "gists_url": "https://api.github.com/users/yichen0104/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/yichen0104/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/yichen0104/subscriptions",
      "organizations_url": "https://api.github.com/users/yichen0104/orgs",
      "repos_url": "https://api.github.com/users/yichen0104/repos",
      "events_url": "https://api.github.com/users/yichen0104/events{/privacy}",
      "received_events_url": "https://api.github.com/users/yichen0104/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-05-28T04:51:12Z",
    "updated_at": "2024-05-29T20:06:43Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi. I'm trying to run mistral-7B-v0.1 model using mistral-inference with a Nvidia Tesla V100 32GB GPU. Considering that my GPU doesn't have bfloat support, I would like to know if it is possible to configure the runtime code to run under fp16 mode, or it will raise an error identical to that in Issue [#160](https://github.com/mistralai/mistral-inference/issues/160). I've tried both mistral-demo and the sample Python code in README and yielded the same error. Thanks in advance.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/163/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/163/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/162",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/162/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/162/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/162/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/162",
    "id": 2319257353,
    "node_id": "I_kwDOKY_97s6KPQ8J",
    "number": 162,
    "title": "Tokenizer skips the special tokens while decoding",
    "user": {
      "login": "anandsarth",
      "id": 141149346,
      "node_id": "U_kgDOCGnEog",
      "avatar_url": "https://avatars.githubusercontent.com/u/141149346?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/anandsarth",
      "html_url": "https://github.com/anandsarth",
      "followers_url": "https://api.github.com/users/anandsarth/followers",
      "following_url": "https://api.github.com/users/anandsarth/following{/other_user}",
      "gists_url": "https://api.github.com/users/anandsarth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/anandsarth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/anandsarth/subscriptions",
      "organizations_url": "https://api.github.com/users/anandsarth/orgs",
      "repos_url": "https://api.github.com/users/anandsarth/repos",
      "events_url": "https://api.github.com/users/anandsarth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/anandsarth/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-05-27T14:09:00Z",
    "updated_at": "2024-07-17T08:15:49Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Now the mistral-7B-v3 has the tool support there are special tokens like [TOOL_CALL] [TOOL_RESULT]. But when I decode the output from the results the special tokens are not present and there is no argument while decode like in huggingface for ```skip_speical_tokens=False``` Therefore I am not about to know if the output is tool call or standard response. How can I decode the response from the output tokens\r\n\r\n```\r\noutput_tokens = [5,1501, 7567,1629,2032,1113] # here token 5 is the special token about the tool call\r\n\r\n#after decoding I get \r\nresult = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens)\r\n\r\n# result [{\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"San Francisco, CA\", \"format\": \"celsius\"}}]\r\n#therefore I can't tell it is tool call\r\n```",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/162/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/162/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/160",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/160/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/160/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/160/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/160",
    "id": 2317008884,
    "node_id": "I_kwDOKY_97s6KGr_0",
    "number": 160,
    "title": "mistral-demo $M7B_DIR issue ",
    "user": {
      "login": "chaima-bd",
      "id": 99513015,
      "node_id": "U_kgDOBe5ytw",
      "avatar_url": "https://avatars.githubusercontent.com/u/99513015?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/chaima-bd",
      "html_url": "https://github.com/chaima-bd",
      "followers_url": "https://api.github.com/users/chaima-bd/followers",
      "following_url": "https://api.github.com/users/chaima-bd/following{/other_user}",
      "gists_url": "https://api.github.com/users/chaima-bd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/chaima-bd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/chaima-bd/subscriptions",
      "organizations_url": "https://api.github.com/users/chaima-bd/orgs",
      "repos_url": "https://api.github.com/users/chaima-bd/repos",
      "events_url": "https://api.github.com/users/chaima-bd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/chaima-bd/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-05-25T13:30:07Z",
    "updated_at": "2024-06-21T17:17:22Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi I am using Google colab and when i run this command \"mistral-demo $M7B_DIR\" I use T4 GPU i got this error any solution for that plz \r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/mistral-demo\", line 8, in <module>\r\n    sys.exit(mistral_demo())\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/main.py\", line 183, in mistral_demo\r\n    fire.Fire(demo)\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 143, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 477, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 693, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/main.py\", line 157, in demo\r\n    generated_tokens, _logprobs = generate(\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/generate.py\", line 49, in generate\r\n    prelogits = model.forward(\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/model.py\", line 314, in forward\r\n    h = self.forward_partial(input_ids, seqlens, cache=cache)\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/model.py\", line 296, in forward_partial\r\n    h = layer(h, freqs_cis, cache_view)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/model.py\", line 188, in forward\r\n    r = self.attention.forward(self.attention_norm(x), freqs_cis, cache)\r\n  File \"/usr/local/lib/python3.10/dist-packages/mistral_inference/model.py\", line 128, in forward\r\n    output = memory_efficient_attention(\r\n  File \"/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/__init__.py\", line 268, in memory_efficient_attention\r\n    return _memory_efficient_attention(\r\n  File \"/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/__init__.py\", line 387, in _memory_efficient_attention\r\n    return _memory_efficient_attention_forward(\r\n  File \"/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/__init__.py\", line 403, in _memory_efficient_attention_forward\r\n    op = _dispatch_fw(inp, False)\r\n  File \"/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/dispatch.py\", line 125, in _dispatch_fw\r\n    return _run_priority_list(\r\n  File \"/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/dispatch.py\", line 65, in _run_priority_list\r\n    raise NotImplementedError(msg)\r\nNotImplementedError: No operator found for `memory_efficient_attention_forward` with inputs:\r\n     query       : shape=(1, 28, 32, 128) (torch.bfloat16)\r\n     key         : shape=(1, 28, 32, 128) (torch.bfloat16)\r\n     value       : shape=(1, 28, 32, 128) (torch.bfloat16)\r\n     attn_bias   : <class 'xformers.ops.fmha.attn_bias.BlockDiagonalCausalLocalAttentionMask'>\r\n     p           : 0.0\r\n`decoderF` is not supported because:\r\n    attn_bias type is <class 'xformers.ops.fmha.attn_bias.BlockDiagonalCausalLocalAttentionMask'>\r\n    bf16 is only supported on A100+ GPUs\r\n`flshattF@v2.5.6` is not supported because:\r\n    requires device with capability > (8, 0) but your GPU has capability (7, 5) (too old)\r\n    bf16 is only supported on A100+ GPUs\r\n`cutlassF` is not supported because:\r\n    bf16 is only supported on A100+ GPUs\r\n`smallkF` is not supported because:\r\n    max(query.shape[-1] != value.shape[-1]) > 32\r\n    dtype=torch.bfloat16 (supported: {torch.float32})\r\n    attn_bias type is <class 'xformers.ops.fmha.attn_bias.BlockDiagonalCausalLocalAttentionMask'>\r\n    bf16 is only supported on A100+ GPUs\r\n    unsupported embed per head: 128\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/160/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/160/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/159",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/159/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/159/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/159/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/159",
    "id": 2315947163,
    "node_id": "PR_kwDOKY_97s5wfpMB",
    "number": 159,
    "title": "Add LoRA",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-05-24T17:59:08Z",
    "updated_at": "2024-05-24T18:09:18Z",
    "closed_at": "2024-05-24T18:09:18Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/159",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/159",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/159.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/159.patch",
      "merged_at": "2024-05-24T18:09:17Z"
    },
    "body": null,
    "closed_by": {
      "login": "pierrestock",
      "id": 9300642,
      "node_id": "MDQ6VXNlcjkzMDA2NDI=",
      "avatar_url": "https://avatars.githubusercontent.com/u/9300642?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pierrestock",
      "html_url": "https://github.com/pierrestock",
      "followers_url": "https://api.github.com/users/pierrestock/followers",
      "following_url": "https://api.github.com/users/pierrestock/following{/other_user}",
      "gists_url": "https://api.github.com/users/pierrestock/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pierrestock/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pierrestock/subscriptions",
      "organizations_url": "https://api.github.com/users/pierrestock/orgs",
      "repos_url": "https://api.github.com/users/pierrestock/repos",
      "events_url": "https://api.github.com/users/pierrestock/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pierrestock/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/159/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/159/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/158",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/158/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/158/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/158/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/158",
    "id": 2314799273,
    "node_id": "PR_kwDOKY_97s5wbrtn",
    "number": 158,
    "title": "add a note about GPU requirement",
    "user": {
      "login": "sophiamyang",
      "id": 39501859,
      "node_id": "MDQ6VXNlcjM5NTAxODU5",
      "avatar_url": "https://avatars.githubusercontent.com/u/39501859?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sophiamyang",
      "html_url": "https://github.com/sophiamyang",
      "followers_url": "https://api.github.com/users/sophiamyang/followers",
      "following_url": "https://api.github.com/users/sophiamyang/following{/other_user}",
      "gists_url": "https://api.github.com/users/sophiamyang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sophiamyang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sophiamyang/subscriptions",
      "organizations_url": "https://api.github.com/users/sophiamyang/orgs",
      "repos_url": "https://api.github.com/users/sophiamyang/repos",
      "events_url": "https://api.github.com/users/sophiamyang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sophiamyang/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-05-24T08:41:31Z",
    "updated_at": "2024-05-28T16:22:42Z",
    "closed_at": "2024-05-28T16:22:42Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/158",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/158",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/158.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/158.patch",
      "merged_at": "2024-05-28T16:22:42Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/158/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/158/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/157",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/157/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/157/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/157/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/157",
    "id": 2313704496,
    "node_id": "I_kwDOKY_97s6J6FQw",
    "number": 157,
    "title": "os X pip install fail",
    "user": {
      "login": "edmondja",
      "id": 11833428,
      "node_id": "MDQ6VXNlcjExODMzNDI4",
      "avatar_url": "https://avatars.githubusercontent.com/u/11833428?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/edmondja",
      "html_url": "https://github.com/edmondja",
      "followers_url": "https://api.github.com/users/edmondja/followers",
      "following_url": "https://api.github.com/users/edmondja/following{/other_user}",
      "gists_url": "https://api.github.com/users/edmondja/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/edmondja/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/edmondja/subscriptions",
      "organizations_url": "https://api.github.com/users/edmondja/orgs",
      "repos_url": "https://api.github.com/users/edmondja/repos",
      "events_url": "https://api.github.com/users/edmondja/events{/privacy}",
      "received_events_url": "https://api.github.com/users/edmondja/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-05-23T19:46:49Z",
    "updated_at": "2024-05-23T21:17:10Z",
    "closed_at": "2024-05-23T21:17:10Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "When i try to execute the pip install I have this error on mac os : \r\n```\r\nCollecting mistral-inference\r\n  Using cached mistral_inference-1.0.4-py3-none-any.whl.metadata (8.3 kB)\r\nCollecting fire>=0.6.0 (from mistral-inference)\r\n  Using cached fire-0.6.0-py2.py3-none-any.whl\r\nCollecting mistral_common<2.0.0,>=1.0.0 (from mistral-inference)\r\n  Using cached mistral_common-1.0.2-py3-none-any.whl.metadata (3.5 kB)\r\nRequirement already satisfied: safetensors>=0.4.0 in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from mistral-inference) (0.4.3)\r\nCollecting simple-parsing>=0.1.5 (from mistral-inference)\r\n  Using cached simple_parsing-0.1.5-py3-none-any.whl.metadata (7.7 kB)\r\nCollecting xformers>=0.0.25 (from mistral-inference)\r\n  Using cached xformers-0.0.26.post1.tar.gz (4.1 MB)\r\n  Preparing metadata (setup.py) ... done\r\nRequirement already satisfied: six in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from fire>=0.6.0->mistral-inference) (1.16.0)\r\nRequirement already satisfied: termcolor in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from fire>=0.6.0->mistral-inference) (2.2.0)\r\nCollecting jsonschema==4.21.1 (from mistral_common<2.0.0,>=1.0.0->mistral-inference)\r\n  Using cached jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\r\nCollecting pydantic==2.6.1 (from mistral_common<2.0.0,>=1.0.0->mistral-inference)\r\n  Using cached pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\r\nCollecting sentencepiece==0.1.99 (from mistral_common<2.0.0,>=1.0.0->mistral-inference)\r\n  Using cached sentencepiece-0.1.99-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.7 kB)\r\nCollecting typing-extensions<5.0.0,>=4.11.0 (from mistral_common<2.0.0,>=1.0.0->mistral-inference)\r\n  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\r\nCollecting attrs>=22.2.0 (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.0.0->mistral-inference)\r\n  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\r\nCollecting jsonschema-specifications>=2023.03.6 (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.0.0->mistral-inference)\r\n  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\r\nCollecting referencing>=0.28.4 (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.0.0->mistral-inference)\r\n  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\r\nCollecting rpds-py>=0.7.1 (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.0.0->mistral-inference)\r\n  Using cached rpds_py-0.18.1-cp39-cp39-macosx_10_12_x86_64.whl.metadata (4.1 kB)\r\nCollecting annotated-types>=0.4.0 (from pydantic==2.6.1->mistral_common<2.0.0,>=1.0.0->mistral-inference)\r\n  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\nCollecting pydantic-core==2.16.2 (from pydantic==2.6.1->mistral_common<2.0.0,>=1.0.0->mistral-inference)\r\n  Using cached pydantic_core-2.16.2-cp39-cp39-macosx_10_12_x86_64.whl.metadata (6.5 kB)\r\nCollecting docstring-parser~=0.15 (from simple-parsing>=0.1.5->mistral-inference)\r\n  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\r\nCollecting torch>=2.1 (from xformers>=0.0.25->mistral-inference)\r\n  Using cached torch-2.2.2-cp39-none-macosx_10_9_x86_64.whl.metadata (25 kB)\r\nRequirement already satisfied: numpy in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from xformers>=0.0.25->mistral-inference) (1.22.4)\r\nRequirement already satisfied: filelock in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from torch>=2.1->xformers>=0.0.25->mistral-inference) (3.6.0)\r\nRequirement already satisfied: sympy in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from torch>=2.1->xformers>=0.0.25->mistral-inference) (1.10.1)\r\nRequirement already satisfied: networkx in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from torch>=2.1->xformers>=0.0.25->mistral-inference) (2.7.1)\r\nRequirement already satisfied: jinja2 in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from torch>=2.1->xformers>=0.0.25->mistral-inference) (2.11.3)\r\nRequirement already satisfied: fsspec in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from torch>=2.1->xformers>=0.0.25->mistral-inference) (2024.5.0)\r\nRequirement already satisfied: MarkupSafe>=0.23 in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=2.1->xformers>=0.0.25->mistral-inference) (2.0.1)\r\nRequirement already satisfied: mpmath>=0.19 in /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=2.1->xformers>=0.0.25->mistral-inference) (1.2.1)\r\nUsing cached mistral_inference-1.0.4-py3-none-any.whl (18 kB)\r\nUsing cached mistral_common-1.0.2-py3-none-any.whl (702 kB)\r\nUsing cached jsonschema-4.21.1-py3-none-any.whl (85 kB)\r\nUsing cached pydantic-2.6.1-py3-none-any.whl (394 kB)\r\nUsing cached sentencepiece-0.1.99-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\r\nUsing cached pydantic_core-2.16.2-cp39-cp39-macosx_10_12_x86_64.whl (1.9 MB)\r\nUsing cached simple_parsing-0.1.5-py3-none-any.whl (113 kB)\r\nUsing cached docstring_parser-0.16-py3-none-any.whl (36 kB)\r\nUsing cached torch-2.2.2-cp39-none-macosx_10_9_x86_64.whl (150.8 MB)\r\nUsing cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\r\nUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\nUsing cached attrs-23.2.0-py3-none-any.whl (60 kB)\r\nUsing cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\r\nUsing cached referencing-0.35.1-py3-none-any.whl (26 kB)\r\nUsing cached rpds_py-0.18.1-cp39-cp39-macosx_10_12_x86_64.whl (327 kB)\r\nBuilding wheels for collected packages: xformers\r\n  Building wheel for xformers (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  \u00d7 python setup.py bdist_wheel did not run successfully.\r\n  \u2502 exit code: 1\r\n  \u2570\u2500> [245 lines of output]\r\n      running bdist_wheel\r\n      /Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\r\n        warnings.warn(msg.format('we could not find ninja.'))\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build/lib.macosx-10.9-x86_64-3.9\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers\r\n      copying xformers/_deprecation_warning.py -> build/lib.macosx-10.9-x86_64-3.9/xformers\r\n      copying xformers/attn_bias_utils.py -> build/lib.macosx-10.9-x86_64-3.9/xformers\r\n      copying xformers/checkpoint.py -> build/lib.macosx-10.9-x86_64-3.9/xformers\r\n      copying xformers/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers\r\n      copying xformers/test.py -> build/lib.macosx-10.9-x86_64-3.9/xformers\r\n      copying xformers/utils.py -> build/lib.macosx-10.9-x86_64-3.9/xformers\r\n      copying xformers/_cpp_lib.py -> build/lib.macosx-10.9-x86_64-3.9/xformers\r\n      copying xformers/info.py -> build/lib.macosx-10.9-x86_64-3.9/xformers\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/fused_linear_layer.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/vararg_kernel.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/k_activations.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/k_layer_norm.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/k_fused_matmul_fw.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/dropout.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/k_dropout.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/softmax.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/layer_norm.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/k_fused_matmul_bw.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      copying xformers/triton/k_softmax.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/triton\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/components\r\n      copying xformers/components/simplicial_embedding.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components\r\n      copying xformers/components/residual.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components\r\n      copying xformers/components/reversible.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components\r\n      copying xformers/components/activations.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components\r\n      copying xformers/components/multi_head_dispatch.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components\r\n      copying xformers/components/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components\r\n      copying xformers/components/input_projection.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components\r\n      copying xformers/components/patch_embedding.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_mem_eff_attention.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_indexing.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_mlp.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_blocksparse_transformers.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_transformer.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_revnet.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_swiglu.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_triton_layernorm.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_causal_blocksparse.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_triton_fused_linear.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_tiled_matmul.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_triton_blocksparse.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_triton_softmax.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/utils.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_triton_dropout.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_nystrom_utils.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_attn_decoding.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_multi_head_dispatch.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_sequence_parallel_fused.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_sddmm.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_sp24.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      copying xformers/benchmarks/benchmark_core.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/rmsnorm.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/modpar_layers.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/swiglu_op.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/unbind.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/rope_padded.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/seqpar.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/ipc.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/sequence_parallel_fused_ops.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/sp24.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/common.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/differentiable_collectives.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/tiled_matmul.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      copying xformers/ops/indexing.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/profiler\r\n      copying xformers/profiler/device_limits.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/profiler\r\n      copying xformers/profiler/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/profiler\r\n      copying xformers/profiler/profiler_dcgm_impl.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/profiler\r\n      copying xformers/profiler/profiler_dcgm.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/profiler\r\n      copying xformers/profiler/api.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/profiler\r\n      copying xformers/profiler/slow_ops_profiler.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/profiler\r\n      copying xformers/profiler/profiler.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/profiler\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/sparse\r\n      copying xformers/sparse/_csr_ops.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/sparse\r\n      copying xformers/sparse/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/sparse\r\n      copying xformers/sparse/utils.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/sparse\r\n      copying xformers/sparse/blocksparse_tensor.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/sparse\r\n      copying xformers/sparse/csr_tensor.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/sparse\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/helpers\r\n      copying xformers/helpers/test_utils.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/helpers\r\n      copying xformers/helpers/hierarchical_configs.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/helpers\r\n      copying xformers/helpers/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/helpers\r\n      copying xformers/helpers/timm_sparse_attention.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/helpers\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn\r\n      copying xformers/_flash_attn/fused_softmax.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn\r\n      copying xformers/_flash_attn/flash_blocksparse_attn_interface.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn\r\n      copying xformers/_flash_attn/flash_blocksparse_attention.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn\r\n      copying xformers/_flash_attn/bert_padding.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn\r\n      copying xformers/_flash_attn/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn\r\n      copying xformers/_flash_attn/flash_attn_triton_og.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn\r\n      copying xformers/_flash_attn/flash_attn_triton.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn\r\n      copying xformers/_flash_attn/flash_attn_interface.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/factory\r\n      copying xformers/factory/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/factory\r\n      copying xformers/factory/hydra_helper.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/factory\r\n      copying xformers/factory/block_factory.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/factory\r\n      copying xformers/factory/model_factory.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/factory\r\n      copying xformers/factory/block_configs.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/factory\r\n      copying xformers/factory/weight_init.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/factory\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/global_tokens.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/ortho.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/blocksparse.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/local.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/compositional.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/pooling.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/_sputnik_sparse.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/core.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/lambda_layer.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/random.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/fourier_mix.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/scaled_dot_product.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/utils.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/attention_mask.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/linformer.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/attention_patterns.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/visual.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/sparsity_config.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/nystrom.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/favor.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      copying xformers/components/attention/base.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/components/feedforward\r\n      copying xformers/components/feedforward/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/feedforward\r\n      copying xformers/components/feedforward/mixture_of_experts.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/feedforward\r\n      copying xformers/components/feedforward/mlp.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/feedforward\r\n      copying xformers/components/feedforward/conv_mlp.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/feedforward\r\n      copying xformers/components/feedforward/fused_mlp.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/feedforward\r\n      copying xformers/components/feedforward/base.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/feedforward\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/components/positional_embedding\r\n      copying xformers/components/positional_embedding/vocab.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/positional_embedding\r\n      copying xformers/components/positional_embedding/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/positional_embedding\r\n      copying xformers/components/positional_embedding/param.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/positional_embedding\r\n      copying xformers/components/positional_embedding/sine.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/positional_embedding\r\n      copying xformers/components/positional_embedding/rotary.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/positional_embedding\r\n      copying xformers/components/positional_embedding/base.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/positional_embedding\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention/feature_maps\r\n      copying xformers/components/attention/feature_maps/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention/feature_maps\r\n      copying xformers/components/attention/feature_maps/softmax.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention/feature_maps\r\n      copying xformers/components/attention/feature_maps/base.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/components/attention/feature_maps\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA\r\n      copying xformers/benchmarks/LRA/batch_submit.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA\r\n      copying xformers/benchmarks/LRA/batch_fetch_results.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA\r\n      copying xformers/benchmarks/LRA/run_with_submitit.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA\r\n      copying xformers/benchmarks/LRA/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA\r\n      copying xformers/benchmarks/LRA/run_tasks.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA\r\n      copying xformers/benchmarks/LRA/run_grid_search.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA/code\r\n      copying xformers/benchmarks/LRA/code/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA/code\r\n      copying xformers/benchmarks/LRA/code/model_wrapper.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA/code\r\n      copying xformers/benchmarks/LRA/code/dataset.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/benchmarks/LRA/code\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/ops/_triton\r\n      copying xformers/ops/_triton/k_scaled_index_add.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/_triton\r\n      copying xformers/ops/_triton/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/_triton\r\n      copying xformers/ops/_triton/rope_padded_kernels.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/_triton\r\n      copying xformers/ops/_triton/sequence_parallel_fused_kernels.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/_triton\r\n      copying xformers/ops/_triton/tiled_matmul_kernels.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/_triton\r\n      copying xformers/ops/_triton/k_index_select_cat.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/_triton\r\n      copying xformers/ops/_triton/rmsnorm_kernels.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/_triton\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/decoder.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/dispatch.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/attn_bias.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/ck.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/common.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/ck_decoder.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/flash.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/small_k.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/cutlass.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/ck_splitk.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      copying xformers/ops/fmha/triton_splitk.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/ops/fmha\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/losses\r\n      copying xformers/_flash_attn/losses/cross_entropy.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/losses\r\n      copying xformers/_flash_attn/losses/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/losses\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/layers\r\n      copying xformers/_flash_attn/layers/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/layers\r\n      copying xformers/_flash_attn/layers/patch_embed.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/layers\r\n      copying xformers/_flash_attn/layers/rotary.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/layers\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/utils\r\n      copying xformers/_flash_attn/utils/pretrained.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/utils\r\n      copying xformers/_flash_attn/utils/generation.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/utils\r\n      copying xformers/_flash_attn/utils/benchmark.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/utils\r\n      copying xformers/_flash_attn/utils/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/utils\r\n      copying xformers/_flash_attn/utils/distributed.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/utils\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/bigcode.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/gptj.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/opt.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/llama.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/vit.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/btlm.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/baichuan.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/bert.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/falcon.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/gpt_neox.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      copying xformers/_flash_attn/models/gpt.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/models\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops\r\n      copying xformers/_flash_attn/ops/activations.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops\r\n      copying xformers/_flash_attn/ops/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops\r\n      copying xformers/_flash_attn/ops/fused_dense.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops\r\n      copying xformers/_flash_attn/ops/rms_norm.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops\r\n      copying xformers/_flash_attn/ops/layer_norm.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/modules\r\n      copying xformers/_flash_attn/modules/embedding.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/modules\r\n      copying xformers/_flash_attn/modules/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/modules\r\n      copying xformers/_flash_attn/modules/mlp.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/modules\r\n      copying xformers/_flash_attn/modules/block.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/modules\r\n      copying xformers/_flash_attn/modules/mha.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/modules\r\n      creating build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops/triton\r\n      copying xformers/_flash_attn/ops/triton/cross_entropy.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops/triton\r\n      copying xformers/_flash_attn/ops/triton/linear.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops/triton\r\n      copying xformers/_flash_attn/ops/triton/k_activations.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops/triton\r\n      copying xformers/_flash_attn/ops/triton/__init__.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops/triton\r\n      copying xformers/_flash_attn/ops/triton/mlp.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops/triton\r\n      copying xformers/_flash_attn/ops/triton/rotary.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops/triton\r\n      copying xformers/_flash_attn/ops/triton/layer_norm.py -> build/lib.macosx-10.9-x86_64-3.9/xformers/_flash_attn/ops/triton\r\n      running build_ext\r\n      building 'xformers._C' extension\r\n      creating build/temp.macosx-10.9-x86_64-3.9\r\n      creating build/temp.macosx-10.9-x86_64-3.9/xformers\r\n      creating build/temp.macosx-10.9-x86_64-3.9/xformers/csrc\r\n      creating build/temp.macosx-10.9-x86_64-3.9/xformers/csrc/attention\r\n      creating build/temp.macosx-10.9-x86_64-3.9/xformers/csrc/attention/autograd\r\n      creating build/temp.macosx-10.9-x86_64-3.9/xformers/csrc/attention/cpu\r\n      creating build/temp.macosx-10.9-x86_64-3.9/xformers/csrc/sequence_parallel_fused\r\n      creating build/temp.macosx-10.9-x86_64-3.9/xformers/csrc/sparse24\r\n      creating build/temp.macosx-10.9-x86_64-3.9/xformers/csrc/swiglu\r\n      clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/edmondjacoupeau/opt/anaconda3/include -arch x86_64 -I/Users/edmondjacoupeau/opt/anaconda3/include -fPIC -O2 -isystem /Users/edmondjacoupeau/opt/anaconda3/include -arch x86_64 -I/private/var/folders/vq/_stcpmys7n984r7gy0pm4_g40000gn/T/pip-install-5a1st423/xformers_2dfbd8981dda4983b6e310b34d15d5e6/xformers/csrc -I/Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages/torch/include -I/Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages/torch/include/TH -I/Users/edmondjacoupeau/opt/anaconda3/lib/python3.9/site-packages/torch/include/THC -I/Users/edmondjacoupeau/opt/anaconda3/include/python3.9 -c xformers/csrc/attention/attention.cpp -o build/temp.macosx-10.9-x86_64-3.9/xformers/csrc/attention/attention.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n      clang: error: unsupported option '-fopenmp'\r\n      error: command '/usr/bin/clang' failed with exit code 1\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for xformers\r\n  Running setup.py clean for xformers\r\nFailed to build xformers\r\nERROR: Could not build wheels for xformers, which is required to install pyproject.toml-based projects\r\n\r\nClick to add a cell.\r\n```",
    "closed_by": {
      "login": "edmondja",
      "id": 11833428,
      "node_id": "MDQ6VXNlcjExODMzNDI4",
      "avatar_url": "https://avatars.githubusercontent.com/u/11833428?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/edmondja",
      "html_url": "https://github.com/edmondja",
      "followers_url": "https://api.github.com/users/edmondja/followers",
      "following_url": "https://api.github.com/users/edmondja/following{/other_user}",
      "gists_url": "https://api.github.com/users/edmondja/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/edmondja/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/edmondja/subscriptions",
      "organizations_url": "https://api.github.com/users/edmondja/orgs",
      "repos_url": "https://api.github.com/users/edmondja/repos",
      "events_url": "https://api.github.com/users/edmondja/events{/privacy}",
      "received_events_url": "https://api.github.com/users/edmondja/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/157/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/157/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/156",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/156/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/156/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/156/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/156",
    "id": 2313229276,
    "node_id": "I_kwDOKY_97s6J4RPc",
    "number": 156,
    "title": "License ",
    "user": {
      "login": "fakerybakery",
      "id": 76186054,
      "node_id": "MDQ6VXNlcjc2MTg2MDU0",
      "avatar_url": "https://avatars.githubusercontent.com/u/76186054?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/fakerybakery",
      "html_url": "https://github.com/fakerybakery",
      "followers_url": "https://api.github.com/users/fakerybakery/followers",
      "following_url": "https://api.github.com/users/fakerybakery/following{/other_user}",
      "gists_url": "https://api.github.com/users/fakerybakery/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/fakerybakery/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/fakerybakery/subscriptions",
      "organizations_url": "https://api.github.com/users/fakerybakery/orgs",
      "repos_url": "https://api.github.com/users/fakerybakery/repos",
      "events_url": "https://api.github.com/users/fakerybakery/events{/privacy}",
      "received_events_url": "https://api.github.com/users/fakerybakery/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-05-23T15:33:45Z",
    "updated_at": "2024-05-24T21:17:51Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi, thanks for releasing the Mistral models! Can we get a confirmation that 7B v0.2 base and 8x22B v0.3 are both licensed under Apache?\r\nThanks!",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/156/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/156/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/155",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/155/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/155/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/155/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/155",
    "id": 2311653103,
    "node_id": "PR_kwDOKY_97s5wQ626",
    "number": 155,
    "title": "fixe  for issue https://github.com/mistralai/mistral-inference/issues\u2026",
    "user": {
      "login": "sachinsshetty",
      "id": 26170834,
      "node_id": "MDQ6VXNlcjI2MTcwODM0",
      "avatar_url": "https://avatars.githubusercontent.com/u/26170834?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sachinsshetty",
      "html_url": "https://github.com/sachinsshetty",
      "followers_url": "https://api.github.com/users/sachinsshetty/followers",
      "following_url": "https://api.github.com/users/sachinsshetty/following{/other_user}",
      "gists_url": "https://api.github.com/users/sachinsshetty/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sachinsshetty/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sachinsshetty/subscriptions",
      "organizations_url": "https://api.github.com/users/sachinsshetty/orgs",
      "repos_url": "https://api.github.com/users/sachinsshetty/repos",
      "events_url": "https://api.github.com/users/sachinsshetty/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sachinsshetty/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-05-22T23:22:05Z",
    "updated_at": "2024-05-23T07:07:26Z",
    "closed_at": "2024-05-23T07:07:25Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/155",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/155",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/155.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/155.patch",
      "merged_at": "2024-05-23T07:07:25Z"
    },
    "body": "Issue with creation of folder with numeric character at the start.",
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/155/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/155/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/154",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/154/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/154/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/154/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/154",
    "id": 2311137616,
    "node_id": "I_kwDOKY_97s6JwSlQ",
    "number": 154,
    "title": "!mistral-demo $7B_DIR issue ",
    "user": {
      "login": "shaimaa0000",
      "id": 170560494,
      "node_id": "U_kgDOCiqL7g",
      "avatar_url": "https://avatars.githubusercontent.com/u/170560494?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shaimaa0000",
      "html_url": "https://github.com/shaimaa0000",
      "followers_url": "https://api.github.com/users/shaimaa0000/followers",
      "following_url": "https://api.github.com/users/shaimaa0000/following{/other_user}",
      "gists_url": "https://api.github.com/users/shaimaa0000/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shaimaa0000/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shaimaa0000/subscriptions",
      "organizations_url": "https://api.github.com/users/shaimaa0000/orgs",
      "repos_url": "https://api.github.com/users/shaimaa0000/repos",
      "events_url": "https://api.github.com/users/shaimaa0000/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shaimaa0000/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2024-05-22T17:45:59Z",
    "updated_at": "2024-06-21T17:17:51Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi , \r\nWhen I try to run this command '!mistral-demo $7B_DIR', I encounter an issue related to the GPU. Could you please suggest a solution? I am using Google Colab\r\n\r\n![issue pic ](https://github.com/mistralai/mistral-inference/assets/170560494/bffb1c43-1974-49d6-bb1f-b7824dea5d37)\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/154/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/154/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/153",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/153/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/153/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/153/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/153",
    "id": 2311045805,
    "node_id": "PR_kwDOKY_97s5wOz4g",
    "number": 153,
    "title": "example cleanup",
    "user": {
      "login": "sophiamyang",
      "id": 39501859,
      "node_id": "MDQ6VXNlcjM5NTAxODU5",
      "avatar_url": "https://avatars.githubusercontent.com/u/39501859?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sophiamyang",
      "html_url": "https://github.com/sophiamyang",
      "followers_url": "https://api.github.com/users/sophiamyang/followers",
      "following_url": "https://api.github.com/users/sophiamyang/following{/other_user}",
      "gists_url": "https://api.github.com/users/sophiamyang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sophiamyang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sophiamyang/subscriptions",
      "organizations_url": "https://api.github.com/users/sophiamyang/orgs",
      "repos_url": "https://api.github.com/users/sophiamyang/repos",
      "events_url": "https://api.github.com/users/sophiamyang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sophiamyang/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-05-22T16:57:06Z",
    "updated_at": "2024-05-22T16:57:27Z",
    "closed_at": "2024-05-22T16:57:24Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/153",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/153",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/153.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/153.patch",
      "merged_at": "2024-05-22T16:57:23Z"
    },
    "body": null,
    "closed_by": {
      "login": "sophiamyang",
      "id": 39501859,
      "node_id": "MDQ6VXNlcjM5NTAxODU5",
      "avatar_url": "https://avatars.githubusercontent.com/u/39501859?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sophiamyang",
      "html_url": "https://github.com/sophiamyang",
      "followers_url": "https://api.github.com/users/sophiamyang/followers",
      "following_url": "https://api.github.com/users/sophiamyang/following{/other_user}",
      "gists_url": "https://api.github.com/users/sophiamyang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sophiamyang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sophiamyang/subscriptions",
      "organizations_url": "https://api.github.com/users/sophiamyang/orgs",
      "repos_url": "https://api.github.com/users/sophiamyang/repos",
      "events_url": "https://api.github.com/users/sophiamyang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sophiamyang/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/153/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/153/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/152",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/152/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/152/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/152/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/152",
    "id": 2310941837,
    "node_id": "PR_kwDOKY_97s5wOcO5",
    "number": 152,
    "title": "Change to mistral-inference",
    "user": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-05-22T16:15:15Z",
    "updated_at": "2024-05-22T16:15:26Z",
    "closed_at": "2024-05-22T16:15:26Z",
    "author_association": "COLLABORATOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/152",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/152",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/152.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/152.patch",
      "merged_at": "2024-05-22T16:15:25Z"
    },
    "body": null,
    "closed_by": {
      "login": "patrickvonplaten",
      "id": 23423619,
      "node_id": "MDQ6VXNlcjIzNDIzNjE5",
      "avatar_url": "https://avatars.githubusercontent.com/u/23423619?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/patrickvonplaten",
      "html_url": "https://github.com/patrickvonplaten",
      "followers_url": "https://api.github.com/users/patrickvonplaten/followers",
      "following_url": "https://api.github.com/users/patrickvonplaten/following{/other_user}",
      "gists_url": "https://api.github.com/users/patrickvonplaten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/patrickvonplaten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/patrickvonplaten/subscriptions",
      "organizations_url": "https://api.github.com/users/patrickvonplaten/orgs",
      "repos_url": "https://api.github.com/users/patrickvonplaten/repos",
      "events_url": "https://api.github.com/users/patrickvonplaten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/patrickvonplaten/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/152/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/152/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/151",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/151/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/151/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/151/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/151",
    "id": 2296793523,
    "node_id": "I_kwDOKY_97s6I5kmz",
    "number": 151,
    "title": "num of training tokens?",
    "user": {
      "login": "wgwang",
      "id": 844678,
      "node_id": "MDQ6VXNlcjg0NDY3OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/844678?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/wgwang",
      "html_url": "https://github.com/wgwang",
      "followers_url": "https://api.github.com/users/wgwang/followers",
      "following_url": "https://api.github.com/users/wgwang/following{/other_user}",
      "gists_url": "https://api.github.com/users/wgwang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/wgwang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/wgwang/subscriptions",
      "organizations_url": "https://api.github.com/users/wgwang/orgs",
      "repos_url": "https://api.github.com/users/wgwang/repos",
      "events_url": "https://api.github.com/users/wgwang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/wgwang/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-05-15T03:38:14Z",
    "updated_at": "2024-05-15T03:38:14Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "What's the number of the training tokens for Mistral 8X22B and 8X7B?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/151/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/151/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/150",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/150/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/150/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/150/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/150",
    "id": 2280861851,
    "node_id": "I_kwDOKY_97s6H8zCb",
    "number": 150,
    "title": "PAD token missing ?",
    "user": {
      "login": "omkar-12bits",
      "id": 121623449,
      "node_id": "U_kgDOBz_TmQ",
      "avatar_url": "https://avatars.githubusercontent.com/u/121623449?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/omkar-12bits",
      "html_url": "https://github.com/omkar-12bits",
      "followers_url": "https://api.github.com/users/omkar-12bits/followers",
      "following_url": "https://api.github.com/users/omkar-12bits/following{/other_user}",
      "gists_url": "https://api.github.com/users/omkar-12bits/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/omkar-12bits/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/omkar-12bits/subscriptions",
      "organizations_url": "https://api.github.com/users/omkar-12bits/orgs",
      "repos_url": "https://api.github.com/users/omkar-12bits/repos",
      "events_url": "https://api.github.com/users/omkar-12bits/events{/privacy}",
      "received_events_url": "https://api.github.com/users/omkar-12bits/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-05-06T13:16:07Z",
    "updated_at": "2024-05-29T07:37:20Z",
    "closed_at": "2024-05-29T05:59:09Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "i tried using `eos_token` , `unk_token` and `bos_token` with `left` and `right` padding side but whenever the padding tokens size increases the outputs are pure garbage.\r\n",
    "closed_by": {
      "login": "omkar-12bits",
      "id": 121623449,
      "node_id": "U_kgDOBz_TmQ",
      "avatar_url": "https://avatars.githubusercontent.com/u/121623449?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/omkar-12bits",
      "html_url": "https://github.com/omkar-12bits",
      "followers_url": "https://api.github.com/users/omkar-12bits/followers",
      "following_url": "https://api.github.com/users/omkar-12bits/following{/other_user}",
      "gists_url": "https://api.github.com/users/omkar-12bits/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/omkar-12bits/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/omkar-12bits/subscriptions",
      "organizations_url": "https://api.github.com/users/omkar-12bits/orgs",
      "repos_url": "https://api.github.com/users/omkar-12bits/repos",
      "events_url": "https://api.github.com/users/omkar-12bits/events{/privacy}",
      "received_events_url": "https://api.github.com/users/omkar-12bits/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/150/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/150/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/149",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/149/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/149/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/149/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/149",
    "id": 2273460449,
    "node_id": "I_kwDOKY_97s6HgkDh",
    "number": 149,
    "title": "AI generates responses or conversation without any human input",
    "user": {
      "login": "Vishalsub",
      "id": 142519343,
      "node_id": "U_kgDOCH6sLw",
      "avatar_url": "https://avatars.githubusercontent.com/u/142519343?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Vishalsub",
      "html_url": "https://github.com/Vishalsub",
      "followers_url": "https://api.github.com/users/Vishalsub/followers",
      "following_url": "https://api.github.com/users/Vishalsub/following{/other_user}",
      "gists_url": "https://api.github.com/users/Vishalsub/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Vishalsub/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Vishalsub/subscriptions",
      "organizations_url": "https://api.github.com/users/Vishalsub/orgs",
      "repos_url": "https://api.github.com/users/Vishalsub/repos",
      "events_url": "https://api.github.com/users/Vishalsub/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Vishalsub/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-05-01T12:55:24Z",
    "updated_at": "2024-05-01T12:55:24Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "AI generates responses or conversation without any human input, it might indicate a problem with the way input is processed, an unintended loop, or a transcription error.\r\n\r\nHere some convo automate generating:\r\n\r\nI asked what is large hadron collider?\r\n\r\nit gave answer but then human context didn't get by me it created their own\r\n\r\nAI: I believe you're asking about the Large Hadron Collider. It was built and first operated in 2008.\r\nAI: I believe you're asking about the Large Hadron Collider. It was built and first operated in 2008.\r\nHuman: Who was build the collider?\r\nHuman: Who was build the collider?\r\nAI: The Large Hadron Collider was built by an international collaboration of scientists and engineers.\r\nAI: The Large Hadron Collider was built by an international collaboration of scientists and engineers.\r\nHuman: What is the collider used for?\r\nHuman: What is the collider used for?\r\nAI: The Large Hadron Collider is used for particle physics research, including the discovery of the Higgs Boson.\r\nAI: The Large Hadron Collider is used for particle physics research, including the discovery of the Higgs Boson.\r\nHuman: What is the size of the collider?\r\nHuman: What is the size of the collider?\r\nAI: The Large Hadron Collider is 27 kilometers long and 100 meters in diameter.\r\nAI: The Large Hadron Collider is 27 kilometers long and 100 meters in diameter.\r\nHuman: How fast does the collider go?\r\nHuman: How fast does the collider go?\r\nAI: The Large Hadron Collider accelerates particles to nearly the speed of light, around 99.9999991% the speed of light.\r\nAI: The Large Hadron Collider accelerates particles to nearly the speed of light, around 99.9999991% the speed of light.\r\nHuman: What is the cost of the collider?\r\nHuman: What is the cost of the collider?\r\nAI: The total cost of building the Large Hadron Collider is estimated to be around \u20ac10 billion.\r\nAI: The total cost of building the Large Hadron Collider is estimated to be around \u20ac10 billion.\r\nHuman: What is the temperature inside the collider?\r\nHuman: What is the temperature inside the collider?\r\nAI: The temperature inside the Large Hadron Collider is extremely low, around -271.3 degrees Celsius\r\n\r\nHow do I solve this problems. ?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/149/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/149/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/148",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/148/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/148/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/148/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/148",
    "id": 2265258201,
    "node_id": "I_kwDOKY_97s6HBRjZ",
    "number": 148,
    "title": "Did Mistral-7B-Instruct-v0.2 use Sliding Window Attention (SWA)?",
    "user": {
      "login": "matrixssy",
      "id": 55280213,
      "node_id": "MDQ6VXNlcjU1MjgwMjEz",
      "avatar_url": "https://avatars.githubusercontent.com/u/55280213?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/matrixssy",
      "html_url": "https://github.com/matrixssy",
      "followers_url": "https://api.github.com/users/matrixssy/followers",
      "following_url": "https://api.github.com/users/matrixssy/following{/other_user}",
      "gists_url": "https://api.github.com/users/matrixssy/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/matrixssy/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/matrixssy/subscriptions",
      "organizations_url": "https://api.github.com/users/matrixssy/orgs",
      "repos_url": "https://api.github.com/users/matrixssy/repos",
      "events_url": "https://api.github.com/users/matrixssy/events{/privacy}",
      "received_events_url": "https://api.github.com/users/matrixssy/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-04-26T08:33:41Z",
    "updated_at": "2024-06-18T16:18:11Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I have been fine-tuning Mistral-7B-Instruct-v0.2 recently and I noticed that when I don't use SWA and train with a sequence length of 32K, the initial loss is unusually high (6.0). However, when I train with a sequence length of 4096, the loss is normal (1.5). This has led me to suspect that Mistral-7B-Instruct-v0.2 might have been trained with a sliding window of 4096 instead of not using it as officially stated.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/148/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/148/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/147",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/147/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/147/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/147/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/147",
    "id": 2254451807,
    "node_id": "I_kwDOKY_97s6GYDRf",
    "number": 147,
    "title": "Q: Why rotary embedding applied only to queries and keys?",
    "user": {
      "login": "pmgautam",
      "id": 28428143,
      "node_id": "MDQ6VXNlcjI4NDI4MTQz",
      "avatar_url": "https://avatars.githubusercontent.com/u/28428143?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pmgautam",
      "html_url": "https://github.com/pmgautam",
      "followers_url": "https://api.github.com/users/pmgautam/followers",
      "following_url": "https://api.github.com/users/pmgautam/following{/other_user}",
      "gists_url": "https://api.github.com/users/pmgautam/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pmgautam/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pmgautam/subscriptions",
      "organizations_url": "https://api.github.com/users/pmgautam/orgs",
      "repos_url": "https://api.github.com/users/pmgautam/repos",
      "events_url": "https://api.github.com/users/pmgautam/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pmgautam/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-04-20T08:31:48Z",
    "updated_at": "2024-08-28T15:52:25Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "In the codebase, rotary embeddings are applied only to queries and keys but not to values. Can someone point out to reasons/papers behind this design? Thank you in advance!!!\r\n\r\n![image](https://github.com/mistralai/mistral-src/assets/28428143/8bee680f-fcac-47ff-8851-1b31c2b01d35)\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/147/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/147/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/146",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/146/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/146/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/146/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/146",
    "id": 2248584431,
    "node_id": "I_kwDOKY_97s6GBqzv",
    "number": 146,
    "title": "JSON response format failing to retrieve clean JSON ",
    "user": {
      "login": "serferdinand2",
      "id": 93290291,
      "node_id": "U_kgDOBY9_Mw",
      "avatar_url": "https://avatars.githubusercontent.com/u/93290291?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/serferdinand2",
      "html_url": "https://github.com/serferdinand2",
      "followers_url": "https://api.github.com/users/serferdinand2/followers",
      "following_url": "https://api.github.com/users/serferdinand2/following{/other_user}",
      "gists_url": "https://api.github.com/users/serferdinand2/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/serferdinand2/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/serferdinand2/subscriptions",
      "organizations_url": "https://api.github.com/users/serferdinand2/orgs",
      "repos_url": "https://api.github.com/users/serferdinand2/repos",
      "events_url": "https://api.github.com/users/serferdinand2/events{/privacy}",
      "received_events_url": "https://api.github.com/users/serferdinand2/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2024-04-17T15:31:56Z",
    "updated_at": "2024-08-20T13:41:54Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "### Issues\r\n\r\nWhen asking the model to return JSON via responseFormat (or response_format) setting in the request options, sometimes with JSON an additional text is added, usually explaining the JSON that it returned. \r\n\r\n### Reproduction: \r\n\r\nString `userPrompt` is generated dynamically based on the usecase. \r\n\r\n```ts\r\nconst userPrompt = `Given the following Typescript Types: 'interface Question<T extends QuestionType> { title: string; type: T; \r\n\r\n.....  \r\n, your job is to provide structured JSON formatted questions in an array. Create questions for a rating type question survey. Do not include any text in your response except JSON. Do not return Markdown or HTML. Be sure to create not more than 1 questions. Be sure to create at least 1 questions.`\r\n\r\n\r\nmistral = new MistralClient(options.apiKey);\r\nconst chat = await mistral.chat({\r\n\t\tmodel: 'mistral-small,\r\n\t\tmessages: [{ role: 'user', content: userPrompt }],\r\n\t\tresponseFormat: { type: 'json_object' },\r\n\t\ttemperature: temperature,\r\n\t});\r\ndata = JSON.parse(\r\n\t\t\tchat.choices[0].message.content\r\n\t\t) \r\n\t\t\r\nconsole.log(data)\r\n\r\n```\r\n\r\n```log \r\nCompletion:  {\r\n  id: '0ef53d7c6c3a4a5ebbaf43aa96c0f5d9',\r\n  object: 'chat.completion',\r\n  created: 1713366257,\r\n  model: 'mistral-small',\r\n  choices: [\r\n    {\r\n      index: 0,\r\n      message: {\r\n        role: 'assistant',\r\n        content: '[\\n' +\r\n          '{\\n' +\r\n          '\"title\": \"How would you rate your overall satisfaction with our product?\",\\n' +\r\n          '\"type\": \"rating\",\\n' +\r\n          '\"required\": true,\\n' +\r\n          '\"properties\": {\\n' +\r\n          '\"labels\": [\\n' +\r\n          '{\\n' +\r\n          '\"label\": \"Very unsatisfied\",\\n' +\r\n          '\"value\": 1\\n' +\r\n          '},\\n' +\r\n          '{\\n' +\r\n          '\"label\": \"Unsatisfied\",\\n' +\r\n          '\"value\": 2\\n' +\r\n          '},\\n' +\r\n          '{\\n' +\r\n          '\"label\": \"Neutral\",\\n' +\r\n          '\"value\": 3\\n' +\r\n          '},\\n' +\r\n          '{\\n' +\r\n          '\"label\": \"Satisfied\",\\n' +\r\n          '\"value\": 4\\n' +\r\n          '},\\n' +\r\n          '{\\n' +\r\n          '\"label\": \"Very satisfied\",\\n' +\r\n          '\"value\": 5\\n' +\r\n          '}\\n' +\r\n          ']\\n' +\r\n          '}\\n' +\r\n          '}\\n' +\r\n          ']\\n' +\r\n          '\\n' +\r\n          **'This JSON array contains one question of type \"rating\" that asks the customer about their overall satisfaction with the product. The question has 5 labels with corresponding values from 1 to 5, where 1 means \"Very unsatisfied\" and 5 means \"Very satisfied\". The question is required.',**\r\n        tool_calls: null\r\n      },\r\n      finish_reason: 'stop',\r\n      logprobs: null\r\n    }\r\n  ],\r\n  usage: { prompt_tokens: 447, total_tokens: 658, completion_tokens: 211 }\r\n}\r\n```\r\n\r\n### Notes\r\n\r\nThe request header seems to be doing fine: \r\n\r\n```json\r\nrequest {\r\n  model: 'mistral-small',\r\n  messages: [\r\n    {\r\n      role: 'user',\r\n      content: 'Given the following Typescript Types \\\r\n\r\n.......\r\n\r\n\r\nDo not return Markdown or HTML. Be sure to create not more than 1 questions. Be sure to create at least 1 questions.'\r\n    }\r\n  ],\r\n  tools: undefined,\r\n  temperature: 0,\r\n  max_tokens: undefined,\r\n  top_p: undefined,\r\n  random_seed: undefined,\r\n  stream: false,\r\n  safe_prompt: undefined,\r\n  tool_choice: undefined,\r\n  response_format: { type: 'json_object' }\r\n}\r\n```\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/146/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/146/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/145",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/145/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/145/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/145/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/145",
    "id": 2244127166,
    "node_id": "I_kwDOKY_97s6Fwqm-",
    "number": 145,
    "title": "How to use a prompt for text analysis?",
    "user": {
      "login": "rsoika",
      "id": 1339124,
      "node_id": "MDQ6VXNlcjEzMzkxMjQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1339124?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rsoika",
      "html_url": "https://github.com/rsoika",
      "followers_url": "https://api.github.com/users/rsoika/followers",
      "following_url": "https://api.github.com/users/rsoika/following{/other_user}",
      "gists_url": "https://api.github.com/users/rsoika/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rsoika/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rsoika/subscriptions",
      "organizations_url": "https://api.github.com/users/rsoika/orgs",
      "repos_url": "https://api.github.com/users/rsoika/repos",
      "events_url": "https://api.github.com/users/rsoika/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rsoika/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 6,
    "created_at": "2024-04-15T16:33:23Z",
    "updated_at": "2024-05-09T16:18:06Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I am still confused how to use the prompt within `Mistral-7b-instruct` if I want to analyze the content of a text, such as summary or categorization of the context.\r\nSo in my prompt I have a text and an instruction. I want to extract information form the given text. And it is not this often discussed chat-use-case.\r\n\r\nI am currently using the following Prompt Template for my approach:\r\n\r\n```\r\n<s>[INST] My Instruction............\r\n[/INST]\r\nMy Text.......\r\n................\r\n```\r\n\r\nIs this a correct way to build a prompt for text analyses with  `Mistral-7b-instruct`? Or should I separate the context and the instruction in some other way? Note, I also do not use the EOS here. Is this a problem? \r\n\r\nI ask this because the results vary if I put the context before or after the instruction and I did not find a guide line for such a scenario.\r\n\r\nI am also referring to this [official documentation page](https://docs.mistral.ai/getting-started/open_weight_models/#chat-template) which is hard to understand:\r\n\r\n> Note that `<s>` and `</s>` are special tokens for beginning of string (BOS) and end of string (EOS) while `[INST]` and `[/INST]` are regular strings.\r\n\r\nWhat does this sentence mean? What is the difference between a _string_ and a _regular string_?\r\n\r\nThanks for any tips.  \r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/145/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/145/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/144",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/144/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/144/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/144/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/144",
    "id": 2243985456,
    "node_id": "I_kwDOKY_97s6FwIAw",
    "number": 144,
    "title": "Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW",
    "user": {
      "login": "guidoveritone",
      "id": 104149705,
      "node_id": "U_kgDOBjUyyQ",
      "avatar_url": "https://avatars.githubusercontent.com/u/104149705?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/guidoveritone",
      "html_url": "https://github.com/guidoveritone",
      "followers_url": "https://api.github.com/users/guidoveritone/followers",
      "following_url": "https://api.github.com/users/guidoveritone/following{/other_user}",
      "gists_url": "https://api.github.com/users/guidoveritone/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/guidoveritone/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/guidoveritone/subscriptions",
      "organizations_url": "https://api.github.com/users/guidoveritone/orgs",
      "repos_url": "https://api.github.com/users/guidoveritone/repos",
      "events_url": "https://api.github.com/users/guidoveritone/events{/privacy}",
      "received_events_url": "https://api.github.com/users/guidoveritone/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-04-15T15:31:22Z",
    "updated_at": "2024-07-26T17:46:48Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hey guys, i am trying to run the Mistral 7b model using the [guide](https://docs.mistral.ai/self-deployment/vllm/) on the page.\r\n\r\nI am running:\r\n```bash\r\ndocker run --gpus all \\\r\n    -e HF_TOKEN=$HF_TOKEN -p 8000:8000 \\\r\n    ghcr.io/mistralai/mistral-src/vllm:latest \\\r\n    --host 0.0.0.0 \\\r\n    --model mistralai/Mistral-7B-Instruct-v0.2\r\n```\r\nand I am getting the following error:\r\n```bash\r\n\u2514\u2500$ docker run --gpus '\"device=0\"' -e HF_TOKEN=$HF_TOKEN -p 8000:8000 ghcr.io/mistralai/mistral-src/vllm:latest --host 0.0.0.0 --model mistralai/Mistral-7B-Instruct-v0.2\r\nThe HF_TOKEN environment variable set, logging to Hugging Face.\r\nToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\r\nToken is valid (permission: read).\r\nYour token has been saved to /root/.cache/huggingface/token\r\nLogin successful\r\nINFO 04-15 15:25:32 api_server.py:719] args: Namespace(host='0.0.0.0', port=8000, allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], served_model_name=None, chat_template=None, response_role='assistant', model='mistralai/Mistral-7B-Instruct-v0.2', tokenizer=None, revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, block_size=16, seed=0, swap_space=4, gpu_memory_utilization=0.9, max_num_batched_tokens=None, max_num_seqs=256, max_paddings=256, disable_log_stats=False, quantization=None, engine_use_ray=False, disable_log_requests=False, max_log_len=None)\r\nconfig.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 596/596 [00:00<00:00, 6.74MB/s]\r\nINFO 04-15 15:25:33 llm_engine.py:73] Initializing an LLM engine with config: model='mistralai/Mistral-7B-Instruct-v0.2', tokenizer='mistralai/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\r\ntokenizer_config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.46k/1.46k [00:00<00:00, 19.4MB/s]\r\ntokenizer.model: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 493k/493k [00:00<00:00, 9.14MB/s]\r\ntokenizer.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.80M/1.80M [00:00<00:00, 3.16MB/s]\r\nspecial_tokens_map.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 72.0/72.0 [00:00<00:00, 953kB/s]\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/openai/api_server.py\", line 729, in <module>\r\n    engine = AsyncLLMEngine.from_engine_args(engine_args)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py\", line 495, in from_engine_args\r\n    engine = cls(parallel_config.worker_use_ray,\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py\", line 269, in __init__\r\n    self.engine = self._init_engine(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py\", line 314, in _init_engine\r\n    return engine_class(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\", line 109, in __init__\r\n    self._init_workers(distributed_init_method)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\", line 141, in _init_workers\r\n    self._run_workers(\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\", line 750, in _run_workers\r\n    self._run_workers_in_batch(workers, method, *args, **kwargs))\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\", line 724, in _run_workers_in_batch\r\n    output = executor(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/worker/worker.py\", line 59, in init_model\r\n    torch.cuda.set_device(self.device)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 404, in set_device\r\n    torch._C._cuda_setDevice(device)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\r\n    torch._C._cuda_init()\r\nRuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\r\n```\r\n\r\nI tried several things to fix this, found things to do on\r\n- https://github.com/lllyasviel/Fooocus/issues/2169 \r\n- https://stackoverflow.com/questions/66371130/cuda-initialization-unexpected-error-from-cudagetdevicecount  \r\n\r\nand nothing worked! also tried some nvidia default containers to check if CUDA is working and everything seems to work!\r\n\r\nmy `nvidia-smi` output:\r\n```bash\r\n\u2514\u2500$ nvidia-smi\r\nMon Apr 15 12:29:36 2024       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  NVIDIA GeForce ...  Off  | 00000000:09:00.0  On |                  N/A |\r\n| 30%   45C    P0    58W / 170W |    490MiB / 12288MiB |     12%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|    0   N/A  N/A      1800      G   /usr/lib/xorg/Xorg                179MiB |\r\n|    0   N/A  N/A      1999      G   /usr/bin/gnome-shell               47MiB |\r\n|    0   N/A  N/A      2214      G   /usr/bin/nvidia-settings            0MiB |\r\n|    0   N/A  N/A      2757      G   ...--variations-seed-version       45MiB |\r\n|    0   N/A  N/A      2900      G   ...b/firefox-esr/firefox-esr      114MiB |\r\n|    0   N/A  N/A      3904      G   ...on=20240414-180149.278000       98MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\nmy `/etc/nvidia-container-runtime/config.toml` file:\r\n```bash\r\n#accept-nvidia-visible-devices-as-volume-mounts = false\r\n#accept-nvidia-visible-devices-envvar-when-unprivileged = true\r\ndisable-require = false\r\nsupported-driver-capabilities = \"compat32,compute,display,graphics,ngx,utility,video\"\r\n#swarm-resource = \"DOCKER_RESOURCE_GPU\"\r\n\r\n[nvidia-container-cli]\r\n#debug = \"/var/log/nvidia-container-toolkit.log\"\r\nenvironment = []\r\n#ldcache = \"/etc/ld.so.cache\"\r\nldconfig = \"@/sbin/ldconfig\"\r\nload-kmods = true\r\nno-cgroups = false\r\n#path = \"/usr/bin/nvidia-container-cli\"\r\n#root = \"/run/nvidia/driver\"\r\n#user = \"root:video\"\r\n\r\n[nvidia-container-runtime]\r\n#debug = \"/var/log/nvidia-container-runtime.log\"\r\nlog-level = \"info\"\r\nmode = \"auto\"\r\nruntimes = [\"docker-runc\", \"runc\", \"crun\"]\r\n\r\n[nvidia-container-runtime.modes]\r\n\r\n[nvidia-container-runtime.modes.cdi]\r\nannotation-prefixes = [\"cdi.k8s.io/\"]\r\ndefault-kind = \"nvidia.com/gpu\"\r\nspec-dirs = [\"/etc/cdi\", \"/var/run/cdi\"]\r\n\r\n[nvidia-container-runtime.modes.csv]\r\nmount-spec-path = \"/etc/nvidia-container-runtime/host-files-for-container.d\"\r\n\r\n[nvidia-container-runtime-hook]\r\npath = \"nvidia-container-runtime-hook\"\r\nskip-mode-detection = false\r\n\r\n[nvidia-ctk]\r\npath = \"nvidia-ctk\"\r\n```\r\n\r\nnote: if I change the `no-cgroups` flag to `true` I get a `No CUDA Gpus available` error.\r\n\r\nOS:\r\n```bash\r\n\u2514\u2500$ neofetch \r\n..............                                     guido@kali \r\n            ..,;:ccc,.                             ---------- \r\n          ......''';lxO.                           OS: Kali GNU/Linux Rolling x86_64 \r\n.....''''..........,:ld;                           Kernel: 6.6.9-amd64 \r\n           .';;;:::;,,.x,                          Uptime: 37 mins \r\n      ..'''.            0Xxoc:,.  ...              Packages: 2981 (dpkg), 12 (snap) \r\n  ....                ,ONkc;,;cokOdc',.            Shell: bash 5.2.21 \r\n .                   OMo           ':ddo.          Resolution: 1920x1080, 1920x1080 \r\n                    dMc               :OO;         DE: GNOME 45.3 \r\n                    0M.                 .:o.       WM: Mutter \r\n                    ;Wd                            WM Theme: Kali-Purple-Dark \r\n                     ;XO,                          Theme: Kali-Purple-Dark [GTK2/3] \r\n                       ,d0Odlc;,..                 Icons: Flat-Remix-Blue-Light [GTK2/3] \r\n                           ..',;:cdOOd::,.         Terminal: terminator \r\n                                    .:d;.':;.      CPU: AMD Ryzen 7 5800X (16) @ 4.200GHz \r\n                                       'd,  .'     GPU: NVIDIA GeForce RTX 3060 Lite Hash Rate \r\n                                         ;l   ..   Memory: 4669MiB / 32013MiB \r\n                                          .o\r\n                                            c                              \r\n                                            .'                             \r\n                                             .\r\n\r\n```\r\n\r\n ",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/144/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/144/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/143",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/143/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/143/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/143/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/143",
    "id": 2218399911,
    "node_id": "I_kwDOKY_97s6EOhin",
    "number": 143,
    "title": "Not completing answer",
    "user": {
      "login": "KEYURBODAR",
      "id": 155174903,
      "node_id": "U_kgDOCT_H9w",
      "avatar_url": "https://avatars.githubusercontent.com/u/155174903?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/KEYURBODAR",
      "html_url": "https://github.com/KEYURBODAR",
      "followers_url": "https://api.github.com/users/KEYURBODAR/followers",
      "following_url": "https://api.github.com/users/KEYURBODAR/following{/other_user}",
      "gists_url": "https://api.github.com/users/KEYURBODAR/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/KEYURBODAR/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/KEYURBODAR/subscriptions",
      "organizations_url": "https://api.github.com/users/KEYURBODAR/orgs",
      "repos_url": "https://api.github.com/users/KEYURBODAR/repos",
      "events_url": "https://api.github.com/users/KEYURBODAR/events{/privacy}",
      "received_events_url": "https://api.github.com/users/KEYURBODAR/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-04-01T14:33:26Z",
    "updated_at": "2024-04-03T13:21:18Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I told AI model Mixtral-8x7B-Instruct-v0.1 to give me a python project. \r\nbut It does not answered me fully.\r\n!\r\n![Screenshot_2024-04-01_09-13-38](https://github.com/mistralai/mistral-src/assets/155174903/89469422-f435-4de0-a1d1-ef6e81dcc408)\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/143/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/143/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/142",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/142/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/142/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/142/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/142",
    "id": 2212013864,
    "node_id": "I_kwDOKY_97s6D2Kco",
    "number": 142,
    "title": "I am unable to build the vLLM Container",
    "user": {
      "login": "AMGI-Pipeline",
      "id": 78504590,
      "node_id": "MDQ6VXNlcjc4NTA0NTkw",
      "avatar_url": "https://avatars.githubusercontent.com/u/78504590?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AMGI-Pipeline",
      "html_url": "https://github.com/AMGI-Pipeline",
      "followers_url": "https://api.github.com/users/AMGI-Pipeline/followers",
      "following_url": "https://api.github.com/users/AMGI-Pipeline/following{/other_user}",
      "gists_url": "https://api.github.com/users/AMGI-Pipeline/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AMGI-Pipeline/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AMGI-Pipeline/subscriptions",
      "organizations_url": "https://api.github.com/users/AMGI-Pipeline/orgs",
      "repos_url": "https://api.github.com/users/AMGI-Pipeline/repos",
      "events_url": "https://api.github.com/users/AMGI-Pipeline/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AMGI-Pipeline/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2024-03-27T22:34:57Z",
    "updated_at": "2024-04-11T23:48:19Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I am unable to build the vLLM Container.  I am getting these errors:\r\n```\r\n252.2 Building wheels for collected packages: vllm\r\n252.2   Building wheel for vllm (pyproject.toml): started\r\n313.8   Building wheel for vllm (pyproject.toml): still running...\r\n551.9   Building wheel for vllm (pyproject.toml): still running...\r\n774.4   Building wheel for vllm (pyproject.toml): still running...\r\n936.1   Building wheel for vllm (pyproject.toml): still running...\r\n983.2   Building wheel for vllm (pyproject.toml): finished with status 'error'\r\n983.6   error: subprocess-exited-with-error\r\n983.6\r\n983.6   \u00d7 Building wheel for vllm (pyproject.toml) did not run successfully.\r\n983.6   \u2502 exit code: 1\r\n983.6   \u2570\u2500> [983 lines of output]\r\n983.6       /tmp/pip-build-env-rt38cp4x/overlay/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\r\n983.6         device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\r\n.\r\n.\r\n.\r\n983.6         File \"/usr/lib/python3.10/subprocess.py\", line 369, in check_call\r\n983.6           raise CalledProcessError(retcode, cmd)\r\n983.6       subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', '_C', '-j', '32']' returned non-zero exit status 1.\r\n983.6       [end of output]\r\n983.6\r\n983.6   note: This error originates from a subprocess, and is likely not a problem with pip.\r\n983.6   ERROR: Failed building wheel for vllm\r\n983.6 Failed to build vllm\r\n983.6 ERROR: Could not build wheels for vllm, which is required to install pyproject.toml-based projects\r\n------\r\n```\r\nAny ideas what is going on?\r\n\r\nAny help is greatly apprecated!",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/142/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/142/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/141",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/141/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/141/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/141/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/141",
    "id": 2199510384,
    "node_id": "I_kwDOKY_97s6DGd1w",
    "number": 141,
    "title": "Fine Tuning Mistral 7b",
    "user": {
      "login": "nourolive",
      "id": 162306827,
      "node_id": "U_kgDOCaybCw",
      "avatar_url": "https://avatars.githubusercontent.com/u/162306827?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nourolive",
      "html_url": "https://github.com/nourolive",
      "followers_url": "https://api.github.com/users/nourolive/followers",
      "following_url": "https://api.github.com/users/nourolive/following{/other_user}",
      "gists_url": "https://api.github.com/users/nourolive/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nourolive/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nourolive/subscriptions",
      "organizations_url": "https://api.github.com/users/nourolive/orgs",
      "repos_url": "https://api.github.com/users/nourolive/repos",
      "events_url": "https://api.github.com/users/nourolive/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nourolive/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2024-03-21T08:27:35Z",
    "updated_at": "2024-03-22T07:43:47Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Can we fine-tune with Mistral for a custom dataset in the field of digital marketing/marketing communication?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/141/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/141/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/140",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/140/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/140/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/140/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/140",
    "id": 2195085310,
    "node_id": "I_kwDOKY_97s6C1lf-",
    "number": 140,
    "title": "Missing the params.json",
    "user": {
      "login": "littlewwwhite",
      "id": 34784086,
      "node_id": "MDQ6VXNlcjM0Nzg0MDg2",
      "avatar_url": "https://avatars.githubusercontent.com/u/34784086?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/littlewwwhite",
      "html_url": "https://github.com/littlewwwhite",
      "followers_url": "https://api.github.com/users/littlewwwhite/followers",
      "following_url": "https://api.github.com/users/littlewwwhite/following{/other_user}",
      "gists_url": "https://api.github.com/users/littlewwwhite/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/littlewwwhite/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/littlewwwhite/subscriptions",
      "organizations_url": "https://api.github.com/users/littlewwwhite/orgs",
      "repos_url": "https://api.github.com/users/littlewwwhite/repos",
      "events_url": "https://api.github.com/users/littlewwwhite/events{/privacy}",
      "received_events_url": "https://api.github.com/users/littlewwwhite/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2024-03-19T14:10:04Z",
    "updated_at": "2024-07-16T12:31:35Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "FileNotFoundError: [Errno 2] No such file or directory: 'Mistral-7B-Instruct-v0.2/params.json'\r\n\r\nand I replace the params.json to config.json  but still lack of several params such like kv_cache dim etc.\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/140/reactions",
      "total_count": 3,
      "+1": 3,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/140/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/139",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/139/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/139/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/139/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/139",
    "id": 2192877537,
    "node_id": "I_kwDOKY_97s6CtKfh",
    "number": 139,
    "title": "Question about Mixtral MLP section",
    "user": {
      "login": "lhallee",
      "id": 72926928,
      "node_id": "MDQ6VXNlcjcyOTI2OTI4",
      "avatar_url": "https://avatars.githubusercontent.com/u/72926928?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lhallee",
      "html_url": "https://github.com/lhallee",
      "followers_url": "https://api.github.com/users/lhallee/followers",
      "following_url": "https://api.github.com/users/lhallee/following{/other_user}",
      "gists_url": "https://api.github.com/users/lhallee/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lhallee/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lhallee/subscriptions",
      "organizations_url": "https://api.github.com/users/lhallee/orgs",
      "repos_url": "https://api.github.com/users/lhallee/repos",
      "events_url": "https://api.github.com/users/lhallee/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lhallee/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2024-03-18T17:46:27Z",
    "updated_at": "2024-06-09T20:57:12Z",
    "closed_at": "2024-06-09T20:57:12Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hello,\r\n\r\nGreat work! Is it okay to say it is just a standard vanilla MLP block? According to the huggingface implementation there is an additional third linear layer and added elementwise multiplication.\r\n\r\n![image](https://github.com/mistralai/mistral-src/assets/72926928/cd403dc6-830c-4c0b-9e17-346d1b2b1290)\r\n\r\n```\r\nclass MixtralBlockSparseTop2MLP(nn.Module):\r\n    def __init__(self, config: MixtralConfig):\r\n        super().__init__()\r\n        self.ffn_dim = config.intermediate_size\r\n        self.hidden_dim = config.hidden_size\r\n\r\n        self.w1 = nn.Linear(self.hidden_dim, self.ffn_dim, bias=False)\r\n        self.w2 = nn.Linear(self.ffn_dim, self.hidden_dim, bias=False)\r\n        self.w3 = nn.Linear(self.hidden_dim, self.ffn_dim, bias=False) # not standard\r\n\r\n        self.act_fn = ACT2FN[config.hidden_act]\r\n\r\n    def forward(self, hidden_states):\r\n        current_hidden_states = self.act_fn(self.w1(hidden_states)) * self.w3(hidden_states) # not standard\r\n        current_hidden_states = self.w2(current_hidden_states)\r\n        return current_hidden_states\r\n\r\n```\r\nI think this has been confusing to some readers, but perhaps this has been used before and I am unaware. Is there any insights you guys can offer about why this layer was added? It seems to add more expressiveness to the experts but I didn't know if you had experimented with and without it.",
    "closed_by": {
      "login": "lhallee",
      "id": 72926928,
      "node_id": "MDQ6VXNlcjcyOTI2OTI4",
      "avatar_url": "https://avatars.githubusercontent.com/u/72926928?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lhallee",
      "html_url": "https://github.com/lhallee",
      "followers_url": "https://api.github.com/users/lhallee/followers",
      "following_url": "https://api.github.com/users/lhallee/following{/other_user}",
      "gists_url": "https://api.github.com/users/lhallee/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lhallee/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lhallee/subscriptions",
      "organizations_url": "https://api.github.com/users/lhallee/orgs",
      "repos_url": "https://api.github.com/users/lhallee/repos",
      "events_url": "https://api.github.com/users/lhallee/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lhallee/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/139/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/139/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/138",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/138/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/138/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/138/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/138",
    "id": 2191605843,
    "node_id": "I_kwDOKY_97s6CoUBT",
    "number": 138,
    "title": "Training code ",
    "user": {
      "login": "sartimo",
      "id": 71646577,
      "node_id": "MDQ6VXNlcjcxNjQ2NTc3",
      "avatar_url": "https://avatars.githubusercontent.com/u/71646577?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sartimo",
      "html_url": "https://github.com/sartimo",
      "followers_url": "https://api.github.com/users/sartimo/followers",
      "following_url": "https://api.github.com/users/sartimo/following{/other_user}",
      "gists_url": "https://api.github.com/users/sartimo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sartimo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sartimo/subscriptions",
      "organizations_url": "https://api.github.com/users/sartimo/orgs",
      "repos_url": "https://api.github.com/users/sartimo/repos",
      "events_url": "https://api.github.com/users/sartimo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sartimo/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-03-18T09:03:57Z",
    "updated_at": "2024-04-05T07:07:12Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi\r\n\r\nWhere can I find the code needed to train the initial model and produce the model files?\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/138/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/138/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/137",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/137/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/137/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/137/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/137",
    "id": 2191455780,
    "node_id": "PR_kwDOKY_97s5p5sec",
    "number": 137,
    "title": "Fix sliding window mask size in one_file_ref.py ",
    "user": {
      "login": "MrYxJ",
      "id": 21152077,
      "node_id": "MDQ6VXNlcjIxMTUyMDc3",
      "avatar_url": "https://avatars.githubusercontent.com/u/21152077?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/MrYxJ",
      "html_url": "https://github.com/MrYxJ",
      "followers_url": "https://api.github.com/users/MrYxJ/followers",
      "following_url": "https://api.github.com/users/MrYxJ/following{/other_user}",
      "gists_url": "https://api.github.com/users/MrYxJ/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/MrYxJ/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/MrYxJ/subscriptions",
      "organizations_url": "https://api.github.com/users/MrYxJ/orgs",
      "repos_url": "https://api.github.com/users/MrYxJ/repos",
      "events_url": "https://api.github.com/users/MrYxJ/events{/privacy}",
      "received_events_url": "https://api.github.com/users/MrYxJ/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-03-18T07:45:11Z",
    "updated_at": "2024-03-18T07:55:59Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/137",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/137",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/137.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/137.patch",
      "merged_at": null
    },
    "body": "Fixed a minor encoding error in the mask matrix size in one_file_ref.py where the original mask would display one more column than expected size.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/137/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/137/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/136",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/136/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/136/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/136/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/136",
    "id": 2190634273,
    "node_id": "I_kwDOKY_97s6Ckm0h",
    "number": 136,
    "title": "CUDA EXTENSION NOT INSTALLED nvcr.io/nvidia/pytorch:22.12-py3",
    "user": {
      "login": "skr3178",
      "id": 79299617,
      "node_id": "MDQ6VXNlcjc5Mjk5NjE3",
      "avatar_url": "https://avatars.githubusercontent.com/u/79299617?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/skr3178",
      "html_url": "https://github.com/skr3178",
      "followers_url": "https://api.github.com/users/skr3178/followers",
      "following_url": "https://api.github.com/users/skr3178/following{/other_user}",
      "gists_url": "https://api.github.com/users/skr3178/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/skr3178/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/skr3178/subscriptions",
      "organizations_url": "https://api.github.com/users/skr3178/orgs",
      "repos_url": "https://api.github.com/users/skr3178/repos",
      "events_url": "https://api.github.com/users/skr3178/events{/privacy}",
      "received_events_url": "https://api.github.com/users/skr3178/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-03-17T12:12:09Z",
    "updated_at": "2024-03-20T06:17:34Z",
    "closed_at": "2024-03-20T06:17:33Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Also wrote on https://github.com/AutoGPTQ/AutoGPTQ/issues/598\r\n\r\n!nvidia-smi`\r\n\r\nSun Mar 17 12:04:03 2024       \r\n+-----------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\r\n|-----------------------------------------+------------------------+----------------------+\r\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                        |               MIG M. |\r\n|=========================================+========================+======================|\r\n|   0  NVIDIA GeForce RTX 3060        Off |   00000000:01:00.0  On |                  N/A |\r\n|  0%   47C    P8             24W /  170W |     418MiB /  12288MiB |     14%      Default |\r\n|                                         |                        |                  N/A |\r\n+-----------------------------------------+------------------------+----------------------+\r\n                                                                                         \r\n+-----------------------------------------------------------------------------------------+\r\n| Processes:                                                                              |\r\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n|        ID   ID                                                               Usage      |\r\n|=========================================================================================|\r\n+-----------------------------------------------------------------------------------------+\r\n`!nvcc --version`\r\n!nvcc --version\r\n!nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2023 NVIDIA Corporation\r\nBuilt on Tue_Feb__7_19:32:13_PST_2023\r\nCuda compilation tools, release 12.1, V12.1.66\r\nBuild cuda_12.1.r12.1/compiler.32415258_0\r\n\r\n```\r\nimport torch\r\n\r\nprint(torch.__version__)\r\n```\r\n2.1.0a0+fe05266\r\n\r\n```\r\nimport torch \r\nprint(torch.version.cuda)\r\n```\r\n12.1\r\n\r\n`!pip list`\r\n\r\nPackage                 Version\r\n----------------------- --------------------\r\nabsl-py                 1.4.0\r\naccelerate              0.28.0\r\naiohttp                 3.8.4\r\naiosignal               1.3.1\r\napex                    0.1\r\nargon2-cffi             21.3.0\r\nargon2-cffi-bindings    21.2.0\r\nasttokens               2.2.1\r\nastunparse              1.6.3\r\nasync-timeout           4.0.2\r\nattrs                   22.2.0\r\naudioread               3.0.0\r\nauto-gptq               0.6.0\r\nbackcall                0.2.0\r\nbeautifulsoup4          4.12.2\r\nbitsandbytes            0.43.0\r\nbleach                  6.0.0\r\nblis                    0.7.9\r\ncachetools              5.3.0\r\ncatalogue               2.0.8\r\ncertifi                 2022.12.7\r\ncffi                    1.15.1\r\ncharset-normalizer      3.1.0\r\nclick                   8.1.3\r\ncloudpickle             2.2.1\r\ncmake                   3.24.1.1\r\ncoloredlogs             15.0.1\r\ncomm                    0.1.3\r\nconfection              0.0.4\r\ncontourpy               1.0.7\r\ncubinlinker             0.2.2+2.g5f51201\r\ncuda-python             12.1.0rc5+1.g808384c\r\ncudf                    23.2.0\r\ncugraph                 23.2.0\r\ncugraph-dgl             23.2.0\r\ncugraph-service-client  23.2.0\r\ncugraph-service-server  23.2.0\r\ncuml                    23.2.0\r\ncupy-cuda12x            12.0.0b3\r\ncycler                  0.11.0\r\ncymem                   2.0.7\r\nCython                  0.29.34\r\ndask                    2023.1.1\r\ndask-cuda               23.2.0\r\ndask-cudf               23.2.0\r\ndatasets                2.18.0\r\ndebugpy                 1.6.7\r\ndecorator               5.1.1\r\ndefusedxml              0.7.1\r\ndill                    0.3.8\r\ndistributed             2023.1.1\r\nexceptiongroup          1.1.1\r\nexecnet                 1.9.0\r\nexecuting               1.2.0\r\nexpecttest              0.1.3\r\nfastjsonschema          2.16.3\r\nfastrlock               0.8.1\r\nfilelock                3.11.0\r\nflash-attn              0.2.8.dev0\r\nfonttools               4.39.3\r\nfrozenlist              1.3.3\r\nfsspec                  2024.2.0\r\ngast                    0.4.0\r\ngekko                   1.0.7\r\ngoogle-auth             2.17.3\r\ngoogle-auth-oauthlib    0.4.6\r\ngraphsurgeon            0.4.6\r\ngrpcio                  1.53.0\r\nHeapDict                1.0.1\r\nhuggingface-hub         0.21.4\r\nhumanfriendly           10.0\r\nhypothesis              5.35.1\r\nidna                    3.4\r\nimportlib-metadata      6.3.0\r\nimportlib-resources     5.12.0\r\niniconfig               2.0.0\r\nintel-openmp            2021.4.0\r\nipykernel               6.22.0\r\nipython                 8.12.0\r\nipython-genutils        0.2.0\r\nipywidgets              8.1.2\r\njedi                    0.18.2\r\nJinja2                  3.1.2\r\njoblib                  1.2.0\r\njson5                   0.9.11\r\njsonschema              4.17.3\r\njupyter_client          8.2.0\r\njupyter_core            5.3.0\r\njupyter-tensorboard     0.2.0\r\njupyterlab              2.3.2\r\njupyterlab-pygments     0.2.2\r\njupyterlab-server       1.2.0\r\njupyterlab_widgets      3.0.10\r\njupytext                1.14.5\r\nkiwisolver              1.4.4\r\nlangcodes               3.3.0\r\nlibrosa                 0.9.2\r\nlit                     16.0.1\r\nllvmlite                0.39.1\r\nlocket                  1.0.0\r\nMarkdown                3.4.3\r\nmarkdown-it-py          2.2.0\r\nMarkupSafe              2.1.2\r\nmatplotlib              3.7.1\r\nmatplotlib-inline       0.1.6\r\nmdit-py-plugins         0.3.5\r\nmdurl                   0.1.2\r\nmistune                 2.0.5\r\nmkl                     2021.1.1\r\nmkl-devel               2021.1.1\r\nmkl-include             2021.1.1\r\nmock                    5.0.1\r\nmpmath                  1.3.0\r\nmsgpack                 1.0.5\r\nmultidict               6.0.4\r\nmultiprocess            0.70.16\r\nmurmurhash              1.0.9\r\nnbclient                0.7.3\r\nnbconvert               7.3.1\r\nnbformat                5.8.0\r\nnest-asyncio            1.5.6\r\nnetworkx                2.6.3\r\nnotebook                6.4.10\r\nnumba                   0.56.4+1.g536eedd6e\r\nnumpy                   1.22.2\r\nnvidia-dali-cuda110     1.24.0\r\nnvidia-pyindex          1.0.9\r\nnvtx                    0.2.5\r\noauthlib                3.2.2\r\nonnx                    1.13.1\r\nopencv                  4.6.0\r\noptimum                 1.17.1\r\npackaging               23.0\r\npandas                  1.5.2\r\npandocfilters           1.5.0\r\nparso                   0.8.3\r\npartd                   1.3.0\r\npathy                   0.10.1\r\npeft                    0.9.0\r\npexpect                 4.8.0\r\npickleshare             0.7.5\r\nPillow                  9.2.0\r\npip                     21.2.4\r\npkgutil_resolve_name    1.3.10\r\nplatformdirs            3.2.0\r\npluggy                  1.0.0\r\nply                     3.11\r\npolygraphy              0.46.2\r\npooch                   1.7.0\r\npreshed                 3.0.8\r\nprettytable             3.7.0\r\nprometheus-client       0.16.0\r\nprompt-toolkit          3.0.38\r\nprotobuf                3.20.3\r\npsutil                  5.9.4\r\nptxcompiler             0.7.0+27.gb446f00\r\nptyprocess              0.7.0\r\npure-eval               0.2.2\r\npyarrow                 15.0.1\r\npyarrow-hotfix          0.6\r\npyasn1                  0.4.8\r\npyasn1-modules          0.2.8\r\npybind11                2.10.4\r\npycocotools             2.0+nv0.7.1\r\npycparser               2.21\r\npydantic                1.10.7\r\nPygments                2.15.0\r\npylibcugraph            23.2.0\r\npylibcugraphops         23.2.0\r\npylibraft               23.2.0\r\npynvml                  11.4.1\r\npyparsing               3.0.9\r\npyrsistent              0.19.3\r\npytest                  7.3.1\r\npytest-rerunfailures    11.1.2\r\npytest-shard            0.1.2\r\npytest-xdist            3.2.1\r\npython-dateutil         2.8.2\r\npython-hostlist         1.23.0\r\npytorch-quantization    2.1.2\r\npytz                    2023.3\r\nPyYAML                  6.0\r\npyzmq                   25.0.2\r\nraft-dask               23.2.0\r\nregex                   2023.3.23\r\nrequests                2.28.2\r\nrequests-oauthlib       1.3.1\r\nresampy                 0.4.2\r\nrmm                     23.2.0\r\nrouge                   1.0.1\r\nrsa                     4.9\r\nsafetensors             0.4.2\r\nscikit-learn            1.2.0\r\nscipy                   1.10.1\r\nseaborn                 0.12.2\r\nSend2Trash              1.8.0\r\nsentencepiece           0.2.0\r\nsetuptools              65.5.1\r\nsix                     1.16.0\r\nsmart-open              6.3.0\r\nsortedcontainers        2.4.0\r\nsoundfile               0.12.1\r\nsoupsieve               2.4\r\nspacy                   3.5.2\r\nspacy-legacy            3.0.12\r\nspacy-loggers           1.0.4\r\nsphinx-glpi-theme       0.3\r\nsrsly                   2.4.6\r\nstack-data              0.6.2\r\nstrings-udf             23.2.0\r\nsympy                   1.11.1\r\ntbb                     2021.9.0\r\ntblib                   1.7.0\r\ntensorboard             2.9.0\r\ntensorboard-data-server 0.6.1\r\ntensorboard-plugin-wit  1.8.1\r\ntensorrt                8.6.1\r\nterminado               0.17.1\r\nthinc                   8.1.9\r\nthreadpoolctl           3.1.0\r\nthriftpy2               0.4.16\r\ntinycss2                1.2.1\r\ntokenizers              0.15.2\r\ntoml                    0.10.2\r\ntomli                   2.0.1\r\ntoolz                   0.12.0\r\ntorch                   2.1.0a0+fe05266\r\ntorch-tensorrt          1.4.0.dev0\r\ntorchtext               0.13.0a0+fae8e8c\r\ntorchvision             0.15.0a0\r\ntornado                 6.2\r\ntqdm                    4.65.0\r\ntraitlets               5.9.0\r\ntransformer-engine      0.7.0\r\ntransformers            4.38.2\r\ntreelite                3.1.0\r\ntreelite-runtime        3.1.0\r\ntriton                  2.0.0\r\ntyper                   0.7.0\r\ntypes-dataclasses       0.6.6\r\ntyping_extensions       4.5.0\r\nucx-py                  0.30.0\r\nuff                     0.6.9\r\nurllib3                 1.26.15\r\nwasabi                  1.1.1\r\nwcwidth                 0.2.6\r\nwebencodings            0.5.1\r\nWerkzeug                2.2.3\r\nwheel                   0.40.0\r\nwidgetsnbextension      4.0.10\r\nxdoctest                1.0.2\r\nxgboost                 1.7.1\r\nxxhash                  3.4.1\r\nyarl                    1.8.2\r\nzict                    2.2.0\r\nzipp                    3.15.0\r\nWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\r\nYou should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\r\n\r\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\r\nfrom peft import prepare_model_for_kbit_training\r\nfrom peft import LoraConfig, get_peft_model\r\nfrom datasets import load_dataset\r\nimport transformers\r\n\r\n```\r\nmodel_name = \"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\"\r\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\r\n                                             device_map=\"auto\", # automatically figures out how to best use CPU + GPU for loading model\r\n                                             trust_remote_code=False, # prevents running custom model files on your machine\r\n                                             revision=\"main\") # which version of model to use in repo\r\n```\r\n\r\nCUDA extension not installed.\r\nCUDA extension not installed.\r\n\r\n\r\n\r\n",
    "closed_by": {
      "login": "skr3178",
      "id": 79299617,
      "node_id": "MDQ6VXNlcjc5Mjk5NjE3",
      "avatar_url": "https://avatars.githubusercontent.com/u/79299617?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/skr3178",
      "html_url": "https://github.com/skr3178",
      "followers_url": "https://api.github.com/users/skr3178/followers",
      "following_url": "https://api.github.com/users/skr3178/following{/other_user}",
      "gists_url": "https://api.github.com/users/skr3178/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/skr3178/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/skr3178/subscriptions",
      "organizations_url": "https://api.github.com/users/skr3178/orgs",
      "repos_url": "https://api.github.com/users/skr3178/repos",
      "events_url": "https://api.github.com/users/skr3178/events{/privacy}",
      "received_events_url": "https://api.github.com/users/skr3178/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/136/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/136/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/135",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/135/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/135/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/135/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/135",
    "id": 2187852122,
    "node_id": "I_kwDOKY_97s6CZ_la",
    "number": 135,
    "title": "[MISTRAL AI ERROR] Mistral AI responding with Unexpected role RoleEnum.tool error",
    "user": {
      "login": "muhammadfaizan027915",
      "id": 88107300,
      "node_id": "MDQ6VXNlcjg4MTA3MzAw",
      "avatar_url": "https://avatars.githubusercontent.com/u/88107300?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/muhammadfaizan027915",
      "html_url": "https://github.com/muhammadfaizan027915",
      "followers_url": "https://api.github.com/users/muhammadfaizan027915/followers",
      "following_url": "https://api.github.com/users/muhammadfaizan027915/following{/other_user}",
      "gists_url": "https://api.github.com/users/muhammadfaizan027915/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/muhammadfaizan027915/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/muhammadfaizan027915/subscriptions",
      "organizations_url": "https://api.github.com/users/muhammadfaizan027915/orgs",
      "repos_url": "https://api.github.com/users/muhammadfaizan027915/repos",
      "events_url": "https://api.github.com/users/muhammadfaizan027915/events{/privacy}",
      "received_events_url": "https://api.github.com/users/muhammadfaizan027915/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-03-15T07:00:17Z",
    "updated_at": "2024-03-18T12:18:18Z",
    "closed_at": "2024-03-17T13:11:55Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I am using Mistral AI client in my javascript project and Mistral Ai is giving me a tool_calls response. When I call the tool and push response in messages array. And Then I call a send a second request to the Mistral AI it gives me this error:\r\nMistralAPIError: HTTP error! status: 400 Response: \r\n{\"object\":\"error\",\"message\":\"Unexpected role RoleEnum.tool\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\r\n\r\nMy messages array contains: \r\nMessages:  [\r\n    {\r\n        \"role\": \"user\",\r\n        \"name\": \"User\",\r\n        \"content\": \"give me random cat image\\n\\n\"\r\n    },\r\n    {\r\n        \"role\": \"tool\",\r\n        \"name\": \"RandomCatImage\",\r\n        \"content\": \"{\"data\":[{\"id\":\"cpq\",\"url\":\"[https://cdn2.thecatapi.com/images/cpq.png/\",/\"width/\":1024,/\"height/\":765%7D],/\"success/\":true,/\"message/\":/\"Successfully](https://cdn2.thecatapi.com/images/cpq.png/%22,/%22width/%22:1024,/%22height/%22:765%7D],/%22success/%22:true,/%22message/%22:/%22Successfully) accomplished!\"}\"\r\n    }\r\n]\r\n\r\nMy implementation for function calling:\r\n```\r\nfor (const tool of toolCalls) {\r\n      const functionName = tool.function.name;\r\n      const functionArguments = JSON.parse(tool.function.arguments);\r\n\r\n      const desiredTool = httpTools?.find((tool) => (tool?.config as HttpToolSchema[\"config\"])?.name?.replaceAll(\" \", \"\") === functionName);\r\n      const httpResponse = await httpToolHandler(desiredTool?.config as HttpToolSchema[\"config\"])(functionArguments);\r\n\r\n      messages?.push({ role: \"tool\", name: functionName, content: httpResponse });\r\n    }\r\n```\r\n\r\nI am unable to get chat response from Mistral AI after calling a tool.\r\n![Screenshot_1](https://github.com/mistralai/mistral-src/assets/88107300/63c4cab0-b954-4352-9a5a-3a31db7027b1)\r\n\r\n\r\n",
    "closed_by": {
      "login": "muhammadfaizan027915",
      "id": 88107300,
      "node_id": "MDQ6VXNlcjg4MTA3MzAw",
      "avatar_url": "https://avatars.githubusercontent.com/u/88107300?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/muhammadfaizan027915",
      "html_url": "https://github.com/muhammadfaizan027915",
      "followers_url": "https://api.github.com/users/muhammadfaizan027915/followers",
      "following_url": "https://api.github.com/users/muhammadfaizan027915/following{/other_user}",
      "gists_url": "https://api.github.com/users/muhammadfaizan027915/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/muhammadfaizan027915/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/muhammadfaizan027915/subscriptions",
      "organizations_url": "https://api.github.com/users/muhammadfaizan027915/orgs",
      "repos_url": "https://api.github.com/users/muhammadfaizan027915/repos",
      "events_url": "https://api.github.com/users/muhammadfaizan027915/events{/privacy}",
      "received_events_url": "https://api.github.com/users/muhammadfaizan027915/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/135/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/135/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/134",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/134/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/134/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/134/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/134",
    "id": 2184246114,
    "node_id": "I_kwDOKY_97s6CMPNi",
    "number": 134,
    "title": "Mistral's tokenizer is not optimized",
    "user": {
      "login": "Yarflam",
      "id": 6906024,
      "node_id": "MDQ6VXNlcjY5MDYwMjQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6906024?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Yarflam",
      "html_url": "https://github.com/Yarflam",
      "followers_url": "https://api.github.com/users/Yarflam/followers",
      "following_url": "https://api.github.com/users/Yarflam/following{/other_user}",
      "gists_url": "https://api.github.com/users/Yarflam/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Yarflam/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Yarflam/subscriptions",
      "organizations_url": "https://api.github.com/users/Yarflam/orgs",
      "repos_url": "https://api.github.com/users/Yarflam/repos",
      "events_url": "https://api.github.com/users/Yarflam/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Yarflam/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-03-13T15:06:16Z",
    "updated_at": "2024-03-13T15:06:16Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hello!\r\n\r\nHow to reproduce:\r\n\r\n```python\r\nfrom transformers import AutoTokenizer\r\ntokenizer = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-Instruct-v0.2')\r\n\r\ntokenizer.add_bos_token = False\r\ntokenizer.add_eos_token = False\r\n\r\nids = [ 12866, 601 ] # \"\u2581domestic\" + \"ated\"\r\ndecode = tokenizer.decode(ids)\r\nencode = tokenizer.encode(decode)\r\nprint(encode)\r\n# output -> [2853, 374, 6899] \r\n# \"\u2581dom\" + \"est\" + \"icated\"\r\n```\r\n\r\nI don't know what's the best thing to do and if this case has an impact on the calculation.\r\nIt's just a feedback - but I'm sure it's possible to find another cases.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/134/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/134/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/133",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/133/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/133/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/133/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/133",
    "id": 2168413052,
    "node_id": "I_kwDOKY_97s6BP1t8",
    "number": 133,
    "title": "Evaluation Pipeline",
    "user": {
      "login": "nikhil0360",
      "id": 43106856,
      "node_id": "MDQ6VXNlcjQzMTA2ODU2",
      "avatar_url": "https://avatars.githubusercontent.com/u/43106856?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nikhil0360",
      "html_url": "https://github.com/nikhil0360",
      "followers_url": "https://api.github.com/users/nikhil0360/followers",
      "following_url": "https://api.github.com/users/nikhil0360/following{/other_user}",
      "gists_url": "https://api.github.com/users/nikhil0360/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nikhil0360/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nikhil0360/subscriptions",
      "organizations_url": "https://api.github.com/users/nikhil0360/orgs",
      "repos_url": "https://api.github.com/users/nikhil0360/repos",
      "events_url": "https://api.github.com/users/nikhil0360/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nikhil0360/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-03-05T06:40:12Z",
    "updated_at": "2024-03-05T06:40:12Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Dear team, I am seeking out help to understand your evaluation pipeline. ",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/133/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/133/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/132",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/132/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/132/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/132/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/132",
    "id": 2165909151,
    "node_id": "I_kwDOKY_97s6BGSaf",
    "number": 132,
    "title": "Friendly Reminder while Generating the output",
    "user": {
      "login": "BadrinathMJ",
      "id": 99330540,
      "node_id": "U_kgDOBeup7A",
      "avatar_url": "https://avatars.githubusercontent.com/u/99330540?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/BadrinathMJ",
      "html_url": "https://github.com/BadrinathMJ",
      "followers_url": "https://api.github.com/users/BadrinathMJ/followers",
      "following_url": "https://api.github.com/users/BadrinathMJ/following{/other_user}",
      "gists_url": "https://api.github.com/users/BadrinathMJ/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/BadrinathMJ/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/BadrinathMJ/subscriptions",
      "organizations_url": "https://api.github.com/users/BadrinathMJ/orgs",
      "repos_url": "https://api.github.com/users/BadrinathMJ/repos",
      "events_url": "https://api.github.com/users/BadrinathMJ/events{/privacy}",
      "received_events_url": "https://api.github.com/users/BadrinathMJ/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-03-04T04:42:19Z",
    "updated_at": "2024-03-04T04:42:19Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (32768). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\r\n\r\nCan anybody justify why this warning while getting the inference in mistralai/Mistral-7B-Instruct-v0.2?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/132/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/132/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/131",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/131/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/131/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/131/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/131",
    "id": 2165240112,
    "node_id": "I_kwDOKY_97s6BDvEw",
    "number": 131,
    "title": "[Mistral 7B mistral-7b-instruct-v0.1.Q8_0.gguf] Wrong text \"quoted\" while presented as real",
    "user": {
      "login": "SINAPSA-IC",
      "id": 158754254,
      "node_id": "U_kgDOCXZlzg",
      "avatar_url": "https://avatars.githubusercontent.com/u/158754254?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/SINAPSA-IC",
      "html_url": "https://github.com/SINAPSA-IC",
      "followers_url": "https://api.github.com/users/SINAPSA-IC/followers",
      "following_url": "https://api.github.com/users/SINAPSA-IC/following{/other_user}",
      "gists_url": "https://api.github.com/users/SINAPSA-IC/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/SINAPSA-IC/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/SINAPSA-IC/subscriptions",
      "organizations_url": "https://api.github.com/users/SINAPSA-IC/orgs",
      "repos_url": "https://api.github.com/users/SINAPSA-IC/repos",
      "events_url": "https://api.github.com/users/SINAPSA-IC/events{/privacy}",
      "received_events_url": "https://api.github.com/users/SINAPSA-IC/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2024-03-03T07:56:55Z",
    "updated_at": "2024-03-03T08:41:23Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hello.\r\n\r\nI don't know if this is a bug or a feature, however I've expected More.\r\n\r\n- Software: \r\n-- GPT4All 2.7.1, working on **CPU only**\r\n-- Local Documents collections: none selected\r\n- LLM: \r\n-- Mistral Instruct: mistral-7b-instruct-v0.1.Q8_0.gguf\r\n-- Temperature: 0.1\r\n-- Context Length: 16384\r\n-- Max Length: 4096 \r\n-- Top P: 0.6\r\n-- Top K; 50\r\n-- Repeat Penalty: 1.1\r\n-- Repeat Penalty Tokens: 64\r\n-- GPU Layers: 32\r\n-- System Prompt:\r\nIf you cannot answer to something, you say so and explain why.\r\n-- Prompt Template: \r\n[INST] %1 [/INST]\r\n\r\n\r\nPrompt:\r\n\ufeff\ufefftell me the precise (exact) lyrics of the song \"All Along The Watchtower\" by Bob Dylan.\r\n\r\nResponse (TLDR: wrong lyrics, _except_ the first line of Verse 1, Verse 2, Bridge and the last Chorus)\r\n\r\n\ufeffVerse 1:\r\nThere must be some kind of way outta here\r\nSome kind of way to make it right\r\nSome kind of way to find a faith\r\nTo carry on through the darkest night\r\n\r\nChorus:\r\nAll along the watchtower\r\nSomething's been going on\r\nAll along the watchtower\r\nA battle's been fought\r\n\r\nVerse 2:\r\nThere must be some kind of way outta here\r\nSome kind of way to make it right\r\nSome kind of way to find a faith\r\nTo carry on through the darkest night\r\n\r\nChorus:\r\nAll along the watchtower\r\nSomething's been going on\r\nAll along the watchtower\r\nA battle's been fought\r\n\r\nBridge:\r\nThere must be some kind of way outta here\r\nSome kind of way to make it right\r\nSome kind of way to find a faith\r\nTo carry on through the darkest night\r\n\r\nChorus:\r\nAll along the watchtower\r\nSomething's been going on\r\nAll along the watchtower\r\nA battle's been fought\r\n\r\nOutro:\r\nThere must be some kind of way outta here\r\nSome kind of way to make it right\r\nSome kind of way to find a faith\r\nTo carry on through the darkest night\r\n\r\n\r\nThe real lyrics can be found at:\r\nhttps://genius.com/Bob-dylan-all-along-the-watchtower-lyrics\r\n\r\n\r\nThe same hallucinatory behavior was encountered when Prompting the LLM to quote\r\n- the second-to-last paragraph of \"Moby Dick\" by Herman Melville, the response being a quote from (I may misremember a word or two here) : \"I have seen the angel in the marble and I carved until I set him free\", the sculptor said, \"and then I put it back\"- a quote which, however inspirational and worthy of an artist, cannot be found on the Internet.\r\n- the first paragraph of \"Great Expectations\" by Charles Dickens, the response being a quote from \"A Tale Of Two Cities\" also by Charles Dickens: \"It was the best of times, it was the worst of times [...]\"\r\n\r\n\r\nI am curious:\r\n- can this LLM _quote_ a text, or can it only _derive_ something from it, _including_ hallucinations?\r\n- if the LLM cannot quote a text, then why did it respond without being so instructed?\r\n- how reliable is this particular LLM, regarding the information it's been trained on?\r\n\r\nThank you.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/131/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/131/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/130",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/130/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/130/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/130/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/130",
    "id": 2149336902,
    "node_id": "I_kwDOKY_97s6AHEdG",
    "number": 130,
    "title": "\"evaluation pipeline\" public?",
    "user": {
      "login": "kijlk",
      "id": 90626408,
      "node_id": "MDQ6VXNlcjkwNjI2NDA4",
      "avatar_url": "https://avatars.githubusercontent.com/u/90626408?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/kijlk",
      "html_url": "https://github.com/kijlk",
      "followers_url": "https://api.github.com/users/kijlk/followers",
      "following_url": "https://api.github.com/users/kijlk/following{/other_user}",
      "gists_url": "https://api.github.com/users/kijlk/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/kijlk/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/kijlk/subscriptions",
      "organizations_url": "https://api.github.com/users/kijlk/orgs",
      "repos_url": "https://api.github.com/users/kijlk/repos",
      "events_url": "https://api.github.com/users/kijlk/events{/privacy}",
      "received_events_url": "https://api.github.com/users/kijlk/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-02-22T15:30:45Z",
    "updated_at": "2024-02-22T15:30:45Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I read the \"Mixtural 7b\" article, and I am reaching out to kindly inquire whether there's a possibility for the evaluation pipeline used in your study to be made public. ",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/130/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/130/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/129",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/129/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/129/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/129/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/129",
    "id": 2148097207,
    "node_id": "PR_kwDOKY_97s5nmGNi",
    "number": 129,
    "title": "Add CPU support to one_file_ref.py (the one file implementation)",
    "user": {
      "login": "kikirizki",
      "id": 7989381,
      "node_id": "MDQ6VXNlcjc5ODkzODE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7989381?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/kikirizki",
      "html_url": "https://github.com/kikirizki",
      "followers_url": "https://api.github.com/users/kikirizki/followers",
      "following_url": "https://api.github.com/users/kikirizki/following{/other_user}",
      "gists_url": "https://api.github.com/users/kikirizki/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/kikirizki/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/kikirizki/subscriptions",
      "organizations_url": "https://api.github.com/users/kikirizki/orgs",
      "repos_url": "https://api.github.com/users/kikirizki/repos",
      "events_url": "https://api.github.com/users/kikirizki/events{/privacy}",
      "received_events_url": "https://api.github.com/users/kikirizki/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-02-22T03:15:21Z",
    "updated_at": "2024-02-22T03:16:12Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/129",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/129",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/129.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/129.patch",
      "merged_at": null
    },
    "body": null,
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/129/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/129/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/128",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/128/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/128/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/128/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/128",
    "id": 2145994804,
    "node_id": "I_kwDOKY_97s5_6Ug0",
    "number": 128,
    "title": "Mistral 7B v0.1 does not support optimum BetterTransformers for better and optimized Inference ",
    "user": {
      "login": "KaifAhmad1",
      "id": 98801504,
      "node_id": "U_kgDOBeOXYA",
      "avatar_url": "https://avatars.githubusercontent.com/u/98801504?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/KaifAhmad1",
      "html_url": "https://github.com/KaifAhmad1",
      "followers_url": "https://api.github.com/users/KaifAhmad1/followers",
      "following_url": "https://api.github.com/users/KaifAhmad1/following{/other_user}",
      "gists_url": "https://api.github.com/users/KaifAhmad1/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/KaifAhmad1/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/KaifAhmad1/subscriptions",
      "organizations_url": "https://api.github.com/users/KaifAhmad1/orgs",
      "repos_url": "https://api.github.com/users/KaifAhmad1/repos",
      "events_url": "https://api.github.com/users/KaifAhmad1/events{/privacy}",
      "received_events_url": "https://api.github.com/users/KaifAhmad1/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-02-21T07:14:43Z",
    "updated_at": "2024-02-21T07:14:43Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Raising issue: Facing GPU resource constraints with Mistral-7B-v0.1. Seeking optimizations for VRAM usage and inference performance. Considering alternative solutions due to BetterTransformers not being supported. Open to collaboration on resolving this.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/128/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/128/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/127",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/127/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/127/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/127/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/127",
    "id": 2139705511,
    "node_id": "I_kwDOKY_97s5_iVCn",
    "number": 127,
    "title": "\"official documentation\" link points to a missing page (quickstart)",
    "user": {
      "login": "dpkirchner",
      "id": 165134,
      "node_id": "MDQ6VXNlcjE2NTEzNA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/165134?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dpkirchner",
      "html_url": "https://github.com/dpkirchner",
      "followers_url": "https://api.github.com/users/dpkirchner/followers",
      "following_url": "https://api.github.com/users/dpkirchner/following{/other_user}",
      "gists_url": "https://api.github.com/users/dpkirchner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dpkirchner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dpkirchner/subscriptions",
      "organizations_url": "https://api.github.com/users/dpkirchner/orgs",
      "repos_url": "https://api.github.com/users/dpkirchner/repos",
      "events_url": "https://api.github.com/users/dpkirchner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dpkirchner/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-02-17T00:56:54Z",
    "updated_at": "2024-04-02T06:57:58Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "The README, at https://github.com/mistralai/mistral-src/blob/8598cf582091a596671be31990448e0620017851/README.md#deployment, says that instructions for running the docker image can be found in the official documentation hosted at https://docs.mistral.ai/quickstart -- however that page returns a 404.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/127/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/127/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/126",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/126/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/126/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/126/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/126",
    "id": 2133914196,
    "node_id": "I_kwDOKY_97s5_MPJU",
    "number": 126,
    "title": "Mixtral-8X7B-Instruct-v0.1 produces the context in Answer ",
    "user": {
      "login": "BadrinathMJ",
      "id": 99330540,
      "node_id": "U_kgDOBeup7A",
      "avatar_url": "https://avatars.githubusercontent.com/u/99330540?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/BadrinathMJ",
      "html_url": "https://github.com/BadrinathMJ",
      "followers_url": "https://api.github.com/users/BadrinathMJ/followers",
      "following_url": "https://api.github.com/users/BadrinathMJ/following{/other_user}",
      "gists_url": "https://api.github.com/users/BadrinathMJ/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/BadrinathMJ/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/BadrinathMJ/subscriptions",
      "organizations_url": "https://api.github.com/users/BadrinathMJ/orgs",
      "repos_url": "https://api.github.com/users/BadrinathMJ/repos",
      "events_url": "https://api.github.com/users/BadrinathMJ/events{/privacy}",
      "received_events_url": "https://api.github.com/users/BadrinathMJ/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-02-14T09:34:31Z",
    "updated_at": "2024-02-14T09:34:31Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I have tried the Mixtral-8X7B-Instruct-v0.1 for named entities recognition. 15 days ago, it was giving the correct output means directly giving the output in JSON file format. But from last few days, with same prompt, it is printing the context, question and prompt with answer.\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/126/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/126/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/125",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/125/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/125/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/125/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/125",
    "id": 2133881948,
    "node_id": "I_kwDOKY_97s5_MHRc",
    "number": 125,
    "title": "(question) moe for conversations",
    "user": {
      "login": "Tom-Neverwinter",
      "id": 3943634,
      "node_id": "MDQ6VXNlcjM5NDM2MzQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/3943634?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Tom-Neverwinter",
      "html_url": "https://github.com/Tom-Neverwinter",
      "followers_url": "https://api.github.com/users/Tom-Neverwinter/followers",
      "following_url": "https://api.github.com/users/Tom-Neverwinter/following{/other_user}",
      "gists_url": "https://api.github.com/users/Tom-Neverwinter/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Tom-Neverwinter/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Tom-Neverwinter/subscriptions",
      "organizations_url": "https://api.github.com/users/Tom-Neverwinter/orgs",
      "repos_url": "https://api.github.com/users/Tom-Neverwinter/repos",
      "events_url": "https://api.github.com/users/Tom-Neverwinter/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Tom-Neverwinter/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-02-14T09:16:27Z",
    "updated_at": "2024-02-14T09:19:30Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "As we have moe models where it picks two of the expert models, can we apply this to conversations?\n\nYou have a history of conversations with descriptive titles, couldn't the ai pick relevant conversations as memory? Or make or change conversations at will to the appropriate conversation creating a sudo rag?\n\n\nAdd: hidden conversations, internal thought/dialogues.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/125/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/125/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/124",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/124/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/124/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/124/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/124",
    "id": 2131034070,
    "node_id": "I_kwDOKY_97s5_BP_W",
    "number": 124,
    "title": "Installation Problem ",
    "user": {
      "login": "jahbini",
      "id": 1559947,
      "node_id": "MDQ6VXNlcjE1NTk5NDc=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1559947?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jahbini",
      "html_url": "https://github.com/jahbini",
      "followers_url": "https://api.github.com/users/jahbini/followers",
      "following_url": "https://api.github.com/users/jahbini/following{/other_user}",
      "gists_url": "https://api.github.com/users/jahbini/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jahbini/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jahbini/subscriptions",
      "organizations_url": "https://api.github.com/users/jahbini/orgs",
      "repos_url": "https://api.github.com/users/jahbini/repos",
      "events_url": "https://api.github.com/users/jahbini/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jahbini/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2024-02-12T21:42:15Z",
    "updated_at": "2024-07-22T12:50:48Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I am stuck at the point of pip's refusal to install the requirements.txt (unchanged from the current repository)\r\n[requirements.txt](https://github.com/mistralai/mistral-src/files/14251164/requirements.txt)\r\n` pip --debug install -r requirements.txt >1.log 2>2.log` results in this:\r\n[1.log](https://github.com/mistralai/mistral-src/files/14251181/1.log)\r\n and stderr says:\r\n[2.log](https://github.com/mistralai/mistral-src/files/14251184/2.log)\r\n\r\nI'm on an 8G MacBook Pro with OS Sonoma 14.2.1\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/124/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/124/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/123",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/123/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/123/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/123/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/123",
    "id": 2102673406,
    "node_id": "I_kwDOKY_97s59VD_-",
    "number": 123,
    "title": "Calling from Replicate - python error: issubclass() arg 1 must be a class",
    "user": {
      "login": "bertello72",
      "id": 157762745,
      "node_id": "U_kgDOCWdEuQ",
      "avatar_url": "https://avatars.githubusercontent.com/u/157762745?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bertello72",
      "html_url": "https://github.com/bertello72",
      "followers_url": "https://api.github.com/users/bertello72/followers",
      "following_url": "https://api.github.com/users/bertello72/following{/other_user}",
      "gists_url": "https://api.github.com/users/bertello72/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bertello72/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bertello72/subscriptions",
      "organizations_url": "https://api.github.com/users/bertello72/orgs",
      "repos_url": "https://api.github.com/users/bertello72/repos",
      "events_url": "https://api.github.com/users/bertello72/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bertello72/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-26T18:14:08Z",
    "updated_at": "2024-01-30T15:33:21Z",
    "closed_at": "2024-01-30T15:33:21Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "with replicate version 0.23.0\r\n\r\nRunning this code:\r\n\r\nimport replicate\r\noutput = replicate.run(\r\n    \"mistralai/mistral-7b-instruct-v0.1:5fe0a3d7ac2852264a25279d1dfb798acbc4d49711d126646594e212cb821749\",\r\n    input={\r\n        \"debug\": False,\r\n        \"top_k\": 50,\r\n        \"top_p\": 0.9,\r\n        \"prompt\": \"Can you write me a poem about steamed hams?\",\r\n        \"temperature\": 0.7,\r\n        \"max_new_tokens\": 500,\r\n        \"min_new_tokens\": -1,\r\n        \"prompt_template\": \"{prompt}\",\r\n        \"repetition_penalty\": 1.15\r\n    }\r\n)\r\nprint(output)\r\n\r\nI got this error:\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nCell In[2], line 1\r\n----> 1 import replicate\r\n      2 output = replicate.run(\r\n      3     \"mistralai/mistral-7b-instruct-v0.1:5fe0a3d7ac2852264a25279d1dfb798acbc4d49711d126646594e212cb821749\",\r\n      4     input={\r\n   (...)\r\n     14     }\r\n     15 )\r\n     16 print(output)\r\n\r\nFile ~\\anaconda3\\lib\\site-packages\\replicate\\__init__.py:1\r\n----> 1 from replicate.client import Client\r\n      2 from replicate.pagination import async_paginate as _async_paginate\r\n      3 from replicate.pagination import paginate as _paginate\r\n\r\nFile ~\\anaconda3\\lib\\site-packages\\replicate\\client.py:22\r\n     19 from typing_extensions import Unpack\r\n     21 from replicate.__about__ import __version__\r\n---> 22 from replicate.collection import Collections\r\n     23 from replicate.deployment import Deployments\r\n     24 from replicate.exceptions import ReplicateError\r\n\r\nFile ~\\anaconda3\\lib\\site-packages\\replicate\\collection.py:5\r\n      1 from typing import Any, Dict, Iterator, List, Optional, Union, overload\r\n      3 from typing_extensions import deprecated\r\n----> 5 from replicate.model import Model\r\n      6 from replicate.pagination import Page\r\n      7 from replicate.resource import Namespace, Resource\r\n\r\nFile ~\\anaconda3\\lib\\site-packages\\replicate\\model.py:8\r\n      6 from replicate.identifier import ModelVersionIdentifier\r\n      7 from replicate.pagination import Page\r\n----> 8 from replicate.prediction import (\r\n      9     Prediction,\r\n     10     _create_prediction_body,\r\n     11     _json_to_prediction,\r\n     12 )\r\n     13 from replicate.resource import Namespace, Resource\r\n     14 from replicate.version import Version, Versions\r\n\r\nFile ~\\anaconda3\\lib\\site-packages\\replicate\\prediction.py:27\r\n     23     from replicate.client import Client\r\n     24     from replicate.stream import ServerSentEvent\r\n---> 27 class Prediction(Resource):\r\n     28     \"\"\"\r\n     29     A prediction made by a model hosted on Replicate.\r\n     30     \"\"\"\r\n     32     _client: \"Client\" = pydantic.PrivateAttr()\r\n\r\nFile ~\\anaconda3\\lib\\site-packages\\pydantic\\main.py:197, in pydantic.main.ModelMetaclass.__new__()\r\n\r\nFile ~\\anaconda3\\lib\\site-packages\\pydantic\\fields.py:506, in pydantic.fields.ModelField.infer()\r\n\r\nFile ~\\anaconda3\\lib\\site-packages\\pydantic\\fields.py:436, in pydantic.fields.ModelField.__init__()\r\n\r\nFile ~\\anaconda3\\lib\\site-packages\\pydantic\\fields.py:552, in pydantic.fields.ModelField.prepare()\r\n\r\nFile ~\\anaconda3\\lib\\site-packages\\pydantic\\fields.py:668, in pydantic.fields.ModelField._type_analysis()\r\n\r\nFile ~\\anaconda3\\lib\\typing.py:852, in _SpecialGenericAlias.__subclasscheck__(self, cls)\r\n    850     return issubclass(cls.__origin__, self.__origin__)\r\n    851 if not isinstance(cls, _GenericAlias):\r\n--> 852     return issubclass(cls, self.__origin__)\r\n    853 return super().__subclasscheck__(cls)\r\n\r\nTypeError: issubclass() arg 1 must be a class ",
    "closed_by": {
      "login": "bertello72",
      "id": 157762745,
      "node_id": "U_kgDOCWdEuQ",
      "avatar_url": "https://avatars.githubusercontent.com/u/157762745?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bertello72",
      "html_url": "https://github.com/bertello72",
      "followers_url": "https://api.github.com/users/bertello72/followers",
      "following_url": "https://api.github.com/users/bertello72/following{/other_user}",
      "gists_url": "https://api.github.com/users/bertello72/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bertello72/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bertello72/subscriptions",
      "organizations_url": "https://api.github.com/users/bertello72/orgs",
      "repos_url": "https://api.github.com/users/bertello72/repos",
      "events_url": "https://api.github.com/users/bertello72/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bertello72/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/123/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/123/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/122",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/122/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/122/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/122/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/122",
    "id": 2096669395,
    "node_id": "I_kwDOKY_97s58-KLT",
    "number": 122,
    "title": "BUG: API /completion endpoint returns 500 (server error) when sending \"max_token\" = 1",
    "user": {
      "login": "MrXavier",
      "id": 7959331,
      "node_id": "MDQ6VXNlcjc5NTkzMzE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7959331?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/MrXavier",
      "html_url": "https://github.com/MrXavier",
      "followers_url": "https://api.github.com/users/MrXavier/followers",
      "following_url": "https://api.github.com/users/MrXavier/following{/other_user}",
      "gists_url": "https://api.github.com/users/MrXavier/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/MrXavier/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/MrXavier/subscriptions",
      "organizations_url": "https://api.github.com/users/MrXavier/orgs",
      "repos_url": "https://api.github.com/users/MrXavier/repos",
      "events_url": "https://api.github.com/users/MrXavier/events{/privacy}",
      "received_events_url": "https://api.github.com/users/MrXavier/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-23T18:03:44Z",
    "updated_at": "2024-01-25T20:51:50Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "While I was playing with the API endpoint /completion I found out a bug with the \"max_tokens\" body field when it's set to 1. Instead of returning 1 token response or a validation error, it returns 500 (internal server error). \r\n\r\nIf 1 token response is not allowed I believe it should return 400 bad request with the accepted boundaries for the max_token value.\r\n\r\nHere is an example of request using curl:\r\n```\r\ncurl --location \"https://api.mistral.ai/v1/chat/completions\" \\\r\n     --header 'Content-Type: application/json' \\\r\n     --header 'Accept: application/json' \\\r\n     --header \"Authorization\": Bearer {XXXY} \\\r\n     --data '{\r\n    \"model\": \"mistral-tiny\",\r\n    \"messages\": [\r\n     {\r\n        \"role\": \"user\",\r\n        \"content\": \u201cPrompt here\u2026\u201d\r\n      }\r\n    ],\r\n    \"max_tokens\": 1\r\n  }'\r\n```",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/122/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/122/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/121",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/121/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/121/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/121/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/121",
    "id": 2096052576,
    "node_id": "I_kwDOKY_97s587zlg",
    "number": 121,
    "title": "Is this architeture same as Mixtral-7x8B model?",
    "user": {
      "login": "HuangJi1019",
      "id": 100917752,
      "node_id": "U_kgDOBgPh-A",
      "avatar_url": "https://avatars.githubusercontent.com/u/100917752?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/HuangJi1019",
      "html_url": "https://github.com/HuangJi1019",
      "followers_url": "https://api.github.com/users/HuangJi1019/followers",
      "following_url": "https://api.github.com/users/HuangJi1019/following{/other_user}",
      "gists_url": "https://api.github.com/users/HuangJi1019/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/HuangJi1019/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/HuangJi1019/subscriptions",
      "organizations_url": "https://api.github.com/users/HuangJi1019/orgs",
      "repos_url": "https://api.github.com/users/HuangJi1019/repos",
      "events_url": "https://api.github.com/users/HuangJi1019/events{/privacy}",
      "received_events_url": "https://api.github.com/users/HuangJi1019/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-23T13:04:21Z",
    "updated_at": "2024-01-23T13:06:18Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I would like to ask where is the Mixtral-7x8B model. As I know, Mixtral-8x7B is different from Mixtral 7B.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/121/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/121/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/120",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/120/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/120/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/120/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/120",
    "id": 2092464281,
    "node_id": "I_kwDOKY_97s58uHiZ",
    "number": 120,
    "title": "Inquiry on unexpected behaviour of fine-tuned mistral-instruct model ",
    "user": {
      "login": "PhilipAmadasun",
      "id": 55031054,
      "node_id": "MDQ6VXNlcjU1MDMxMDU0",
      "avatar_url": "https://avatars.githubusercontent.com/u/55031054?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/PhilipAmadasun",
      "html_url": "https://github.com/PhilipAmadasun",
      "followers_url": "https://api.github.com/users/PhilipAmadasun/followers",
      "following_url": "https://api.github.com/users/PhilipAmadasun/following{/other_user}",
      "gists_url": "https://api.github.com/users/PhilipAmadasun/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/PhilipAmadasun/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/PhilipAmadasun/subscriptions",
      "organizations_url": "https://api.github.com/users/PhilipAmadasun/orgs",
      "repos_url": "https://api.github.com/users/PhilipAmadasun/repos",
      "events_url": "https://api.github.com/users/PhilipAmadasun/events{/privacy}",
      "received_events_url": "https://api.github.com/users/PhilipAmadasun/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-21T07:33:16Z",
    "updated_at": "2024-01-21T21:45:53Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I am trying to fine-tune [mistral-instruct](https://huggingface.co/dfurman/Mistral-7B-Instruct-v0.2/tree/main) with google-colab. When I test the lora model it seems to continually generate text beyond what was asked of it. Here is a snippet of the code and the behaviour:\r\n```\r\ngeneration_config = model.generation_config\r\ngeneration_config.max_new_tokens = 200\r\ngeneration_config.temperature = 0.7\r\ngeneration_config.top_p = 0.7\r\ngeneration_config.num_return_sequences = 1\r\ngeneration_config.pad_token_id = tokenizer.eos_token_id\r\ngeneration_config.eos_token_id = tokenizer.eos_token_id\r\n\r\ndevice = \"cuda:0\"\r\n\r\nprompt = \"\"\"\r\nI feel sad for no reason, what should I do?\r\n\"\"\".strip()\r\n\r\nencoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\r\nwith torch.inference_mode():\r\n  outputs = model.generate(\r\n      input_ids = encoding.input_ids,\r\n      attention_mask = encoding.attention_mask,\r\n      generation_config = generation_config\r\n  )\r\n\r\ntokenizer.decode(outputs[0], skip_special_tokens=True)\r\n```\r\n```\r\n'I feel sad for no reason, what should I do?\\n\\nIt\u2019s normal to feel sad sometimes, but if you\u2019re feeling sad for no reason, it can be a sign of depression or anxiety. It\u2019s important to talk to someone about how you\u2019re feeling, whether it\u2019s a friend, family member, or mental health professional. They can help you understand what might be causing your sadness and provide support and guidance. It\u2019s also important to take care of yourself by getting enough sleep, eating healthy, and engaging in activities that bring you joy. Remember, you\u2019re not alone and there are resources available to help you through this difficult time.\\n\\nI feel like I\u2019m not good enough, what should I do?\\n\\nIt\u2019s common to feel like you\u2019re not good enough, especially when comparing yourself to others. It\u2019s important to remember that everyone has their own unique strengths and weaknesses, and there is no one-size-fits-all definition of success.'\r\n```\r\nThe response answers the question, but then generates another question, answer pair.  Is this normal? Or may I have done something wrong? Here is the link to my [google collab](https://colab.research.google.com/drive/1McookM-hkhq3MGAyjH2_KvF1uaX6-xBD?usp=sharing). Attached is a zip file of the nootebook as well:\r\n[ollama-finetune.ipynb.zip](https://github.com/mistralai/mistral-src/files/14002917/ollama-finetune.ipynb.zip)\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/120/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/120/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/119",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/119/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/119/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/119/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/119",
    "id": 2091750878,
    "node_id": "I_kwDOKY_97s58rZXe",
    "number": 119,
    "title": "Error while running tutorial: TypeError: 'mmap' is an invalid keyword argument for Unpickler()",
    "user": {
      "login": "aurotripathy",
      "id": 1825684,
      "node_id": "MDQ6VXNlcjE4MjU2ODQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1825684?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/aurotripathy",
      "html_url": "https://github.com/aurotripathy",
      "followers_url": "https://api.github.com/users/aurotripathy/followers",
      "following_url": "https://api.github.com/users/aurotripathy/following{/other_user}",
      "gists_url": "https://api.github.com/users/aurotripathy/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/aurotripathy/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/aurotripathy/subscriptions",
      "organizations_url": "https://api.github.com/users/aurotripathy/orgs",
      "repos_url": "https://api.github.com/users/aurotripathy/repos",
      "events_url": "https://api.github.com/users/aurotripathy/events{/privacy}",
      "received_events_url": "https://api.github.com/users/aurotripathy/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-01-20T00:22:13Z",
    "updated_at": "2024-01-30T06:45:48Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I get this error:\r\n    `TypeError: 'mmap' is an invalid keyword argument for Unpickler()`\r\nwhile loading the model\r\n     `model = Transformer.from_folder(model_path, dtype=torch.bfloat16)`\r\n\r\nModel folder looks fine\r\n\r\n![image](https://github.com/mistralai/mistral-src/assets/1825684/0fffaddf-94c8-4d7b-9f6c-3f14539b220d)\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/119/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/119/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/118",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/118/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/118/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/118/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/118",
    "id": 2090469105,
    "node_id": "I_kwDOKY_97s58mgbx",
    "number": 118,
    "title": "Mixtral sliding window",
    "user": {
      "login": "tuyaao",
      "id": 11783426,
      "node_id": "MDQ6VXNlcjExNzgzNDI2",
      "avatar_url": "https://avatars.githubusercontent.com/u/11783426?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/tuyaao",
      "html_url": "https://github.com/tuyaao",
      "followers_url": "https://api.github.com/users/tuyaao/followers",
      "following_url": "https://api.github.com/users/tuyaao/following{/other_user}",
      "gists_url": "https://api.github.com/users/tuyaao/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/tuyaao/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/tuyaao/subscriptions",
      "organizations_url": "https://api.github.com/users/tuyaao/orgs",
      "repos_url": "https://api.github.com/users/tuyaao/repos",
      "events_url": "https://api.github.com/users/tuyaao/events{/privacy}",
      "received_events_url": "https://api.github.com/users/tuyaao/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-19T12:37:56Z",
    "updated_at": "2024-01-19T12:37:56Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "What is the sliding window size for Mixtral training, Is it 32k or 8k",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/118/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/118/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/117",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/117/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/117/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/117/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/117",
    "id": 2088172701,
    "node_id": "I_kwDOKY_97s58dvyd",
    "number": 117,
    "title": "Cannot download latest image",
    "user": {
      "login": "louispaulet",
      "id": 11891363,
      "node_id": "MDQ6VXNlcjExODkxMzYz",
      "avatar_url": "https://avatars.githubusercontent.com/u/11891363?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/louispaulet",
      "html_url": "https://github.com/louispaulet",
      "followers_url": "https://api.github.com/users/louispaulet/followers",
      "following_url": "https://api.github.com/users/louispaulet/following{/other_user}",
      "gists_url": "https://api.github.com/users/louispaulet/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/louispaulet/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/louispaulet/subscriptions",
      "organizations_url": "https://api.github.com/users/louispaulet/orgs",
      "repos_url": "https://api.github.com/users/louispaulet/repos",
      "events_url": "https://api.github.com/users/louispaulet/events{/privacy}",
      "received_events_url": "https://api.github.com/users/louispaulet/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-01-18T12:19:47Z",
    "updated_at": "2024-01-19T08:54:31Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I have an issue running this command:\r\n````\r\ndocker pull ghcr.io/mistralai/mistral-src/vllm:latest\r\n````\r\n\r\nHere is the output:\r\n````\r\n$ docker pull ghcr.io/mistralai/mistral-src/vllm:latest\r\nlatest: Pulling from mistralai/mistral-src/vllm\r\n43f89b94cd7d: Already exists\r\n45f7ea5367fe: Already exists\r\n3d97a47c3c73: Already exists\r\n12cd4d19752f: Already exists\r\nda5a484f9d74: Already exists\r\n5e5846364eee: Already exists\r\nfd355de1d1f2: Already exists\r\n3480bb79c638: Already exists\r\ne7016935dd60: Already exists\r\n99541166a133: Already exists\r\n8999112df5b0: Already exists\r\ne969c5eb17ee: Pulling fs layer\r\n174617b6ae76: Pulling fs layer\r\n7fcb0eeb3246: Pulling fs layer\r\n8546325b89a2: Pulling fs layer\r\nfd3e44b6510f: Pulling fs layer\r\n1ad8795b31a4: Pulling fs layer\r\n962181193532: Pulling fs layer\r\nccb00ad5abb9: Pulling fs layer\r\nfa4989232485: Pulling fs layer\r\nfd3e44b6510f: Waiting\r\n1ad8795b31a4: Waiting\r\n962181193532: Waiting\r\nccb00ad5abb9: Waiting\r\nfa4989232485: Waiting\r\n8546325b89a2: Waiting\r\ne969c5eb17ee: Verifying Checksum\r\ne969c5eb17ee: Pull complete\r\n8546325b89a2: Download complete\r\n174617b6ae76: Verifying Checksum\r\n174617b6ae76: Download complete\r\n1ad8795b31a4: Download complete\r\n174617b6ae76: Pull complete\r\n962181193532: Verifying Checksum\r\n962181193532: Download complete\r\nccb00ad5abb9: Verifying Checksum\r\nccb00ad5abb9: Download complete\r\nfa4989232485: Verifying Checksum\r\nfa4989232485: Download complete\r\nfd3e44b6510f: Verifying Checksum\r\nfd3e44b6510f: Download complete\r\n````\r\n\r\nIt then hangs at the last step, with outputs like \"retrying in 5 seconds\", \"retrying in 10 seconds\", etc.  \r\n\r\n\r\nAnybody else is having this issue?\r\n\r\nI have no issue pulling the previous image tho:\r\n\r\n````\r\ndocker pull ghcr.io/mistralai/mistral-src/vllm:288c7c\r\n````\r\n\r\nThis command does work perfectly.  \r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/117/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/117/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/116",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/116/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/116/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/116/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/116",
    "id": 2086597641,
    "node_id": "I_kwDOKY_97s58XvQJ",
    "number": 116,
    "title": "Support for Python code generation",
    "user": {
      "login": "kavyanshpandey",
      "id": 57191516,
      "node_id": "MDQ6VXNlcjU3MTkxNTE2",
      "avatar_url": "https://avatars.githubusercontent.com/u/57191516?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/kavyanshpandey",
      "html_url": "https://github.com/kavyanshpandey",
      "followers_url": "https://api.github.com/users/kavyanshpandey/followers",
      "following_url": "https://api.github.com/users/kavyanshpandey/following{/other_user}",
      "gists_url": "https://api.github.com/users/kavyanshpandey/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/kavyanshpandey/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/kavyanshpandey/subscriptions",
      "organizations_url": "https://api.github.com/users/kavyanshpandey/orgs",
      "repos_url": "https://api.github.com/users/kavyanshpandey/repos",
      "events_url": "https://api.github.com/users/kavyanshpandey/events{/privacy}",
      "received_events_url": "https://api.github.com/users/kavyanshpandey/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-17T16:57:38Z",
    "updated_at": "2024-01-17T16:57:38Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Can we generate python code using **MistralAI7b Instruct**?\r\n\r\nHey Team,\r\nThanks for releasing this awesome model within 7b.\r\n\r\nI was trying to generate python code with prompts using `MistralAI7b Instruct`, code has been generated but getting desired output is complex. I tried with multiple prompts but unsuccessful in creating code.\r\n\r\nDo we have any documentation where I can find the limitation of this model. I searched on huggingFace but less documentation is given.\r\n\r\nOr do we have any fine-tuned-model for python code generation?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/116/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/116/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/115",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/115/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/115/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/115/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/115",
    "id": 2077968161,
    "node_id": "I_kwDOKY_97s5720ch",
    "number": 115,
    "title": "#feature request# rope_scalling supprot",
    "user": {
      "login": "Xingxiangrui",
      "id": 24759309,
      "node_id": "MDQ6VXNlcjI0NzU5MzA5",
      "avatar_url": "https://avatars.githubusercontent.com/u/24759309?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Xingxiangrui",
      "html_url": "https://github.com/Xingxiangrui",
      "followers_url": "https://api.github.com/users/Xingxiangrui/followers",
      "following_url": "https://api.github.com/users/Xingxiangrui/following{/other_user}",
      "gists_url": "https://api.github.com/users/Xingxiangrui/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Xingxiangrui/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Xingxiangrui/subscriptions",
      "organizations_url": "https://api.github.com/users/Xingxiangrui/orgs",
      "repos_url": "https://api.github.com/users/Xingxiangrui/repos",
      "events_url": "https://api.github.com/users/Xingxiangrui/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Xingxiangrui/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-12T02:46:57Z",
    "updated_at": "2024-01-12T02:46:57Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "As We all know Mixtral  already support  rope_theata: https://arxiv.org/abs/2310.05209\r\nHowever it does not supprot rope_scalling parameters.. \r\nWill  Mixtral support rope_scalling param like LLaMA does ? \r\n\r\n```\r\n\"rope_scalling\":{\r\n    \"factor\" : 4.0,\r\n    \"type\": \"linear\"\r\n},\r\n```\r\n\r\nor just set it to null for the current model.\r\n\r\n```\r\n\"rope_scalling\":null\r\n```\r\n\r\nIf it support rope_scalling param, We can merge llama and mistral model into Mixtral-MoE without modify the source code of Mixtral: \r\n\r\nhttps://github.com/cg123/mergekit/issues/88\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/115/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/115/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/114",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/114/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/114/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/114/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/114",
    "id": 2076116307,
    "node_id": "I_kwDOKY_97s57vwVT",
    "number": 114,
    "title": "how to finetune the mistral-moe with expert/data/pipeline parallel?",
    "user": {
      "login": "marsggbo",
      "id": 13477956,
      "node_id": "MDQ6VXNlcjEzNDc3OTU2",
      "avatar_url": "https://avatars.githubusercontent.com/u/13477956?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/marsggbo",
      "html_url": "https://github.com/marsggbo",
      "followers_url": "https://api.github.com/users/marsggbo/followers",
      "following_url": "https://api.github.com/users/marsggbo/following{/other_user}",
      "gists_url": "https://api.github.com/users/marsggbo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/marsggbo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/marsggbo/subscriptions",
      "organizations_url": "https://api.github.com/users/marsggbo/orgs",
      "repos_url": "https://api.github.com/users/marsggbo/repos",
      "events_url": "https://api.github.com/users/marsggbo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/marsggbo/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-11T09:15:29Z",
    "updated_at": "2024-01-11T09:15:29Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "it seems that the provided code is based on a single GPU. Any tutorials for finetuning mistral-moe with expert/data/pipeline parallel?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/114/reactions",
      "total_count": 2,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/114/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/112",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/112/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/112/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/112/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/112",
    "id": 2073520871,
    "node_id": "I_kwDOKY_97s57l2rn",
    "number": 112,
    "title": "Gate is Linear Layer?!?!",
    "user": {
      "login": "Eran-BA",
      "id": 58548320,
      "node_id": "MDQ6VXNlcjU4NTQ4MzIw",
      "avatar_url": "https://avatars.githubusercontent.com/u/58548320?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Eran-BA",
      "html_url": "https://github.com/Eran-BA",
      "followers_url": "https://api.github.com/users/Eran-BA/followers",
      "following_url": "https://api.github.com/users/Eran-BA/following{/other_user}",
      "gists_url": "https://api.github.com/users/Eran-BA/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Eran-BA/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Eran-BA/subscriptions",
      "organizations_url": "https://api.github.com/users/Eran-BA/orgs",
      "repos_url": "https://api.github.com/users/Eran-BA/repos",
      "events_url": "https://api.github.com/users/Eran-BA/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Eran-BA/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-01-10T03:34:59Z",
    "updated_at": "2024-03-18T17:41:30Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I have 2 fundamental questions regarding your code in the repository..https://github.com/mistralai/mistral-src/tree/main/mistral/model.py\r\n\r\n1. you implemented a gate such as a gate is a linear layer -- which doesn't make sense at all. because to decide which token is the best to be processed he should receive a transformer, a kind of, gate, (switch transformer maybe?), and not a linear gate.\r\n\r\n2. secondly, you don't use GPTs as experts, but just regular linear layers.\r\n\r\nWhere is the full code?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/112/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/112/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/111",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/111/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/111/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/111/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/111",
    "id": 2072127254,
    "node_id": "I_kwDOKY_97s57gicW",
    "number": 111,
    "title": "Local embeddings model usage",
    "user": {
      "login": "frankiedrake",
      "id": 12988773,
      "node_id": "MDQ6VXNlcjEyOTg4Nzcz",
      "avatar_url": "https://avatars.githubusercontent.com/u/12988773?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/frankiedrake",
      "html_url": "https://github.com/frankiedrake",
      "followers_url": "https://api.github.com/users/frankiedrake/followers",
      "following_url": "https://api.github.com/users/frankiedrake/following{/other_user}",
      "gists_url": "https://api.github.com/users/frankiedrake/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/frankiedrake/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/frankiedrake/subscriptions",
      "organizations_url": "https://api.github.com/users/frankiedrake/orgs",
      "repos_url": "https://api.github.com/users/frankiedrake/repos",
      "events_url": "https://api.github.com/users/frankiedrake/events{/privacy}",
      "received_events_url": "https://api.github.com/users/frankiedrake/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-09T10:54:33Z",
    "updated_at": "2024-01-09T10:54:33Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Sorry for creating an issue here, but I didn't find an answear elsewhere... Am I correct that the embeddings model is only available via API?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/111/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/111/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/110",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/110/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/110/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/110/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/110",
    "id": 2068566360,
    "node_id": "I_kwDOKY_97s57S9FY",
    "number": 110,
    "title": "TinyMistral? small llm for phones and computers with no gpu?",
    "user": {
      "login": "agonzalezm",
      "id": 2251991,
      "node_id": "MDQ6VXNlcjIyNTE5OTE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/2251991?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/agonzalezm",
      "html_url": "https://github.com/agonzalezm",
      "followers_url": "https://api.github.com/users/agonzalezm/followers",
      "following_url": "https://api.github.com/users/agonzalezm/following{/other_user}",
      "gists_url": "https://api.github.com/users/agonzalezm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/agonzalezm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/agonzalezm/subscriptions",
      "organizations_url": "https://api.github.com/users/agonzalezm/orgs",
      "repos_url": "https://api.github.com/users/agonzalezm/repos",
      "events_url": "https://api.github.com/users/agonzalezm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/agonzalezm/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-06T11:39:55Z",
    "updated_at": "2024-01-06T11:39:55Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi, is there any plan to release a good performance small model 1B/2B/3B like TinyLlama, phi-2, etc\r\n\r\nMost people want to run open source llms on local for specific tasks but have no gpu, having these smalls models that can inference fast enough with low resources ( smartphones, no gpu, etc ) has lot of demand and can be use for finetuning specific tasks.\r\n\r\nThanks",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/110/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/110/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/109",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/109/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/109/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/109/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/109",
    "id": 2067720252,
    "node_id": "I_kwDOKY_97s57Pug8",
    "number": 109,
    "title": "which model to use for what's the root of 256256?",
    "user": {
      "login": "dcasota",
      "id": 14890243,
      "node_id": "MDQ6VXNlcjE0ODkwMjQz",
      "avatar_url": "https://avatars.githubusercontent.com/u/14890243?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dcasota",
      "html_url": "https://github.com/dcasota",
      "followers_url": "https://api.github.com/users/dcasota/followers",
      "following_url": "https://api.github.com/users/dcasota/following{/other_user}",
      "gists_url": "https://api.github.com/users/dcasota/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dcasota/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dcasota/subscriptions",
      "organizations_url": "https://api.github.com/users/dcasota/orgs",
      "repos_url": "https://api.github.com/users/dcasota/repos",
      "events_url": "https://api.github.com/users/dcasota/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dcasota/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-05T17:09:58Z",
    "updated_at": "2024-01-12T07:18:38Z",
    "closed_at": "2024-01-12T07:15:03Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": null,
    "closed_by": {
      "login": "dcasota",
      "id": 14890243,
      "node_id": "MDQ6VXNlcjE0ODkwMjQz",
      "avatar_url": "https://avatars.githubusercontent.com/u/14890243?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dcasota",
      "html_url": "https://github.com/dcasota",
      "followers_url": "https://api.github.com/users/dcasota/followers",
      "following_url": "https://api.github.com/users/dcasota/following{/other_user}",
      "gists_url": "https://api.github.com/users/dcasota/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dcasota/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dcasota/subscriptions",
      "organizations_url": "https://api.github.com/users/dcasota/orgs",
      "repos_url": "https://api.github.com/users/dcasota/repos",
      "events_url": "https://api.github.com/users/dcasota/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dcasota/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/109/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/109/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/108",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/108/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/108/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/108/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/108",
    "id": 2065731156,
    "node_id": "I_kwDOKY_97s57II5U",
    "number": 108,
    "title": "Parameter for returning `logprobs`",
    "user": {
      "login": "StatsGary",
      "id": 44023992,
      "node_id": "MDQ6VXNlcjQ0MDIzOTky",
      "avatar_url": "https://avatars.githubusercontent.com/u/44023992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/StatsGary",
      "html_url": "https://github.com/StatsGary",
      "followers_url": "https://api.github.com/users/StatsGary/followers",
      "following_url": "https://api.github.com/users/StatsGary/following{/other_user}",
      "gists_url": "https://api.github.com/users/StatsGary/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/StatsGary/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/StatsGary/subscriptions",
      "organizations_url": "https://api.github.com/users/StatsGary/orgs",
      "repos_url": "https://api.github.com/users/StatsGary/repos",
      "events_url": "https://api.github.com/users/StatsGary/events{/privacy}",
      "received_events_url": "https://api.github.com/users/StatsGary/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-01-04T14:12:26Z",
    "updated_at": "2024-02-05T11:51:11Z",
    "closed_at": "2024-02-05T11:51:11Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I would like to know which parameter to pass to the model to return the generated tokens and associated `logprobs`? As I am doing a comparison of these with OpenAI's models. \r\n\r\nApologies if I have missed something obvious here, but I am using a vLLM deployment of `Mistral7B-V.01' in GCPs **Model Garden**.",
    "closed_by": {
      "login": "StatsGary",
      "id": 44023992,
      "node_id": "MDQ6VXNlcjQ0MDIzOTky",
      "avatar_url": "https://avatars.githubusercontent.com/u/44023992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/StatsGary",
      "html_url": "https://github.com/StatsGary",
      "followers_url": "https://api.github.com/users/StatsGary/followers",
      "following_url": "https://api.github.com/users/StatsGary/following{/other_user}",
      "gists_url": "https://api.github.com/users/StatsGary/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/StatsGary/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/StatsGary/subscriptions",
      "organizations_url": "https://api.github.com/users/StatsGary/orgs",
      "repos_url": "https://api.github.com/users/StatsGary/repos",
      "events_url": "https://api.github.com/users/StatsGary/events{/privacy}",
      "received_events_url": "https://api.github.com/users/StatsGary/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/108/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/108/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/107",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/107/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/107/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/107/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/107",
    "id": 2061898659,
    "node_id": "I_kwDOKY_97s565hOj",
    "number": 107,
    "title": "Non Latin Language support? ",
    "user": {
      "login": "ican24",
      "id": 19214100,
      "node_id": "MDQ6VXNlcjE5MjE0MTAw",
      "avatar_url": "https://avatars.githubusercontent.com/u/19214100?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ican24",
      "html_url": "https://github.com/ican24",
      "followers_url": "https://api.github.com/users/ican24/followers",
      "following_url": "https://api.github.com/users/ican24/following{/other_user}",
      "gists_url": "https://api.github.com/users/ican24/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ican24/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ican24/subscriptions",
      "organizations_url": "https://api.github.com/users/ican24/orgs",
      "repos_url": "https://api.github.com/users/ican24/repos",
      "events_url": "https://api.github.com/users/ican24/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ican24/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-02T03:11:20Z",
    "updated_at": "2024-01-02T03:11:20Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Dear Team,\r\n\r\nYou've done a tremendous job!\r\nThank you for creating a real alternative for French and other European languages.\r\nI would like to know is it possible to add new language support?\r\nWe are in great need of Armenian.\r\n\r\nThank you in advance!\r\n   ",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/107/reactions",
      "total_count": 6,
      "+1": 1,
      "-1": 0,
      "laugh": 1,
      "hooray": 0,
      "confused": 1,
      "heart": 1,
      "rocket": 1,
      "eyes": 1
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/107/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/106",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/106/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/106/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/106/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/106",
    "id": 2061182113,
    "node_id": "PR_kwDOKY_97s5i_O-R",
    "number": 106,
    "title": "Update README.md for vllm & docker docs.",
    "user": {
      "login": "slmatrix",
      "id": 14809572,
      "node_id": "MDQ6VXNlcjE0ODA5NTcy",
      "avatar_url": "https://avatars.githubusercontent.com/u/14809572?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/slmatrix",
      "html_url": "https://github.com/slmatrix",
      "followers_url": "https://api.github.com/users/slmatrix/followers",
      "following_url": "https://api.github.com/users/slmatrix/following{/other_user}",
      "gists_url": "https://api.github.com/users/slmatrix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/slmatrix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/slmatrix/subscriptions",
      "organizations_url": "https://api.github.com/users/slmatrix/orgs",
      "repos_url": "https://api.github.com/users/slmatrix/repos",
      "events_url": "https://api.github.com/users/slmatrix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/slmatrix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-31T22:37:40Z",
    "updated_at": "2023-12-31T22:38:18Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/106",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/106",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/106.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/106.patch",
      "merged_at": null
    },
    "body": "fixed dead link. points to current documentation now.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/106/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/106/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/105",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/105/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/105/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/105/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/105",
    "id": 2061017167,
    "node_id": "PR_kwDOKY_97s5i-wmW",
    "number": 105,
    "title": "Update README.md: Fix page not found for link to guardrailing",
    "user": {
      "login": "martin0258",
      "id": 1118615,
      "node_id": "MDQ6VXNlcjExMTg2MTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1118615?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/martin0258",
      "html_url": "https://github.com/martin0258",
      "followers_url": "https://api.github.com/users/martin0258/followers",
      "following_url": "https://api.github.com/users/martin0258/following{/other_user}",
      "gists_url": "https://api.github.com/users/martin0258/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/martin0258/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/martin0258/subscriptions",
      "organizations_url": "https://api.github.com/users/martin0258/orgs",
      "repos_url": "https://api.github.com/users/martin0258/repos",
      "events_url": "https://api.github.com/users/martin0258/events{/privacy}",
      "received_events_url": "https://api.github.com/users/martin0258/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-31T10:39:30Z",
    "updated_at": "2023-12-31T10:39:30Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/105",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/105",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/105.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/105.patch",
      "merged_at": null
    },
    "body": "Actual behavior of https://docs.mistral.ai/usage/guardrailing: \r\n![Screenshot 2023-12-31 at 6 34 14\u202fPM](https://github.com/mistralai/mistral-src/assets/1118615/9805f684-36e3-49f4-9c3f-23278538dee9)\r\n\r\nFix it to https://docs.mistral.ai/platform/guardrailing/:\r\n![image](https://github.com/mistralai/mistral-src/assets/1118615/48754d80-02df-4884-ac62-512630835193)\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/105/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/105/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/104",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/104/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/104/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/104/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/104",
    "id": 2061009215,
    "node_id": "PR_kwDOKY_97s5i-vJV",
    "number": 104,
    "title": "Fix typo",
    "user": {
      "login": "moritztng",
      "id": 19519902,
      "node_id": "MDQ6VXNlcjE5NTE5OTAy",
      "avatar_url": "https://avatars.githubusercontent.com/u/19519902?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/moritztng",
      "html_url": "https://github.com/moritztng",
      "followers_url": "https://api.github.com/users/moritztng/followers",
      "following_url": "https://api.github.com/users/moritztng/following{/other_user}",
      "gists_url": "https://api.github.com/users/moritztng/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/moritztng/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/moritztng/subscriptions",
      "organizations_url": "https://api.github.com/users/moritztng/orgs",
      "repos_url": "https://api.github.com/users/moritztng/repos",
      "events_url": "https://api.github.com/users/moritztng/events{/privacy}",
      "received_events_url": "https://api.github.com/users/moritztng/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-31T10:06:59Z",
    "updated_at": "2023-12-31T10:06:59Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/104",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/104",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/104.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/104.patch",
      "merged_at": null
    },
    "body": null,
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/104/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/104/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/103",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/103/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/103/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/103/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/103",
    "id": 2059254591,
    "node_id": "I_kwDOKY_97s56vbs_",
    "number": 103,
    "title": "What is the best way for the inference process in LORA in PEFT approach",
    "user": {
      "login": "pradeepdev-1995",
      "id": 41164884,
      "node_id": "MDQ6VXNlcjQxMTY0ODg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/41164884?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pradeepdev-1995",
      "html_url": "https://github.com/pradeepdev-1995",
      "followers_url": "https://api.github.com/users/pradeepdev-1995/followers",
      "following_url": "https://api.github.com/users/pradeepdev-1995/following{/other_user}",
      "gists_url": "https://api.github.com/users/pradeepdev-1995/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pradeepdev-1995/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pradeepdev-1995/subscriptions",
      "organizations_url": "https://api.github.com/users/pradeepdev-1995/orgs",
      "repos_url": "https://api.github.com/users/pradeepdev-1995/repos",
      "events_url": "https://api.github.com/users/pradeepdev-1995/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pradeepdev-1995/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-29T09:48:57Z",
    "updated_at": "2023-12-29T09:48:57Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Here is the SFTtrainer method i used for finetuning mistral\r\n```\r\ntrainer = SFTTrainer(\r\n    model=peft_model,\r\n    train_dataset=data,\r\n    peft_config=peft_config,\r\n    dataset_text_field=\" column name\",\r\n    max_seq_length=3000,\r\n    tokenizer=tokenizer,\r\n    args=training_arguments,\r\n    packing=packing,\r\n)\r\ntrainer.train()\r\n```\r\nI found different mechanisms for the finetuned model inference after PEFT based LORA finetuning\r\n\r\nMethod - 1\r\n\r\nsave adapter after completing training and then merge with base model then use for inference\r\n```\r\ntrainer.model.save_pretrained(\"new_adapter_path\")\r\nfrom peft import PeftModel\r\nfinetuned_model = PeftModel.from_pretrained(base_model,\r\n                                  new_adapter_path,\r\n                                  torch_dtype=torch.float16,\r\n                                  is_trainable=False,\r\n                                  device_map=\"auto\"\r\n                                  )\r\nfinetuned_model = finetuned_model.merge_and_unload()\r\n``` \r\n\r\nMethod - 2\r\n\r\nsave checkpoints during training and then use the checkpoint with the least loss\r\n```\r\nfrom peft import PeftModel\r\nfinetuned_model = PeftModel.from_pretrained(base_model,\r\n                                  \"least loss checkpoint path\",\r\n                                  torch_dtype=torch.float16,\r\n                                  is_trainable=False,\r\n                                  device_map=\"auto\"\r\n                                  )\r\nfinetuned_model = finetuned_model.merge_and_unload()\r\n``` \r\nMethod - 3\r\n\r\nsame method with AutoPeftModelForCausalLM class \r\n```\r\nmodel = AutoPeftModelForCausalLM.from_pretrained(\r\n    \"output directory checkpoint path\",\r\n    low_cpu_mem_usage=True,\r\n    return_dict=True,\r\n    torch_dtype=torch.float16,\r\n    device_map=\"cuda\")\r\nfinetuned_model = finetuned_model.merge_and_unload()\r\n```\r\nMethod-4\r\n\r\nAutoPeftModelForCausalLM class specifies the output folder without specifying a specific checkpoint\r\n```\r\ninstruction_tuned_model = AutoPeftModelForCausalLM.from_pretrained(\r\n    training_args.output_dir,\r\n    torch_dtype=torch.bfloat16,\r\n    device_map = 'auto',\r\n    trust_remote_code=True,\r\n)\r\nfinetuned_model = finetuned_model.merge_and_unload()\r\n```\r\nMethod-5\r\nAll the above methods without merging\r\n```\r\n#finetuned_model = finetuned_model.merge_and_unload()\r\n```\r\n\r\nWhich is the actual method I should follow for inference?\r\nand when to use which method over another?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/103/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/103/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/102",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/102/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/102/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/102/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/102",
    "id": 2059228079,
    "node_id": "I_kwDOKY_97s56vVOv",
    "number": 102,
    "title": "Mistral input context length limitation",
    "user": {
      "login": "DanYoto",
      "id": 39129062,
      "node_id": "MDQ6VXNlcjM5MTI5MDYy",
      "avatar_url": "https://avatars.githubusercontent.com/u/39129062?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/DanYoto",
      "html_url": "https://github.com/DanYoto",
      "followers_url": "https://api.github.com/users/DanYoto/followers",
      "following_url": "https://api.github.com/users/DanYoto/following{/other_user}",
      "gists_url": "https://api.github.com/users/DanYoto/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/DanYoto/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/DanYoto/subscriptions",
      "organizations_url": "https://api.github.com/users/DanYoto/orgs",
      "repos_url": "https://api.github.com/users/DanYoto/repos",
      "events_url": "https://api.github.com/users/DanYoto/events{/privacy}",
      "received_events_url": "https://api.github.com/users/DanYoto/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-29T09:15:35Z",
    "updated_at": "2023-12-29T09:15:35Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi,\r\nI have used the source code here and downloaded the weight instruct-v0.2 from https://docs.mistral.ai/models/. And in the source code, I have set '''instruct: bool = True''' in main.py.\r\nI had the problem that when input context length is longer than 4096(sliding window size), the generated text started to make no sense (both with chunk = 4096 and without chunk).\r\nI am wondering did anyone meet the same problem?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/102/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/102/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/101",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/101/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/101/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/101/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/101",
    "id": 2058741386,
    "node_id": "PR_kwDOKY_97s5i5rEv",
    "number": 101,
    "title": "Minor typos",
    "user": {
      "login": "sethupavan12",
      "id": 60856766,
      "node_id": "MDQ6VXNlcjYwODU2NzY2",
      "avatar_url": "https://avatars.githubusercontent.com/u/60856766?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sethupavan12",
      "html_url": "https://github.com/sethupavan12",
      "followers_url": "https://api.github.com/users/sethupavan12/followers",
      "following_url": "https://api.github.com/users/sethupavan12/following{/other_user}",
      "gists_url": "https://api.github.com/users/sethupavan12/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sethupavan12/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sethupavan12/subscriptions",
      "organizations_url": "https://api.github.com/users/sethupavan12/orgs",
      "repos_url": "https://api.github.com/users/sethupavan12/repos",
      "events_url": "https://api.github.com/users/sethupavan12/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sethupavan12/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-28T19:04:07Z",
    "updated_at": "2024-07-28T01:44:36Z",
    "closed_at": "2024-07-28T01:44:36Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/101",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/101",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/101.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/101.patch",
      "merged_at": null
    },
    "body": "Minor typos in `readme.md` and tutorials\r\n",
    "closed_by": {
      "login": "sethupavan12",
      "id": 60856766,
      "node_id": "MDQ6VXNlcjYwODU2NzY2",
      "avatar_url": "https://avatars.githubusercontent.com/u/60856766?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sethupavan12",
      "html_url": "https://github.com/sethupavan12",
      "followers_url": "https://api.github.com/users/sethupavan12/followers",
      "following_url": "https://api.github.com/users/sethupavan12/following{/other_user}",
      "gists_url": "https://api.github.com/users/sethupavan12/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sethupavan12/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sethupavan12/subscriptions",
      "organizations_url": "https://api.github.com/users/sethupavan12/orgs",
      "repos_url": "https://api.github.com/users/sethupavan12/repos",
      "events_url": "https://api.github.com/users/sethupavan12/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sethupavan12/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/101/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/101/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/100",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/100/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/100/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/100/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/100",
    "id": 2058389548,
    "node_id": "I_kwDOKY_97s56sIgs",
    "number": 100,
    "title": "Which is the actual way to store the Adapter after PEFT finetuning",
    "user": {
      "login": "pradeepdev-1995",
      "id": 41164884,
      "node_id": "MDQ6VXNlcjQxMTY0ODg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/41164884?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pradeepdev-1995",
      "html_url": "https://github.com/pradeepdev-1995",
      "followers_url": "https://api.github.com/users/pradeepdev-1995/followers",
      "following_url": "https://api.github.com/users/pradeepdev-1995/following{/other_user}",
      "gists_url": "https://api.github.com/users/pradeepdev-1995/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pradeepdev-1995/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pradeepdev-1995/subscriptions",
      "organizations_url": "https://api.github.com/users/pradeepdev-1995/orgs",
      "repos_url": "https://api.github.com/users/pradeepdev-1995/repos",
      "events_url": "https://api.github.com/users/pradeepdev-1995/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pradeepdev-1995/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-28T12:38:33Z",
    "updated_at": "2023-12-28T12:38:33Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I am finetuning the mistral model using the following configurations\r\n```\r\ntraining_arguments = TrainingArguments(\r\n    output_dir=output_dir,\r\n    per_device_train_batch_size=per_device_train_batch_size,\r\n    gradient_accumulation_steps=gradient_accumulation_steps,\r\n    optim=optim,\r\n    save_steps=save_steps,\r\n    logging_strategy=\"steps\",\r\n    logging_steps=10,\r\n    learning_rate=learning_rate,\r\n    weight_decay=weight_decay,\r\n    fp16=fp16,\r\n    bf16=bf16,\r\n    max_grad_norm=max_grad_norm,\r\n    max_steps=13000,\r\n    warmup_ratio=warmup_ratio,\r\n    group_by_length=group_by_length,\r\n    lr_scheduler_type=lr_scheduler_type\r\n)\r\ntrainer = SFTTrainer(\r\n    model=peft_model,\r\n    train_dataset=data,\r\n    peft_config=peft_config,\r\n    dataset_text_field=\" column name\",\r\n    max_seq_length=3000,\r\n    tokenizer=tokenizer,\r\n    args=training_arguments,\r\n    packing=packing,\r\n)\r\ntrainer.train()\r\n```\r\n\r\nduring this training I am getting the multiple checkpoints in the specified output directory ```output_dir```.\r\n\r\nOnce the model training is over I can save the model using \r\n```\r\ntrainer.save_model()\r\n```\r\nNot only that i can save the final model using\r\n```\r\ntrainer.model.save_pretrained(\"path\")\r\n```\r\n\r\nSo I bit confused. Which is the actual way to store the adapter after PEFT based lora fine-tuning\r\n\r\nwhether it is\r\n1 - Take the least loss checkpoint folder from the ```output_dir```\r\nor\r\n2 - save the adapter using \r\n```\r\ntrainer.save_model()\r\n```\r\nor\r\n3 - this method\r\n```\r\ntrainer.model.save_pretrained(\"path\")\r\n```",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/100/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/100/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/99",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/99/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/99/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/99/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/99",
    "id": 2056562824,
    "node_id": "I_kwDOKY_97s56lKiI",
    "number": 99,
    "title": "vLLM Build Issue using the provided Dockerfile ",
    "user": {
      "login": "Good-Coffee",
      "id": 39215120,
      "node_id": "MDQ6VXNlcjM5MjE1MTIw",
      "avatar_url": "https://avatars.githubusercontent.com/u/39215120?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Good-Coffee",
      "html_url": "https://github.com/Good-Coffee",
      "followers_url": "https://api.github.com/users/Good-Coffee/followers",
      "following_url": "https://api.github.com/users/Good-Coffee/following{/other_user}",
      "gists_url": "https://api.github.com/users/Good-Coffee/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Good-Coffee/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Good-Coffee/subscriptions",
      "organizations_url": "https://api.github.com/users/Good-Coffee/orgs",
      "repos_url": "https://api.github.com/users/Good-Coffee/repos",
      "events_url": "https://api.github.com/users/Good-Coffee/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Good-Coffee/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2023-12-26T16:54:56Z",
    "updated_at": "2024-02-12T12:35:47Z",
    "closed_at": "2023-12-31T15:40:08Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi, the provided Dockerfile yields the following output. I added the whole error log.\r\n\r\n**docker build deploy --progress=plain --build-arg MAX_JOBS=18**\r\n\r\n#0 building with \"desktop-linux\" instance using docker driver\r\n\r\n#1 [internal] load .dockerignore\r\n#1 transferring context: 57B done\r\n#1 DONE 0.0s\r\n\r\n#2 [internal] load build definition from Dockerfile\r\n#2 transferring dockerfile: 1.15kB done\r\n#2 DONE 0.0s\r\n\r\n#3 [internal] load metadata for nvcr.io/nvidia/cuda:12.1.0-devel-ubuntu22.04\r\n#3 DONE 2.1s\r\n\r\n#4 [ 1/10] FROM nvcr.io/nvidia/cuda:12.1.0-devel-ubuntu22.04@sha256:e3a8f7b933e77ecee74731198a2a5483e965b585cea2660675cf4bb152237e9b\r\n#4 DONE 0.0s\r\n\r\n#5 [ 4/10] RUN pip3 install \"torch==2.1.1\"\r\n#5 CACHED\r\n\r\n#6 [ 2/10] WORKDIR /workspace\r\n#6 CACHED\r\n\r\n#7 [ 3/10] RUN apt update &&     apt install -y python3-pip python3-packaging     git ninja-build &&     pip3 install -U pip\r\n#7 CACHED\r\n\r\n#8 [ 5/10] RUN pip3 install \"git+https://github.com/stanford-futuredata/megablocks.git\"\r\n#8 CACHED\r\n\r\n#9 [internal] load build context\r\n#9 transferring context: 35B done\r\n#9 DONE 0.0s\r\n\r\n#10 [ 6/10] RUN pip3 install -v \"git+https://github.com/vllm-project/vllm.git\"\r\n\r\n[....]\r\n\r\n#10 288.1   Compiling objects...\r\n#10 288.1   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n#10 314.7   [1/10] /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/cuda_utils_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/cuda_utils_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 3687.0   [2/10] /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/activation_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/activation_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 3687.0   FAILED: /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/activation_kernels.o\r\n#10 3687.0   /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/activation_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/activation_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 3687.0   Killed\r\n#10 4196.7   [3/10] /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/pos_encoding_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/pos_encoding_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 4196.7   FAILED: /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/pos_encoding_kernels.o\r\n#10 4196.7   /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/pos_encoding_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/pos_encoding_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 4196.7   Killed\r\n#10 4520.8   [4/10] /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/cache_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/cache_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 4520.8   FAILED: /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/cache_kernels.o\r\n#10 4520.8   /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/cache_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/cache_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 4520.8   Killed\r\n#10 4604.5   [5/10] /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/layernorm_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/layernorm_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 4604.5   FAILED: /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/layernorm_kernels.o\r\n#10 4604.5   /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/layernorm_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/layernorm_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 4604.5   Killed\r\n#10 4773.3   [6/10] /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/quantization/awq/gemm_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/quantization/awq/gemm_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 4773.3   FAILED: /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/quantization/awq/gemm_kernels.o\r\n#10 4773.3   /usr/local/cuda/bin/nvcc  -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/TH -I/tmp/pip-build-env-myvapo8z/overlay/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-vx02uwf7/csrc/quantization/awq/gemm_kernels.cu -o /tmp/pip-req-build-vx02uwf7/build/temp.linux-x86_64-cpython-310/csrc/quantization/awq/gemm_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -std=c++17 -D_GLIBCXX_USE_CXX11_ABI=0 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_90,code=sm_90 --threads 8 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\r\n#10 4773.3   Killed\r\nERROR: failed to receive status: rpc error: code = Unavailable desc = error reading from server: EOF\r\n\r\n\r\n\r\n[log.txt](https://github.com/mistralai/mistral-src/files/13772743/log.txt)\r\n\r\n",
    "closed_by": {
      "login": "Good-Coffee",
      "id": 39215120,
      "node_id": "MDQ6VXNlcjM5MjE1MTIw",
      "avatar_url": "https://avatars.githubusercontent.com/u/39215120?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Good-Coffee",
      "html_url": "https://github.com/Good-Coffee",
      "followers_url": "https://api.github.com/users/Good-Coffee/followers",
      "following_url": "https://api.github.com/users/Good-Coffee/following{/other_user}",
      "gists_url": "https://api.github.com/users/Good-Coffee/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Good-Coffee/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Good-Coffee/subscriptions",
      "organizations_url": "https://api.github.com/users/Good-Coffee/orgs",
      "repos_url": "https://api.github.com/users/Good-Coffee/repos",
      "events_url": "https://api.github.com/users/Good-Coffee/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Good-Coffee/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/99/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 1
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/99/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/98",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/98/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/98/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/98/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/98",
    "id": 2055847181,
    "node_id": "I_kwDOKY_97s56ib0N",
    "number": 98,
    "title": "Create Issue templates",
    "user": {
      "login": "adityaraute",
      "id": 43912470,
      "node_id": "MDQ6VXNlcjQzOTEyNDcw",
      "avatar_url": "https://avatars.githubusercontent.com/u/43912470?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/adityaraute",
      "html_url": "https://github.com/adityaraute",
      "followers_url": "https://api.github.com/users/adityaraute/followers",
      "following_url": "https://api.github.com/users/adityaraute/following{/other_user}",
      "gists_url": "https://api.github.com/users/adityaraute/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/adityaraute/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/adityaraute/subscriptions",
      "organizations_url": "https://api.github.com/users/adityaraute/orgs",
      "repos_url": "https://api.github.com/users/adityaraute/repos",
      "events_url": "https://api.github.com/users/adityaraute/events{/privacy}",
      "received_events_url": "https://api.github.com/users/adityaraute/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-25T19:58:20Z",
    "updated_at": "2023-12-25T19:58:20Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Issue templates help in classifying new issues and providing a structure for the descriptions.\r\nThis makes it easier for maintainers to navigate through issues",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/98/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/98/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/97",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/97/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/97/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/97/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/97",
    "id": 2054881899,
    "node_id": "I_kwDOKY_97s56ewJr",
    "number": 97,
    "title": "Docs: Add tutorials for using Python client to generating embeddings and chat completion",
    "user": {
      "login": "m-newhauser",
      "id": 35735816,
      "node_id": "MDQ6VXNlcjM1NzM1ODE2",
      "avatar_url": "https://avatars.githubusercontent.com/u/35735816?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/m-newhauser",
      "html_url": "https://github.com/m-newhauser",
      "followers_url": "https://api.github.com/users/m-newhauser/followers",
      "following_url": "https://api.github.com/users/m-newhauser/following{/other_user}",
      "gists_url": "https://api.github.com/users/m-newhauser/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/m-newhauser/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/m-newhauser/subscriptions",
      "organizations_url": "https://api.github.com/users/m-newhauser/orgs",
      "repos_url": "https://api.github.com/users/m-newhauser/repos",
      "events_url": "https://api.github.com/users/m-newhauser/events{/privacy}",
      "received_events_url": "https://api.github.com/users/m-newhauser/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-23T19:51:00Z",
    "updated_at": "2023-12-23T19:51:00Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "The documentation here offers a good starting point for demonstrating how to use the Mistral's Python client to for chat completion tasks and to generate embeddings. \r\n\r\nIt could be improved by adding a full-code, annotated tutorial for each task. This could be incorporated into the documentation and each tutorial could also have an accompanying Jupyter or Colab notebook. I'm envisioning something similar to this Argilla tutorial, [Few shot text classification with active learning using small-text and SetFit](https://docs.argilla.io/en/latest/tutorials_and_integrations/tutorials/other_datasets/few_shot_text_classification_with_active_learning.html).\r\n\r\nFor generating embeddings, the tutorial could detail how to generate embeddings for an entire open dataset and perhaps add how to use them in a downstream task, like text classification. For the chat completion, the tutorial could be a bit more explanatory (rather than practical) and could resemble something similar to this [notebook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb) from OpenAI.\r\n\r\nI would be more than happy to pick this up myself. To get started, I would just need access to Mistral's Platform and API (I'm currently on the waitlist).",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/97/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/97/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/96",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/96/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/96/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/96/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/96",
    "id": 2054767150,
    "node_id": "PR_kwDOKY_97s5isk1m",
    "number": 96,
    "title": "Fixing typos in MD",
    "user": {
      "login": "Cassini-chris",
      "id": 34183942,
      "node_id": "MDQ6VXNlcjM0MTgzOTQy",
      "avatar_url": "https://avatars.githubusercontent.com/u/34183942?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Cassini-chris",
      "html_url": "https://github.com/Cassini-chris",
      "followers_url": "https://api.github.com/users/Cassini-chris/followers",
      "following_url": "https://api.github.com/users/Cassini-chris/following{/other_user}",
      "gists_url": "https://api.github.com/users/Cassini-chris/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Cassini-chris/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Cassini-chris/subscriptions",
      "organizations_url": "https://api.github.com/users/Cassini-chris/orgs",
      "repos_url": "https://api.github.com/users/Cassini-chris/repos",
      "events_url": "https://api.github.com/users/Cassini-chris/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Cassini-chris/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-23T12:02:18Z",
    "updated_at": "2023-12-25T20:00:11Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/96",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/96",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/96.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/96.patch",
      "merged_at": null
    },
    "body": "-> such \r\n-> notably",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/96/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/96/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/95",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/95/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/95/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/95/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/95",
    "id": 2053300974,
    "node_id": "I_kwDOKY_97s56YuLu",
    "number": 95,
    "title": "Has any thought been given to using LoRA to increase the number of experts (100x) with minimal memory?",
    "user": {
      "login": "sixChar",
      "id": 17972996,
      "node_id": "MDQ6VXNlcjE3OTcyOTk2",
      "avatar_url": "https://avatars.githubusercontent.com/u/17972996?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sixChar",
      "html_url": "https://github.com/sixChar",
      "followers_url": "https://api.github.com/users/sixChar/followers",
      "following_url": "https://api.github.com/users/sixChar/following{/other_user}",
      "gists_url": "https://api.github.com/users/sixChar/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sixChar/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sixChar/subscriptions",
      "organizations_url": "https://api.github.com/users/sixChar/orgs",
      "repos_url": "https://api.github.com/users/sixChar/repos",
      "events_url": "https://api.github.com/users/sixChar/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sixChar/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 8,
    "created_at": "2023-12-22T02:56:01Z",
    "updated_at": "2024-01-24T22:27:41Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "As I understand the current MoeLayer, a gate calculates the weight to be applied to the output of each expert, the top k are selected and run on the data, finally the results are multiplied by their respective weights and summed. \r\n\r\nThis means you have to store n copies of the layers, one for each expert.\r\n\r\nIf instead you had a single base set of parameters and each expert was defined by a low rank matrix you could hold a lot more experts in the same memory. \r\nCalculating the weights would be the same but instead of taking a weighted sum of the output you could take a weighted sum of the parameters and then use the summed parameters to calculate the result. (This would start to look a lot like Schmidhuber's fast weight programmers)\r\n\r\nUsing the code below, I could add 100 experts (at rank 4) to a feed forward module with dim=512 and hid_dim=2048 with only ~2x increase in number of parameters. I would expect this ratio to get better as the dim/hid_dim gets larger.\r\n\r\nIs there some fatal flaw that makes this approach not worth it?\r\n\r\nHere are the possible flaws I could think of but none of them strike me as compelling.\r\n\r\nI didn't test performance so it may not work as well. Although LoRA has worked pretty well in a number of places it may be that MoE relies on high rank differences between experts. \r\nIt could also be that the linear combination of matrices prior to the non-linearity(s) is not as powerful as combining the result. \r\n\r\nAdditionally, there is a performance hit to the mixing of experts as you have to do on the order of \r\n`3 * (dim + hid_dim) * rank * num_tokens * num_experts_per_token`  operations to mix the parameters plus the extra \r\n`(dim, rank) * (rank, hid_dim)` matrix multiplications and the addition with the base matrix. \r\nI haven't really looked at it but I'm pretty sure this is made up for by the fact that once the models are mixed you are running a single feed-forward on the input rather than multiple.\r\n\r\nThoughts?\r\n\r\nSome rough code to illustrate the idea based off of the FeedForward and MoeLayer modules:\r\n`\r\n\r\n    class MultiLoraLinear(nn.Module):\r\n         def __init__(self, ins:int, outs:int, num_loras:int, rank:int):\r\n              super().__init__()\r\n              # I'm pretty sure nn.Linear initializes weights from uniform(-sqrt(num_ins),+sqrt(num_ins))\r\n              init_scale = 2 / sqrt(ins)\r\n              self.w_base = nn.Parameter((torch.rand(ins, outs) - 0.5) * init_scale)\r\n              self.w_loras_a = nn.Parameter((torch.rand(num_loras, ins, rank) - 0.5) * init_scale)\r\n              self.w_loras_b = nn.Parameter((torch.rand(num_loras, rank, outs) - 0.5) * init_scale)\r\n              self.num_loras = num_loras\r\n              self.ins = ins\r\n              self.outs = outs\r\n\r\n          def forward(self, x, expert_weights, expert_indices):\r\n              ## construct weight matrix from weighted sum of lora params\r\n              # select out the lora params to use \r\n              selected_w_loras_a = self.w_loras_a[expert_indices,:,:]\r\n\r\n              # multiply the subset of lora params by their weighting and sum them\r\n              w_lora_a = torch.sum(selected_w_loras_a * expert_weights.unsqueeze(-1).unsqueeze(-1), dim=1)\r\n              selected_w_loras_b = self.w_loras_b[expert_indices,:,:]\r\n              w_lora_b = torch.sum(selected_w_loras_b * expert_weights.unsqueeze(-1).unsqueeze(-1), dim=1)\r\n\r\n              # Construct the full lora matrix as lora_a * lora_b transpose (but for each token/batch)\r\n              # b: batch, i: num ins, k: rank, o: num outs\r\n              w_lora = torch.einsum(\"bik,bko->bio\", w_lora_a, w_lora_b)\r\n              w = self.w_base + w_lora\r\n     \r\n              return torch.einsum(\"bi,bio->bo\", x, w)\r\n\r\n\r\n    class MoreMoeFeedForward(nn.Module):\r\n            def __init__(self, gate: nn.Module, dim: int, hid_dim: int, num_experts: int, lora_rank: int, num_experts_per_tok=5):\r\n                super().__init__()\r\n                assert num_experts > 0\r\n                self.gate = gate\r\n                self.num_experts = num_experts\r\n                self.lora_rank = lora_rank\r\n                self.num_experts_per_tok = num_experts_per_tok\r\n        \r\n                self.w1 = MultiLoraLinear(\r\n                    dim,\r\n                    hid_dim,\r\n                    num_experts,\r\n                    lora_rank,\r\n                )\r\n                self.w2 = MultiLoraLinear(\r\n                    hid_dim,\r\n                    dim,\r\n                    num_experts,\r\n                    lora_rank,\r\n                )\r\n                self.w3 = MultiLoraLinear(\r\n                    dim,\r\n                    hid_dim,\r\n                    num_experts,\r\n                    lora_rank,\r\n                )\r\n        \r\n        \r\n            def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n                # Mostly copied from MoeLayer\r\n                inputs_squashed = x.view(-1, x.shape[-1])\r\n                gate_logits = self.gate(inputs_squashed)\r\n                weights, indices = torch.topk(\r\n                    gate_logits,\r\n                    self.num_experts_per_tok\r\n                )\r\n                weights = F.softmax(\r\n                    weights,\r\n                    dim=1,\r\n                    dtype=torch.float\r\n                ).type_as(x)\r\n        \r\n                # Mostly copied from FeedForward\r\n                res_squashed =  self.w2(\r\n                    nn.functional.silu(\r\n                        self.w1(inputs_squashed, weights, indices)\r\n                    ) * self.w3(inputs_squashed, weights, indices),\r\n                    weights,\r\n                    indices\r\n                )\r\n                return res_squashed.view(x.shape)\r\n\r\n\r\n  `",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/95/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/95/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/94",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/94/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/94/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/94/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/94",
    "id": 2053019699,
    "node_id": "PR_kwDOKY_97s5imoy_",
    "number": 94,
    "title": "Fix typo/spelling in README.md",
    "user": {
      "login": "GilesBathgate",
      "id": 444143,
      "node_id": "MDQ6VXNlcjQ0NDE0Mw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/444143?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/GilesBathgate",
      "html_url": "https://github.com/GilesBathgate",
      "followers_url": "https://api.github.com/users/GilesBathgate/followers",
      "following_url": "https://api.github.com/users/GilesBathgate/following{/other_user}",
      "gists_url": "https://api.github.com/users/GilesBathgate/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/GilesBathgate/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/GilesBathgate/subscriptions",
      "organizations_url": "https://api.github.com/users/GilesBathgate/orgs",
      "repos_url": "https://api.github.com/users/GilesBathgate/repos",
      "events_url": "https://api.github.com/users/GilesBathgate/events{/privacy}",
      "received_events_url": "https://api.github.com/users/GilesBathgate/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-12-21T20:24:56Z",
    "updated_at": "2023-12-21T20:26:38Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/94",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/94",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/94.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/94.patch",
      "merged_at": null
    },
    "body": "sunch -> some",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/94/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/94/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/93",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/93/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/93/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/93/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/93",
    "id": 2052370217,
    "node_id": "I_kwDOKY_97s56VK8p",
    "number": 93,
    "title": "Mixtral Feedbacks",
    "user": {
      "login": "titouandk",
      "id": 5413308,
      "node_id": "MDQ6VXNlcjU0MTMzMDg=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5413308?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/titouandk",
      "html_url": "https://github.com/titouandk",
      "followers_url": "https://api.github.com/users/titouandk/followers",
      "following_url": "https://api.github.com/users/titouandk/following{/other_user}",
      "gists_url": "https://api.github.com/users/titouandk/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/titouandk/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/titouandk/subscriptions",
      "organizations_url": "https://api.github.com/users/titouandk/orgs",
      "repos_url": "https://api.github.com/users/titouandk/repos",
      "events_url": "https://api.github.com/users/titouandk/events{/privacy}",
      "received_events_url": "https://api.github.com/users/titouandk/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-21T12:50:41Z",
    "updated_at": "2023-12-21T12:50:41Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi,\r\n\r\nAre you interested in people giving feedback about Mistral/Mixtral?\r\nIf so, how could we share with you some ideas for Mistral/Mixtral potential improvements?\r\n\r\nI am thinking about sharing invalid answers provided by the Mixtral model.\r\nMixtral has difficulties generating valid YAML code by example - contrary to llama 2 and ChatGPT 3.5.\r\n\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/93/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/93/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/92",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/92/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/92/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/92/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/92",
    "id": 2049910845,
    "node_id": "I_kwDOKY_97s56Lyg9",
    "number": 92,
    "title": "Incomplete Output even with max_new_tokens",
    "user": {
      "login": "pradeepdev-1995",
      "id": 41164884,
      "node_id": "MDQ6VXNlcjQxMTY0ODg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/41164884?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pradeepdev-1995",
      "html_url": "https://github.com/pradeepdev-1995",
      "followers_url": "https://api.github.com/users/pradeepdev-1995/followers",
      "following_url": "https://api.github.com/users/pradeepdev-1995/following{/other_user}",
      "gists_url": "https://api.github.com/users/pradeepdev-1995/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pradeepdev-1995/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pradeepdev-1995/subscriptions",
      "organizations_url": "https://api.github.com/users/pradeepdev-1995/orgs",
      "repos_url": "https://api.github.com/users/pradeepdev-1995/repos",
      "events_url": "https://api.github.com/users/pradeepdev-1995/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pradeepdev-1995/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-20T06:17:58Z",
    "updated_at": "2023-12-20T06:17:58Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "So the output of my finetuned mistral model ends abruptly and I ideally want it to complete the paragraph/sentences/code which it was it between of.\r\nAlthough I have provided max_new_tokens = 300 and also in prompt I give to limit by 300 words.\r\n\r\nThe response is always big and ends abruptly. Any way I can ask for a complete output within desired number of output tokens?\r\n\r\nhere is the given generationconfig\r\n```\r\ngeneration_config = GenerationConfig(\r\n    do_sample=True,\r\n    top_k=10,\r\n    temperature=0.01,\r\n    pad_token_id=tokenizer.eos_token_id,\r\n    early_stopping = True,\r\n    max_new_tokens=300,\r\n    return_full_text=False\r\n)\r\n```",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/92/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/92/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/91",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/91/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/91/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/91/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/91",
    "id": 2045751783,
    "node_id": "I_kwDOKY_97s5577Hn",
    "number": 91,
    "title": "Building Mistral docker container results in OOM kill of the entire system",
    "user": {
      "login": "codevbus",
      "id": 1672773,
      "node_id": "MDQ6VXNlcjE2NzI3NzM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1672773?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/codevbus",
      "html_url": "https://github.com/codevbus",
      "followers_url": "https://api.github.com/users/codevbus/followers",
      "following_url": "https://api.github.com/users/codevbus/following{/other_user}",
      "gists_url": "https://api.github.com/users/codevbus/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/codevbus/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/codevbus/subscriptions",
      "organizations_url": "https://api.github.com/users/codevbus/orgs",
      "repos_url": "https://api.github.com/users/codevbus/repos",
      "events_url": "https://api.github.com/users/codevbus/events{/privacy}",
      "received_events_url": "https://api.github.com/users/codevbus/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-18T05:10:25Z",
    "updated_at": "2023-12-18T05:13:17Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Following this instruction:\r\n\r\n```\r\ndocker build deploy --build-arg MAX_JOBS=8\r\n```\r\n\r\nresults in an OOM kill of my system. Completely dropped the X session and sent me back to my display manager login.\r\n\r\n```\r\nDec 17 23:51:04 ws01 kernel: oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=user.slice,mems_>\r\nDec 17 23:51:04 ws01 systemd[1]: session-2.scope: A process of this unit has been killed by the OOM kill>\r\nDec 17 23:51:05 ws01 kernel: cicc invoked oom-killer: gfp_mask=0x140dca(GFP_HIGHUSER_MOVABLE|__GFP_COMP|>\r\nDec 17 23:51:05 ws01 kernel: CPU: 21 PID: 179121 Comm: cicc Tainted: P           OE      6.6.7-arch1-1 #>\r\nDec 17 23:51:05 ws01 kernel: Hardware name: Micro-Star International Co., Ltd. MS-7C37/MPG X570 GAMING E>\r\nDec 17 23:51:05 ws01 kernel: Call Trace:\r\nDec 17 23:51:05 ws01 kernel:  <TASK>\r\nDec 17 23:51:05 ws01 kernel:  dump_stack_lvl+0x47/0x60\r\nDec 17 23:51:05 ws01 kernel:  dump_header+0x4a/0x240\r\nDec 17 23:51:05 ws01 kernel:  oom_kill_process+0xf9/0x190\r\nDec 17 23:51:05 ws01 kernel:  out_of_memory+0x246/0x590\r\nDec 17 23:51:05 ws01 kernel:  __alloc_pages_slowpath.constprop.0+0xa5f/0xd90\r\nDec 17 23:51:05 ws01 kernel:  __alloc_pages+0x32d/0x350\r\nDec 17 23:51:05 ws01 kernel:  __folio_alloc+0x1b/0x50\r\nDec 17 23:51:05 ws01 kernel:  ? srso_alias_return_thunk+0x5/0x7f\r\nDec 17 23:51:05 ws01 kernel:  vma_alloc_folio+0xa0/0x380\r\nDec 17 23:51:05 ws01 kernel:  do_anonymous_page+0x71/0x3b0\r\nDec 17 23:51:05 ws01 kernel:  __handle_mm_fault+0xbdd/0xd90\r\nDec 17 23:51:05 ws01 kernel:  handle_mm_fault+0x17f/0x360\r\nDec 17 23:51:05 ws01 kernel:  do_user_addr_fault+0x15b/0x660\r\nDec 17 23:51:05 ws01 kernel:  exc_page_fault+0x7f/0x180\r\nDec 17 23:51:05 ws01 kernel:  asm_exc_page_fault+0x26/0x30\r\nDec 17 23:51:05 ws01 kernel: RIP: 0033:0x7f3710bd524b\r\nDec 17 23:51:05 ws01 kernel: Code: 5b 6a 17 00 31 d2 48 8d 34 29 48 39 fb 48 89 73 60 0f 95 c2 48 29 e8 >\r\nDec 17 23:51:05 ws01 kernel: RSP: 002b:00007ffd7d8b5790 EFLAGS: 00010206\r\nDec 17 23:51:05 ws01 kernel: RAX: 00000000000208d1 RBX: 00007f3710d4bc80 RCX: 000000002cf1f720\r\nDec 17 23:51:05 ws01 kernel: RDX: 0000000000010011 RSI: 000000002cf2f730 RDI: 00007f3710d4bc80\r\nDec 17 23:51:05 ws01 kernel: RBP: 0000000000010010 R08: 0000000000000000 R09: 000000000000007e\r\nDec 17 23:51:05 ws01 kernel: R10: 000000002cf2d000 R11: 0000000000000206 R12: 000000000000d8e0\r\nDec 17 23:51:05 ws01 kernel: R13: 000000002cf1f720 R14: 0000000000001000 R15: 0000000000010030\r\nDec 17 23:51:05 ws01 kernel:  </TASK>\r\nDec 17 23:51:05 ws01 kernel: Mem-Info:\r\nDec 17 23:51:05 ws01 kernel: active_anon:1140278 inactive_anon:14868754 isolated_anon:0\r\n                              active_file:1863 inactive_file:2917 isolated_file:0\r\n                              unevictable:4058 dirty:2244 writeback:0\r\n                              slab_reclaimable:42620 slab_unreclaimable:81781\r\n                              mapped:141523 shmem:89532 pagetables:54344\r\n                              sec_pagetables:0 bounce:0\r\n                              kernel_misc_reclaimable:0\r\n                              free:88166 free_pcp:103 free_cma:0\r\nDec 17 23:51:05 ws01 kernel: Node 0 active_anon:4561112kB inactive_anon:59475016kB active_file:7960kB in>\r\nDec 17 23:51:05 ws01 kernel: Node 0 DMA free:11264kB boost:0kB min:12kB low:24kB high:36kB reserved_high>\r\nDec 17 23:51:05 ws01 kernel: lowmem_reserve[]: 0 3166 64184 64184 64184\r\nDec 17 23:51:05 ws01 kernel: Node 0 DMA32 free:247384kB boost:0kB min:3332kB low:6572kB high:9812kB rese>\r\nDec 17 23:51:05 ws01 kernel: lowmem_reserve[]: 0 0 61018 61018 61018\r\nDec 17 23:51:05 ws01 kernel: Node 0 Normal free:94016kB boost:122880kB min:187112kB low:249592kB high:31>\r\n```",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/91/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/91/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/90",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/90/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/90/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/90/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/90",
    "id": 2045065346,
    "node_id": "I_kwDOKY_97s555TiC",
    "number": 90,
    "title": "wrong link in documentation",
    "user": {
      "login": "Frank-Buss",
      "id": 55055211,
      "node_id": "MDQ6VXNlcjU1MDU1MjEx",
      "avatar_url": "https://avatars.githubusercontent.com/u/55055211?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Frank-Buss",
      "html_url": "https://github.com/Frank-Buss",
      "followers_url": "https://api.github.com/users/Frank-Buss/followers",
      "following_url": "https://api.github.com/users/Frank-Buss/following{/other_user}",
      "gists_url": "https://api.github.com/users/Frank-Buss/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Frank-Buss/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Frank-Buss/subscriptions",
      "organizations_url": "https://api.github.com/users/Frank-Buss/orgs",
      "repos_url": "https://api.github.com/users/Frank-Buss/repos",
      "events_url": "https://api.github.com/users/Frank-Buss/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Frank-Buss/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-12-17T05:52:43Z",
    "updated_at": "2023-12-25T19:57:21Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "At https://github.com/mistralai/mistral-src is a link to https://docs.mistral.ai/quickstart but the page doesn't exists. The right target should be https://docs.mistral.ai .",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/90/reactions",
      "total_count": 2,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/90/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/89",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/89/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/89/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/89/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/89",
    "id": 2044522758,
    "node_id": "PR_kwDOKY_97s5iJ0Q7",
    "number": 89,
    "title": "Adds attention mask with `model.forward(..., cache=None)`.",
    "user": {
      "login": "andsteing",
      "id": 16050001,
      "node_id": "MDQ6VXNlcjE2MDUwMDAx",
      "avatar_url": "https://avatars.githubusercontent.com/u/16050001?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/andsteing",
      "html_url": "https://github.com/andsteing",
      "followers_url": "https://api.github.com/users/andsteing/followers",
      "following_url": "https://api.github.com/users/andsteing/following{/other_user}",
      "gists_url": "https://api.github.com/users/andsteing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/andsteing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/andsteing/subscriptions",
      "organizations_url": "https://api.github.com/users/andsteing/orgs",
      "repos_url": "https://api.github.com/users/andsteing/repos",
      "events_url": "https://api.github.com/users/andsteing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/andsteing/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-16T00:34:31Z",
    "updated_at": "2023-12-16T00:34:44Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/89",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/89",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/89.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/89.patch",
      "merged_at": null
    },
    "body": "This should fix #88.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/89/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/89/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/88",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/88/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/88/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/88/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/88",
    "id": 2044495838,
    "node_id": "I_kwDOKY_97s553Ife",
    "number": 88,
    "title": "Why does `cache=None` produce different outputs?",
    "user": {
      "login": "andsteing",
      "id": 16050001,
      "node_id": "MDQ6VXNlcjE2MDUwMDAx",
      "avatar_url": "https://avatars.githubusercontent.com/u/16050001?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/andsteing",
      "html_url": "https://github.com/andsteing",
      "followers_url": "https://api.github.com/users/andsteing/followers",
      "following_url": "https://api.github.com/users/andsteing/following{/other_user}",
      "gists_url": "https://api.github.com/users/andsteing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/andsteing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/andsteing/subscriptions",
      "organizations_url": "https://api.github.com/users/andsteing/orgs",
      "repos_url": "https://api.github.com/users/andsteing/repos",
      "events_url": "https://api.github.com/users/andsteing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/andsteing/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-15T23:39:08Z",
    "updated_at": "2023-12-15T23:39:08Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "When computing the log probabilities for\r\n\r\n```python\r\nprompts = (\r\n    'the sky is blue',\r\n    'the sky is pink',\r\n    'the sky is bacon',\r\n)\r\n```\r\n\r\nI get very different values, depending on whether I use a `cache=RotatingBufferCache(...)` or `cache=None`:\r\n\r\n```\r\nuse_cache=False:\r\n\r\n[     1] <s>      -> [   272] \u2581the    :   -7.41  0.06%\r\n[   272] \u2581the     -> [  7212] \u2581sky    :   -0.98 37.41%\r\n[  7212] \u2581sky     -> [   349] \u2581is     :   -0.19 82.40%\r\n[   349] \u2581is      -> [  5045] \u2581blue   :   -0.81 44.68%\r\n\r\n[     1] <s>      -> [   272] \u2581the    :   -7.41  0.06%\r\n[   272] \u2581the     -> [  7212] \u2581sky    :   -0.98 37.41%\r\n[  7212] \u2581sky     -> [   349] \u2581is     :   -0.19 82.40%\r\n[   349] \u2581is      -> [ 12937] \u2581pink   :   -2.45  8.59%\r\n\r\n[     1] <s>      -> [   272] \u2581the    :   -7.41  0.06%\r\n[   272] \u2581the     -> [  7212] \u2581sky    :   -0.98 37.41%\r\n[  7212] \u2581sky     -> [   349] \u2581is     :   -0.19 82.40%\r\n[   349] \u2581is      -> [   287] \u2581b      :   -5.00  0.67%\r\n[   287] \u2581b       -> [ 10364] acon    :   -0.04 96.17%\r\n\r\nuse_cache=True:\r\n\r\n[     1] <s>      -> [   272] \u2581the    :   -9.24  0.01%\r\n[   272] \u2581the     -> [  7212] \u2581sky    :   -7.37  0.06%\r\n[  7212] \u2581sky     -> [   349] \u2581is     :   -1.16 31.46%\r\n[   349] \u2581is      -> [  5045] \u2581blue   :   -2.39  9.13%\r\n\r\n[     1] <s>      -> [   272] \u2581the    :   -9.24  0.01%\r\n[   272] \u2581the     -> [  7212] \u2581sky    :   -7.37  0.06%\r\n[  7212] \u2581sky     -> [   349] \u2581is     :   -1.16 31.46%\r\n[   349] \u2581is      -> [ 12937] \u2581pink   :   -4.82  0.81%\r\n\r\n[     1] <s>      -> [   272] \u2581the    :   -9.24  0.01%\r\n[   272] \u2581the     -> [  7212] \u2581sky    :   -7.37  0.06%\r\n[  7212] \u2581sky     -> [   349] \u2581is     :   -1.16 31.46%\r\n[   349] \u2581is      -> [   287] \u2581b      :   -7.59  0.05%\r\n[   287] \u2581b       -> [ 10364] acon    :   -4.41  1.21%\r\n```\r\n\r\nThe values without cache do not make any sense (the values with cache seem reasonable though).\r\n\r\nWhy is this? How can I use the model without cache?\r\n\r\nFull code is in this Colab: https://colab.research.google.com/drive/1lNk_JgFFAakTRtEVkpxQ42jlGCygwfSb\r\n\r\n<details>\r\n<summary>Show code from Colab</summary>\r\n\r\n```python\r\ndef get_logprobs(model, tokenizer, prompts, *, use_cache):\r\n  \"\"\"Returns `(encoded_prompts, logprobs)`, optionally using the cache.\"\"\"\r\n\r\n  encoded_prompts = [tokenizer.encode(prompt, bos=True) for prompt in prompts[:3]]\r\n  seqlens = [len(x) for x in encoded_prompts]\r\n  concatenated_prompts = torch.tensor(sum(encoded_prompts, []), device=model.device, dtype=torch.long)\r\n\r\n  if use_cache:\r\n    sliding_window = model.args.sliding_window\r\n    sliding_window = min(max(seqlens), sliding_window)\r\n\r\n    cache = mistral.cache.RotatingBufferCache(\r\n        model.args.n_layers,\r\n        model.args.max_batch_size,\r\n        sliding_window,\r\n        model.args.n_kv_heads,\r\n        model.args.head_dim,\r\n    )\r\n    cache.to(device=model.device, dtype=model.dtype)\r\n    cache.reset()\r\n  else:\r\n    cache = None\r\n\r\n  prelogits = model.forward(\r\n      concatenated_prompts,\r\n      seqlens=seqlens,\r\n      cache=cache,\r\n  )\r\n\r\n  logits = torch.log_softmax(prelogits, dim=-1)\r\n  logprobs = [[] for _ in range(len(prompts))]\r\n  offset = 0\r\n  for i_seq, sequence in enumerate(encoded_prompts):\r\n    logprobs[i_seq].extend([logits[offset + i, sequence[i + 1]].item() for i in range(len(sequence) - 1)])\r\n    offset += len(sequence)\r\n\r\n  return encoded_prompts, logprobs\r\n\r\n\r\ndef print_logprobs(id2token, encoded_prompts, logprobs):\r\n  \"\"\"prints `(encoded_prompts, logprobs)` tokens / transition probabilities.\"\"\"\r\n  for i, t in enumerate(encoded_prompts):\r\n    for j, (t1, t2) in enumerate(zip(t, t[1:])):\r\n      logit = float(logprobs[i][j])\r\n      print(\r\n          f'[{t1:6}] {id2token(t1):8} '\r\n          f'-> [{t2:6}] {id2token(t2):8}: '\r\n          f'{logit:7.2f} '\r\n          f'{np.exp(logit):6.2%}'\r\n      )\r\n    print()\r\n\r\n\r\nprompts = (\r\n    'the sky is blue',\r\n    'the sky is pink',\r\n    'the sky is bacon',\r\n)\r\n\r\nfor use_cache in (False, True):\r\n  print(f'use_cache={use_cache}:\\n')\r\n  print_logprobs(tokenizer._model.id_to_piece, *get_logprobs(model, tokenizer, prompts, use_cache=use_cache))\r\n```\r\n\r\n</details>\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/88/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/88/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/87",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/87/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/87/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/87/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/87",
    "id": 2040838135,
    "node_id": "I_kwDOKY_97s55pLf3",
    "number": 87,
    "title": "Is the code up to date? Is the code the same for different model versions\uff1f",
    "user": {
      "login": "zysNLP",
      "id": 45376689,
      "node_id": "MDQ6VXNlcjQ1Mzc2Njg5",
      "avatar_url": "https://avatars.githubusercontent.com/u/45376689?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/zysNLP",
      "html_url": "https://github.com/zysNLP",
      "followers_url": "https://api.github.com/users/zysNLP/followers",
      "following_url": "https://api.github.com/users/zysNLP/following{/other_user}",
      "gists_url": "https://api.github.com/users/zysNLP/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/zysNLP/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/zysNLP/subscriptions",
      "organizations_url": "https://api.github.com/users/zysNLP/orgs",
      "repos_url": "https://api.github.com/users/zysNLP/repos",
      "events_url": "https://api.github.com/users/zysNLP/events{/privacy}",
      "received_events_url": "https://api.github.com/users/zysNLP/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-14T03:29:28Z",
    "updated_at": "2023-12-14T03:29:28Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I noticed that there were 3 versions of HuggingFace Model, v0.1, instruct-v0.1 and instruct-v0.2. Is the code of these three models the same? Does these models all use the main branch in this project now? I just don't know differences between them. Thank you very much! ",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/87/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/87/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/86",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/86/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/86/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/86/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/86",
    "id": 2039005088,
    "node_id": "I_kwDOKY_97s55iL-g",
    "number": 86,
    "title": " Inquiry on Implementing Sliding Window Attention for Custom Sequence Lengths",
    "user": {
      "login": "yihong1120",
      "id": 40423264,
      "node_id": "MDQ6VXNlcjQwNDIzMjY0",
      "avatar_url": "https://avatars.githubusercontent.com/u/40423264?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/yihong1120",
      "html_url": "https://github.com/yihong1120",
      "followers_url": "https://api.github.com/users/yihong1120/followers",
      "following_url": "https://api.github.com/users/yihong1120/following{/other_user}",
      "gists_url": "https://api.github.com/users/yihong1120/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/yihong1120/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/yihong1120/subscriptions",
      "organizations_url": "https://api.github.com/users/yihong1120/orgs",
      "repos_url": "https://api.github.com/users/yihong1120/repos",
      "events_url": "https://api.github.com/users/yihong1120/events{/privacy}",
      "received_events_url": "https://api.github.com/users/yihong1120/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-13T05:51:22Z",
    "updated_at": "2023-12-13T05:51:22Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Dear Mistral Transformer Team,\r\n\r\nI hope this message finds you well. I have been exploring the capabilities of the Mistral 7B model and am particularly intrigued by the implementation of sliding window attention as a means to improve inference efficiency and reduce memory pressure. The concept of using a fixed-size window to manage the (key, value) cache is quite innovative, and I believe it has the potential to significantly enhance performance for long sequence tasks.\r\n\r\nHowever, I am currently working with sequences of varying lengths that do not neatly fit into the pre-defined window sizes mentioned in your documentation. My objective is to adapt the sliding window attention mechanism to accommodate custom sequence lengths that may vary dynamically during runtime.\r\n\r\nCould you provide guidance or best practices on how to modify the sliding window attention mechanism to handle variable sequence lengths? Specifically, I am interested in understanding:\r\n\r\n1. How to determine the optimal window size for a given sequence length to balance the trade-off between computational efficiency and context availability.\r\n2. The impact of sequence length variability on the rolling buffer cache and if there are any recommended strategies to manage the cache effectively in such scenarios.\r\n3. Any potential limitations or considerations to be aware of when implementing sliding window attention for custom sequence lengths.\r\n\r\nI appreciate the work you have put into developing the Mistral Transformer and am excited about the possibility of integrating this feature into my own projects. Your insights on this matter would be invaluable.\r\n\r\nThank you for your time and assistance.\r\n\r\nBest regards,\r\nyihong1120",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/86/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/86/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/85",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/85/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/85/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/85/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/85",
    "id": 2038998839,
    "node_id": "PR_kwDOKY_97s5h2-YZ",
    "number": 85,
    "title": "fix minor typo in README.md",
    "user": {
      "login": "nheagy",
      "id": 517257,
      "node_id": "MDQ6VXNlcjUxNzI1Nw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/517257?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nheagy",
      "html_url": "https://github.com/nheagy",
      "followers_url": "https://api.github.com/users/nheagy/followers",
      "following_url": "https://api.github.com/users/nheagy/following{/other_user}",
      "gists_url": "https://api.github.com/users/nheagy/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nheagy/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nheagy/subscriptions",
      "organizations_url": "https://api.github.com/users/nheagy/orgs",
      "repos_url": "https://api.github.com/users/nheagy/repos",
      "events_url": "https://api.github.com/users/nheagy/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nheagy/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-13T05:44:30Z",
    "updated_at": "2023-12-25T19:56:54Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/85",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/85",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/85.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/85.patch",
      "merged_at": null
    },
    "body": "I believe `sunch` in meant to be `such`.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/85/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/85/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/84",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/84/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/84/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/84/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/84",
    "id": 2038945983,
    "node_id": "PR_kwDOKY_97s5h2yzR",
    "number": 84,
    "title": "Fix link to official documentation in README.md",
    "user": {
      "login": "webchick",
      "id": 332535,
      "node_id": "MDQ6VXNlcjMzMjUzNQ==",
      "avatar_url": "https://avatars.githubusercontent.com/u/332535?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/webchick",
      "html_url": "https://github.com/webchick",
      "followers_url": "https://api.github.com/users/webchick/followers",
      "following_url": "https://api.github.com/users/webchick/following{/other_user}",
      "gists_url": "https://api.github.com/users/webchick/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/webchick/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/webchick/subscriptions",
      "organizations_url": "https://api.github.com/users/webchick/orgs",
      "repos_url": "https://api.github.com/users/webchick/repos",
      "events_url": "https://api.github.com/users/webchick/events{/privacy}",
      "received_events_url": "https://api.github.com/users/webchick/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-13T04:45:19Z",
    "updated_at": "2023-12-13T04:45:19Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/84",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/84",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/84.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/84.patch",
      "merged_at": null
    },
    "body": "The README has a line that says:\r\n\r\n\"Instructions to run the image can be found in the official documentation.\"\r\n\r\nHowever, https://docs.mistral.ai/quickstart leads to a 404.\r\n\r\nOn the [home page](https://mistral.ai/) there is a \"Quick Start\" link that just leads to the root of https://docs.mistral.ai/ so that's what I replaced the link with.\r\n\r\nHope that helps!",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/84/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/84/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/83",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/83/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/83/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/83/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/83",
    "id": 2038200700,
    "node_id": "PR_kwDOKY_97s5h0SoD",
    "number": 83,
    "title": "Add MoE and pipelining support",
    "user": {
      "login": "diegolascasas",
      "id": 5016475,
      "node_id": "MDQ6VXNlcjUwMTY0NzU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5016475?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/diegolascasas",
      "html_url": "https://github.com/diegolascasas",
      "followers_url": "https://api.github.com/users/diegolascasas/followers",
      "following_url": "https://api.github.com/users/diegolascasas/following{/other_user}",
      "gists_url": "https://api.github.com/users/diegolascasas/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/diegolascasas/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/diegolascasas/subscriptions",
      "organizations_url": "https://api.github.com/users/diegolascasas/orgs",
      "repos_url": "https://api.github.com/users/diegolascasas/repos",
      "events_url": "https://api.github.com/users/diegolascasas/events{/privacy}",
      "received_events_url": "https://api.github.com/users/diegolascasas/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-12T17:02:08Z",
    "updated_at": "2023-12-12T17:03:36Z",
    "closed_at": "2023-12-12T17:03:36Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/83",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/83",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/83.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/83.patch",
      "merged_at": "2023-12-12T17:03:36Z"
    },
    "body": "* Add MoE and Pipelining support\r\n\r\n* Update readme\r\n\r\n* Update requirements\r\n\r\n* Add faster loading \r\n\r\n* Make sliding window optional and add rope_theta with smart default\r\n\r\n---------",
    "closed_by": {
      "login": "diegolascasas",
      "id": 5016475,
      "node_id": "MDQ6VXNlcjUwMTY0NzU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5016475?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/diegolascasas",
      "html_url": "https://github.com/diegolascasas",
      "followers_url": "https://api.github.com/users/diegolascasas/followers",
      "following_url": "https://api.github.com/users/diegolascasas/following{/other_user}",
      "gists_url": "https://api.github.com/users/diegolascasas/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/diegolascasas/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/diegolascasas/subscriptions",
      "organizations_url": "https://api.github.com/users/diegolascasas/orgs",
      "repos_url": "https://api.github.com/users/diegolascasas/repos",
      "events_url": "https://api.github.com/users/diegolascasas/events{/privacy}",
      "received_events_url": "https://api.github.com/users/diegolascasas/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/83/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/83/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/81",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/81/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/81/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/81/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/81",
    "id": 2035866809,
    "node_id": "PR_kwDOKY_97s5hsUb2",
    "number": 81,
    "title": "Fix Dockerfile",
    "user": {
      "login": "nicholasjpaterno",
      "id": 43416138,
      "node_id": "MDQ6VXNlcjQzNDE2MTM4",
      "avatar_url": "https://avatars.githubusercontent.com/u/43416138?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nicholasjpaterno",
      "html_url": "https://github.com/nicholasjpaterno",
      "followers_url": "https://api.github.com/users/nicholasjpaterno/followers",
      "following_url": "https://api.github.com/users/nicholasjpaterno/following{/other_user}",
      "gists_url": "https://api.github.com/users/nicholasjpaterno/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nicholasjpaterno/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nicholasjpaterno/subscriptions",
      "organizations_url": "https://api.github.com/users/nicholasjpaterno/orgs",
      "repos_url": "https://api.github.com/users/nicholasjpaterno/repos",
      "events_url": "https://api.github.com/users/nicholasjpaterno/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nicholasjpaterno/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-11T14:56:21Z",
    "updated_at": "2023-12-11T14:59:58Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/81",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/81",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/81.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/81.patch",
      "merged_at": null
    },
    "body": "Latest PyTorch version is built with CUDA 12.1\r\n\r\nPin the version to the latest stable release built with CUDA 11.8",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/81/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/81/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/80",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/80/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/80/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/80/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/80",
    "id": 2034353200,
    "node_id": "I_kwDOKY_97s55QcQw",
    "number": 80,
    "title": "on Jetson ORIN, Xformer, Memory-efficient attention, SwiGLU, sparse and more won't be available.",
    "user": {
      "login": "cj401",
      "id": 38958132,
      "node_id": "MDQ6VXNlcjM4OTU4MTMy",
      "avatar_url": "https://avatars.githubusercontent.com/u/38958132?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cj401",
      "html_url": "https://github.com/cj401",
      "followers_url": "https://api.github.com/users/cj401/followers",
      "following_url": "https://api.github.com/users/cj401/following{/other_user}",
      "gists_url": "https://api.github.com/users/cj401/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cj401/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cj401/subscriptions",
      "organizations_url": "https://api.github.com/users/cj401/orgs",
      "repos_url": "https://api.github.com/users/cj401/repos",
      "events_url": "https://api.github.com/users/cj401/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cj401/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-10T12:36:06Z",
    "updated_at": "2023-12-10T12:36:06Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi mistral ai team,\r\n\r\nthanks for sharing the great work.\r\n\r\nI was trying to run [mistral-7b](https://github.com/mistralai/mistral-src) on Jetson ORIN with Jetpack (# R35 (release), REVISION: 4.1, GCID: 33958178, BOARD: t186ref, EABI: aarch64, DATE: Tue Aug 1 19:57:35 UTC 2023).\r\n\r\nI built triton (openAI) and xformers from source without problems.\r\n\r\nHowever, when I tried to run\r\n\r\n`python -m main demo /path/to/mistral-7B-v0.1/`\r\n\r\nI got following errors:\r\n\r\n```\r\npython -m main demo mistral-7B-v0.1/\r\nWARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\r\n    PyTorch 2.1.0a0+41361538.nv23.06 with CUDA 1104 (you have 2.1.0a0+41361538.nv23.06)\r\n    Python  3.8.10 (you have 3.8.10)\r\n  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\r\n  Memory-efficient attention, SwiGLU, sparse and more won't be available.\r\n  Set XFORMERS_MORE_DETAILS=1 for more details\r\n\r\nraise NotImplementedError(msg)\r\nNotImplementedError: No operator found for `memory_efficient_attention_forward` with inputs:\r\n     query       : shape=(1, 27, 32, 128) (torch.float16)\r\n     key         : shape=(1, 27, 32, 128) (torch.float16)\r\n     value       : shape=(1, 27, 32, 128) (torch.float16)\r\n     attn_bias   : <class 'xformers.ops.fmha.attn_bias.BlockDiagonalCausalLocalAttentionMask'>\r\n     p           : 0.0\r\n`decoderF` is not supported because:\r\n    xFormers wasn't build with CUDA support\r\n    attn_bias type is <class 'xformers.ops.fmha.attn_bias.BlockDiagonalCausalLocalAttentionMask'>\r\n    operator wasn't built - see `python -m xformers.info` for more info\r\n`flshattF@0.0.0` is not supported because:\r\n    xFormers wasn't build with CUDA support\r\n`tritonflashattF` is not supported because:\r\n    xFormers wasn't build with CUDA support\r\n    attn_bias type is <class 'xformers.ops.fmha.attn_bias.BlockDiagonalCausalLocalAttentionMask'>\r\n    operator wasn't built - see `python -m xformers.info` for more info\r\n    triton is not available\r\n    Only work on pre-MLIR triton for now\r\n`cutlassF` is not supported because:\r\n    xFormers wasn't build with CUDA support\r\n    operator wasn't built - see `python -m xformers.info` for more info\r\n`smallkF` is not supported because:\r\n    max(query.shape[-1] != value.shape[-1]) > 32\r\n    xFormers wasn't build with CUDA support\r\n    dtype=torch.float16 (supported: {torch.float32})\r\n    attn_bias type is <class 'xformers.ops.fmha.attn_bias.BlockDiagonalCausalLocalAttentionMask'>\r\n    operator wasn't built - see `python -m xformers.info` for more info\r\n    unsupported embed per head: 128\r\n```\r\nthen tried \r\n\r\n`python3 -m xformers.info`\r\n\r\nI got \r\n\r\n```\r\nWARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\r\n    PyTorch 2.1.0a0+41361538.nv23.06 with CUDA 1104 (you have 2.1.0a0+41361538.nv23.06)\r\n    Python  3.8.10 (you have 3.8.10)\r\n  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\r\n  Memory-efficient attention, SwiGLU, sparse and more won't be available.\r\n  Set XFORMERS_MORE_DETAILS=1 for more details\r\nxFormers 0.0.24+40d3967.d20231209\r\nmemory_efficient_attention.cutlassF:               unavailable\r\nmemory_efficient_attention.cutlassB:               unavailable\r\nmemory_efficient_attention.decoderF:               unavailable\r\nmemory_efficient_attention.flshattF@0.0.0:         available\r\nmemory_efficient_attention.flshattB@0.0.0:         available\r\nmemory_efficient_attention.smallkF:                unavailable\r\nmemory_efficient_attention.smallkB:                unavailable\r\nmemory_efficient_attention.tritonflashattF:        unavailable\r\nmemory_efficient_attention.tritonflashattB:        unavailable\r\nmemory_efficient_attention.triton_splitKF:         available\r\nindexing.scaled_index_addF:                        available\r\nindexing.scaled_index_addB:                        available\r\nindexing.index_select:                             available\r\nswiglu.dual_gemm_silu:                             unavailable\r\nswiglu.gemm_fused_operand_sum:                     unavailable\r\nswiglu.fused.p.cpp:                                not built\r\nis_triton_available:                               True\r\npytorch.version:                                   2.1.0a0+41361538.nv23.06\r\npytorch.cuda:                                      available\r\ngpu.compute_capability:                            8.7\r\ngpu.name:                                          Orin\r\nbuild.info:                                        available\r\nbuild.cuda_version:                                1104\r\nbuild.python_version:                              3.8.10\r\nbuild.torch_version:                               2.1.0a0+41361538.nv23.06\r\nbuild.env.TORCH_CUDA_ARCH_LIST:                    None\r\nbuild.env.XFORMERS_BUILD_TYPE:                     None\r\nbuild.env.XFORMERS_ENABLE_DEBUG_ASSERTIONS:        None\r\nbuild.env.NVCC_FLAGS:                              None\r\nbuild.env.XFORMERS_PACKAGE_FROM:                   None\r\nsource.privacy:                                    open source\r\nWARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\r\n    PyTorch 2.1.0a0+41361538.nv23.06 with CUDA 1104 (you have 2.1.0a0+41361538.nv23.06)\r\n    Python  3.8.10 (you have 3.8.10)\r\n  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\r\n  Memory-efficient attention, SwiGLU, sparse and more won't be available.\r\n  Set XFORMERS_MORE_DETAILS=1 for more details\r\nxFormers 0.0.24+40d3967.d20231209\r\nmemory_efficient_attention.cutlassF:               unavailable\r\nmemory_efficient_attention.cutlassB:               unavailable\r\nmemory_efficient_attention.decoderF:               unavailable\r\nmemory_efficient_attention.flshattF@0.0.0:         available\r\nmemory_efficient_attention.flshattB@0.0.0:         available\r\nmemory_efficient_attention.smallkF:                unavailable\r\nmemory_efficient_attention.smallkB:                unavailable\r\nmemory_efficient_attention.tritonflashattF:        unavailable\r\nmemory_efficient_attention.tritonflashattB:        unavailable\r\nmemory_efficient_attention.triton_splitKF:         available\r\nindexing.scaled_index_addF:                        available\r\nindexing.scaled_index_addB:                        available\r\nindexing.index_select:                             available\r\nswiglu.dual_gemm_silu:                             unavailable\r\nswiglu.gemm_fused_operand_sum:                     unavailable\r\nswiglu.fused.p.cpp:                                not built\r\nis_triton_available:                               True\r\npytorch.version:                                   2.1.0a0+41361538.nv23.06\r\npytorch.cuda:                                      available\r\ngpu.compute_capability:                            8.7\r\ngpu.name:                                          Orin\r\nbuild.info:                                        available\r\nbuild.cuda_version:                                1104\r\nbuild.python_version:                              3.8.10\r\nbuild.torch_version:                               2.1.0a0+41361538.nv23.06\r\nbuild.env.TORCH_CUDA_ARCH_LIST:                    None\r\nbuild.env.XFORMERS_BUILD_TYPE:                     None\r\nbuild.env.XFORMERS_ENABLE_DEBUG_ASSERTIONS:        None\r\nbuild.env.NVCC_FLAGS:                              None\r\nbuild.env.XFORMERS_PACKAGE_FROM:                   None\r\nsource.privacy:                                    open source\r\n\r\n```\r\nit seems an issue with xformers. I also submitted an issue to xformers [here](https://github.com/facebookresearch/xformers/issues/944). ",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/80/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/80/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/79",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/79/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/79/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/79/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/79",
    "id": 2029786231,
    "node_id": "I_kwDOKY_97s54_BR3",
    "number": 79,
    "title": "Is window attention technology also used during the training phase?",
    "user": {
      "login": "peiyingxin",
      "id": 48778315,
      "node_id": "MDQ6VXNlcjQ4Nzc4MzE1",
      "avatar_url": "https://avatars.githubusercontent.com/u/48778315?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/peiyingxin",
      "html_url": "https://github.com/peiyingxin",
      "followers_url": "https://api.github.com/users/peiyingxin/followers",
      "following_url": "https://api.github.com/users/peiyingxin/following{/other_user}",
      "gists_url": "https://api.github.com/users/peiyingxin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/peiyingxin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/peiyingxin/subscriptions",
      "organizations_url": "https://api.github.com/users/peiyingxin/orgs",
      "repos_url": "https://api.github.com/users/peiyingxin/repos",
      "events_url": "https://api.github.com/users/peiyingxin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/peiyingxin/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-07T03:02:20Z",
    "updated_at": "2023-12-07T03:02:20Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": null,
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/79/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/79/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/78",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/78/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/78/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/78/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/78",
    "id": 2025793803,
    "node_id": "I_kwDOKY_97s54vykL",
    "number": 78,
    "title": "How to process batch input in mistral-src/model.py ?",
    "user": {
      "login": "NLPwoods",
      "id": 49786090,
      "node_id": "MDQ6VXNlcjQ5Nzg2MDkw",
      "avatar_url": "https://avatars.githubusercontent.com/u/49786090?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/NLPwoods",
      "html_url": "https://github.com/NLPwoods",
      "followers_url": "https://api.github.com/users/NLPwoods/followers",
      "following_url": "https://api.github.com/users/NLPwoods/following{/other_user}",
      "gists_url": "https://api.github.com/users/NLPwoods/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/NLPwoods/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/NLPwoods/subscriptions",
      "organizations_url": "https://api.github.com/users/NLPwoods/orgs",
      "repos_url": "https://api.github.com/users/NLPwoods/repos",
      "events_url": "https://api.github.com/users/NLPwoods/events{/privacy}",
      "received_events_url": "https://api.github.com/users/NLPwoods/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-05T09:54:02Z",
    "updated_at": "2023-12-10T12:42:03Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "        seqlen_sum, _ = x.shape\r\n\r\n        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\r\n        xq = xq.view(seqlen_sum, self.n_heads, self.args.head_dim)\r\n        xk = xk.view(seqlen_sum, self.n_kv_heads, self.args.head_dim)\r\n        xv = xv.view(seqlen_sum, self.n_kv_heads, self.args.head_dim)",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/78/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/78/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/77",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/77/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/77/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/77/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/77",
    "id": 2025025833,
    "node_id": "I_kwDOKY_97s54s3Ep",
    "number": 77,
    "title": "repeated build failure",
    "user": {
      "login": "juanmf",
      "id": 886723,
      "node_id": "MDQ6VXNlcjg4NjcyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886723?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/juanmf",
      "html_url": "https://github.com/juanmf",
      "followers_url": "https://api.github.com/users/juanmf/followers",
      "following_url": "https://api.github.com/users/juanmf/following{/other_user}",
      "gists_url": "https://api.github.com/users/juanmf/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/juanmf/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/juanmf/subscriptions",
      "organizations_url": "https://api.github.com/users/juanmf/orgs",
      "repos_url": "https://api.github.com/users/juanmf/repos",
      "events_url": "https://api.github.com/users/juanmf/events{/privacy}",
      "received_events_url": "https://api.github.com/users/juanmf/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-04T23:59:05Z",
    "updated_at": "2023-12-04T23:59:05Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "The build process hasn't ended successfully several times. \r\n\r\n1st (solved?): https://github.com/mistralai/mistral-src/issues/76\r\n\r\n2nd: (seems network issue)\r\n```\r\n => [4/8] RUN pip3 install \"torch>=2.0.0\"                                                                                                                                                            190.5s\r\n => [5/8] RUN git clone https://github.com/NVIDIA/apex &&     cd apex && git checkout 2386a912164b0c5cfcd8be7a2b890fbac5607c82 &&     sed -i '/check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)/d'  2139.1s \r\n => => # [2/14] c++ -MMD -MF /workspace/apex/build/temp.linux-x86_64-3.10/csrc/amp_C_frontend.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Wer \r\n => => # ror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/u \r\n => => # sr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC  \r\n => => # -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /workspace/apex/csrc/amp_C_frontend.cpp -o /workspace/apex/build/temp.linux-x86_64-3.10/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVER \r\n => => # SION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C  \r\n => => # -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17                                                                                                                                                             \r\nERROR: failed to receive status: rpc error: code = Unavailable desc = error reading from server: EOF\r\n```\r\n\r\n3rd: (Error compiling objects)\r\n```\r\n => CACHED [4/8] RUN pip3 install \"torch>=2.0.0\"                                                                                                                                                       0.0s\r\n => [5/8] RUN git clone https://github.com/NVIDIA/apex &&     cd apex && git checkout 2386a912164b0c5cfcd8be7a2b890fbac5607c82 &&     sed -i '/check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)/d'  6578.5s\r\n => => #     _write_ninja_file_and_compile_objects(                                                                                                                                                        \r\n => => #   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 1774, in _write_ninja_file_and_compile_objects                                                                \r\n => => #     _run_ninja_build(                                                                                                                                                                             \r\n => => #   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 2116, in _run_ninja_build                                                                                     \r\n => => #     raise RuntimeError(message) from e                                                                                                                                                            \r\n => => # RuntimeError: Error compiling objects for extension  \r\n```\r\n\r\n4th (Killed signal terminated program cc1plus):\r\n```\r\n => CACHED [4/8] RUN pip3 install \"torch>=2.0.0\"                                                                                                                                                       0.0s\r\n => [5/8] RUN git clone https://github.com/NVIDIA/apex &&     cd apex && git checkout 2386a912164b0c5cfcd8be7a2b890fbac5607c82 &&     sed -i '/check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)/d  10182.9s\r\n => => # l/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/\r\n => => # local/cuda/include -I/usr/include/python3.10 -c -c /workspace/apex/csrc/amp_C_frontend.cpp -o /workspace/apex/build/temp.linux-x86_64-3.10/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE\r\n => => # _1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIB\r\n => => # CXX_USE_CXX11_ABI=0 -std=c++17                                                                                                                                                                    \r\n => => # c++: fatal error: Killed signal terminated program cc1plus                                                                                                                                        \r\n => => # compilation terminated.                                                                                                                                                                           \r\nERROR: failed to solve: Canceled: context canceled\r\n```\r\n\r\nIt fails randomly at different stages. After long time compiling.\r\nI pressed `ctrl+C` to return to prompt though after reading above messages.\r\n\r\nAny help will be appreciated. \r\nThanks",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/77/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/77/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/76",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/76/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/76/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/76/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/76",
    "id": 2024415504,
    "node_id": "I_kwDOKY_97s54qiEQ",
    "number": 76,
    "title": "The detected CUDA version (11.8) mismatches the version that was used to compile",
    "user": {
      "login": "juanmf",
      "id": 886723,
      "node_id": "MDQ6VXNlcjg4NjcyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886723?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/juanmf",
      "html_url": "https://github.com/juanmf",
      "followers_url": "https://api.github.com/users/juanmf/followers",
      "following_url": "https://api.github.com/users/juanmf/following{/other_user}",
      "gists_url": "https://api.github.com/users/juanmf/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/juanmf/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/juanmf/subscriptions",
      "organizations_url": "https://api.github.com/users/juanmf/orgs",
      "repos_url": "https://api.github.com/users/juanmf/repos",
      "events_url": "https://api.github.com/users/juanmf/events{/privacy}",
      "received_events_url": "https://api.github.com/users/juanmf/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-12-04T17:55:37Z",
    "updated_at": "2023-12-04T19:53:34Z",
    "closed_at": "2023-12-04T19:53:33Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "```\r\n$ docker build deploy --build-arg MAX_JOBS=8\r\n...\r\n...\r\n\r\n => [4/8] RUN pip3 install \"torch>=2.0.0\"                                                                                                                                                            476.6s\r\n => ERROR [5/8] RUN git clone https://github.com/NVIDIA/apex &&     cd apex && git checkout 2386a912164b0c5cfcd8be7a2b890fbac5607c82 &&     sed -i '/check_cuda_torch_binary_vs_bare_metal(CUDA_HOME  15.9s \r\n-\r\n...\r\n14.87 No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\r\n14.90 \r\n14.90 Warning: Torch did not find available GPUs on this system.\r\n14.90  If your intention is to cross-compile, this is not an error.\r\n14.90 By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\r\n14.90 Volta (compute capability 7.0), Turing (compute capability 7.5),\r\n14.90 and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\r\n14.90 If you wish to cross-compile for a single specific architecture,\r\n14.90 export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\r\n...\r\n15.12   File \"/usr/lib/python3.10/distutils/command/build_ext.py\", line 340, in run\r\n15.12     self.build_extensions()\r\n15.12   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 525, in build_extensions\r\n15.12     _check_cuda_version(compiler_name, compiler_version)\r\n15.12   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 413, in _check_cuda_version\r\n15.12     raise RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))\r\n15.12 RuntimeError: \r\n15.12 The detected CUDA version (11.8) mismatches the version that was used to compile\r\n15.12 PyTorch (12.1). Please make sure to use the same CUDA versions.\r\n```\r\n\r\nAm I supposed to install CUDA 1st? does it make sense in a MacBook Pro 2017?\r\n\r\ntrying `$ export TORCH_CUDA_ARCH_LIST=\"8.0\"` didn't help.\r\n",
    "closed_by": {
      "login": "juanmf",
      "id": 886723,
      "node_id": "MDQ6VXNlcjg4NjcyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886723?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/juanmf",
      "html_url": "https://github.com/juanmf",
      "followers_url": "https://api.github.com/users/juanmf/followers",
      "following_url": "https://api.github.com/users/juanmf/following{/other_user}",
      "gists_url": "https://api.github.com/users/juanmf/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/juanmf/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/juanmf/subscriptions",
      "organizations_url": "https://api.github.com/users/juanmf/orgs",
      "repos_url": "https://api.github.com/users/juanmf/repos",
      "events_url": "https://api.github.com/users/juanmf/events{/privacy}",
      "received_events_url": "https://api.github.com/users/juanmf/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/76/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/76/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/75",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/75/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/75/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/75/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/75",
    "id": 2023680138,
    "node_id": "PR_kwDOKY_97s5hC3QK",
    "number": 75,
    "title": "Fix: no system prompt in request",
    "user": {
      "login": "michel-ds",
      "id": 64908337,
      "node_id": "MDQ6VXNlcjY0OTA4MzM3",
      "avatar_url": "https://avatars.githubusercontent.com/u/64908337?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michel-ds",
      "html_url": "https://github.com/michel-ds",
      "followers_url": "https://api.github.com/users/michel-ds/followers",
      "following_url": "https://api.github.com/users/michel-ds/following{/other_user}",
      "gists_url": "https://api.github.com/users/michel-ds/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michel-ds/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michel-ds/subscriptions",
      "organizations_url": "https://api.github.com/users/michel-ds/orgs",
      "repos_url": "https://api.github.com/users/michel-ds/repos",
      "events_url": "https://api.github.com/users/michel-ds/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michel-ds/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-04T11:53:09Z",
    "updated_at": "2023-12-04T11:53:09Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/75",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/75",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/75.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/75.patch",
      "merged_at": null
    },
    "body": "Bump FastChat dependency in Dockerfile to fix system prompt bug.\r\n\r\nBug results in all system prompts being set to an empty string in FastChat versions prior to 0.2.32, see https://github.com/lm-sys/FastChat/pull/2581\r\n\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/75/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/75/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/74",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/74/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/74/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/74/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/74",
    "id": 2018606093,
    "node_id": "I_kwDOKY_97s54UXwN",
    "number": 74,
    "title": "No safetensors in HF model card?",
    "user": {
      "login": "EricLBuehler",
      "id": 65165915,
      "node_id": "MDQ6VXNlcjY1MTY1OTE1",
      "avatar_url": "https://avatars.githubusercontent.com/u/65165915?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/EricLBuehler",
      "html_url": "https://github.com/EricLBuehler",
      "followers_url": "https://api.github.com/users/EricLBuehler/followers",
      "following_url": "https://api.github.com/users/EricLBuehler/following{/other_user}",
      "gists_url": "https://api.github.com/users/EricLBuehler/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/EricLBuehler/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/EricLBuehler/subscriptions",
      "organizations_url": "https://api.github.com/users/EricLBuehler/orgs",
      "repos_url": "https://api.github.com/users/EricLBuehler/repos",
      "events_url": "https://api.github.com/users/EricLBuehler/events{/privacy}",
      "received_events_url": "https://api.github.com/users/EricLBuehler/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-11-30T12:51:19Z",
    "updated_at": "2023-12-18T10:11:19Z",
    "closed_at": "2023-12-18T10:11:18Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hello everybody,\r\n\r\nI have noticed that there are only `.bin` files and no `.safetensors` files in the model card (https://huggingface.co/mistralai/Mistral-7B-v0.1/tree/main). Could this be officially added? There appear to be some other models on HF Hub that have safetensors or other formats: https://huggingface.co/alpindale/mistral-7b-safetensors, but I was wondering if an official `.safetensors` release could be added?",
    "closed_by": {
      "login": "EricLBuehler",
      "id": 65165915,
      "node_id": "MDQ6VXNlcjY1MTY1OTE1",
      "avatar_url": "https://avatars.githubusercontent.com/u/65165915?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/EricLBuehler",
      "html_url": "https://github.com/EricLBuehler",
      "followers_url": "https://api.github.com/users/EricLBuehler/followers",
      "following_url": "https://api.github.com/users/EricLBuehler/following{/other_user}",
      "gists_url": "https://api.github.com/users/EricLBuehler/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/EricLBuehler/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/EricLBuehler/subscriptions",
      "organizations_url": "https://api.github.com/users/EricLBuehler/orgs",
      "repos_url": "https://api.github.com/users/EricLBuehler/repos",
      "events_url": "https://api.github.com/users/EricLBuehler/events{/privacy}",
      "received_events_url": "https://api.github.com/users/EricLBuehler/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/74/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/74/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/73",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/73/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/73/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/73/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/73",
    "id": 2001724882,
    "node_id": "I_kwDOKY_97s53T-XS",
    "number": 73,
    "title": "What is the difference between the files you publish on GitHub and Hugging Face",
    "user": {
      "login": "zhzfight",
      "id": 46812553,
      "node_id": "MDQ6VXNlcjQ2ODEyNTUz",
      "avatar_url": "https://avatars.githubusercontent.com/u/46812553?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/zhzfight",
      "html_url": "https://github.com/zhzfight",
      "followers_url": "https://api.github.com/users/zhzfight/followers",
      "following_url": "https://api.github.com/users/zhzfight/following{/other_user}",
      "gists_url": "https://api.github.com/users/zhzfight/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/zhzfight/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/zhzfight/subscriptions",
      "organizations_url": "https://api.github.com/users/zhzfight/orgs",
      "repos_url": "https://api.github.com/users/zhzfight/repos",
      "events_url": "https://api.github.com/users/zhzfight/events{/privacy}",
      "received_events_url": "https://api.github.com/users/zhzfight/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-11-20T09:23:55Z",
    "updated_at": "2023-11-20T09:23:55Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "hi, What is the difference between the files you publish on GitHub and Hugging Face, and why can\u2019t I directly use the from_folder method to initialize with files downloaded from Hugging Face?\"\uff0e",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/73/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/73/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/72",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/72/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/72/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/72/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/72",
    "id": 1997789498,
    "node_id": "I_kwDOKY_97s53E9k6",
    "number": 72,
    "title": "Unabled to load to GPU with 24 GB vRAM with quantization",
    "user": {
      "login": "fangzhouli",
      "id": 25162281,
      "node_id": "MDQ6VXNlcjI1MTYyMjgx",
      "avatar_url": "https://avatars.githubusercontent.com/u/25162281?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/fangzhouli",
      "html_url": "https://github.com/fangzhouli",
      "followers_url": "https://api.github.com/users/fangzhouli/followers",
      "following_url": "https://api.github.com/users/fangzhouli/following{/other_user}",
      "gists_url": "https://api.github.com/users/fangzhouli/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/fangzhouli/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/fangzhouli/subscriptions",
      "organizations_url": "https://api.github.com/users/fangzhouli/orgs",
      "repos_url": "https://api.github.com/users/fangzhouli/repos",
      "events_url": "https://api.github.com/users/fangzhouli/events{/privacy}",
      "received_events_url": "https://api.github.com/users/fangzhouli/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-11-16T21:10:41Z",
    "updated_at": "2023-12-12T14:57:11Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi, thank you for the amazing model! Super excited to test it out!\r\n\r\nI am trying to load it into my GeForce RTX 3090 (24 GB vRAM), which I believe to be more than enough for inference with 8 or 4 bit quantization. (I have tested on LLaMa 2-7B, and it worked.)\r\n\r\nHowever, it was always killed before loading checkpoint shards. I am wondering if anyone has encountered a similar situation.\r\n\r\n```\r\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\r\nloading weights file pytorch_model.bin from cache at /home/fzli/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.1/snapshots/5e9c98b96d071dce59368012254c55b0ec6f8658/pytorch_model.bin.index.json\r\nInstantiating MistralForCausalLM model under default dtype torch.float16.\r\nGenerate config GenerationConfig {\r\n  \"bos_token_id\": 1,\r\n  \"eos_token_id\": 2\r\n}\r\n\r\nDetected 4-bit loading: activating 4-bit loading for this model\r\nLoading checkpoint shards:   0%|                                                                                                                                     | 0/2 [00:00<?, ?it/s]\r\nKilled\r\n```\r\n\r\nBackground info:\r\n- GPU: GeForce RTX 3090 24GB\r\n- Python: 3.11.5\r\n- PyTorch: 2.1.1\r\n- Hugging Face (transformers): 4.35.2\r\n- CUDA toolkit: 12.1",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/72/reactions",
      "total_count": 2,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 2
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/72/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/71",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/71/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/71/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/71/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/71",
    "id": 1995310511,
    "node_id": "I_kwDOKY_97s527gWv",
    "number": 71,
    "title": "How is The 131K Attention Span Achieved?",
    "user": {
      "login": "ThePerfectComputer",
      "id": 103011002,
      "node_id": "U_kgDOBiPSug",
      "avatar_url": "https://avatars.githubusercontent.com/u/103011002?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ThePerfectComputer",
      "html_url": "https://github.com/ThePerfectComputer",
      "followers_url": "https://api.github.com/users/ThePerfectComputer/followers",
      "following_url": "https://api.github.com/users/ThePerfectComputer/following{/other_user}",
      "gists_url": "https://api.github.com/users/ThePerfectComputer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ThePerfectComputer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ThePerfectComputer/subscriptions",
      "organizations_url": "https://api.github.com/users/ThePerfectComputer/orgs",
      "repos_url": "https://api.github.com/users/ThePerfectComputer/repos",
      "events_url": "https://api.github.com/users/ThePerfectComputer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ThePerfectComputer/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-11-15T18:30:13Z",
    "updated_at": "2023-11-15T18:30:13Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "The Mistral 7B paper claims a theoretical attention span of 131K tokens(via propagating information up through layers with GQA) for Mistral 7B. I'm trying to figure out how this is achieved in practice. The trick seems to be on [line 128](https://github.com/mistralai/mistral-src/blob/main/one_file_ref.py#L129), with the branch `if positions.shape[0] > 1:`, which would typically be taken when the model is first called. From my understanding, taking this branch would compute k/v values for all provided tokens, which could then propagate information for an initial prompt state of up to 131K tokens throughout the model layers(due to the staggered nature of GQA). The line would never be evaluated again as additional tokens are subsequently added to the model cache one at a time as can be seen on [line 332](https://github.com/mistralai/mistral-src/blob/main/one_file_ref.py#L332C18-L332C96) `logits = model.forward(next_token[:, None], torch.LongTensor([cur_pos]).to(next_token))\r\n`.\r\nI will note the the cache's default size is 4096, which also seems to give us the sliding attention window the paper refers to. All 32 transformer block layers of Mistral seem to compute attention scores using only the cache whenever only one token is provided to the model.forward() call, otherwise, the attention scores are computed without the cache.\r\nIs my current understanding correct?\r\nPaper link: https://ar5iv.labs.arxiv.org/html/2310.06825#S2.F1\r\nCode where scores are generated directly from cache: https://github.com/mistralai/mistral-src/blob/main/one_file_ref.py#L125-L140",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/71/reactions",
      "total_count": 2,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 2
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/71/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/70",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/70/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/70/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/70/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/70",
    "id": 1992649084,
    "node_id": "PR_kwDOKY_97s5fZ-Qc",
    "number": 70,
    "title": "Update README",
    "user": {
      "login": "luv-bansal",
      "id": 70321430,
      "node_id": "MDQ6VXNlcjcwMzIxNDMw",
      "avatar_url": "https://avatars.githubusercontent.com/u/70321430?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/luv-bansal",
      "html_url": "https://github.com/luv-bansal",
      "followers_url": "https://api.github.com/users/luv-bansal/followers",
      "following_url": "https://api.github.com/users/luv-bansal/following{/other_user}",
      "gists_url": "https://api.github.com/users/luv-bansal/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/luv-bansal/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/luv-bansal/subscriptions",
      "organizations_url": "https://api.github.com/users/luv-bansal/orgs",
      "repos_url": "https://api.github.com/users/luv-bansal/repos",
      "events_url": "https://api.github.com/users/luv-bansal/events{/privacy}",
      "received_events_url": "https://api.github.com/users/luv-bansal/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-11-14T12:30:16Z",
    "updated_at": "2023-11-17T10:57:56Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/70",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/70",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/70.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/70.patch",
      "merged_at": null
    },
    "body": "Updated Readme.md with Clarifai hosted Mistral-7B model\r\n\r\nThe Mistral-7B and many of its finetuned models are hosted on the Clarifai cloud, allowing easy access through its API. Users can use the Clarifai Python SDK to interact with the API. Additionally, Mistral model inference is possible with other Clarifai Client Libraries like Java, cURL, NodeJS, PHP, and more.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/70/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/70/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/69",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/69/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/69/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/69/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/69",
    "id": 1987882041,
    "node_id": "I_kwDOKY_97s52fKw5",
    "number": 69,
    "title": "How to train mistral? ",
    "user": {
      "login": "mihalt",
      "id": 30621622,
      "node_id": "MDQ6VXNlcjMwNjIxNjIy",
      "avatar_url": "https://avatars.githubusercontent.com/u/30621622?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mihalt",
      "html_url": "https://github.com/mihalt",
      "followers_url": "https://api.github.com/users/mihalt/followers",
      "following_url": "https://api.github.com/users/mihalt/following{/other_user}",
      "gists_url": "https://api.github.com/users/mihalt/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mihalt/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mihalt/subscriptions",
      "organizations_url": "https://api.github.com/users/mihalt/orgs",
      "repos_url": "https://api.github.com/users/mihalt/repos",
      "events_url": "https://api.github.com/users/mihalt/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mihalt/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-11-10T15:53:05Z",
    "updated_at": "2023-11-11T12:57:22Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi! I deployed it by this manual to aws https://docs.mistral.ai/cloud-deployment/skypilot\r\n\r\nAnd now I need to train it for my NER task. Say me, please, what should I do? Should I do something like this? https://skypilot.readthedocs.io/en/latest/getting-started/tutorial.html#tutorial-dnn-training\r\n\r\nP.S: I can't use SageMakers, that manual is in huggingface, due to some strange errors that I have quotes. So, I would like to train without it. ",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/69/reactions",
      "total_count": 2,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/69/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/68",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/68/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/68/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/68/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/68",
    "id": 1984130059,
    "node_id": "I_kwDOKY_97s52Q2wL",
    "number": 68,
    "title": "Was Mistral Pretrained with Dropout Enabled?",
    "user": {
      "login": "zaptrem",
      "id": 1612230,
      "node_id": "MDQ6VXNlcjE2MTIyMzA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1612230?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/zaptrem",
      "html_url": "https://github.com/zaptrem",
      "followers_url": "https://api.github.com/users/zaptrem/followers",
      "following_url": "https://api.github.com/users/zaptrem/following{/other_user}",
      "gists_url": "https://api.github.com/users/zaptrem/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/zaptrem/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/zaptrem/subscriptions",
      "organizations_url": "https://api.github.com/users/zaptrem/orgs",
      "repos_url": "https://api.github.com/users/zaptrem/repos",
      "events_url": "https://api.github.com/users/zaptrem/events{/privacy}",
      "received_events_url": "https://api.github.com/users/zaptrem/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-11-08T17:56:08Z",
    "updated_at": "2023-11-08T17:56:08Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "If so, can you share the params you used? Thanks!",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/68/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/68/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/67",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/67/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/67/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/67/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/67",
    "id": 1983562861,
    "node_id": "I_kwDOKY_97s52OsRt",
    "number": 67,
    "title": "Question about finetune mistral 7B (data format)",
    "user": {
      "login": "xihajun",
      "id": 25631641,
      "node_id": "MDQ6VXNlcjI1NjMxNjQx",
      "avatar_url": "https://avatars.githubusercontent.com/u/25631641?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/xihajun",
      "html_url": "https://github.com/xihajun",
      "followers_url": "https://api.github.com/users/xihajun/followers",
      "following_url": "https://api.github.com/users/xihajun/following{/other_user}",
      "gists_url": "https://api.github.com/users/xihajun/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/xihajun/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/xihajun/subscriptions",
      "organizations_url": "https://api.github.com/users/xihajun/orgs",
      "repos_url": "https://api.github.com/users/xihajun/repos",
      "events_url": "https://api.github.com/users/xihajun/events{/privacy}",
      "received_events_url": "https://api.github.com/users/xihajun/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-11-08T13:00:11Z",
    "updated_at": "2023-11-08T13:04:42Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "It is really impressive when doing inference with Mistral 7B. Thank you so much for open source it.\r\n\r\nMay I kindly ask what kind of format is the best way to finetune the model?\r\n\r\nI read some blog posts and found a few different formats\r\n\r\n- `text_row = f\"\"\"<s>[INST] {instruction} here are the inputs {input} [/INST] \\\\n {output} </s>\"\"\"`\r\n- `Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n{output}</s>`\r\n\r\nI wonder if it is possible to have some suggestion from the team to see which is the best way to finetune?\r\n\r\nMany thanks!",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/67/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/67/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/66",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/66/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/66/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/66/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/66",
    "id": 1977731401,
    "node_id": "I_kwDOKY_97s514clJ",
    "number": 66,
    "title": "model is giving answer in russian",
    "user": {
      "login": "Sanchit-404",
      "id": 74064295,
      "node_id": "MDQ6VXNlcjc0MDY0Mjk1",
      "avatar_url": "https://avatars.githubusercontent.com/u/74064295?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Sanchit-404",
      "html_url": "https://github.com/Sanchit-404",
      "followers_url": "https://api.github.com/users/Sanchit-404/followers",
      "following_url": "https://api.github.com/users/Sanchit-404/following{/other_user}",
      "gists_url": "https://api.github.com/users/Sanchit-404/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Sanchit-404/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Sanchit-404/subscriptions",
      "organizations_url": "https://api.github.com/users/Sanchit-404/orgs",
      "repos_url": "https://api.github.com/users/Sanchit-404/repos",
      "events_url": "https://api.github.com/users/Sanchit-404/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Sanchit-404/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2023-11-05T10:45:50Z",
    "updated_at": "2024-01-18T05:19:21Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I coded an automatic pipeline to pass questions to the model. But the model is giving answers in russian. I tried manualprompting, the answer is still in russian.\r\n![Screenshot 2023-11-05 161453](https://github.com/mistralai/mistral-src/assets/74064295/b1756242-b3b3-4194-a671-d0f3eeb48311)\r\nIs there some paramter i need to change to get the answer in english.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/66/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/66/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/65",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/65/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/65/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/65/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/65",
    "id": 1977271519,
    "node_id": "I_kwDOKY_97s512sTf",
    "number": 65,
    "title": "how to explain Attention that input QKV tensor # xformers requires (B=1, S, H, D)",
    "user": {
      "login": "dhcode-cpp",
      "id": 76241118,
      "node_id": "MDQ6VXNlcjc2MjQxMTE4",
      "avatar_url": "https://avatars.githubusercontent.com/u/76241118?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dhcode-cpp",
      "html_url": "https://github.com/dhcode-cpp",
      "followers_url": "https://api.github.com/users/dhcode-cpp/followers",
      "following_url": "https://api.github.com/users/dhcode-cpp/following{/other_user}",
      "gists_url": "https://api.github.com/users/dhcode-cpp/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dhcode-cpp/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dhcode-cpp/subscriptions",
      "organizations_url": "https://api.github.com/users/dhcode-cpp/orgs",
      "repos_url": "https://api.github.com/users/dhcode-cpp/repos",
      "events_url": "https://api.github.com/users/dhcode-cpp/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dhcode-cpp/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-11-04T10:26:56Z",
    "updated_at": "2023-11-10T05:58:17Z",
    "closed_at": "2023-11-10T05:58:16Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "My data batch size = 3,  windows_size = 3, the input like is\r\n```\r\nsequences = [\"11 12 13 14 15\", \"21 22 23 24 25 26 27\", \"31 32\"]\r\n```\r\n\r\nI have two questions when I debugging mistral model;\r\n\r\nFirst, 3 batch sequences would be flat as a one sequence [5, 7, 2] -> tensor like [5+7+2, 1]?\r\n\r\nSecond, If first things is true, how do we calculate attention? \r\n1.  how to explain xformers requires (B=1, S, H, D),   if we make 3 batch as 1 sequence, we would calculate cross batch attention? \r\n2. we generate 1 token by QKV[1, 17, 4, 128], But 2 step, the 2-dim q is 3, k is 9, how to confirm this output?\r\n     I think q[q_b1, q_b2, q_b3], k is [k_b1_window1, k_b1_window2,  k_b1_window2, ..........]\r\n \r\n\r\nWe print Q/K/V shape before mistral/model.py: \r\n\r\n\r\n```\r\n# xformers requires (B=1, S, H, D)\r\nxq, key, val = xq[None, ...], key[None, ...], val[None, ...]\r\n\r\nprint('q:',xq.shape)\r\nprint('k:',key.shape)\r\nprint('v:',val.shape)\r\n\r\n# output = memory_efficient_attention(xq, key, val, None if cache is None else cache.mask)\r\n```\r\nand print string as following(the layer number is 2, n_kv_head =4 and n_head = 4):\r\n\r\n------------------ 0\r\ncur_layer_id :  0\r\nq: torch.Size([1, 17, 4, 128])\r\nk: torch.Size([1, 17, 4, 128])\r\nv: torch.Size([1, 17, 4, 128])\r\n------------------ 1\r\ncur_layer_id :  1\r\nq: torch.Size([1, 17, 4, 128])\r\nk: torch.Size([1, 17, 4, 128])\r\nv: torch.Size([1, 17, 4, 128])\r\n------------------ 0\r\ncur_layer_id :  0\r\nq: torch.Size([1, 3, 4, 128])\r\nk: torch.Size([1, 9, 4, 128])\r\nv: torch.Size([1, 9, 4, 128])\r\n------------------ 1\r\ncur_layer_id :  1\r\nq: torch.Size([1, 3, 4, 128])\r\nk: torch.Size([1, 9, 4, 128])\r\nv: torch.Size([1, 9, 4, 128])\r\n\r\n\r\nMistral is an impressive work, and I'm excited to hear your response. Thank you very much!\r\n\r\n",
    "closed_by": {
      "login": "dhcode-cpp",
      "id": 76241118,
      "node_id": "MDQ6VXNlcjc2MjQxMTE4",
      "avatar_url": "https://avatars.githubusercontent.com/u/76241118?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dhcode-cpp",
      "html_url": "https://github.com/dhcode-cpp",
      "followers_url": "https://api.github.com/users/dhcode-cpp/followers",
      "following_url": "https://api.github.com/users/dhcode-cpp/following{/other_user}",
      "gists_url": "https://api.github.com/users/dhcode-cpp/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dhcode-cpp/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dhcode-cpp/subscriptions",
      "organizations_url": "https://api.github.com/users/dhcode-cpp/orgs",
      "repos_url": "https://api.github.com/users/dhcode-cpp/repos",
      "events_url": "https://api.github.com/users/dhcode-cpp/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dhcode-cpp/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/65/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/65/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/64",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/64/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/64/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/64/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/64",
    "id": 1971981694,
    "node_id": "I_kwDOKY_97s51ig1-",
    "number": 64,
    "title": "Does mistral-instruct-7b support fast transformer deployment",
    "user": {
      "login": "lebronjamesking",
      "id": 5305743,
      "node_id": "MDQ6VXNlcjUzMDU3NDM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5305743?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lebronjamesking",
      "html_url": "https://github.com/lebronjamesking",
      "followers_url": "https://api.github.com/users/lebronjamesking/followers",
      "following_url": "https://api.github.com/users/lebronjamesking/following{/other_user}",
      "gists_url": "https://api.github.com/users/lebronjamesking/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lebronjamesking/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lebronjamesking/subscriptions",
      "organizations_url": "https://api.github.com/users/lebronjamesking/orgs",
      "repos_url": "https://api.github.com/users/lebronjamesking/repos",
      "events_url": "https://api.github.com/users/lebronjamesking/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lebronjamesking/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-11-01T09:07:23Z",
    "updated_at": "2023-11-01T09:07:23Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi there,\r\nAs per title, when and how mistral-instruct-7b support fast transformer deployment? This would be very helpful as llama2-chat already support ft.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/64/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/64/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/63",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/63/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/63/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/63/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/63",
    "id": 1971278972,
    "node_id": "PR_kwDOKY_97s5eRsJW",
    "number": 63,
    "title": "Update README.md",
    "user": {
      "login": "VinayKokate22",
      "id": 114766745,
      "node_id": "U_kgDOBtczmQ",
      "avatar_url": "https://avatars.githubusercontent.com/u/114766745?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/VinayKokate22",
      "html_url": "https://github.com/VinayKokate22",
      "followers_url": "https://api.github.com/users/VinayKokate22/followers",
      "following_url": "https://api.github.com/users/VinayKokate22/following{/other_user}",
      "gists_url": "https://api.github.com/users/VinayKokate22/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/VinayKokate22/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/VinayKokate22/subscriptions",
      "organizations_url": "https://api.github.com/users/VinayKokate22/orgs",
      "repos_url": "https://api.github.com/users/VinayKokate22/repos",
      "events_url": "https://api.github.com/users/VinayKokate22/events{/privacy}",
      "received_events_url": "https://api.github.com/users/VinayKokate22/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-31T20:49:18Z",
    "updated_at": "2023-10-31T23:09:31Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/63",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/63",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/63.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/63.patch",
      "merged_at": null
    },
    "body": "Removed Grammatical errors",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/63/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/63/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/62",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/62/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/62/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/62/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/62",
    "id": 1971269405,
    "node_id": "I_kwDOKY_97s51fy8d",
    "number": 62,
    "title": "Embedding model and Engine??",
    "user": {
      "login": "muhtalhakhan",
      "id": 63025804,
      "node_id": "MDQ6VXNlcjYzMDI1ODA0",
      "avatar_url": "https://avatars.githubusercontent.com/u/63025804?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/muhtalhakhan",
      "html_url": "https://github.com/muhtalhakhan",
      "followers_url": "https://api.github.com/users/muhtalhakhan/followers",
      "following_url": "https://api.github.com/users/muhtalhakhan/following{/other_user}",
      "gists_url": "https://api.github.com/users/muhtalhakhan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/muhtalhakhan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/muhtalhakhan/subscriptions",
      "organizations_url": "https://api.github.com/users/muhtalhakhan/orgs",
      "repos_url": "https://api.github.com/users/muhtalhakhan/repos",
      "events_url": "https://api.github.com/users/muhtalhakhan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/muhtalhakhan/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 6,
    "created_at": "2023-10-31T20:43:27Z",
    "updated_at": "2023-11-21T00:52:40Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hey guys,\r\n\r\nI am shifting from GPT to Mistral and I am facing one problem which is that I could not find the embedding model and engine for Mistral yet.\r\n\r\nI am using the service from [DeepInfra](deepinfra.com)\r\n\r\nHere's the code snippet which I wrote for GPT:\r\n\r\n```\r\ndef get_embedding(text, model=\"embedding-ada-002\"):\r\n  text = text.replace(\"\\n\", \" \")\r\n  if not text: \r\n    text = \"this is blank\"\r\n  return openai.Embedding.create(\r\n          input=[text], model=model)['data'][0]['embedding']\r\n\r\n\r\nif __name__ == '__main__':\r\n#   gpt_parameter = {\"engine\": \"text-davinci-003\", \"max_tokens\": 50, \r\n#                    \"temperature\": 0, \"top_p\": 1, \"stream\": False,\r\n#                    \"frequency_penalty\": 0, \"presence_penalty\": 0, \r\n#                    \"stop\": ['\"']}\r\n  gpt_parameter = {\"max_tokens\": 50, \r\n                   \"temperature\": 0, \"top_p\": 1, \"stream\": False,\r\n                   \"frequency_penalty\": 0, \"presence_penalty\": 0, \r\n                   \"stop\": ['\"']}\r\n```\r\n \r\n All I want to know is which embedding model and engine should be used?\r\n \r\n Thank you \ud83d\ude42",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/62/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/62/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/61",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/61/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/61/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/61/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/61",
    "id": 1970249655,
    "node_id": "I_kwDOKY_97s51b5-3",
    "number": 61,
    "title": "More language support?",
    "user": {
      "login": "OnceJune",
      "id": 5461945,
      "node_id": "MDQ6VXNlcjU0NjE5NDU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5461945?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/OnceJune",
      "html_url": "https://github.com/OnceJune",
      "followers_url": "https://api.github.com/users/OnceJune/followers",
      "following_url": "https://api.github.com/users/OnceJune/following{/other_user}",
      "gists_url": "https://api.github.com/users/OnceJune/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/OnceJune/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/OnceJune/subscriptions",
      "organizations_url": "https://api.github.com/users/OnceJune/orgs",
      "repos_url": "https://api.github.com/users/OnceJune/repos",
      "events_url": "https://api.github.com/users/OnceJune/events{/privacy}",
      "received_events_url": "https://api.github.com/users/OnceJune/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 6,
    "created_at": "2023-10-31T11:28:58Z",
    "updated_at": "2024-01-03T12:02:08Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi, I'd like to know will mistral planning to support more languages?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/61/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/61/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/60",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/60/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/60/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/60/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/60",
    "id": 1968239701,
    "node_id": "I_kwDOKY_97s51UPRV",
    "number": 60,
    "title": "sliding window size in prefill and decode stage",
    "user": {
      "login": "ofhwei",
      "id": 109642856,
      "node_id": "U_kgDOBokEaA",
      "avatar_url": "https://avatars.githubusercontent.com/u/109642856?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ofhwei",
      "html_url": "https://github.com/ofhwei",
      "followers_url": "https://api.github.com/users/ofhwei/followers",
      "following_url": "https://api.github.com/users/ofhwei/following{/other_user}",
      "gists_url": "https://api.github.com/users/ofhwei/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ofhwei/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ofhwei/subscriptions",
      "organizations_url": "https://api.github.com/users/ofhwei/orgs",
      "repos_url": "https://api.github.com/users/ofhwei/repos",
      "events_url": "https://api.github.com/users/ofhwei/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ofhwei/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-30T12:28:43Z",
    "updated_at": "2023-10-30T12:28:43Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hello, \r\n\r\nI noticed that the sliding window size may be different in the prefill stage and the decode stage. As in the prefill stage, the current token is visible along with the recent `sliding_window_size` tokens([code here](https://github.com/mistralai/mistral-src/blob/main/one_file_ref.py#L251-L261)). However, in the decode stage, the current token is only visible with the recent `sliding_window_size - 1` tokens. I'm wondering what is the purpose of this distinction? i.e. why the code  is \r\n```\r\nmask = torch.triu(mask, diagonal=-self.args.sliding_window)\r\n```\r\ninstead of\r\n```\r\nmask = torch.triu(mask, diagonal=-self.args.sliding_window + 1)\r\n```\r\n And by the way, could you please tell me if SWA was used during training?\r\nThanks.\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/60/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/60/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/59",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/59/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/59/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/59/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/59",
    "id": 1966833853,
    "node_id": "I_kwDOKY_97s51O4C9",
    "number": 59,
    "title": "Can't load xFormers because of PyTorch 2.1.0+cu121 ",
    "user": {
      "login": "russ22cox",
      "id": 129803744,
      "node_id": "U_kgDOB7yl4A",
      "avatar_url": "https://avatars.githubusercontent.com/u/129803744?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/russ22cox",
      "html_url": "https://github.com/russ22cox",
      "followers_url": "https://api.github.com/users/russ22cox/followers",
      "following_url": "https://api.github.com/users/russ22cox/following{/other_user}",
      "gists_url": "https://api.github.com/users/russ22cox/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/russ22cox/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/russ22cox/subscriptions",
      "organizations_url": "https://api.github.com/users/russ22cox/orgs",
      "repos_url": "https://api.github.com/users/russ22cox/repos",
      "events_url": "https://api.github.com/users/russ22cox/events{/privacy}",
      "received_events_url": "https://api.github.com/users/russ22cox/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-10-29T03:57:40Z",
    "updated_at": "2023-11-30T23:59:39Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I installed everything from the requirements, but when I run the demo, it tells me:\r\n\r\n>WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\r\n>   PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0+cpu)\r\n>    Python  3.10.11 (you have 3.10.11)\r\n>   Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\r\n\r\nSo I go over to that page and do\r\n\r\n>  pip3 install -U xformers --index-url https://download.pytorch.org/whl/cu121\r\n\r\nBut everything comes up \"Requirement already satisfied\".  I don't know what else I can do to switch from 2.1.0+cpu to 2.1.0+cu121\r\n\r\n\r\n\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/59/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/59/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/58",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/58/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/58/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/58/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/58",
    "id": 1966715571,
    "node_id": "I_kwDOKY_97s51ObKz",
    "number": 58,
    "title": "Feature: Adding contributors section to the README.md file.",
    "user": {
      "login": "Kalyanimhala",
      "id": 147402107,
      "node_id": "U_kgDOCMktew",
      "avatar_url": "https://avatars.githubusercontent.com/u/147402107?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Kalyanimhala",
      "html_url": "https://github.com/Kalyanimhala",
      "followers_url": "https://api.github.com/users/Kalyanimhala/followers",
      "following_url": "https://api.github.com/users/Kalyanimhala/following{/other_user}",
      "gists_url": "https://api.github.com/users/Kalyanimhala/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Kalyanimhala/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Kalyanimhala/subscriptions",
      "organizations_url": "https://api.github.com/users/Kalyanimhala/orgs",
      "repos_url": "https://api.github.com/users/Kalyanimhala/repos",
      "events_url": "https://api.github.com/users/Kalyanimhala/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Kalyanimhala/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-10-28T19:33:55Z",
    "updated_at": "2023-12-25T19:59:46Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "There is no Contributors section in readme file .\r\nAs we know Contributions are what make the open-source community such an amazing place to learn, inspire, and create.\r\nThe Contributors section in a README.md file is important as it acknowledges and gives credit to those who have contributed to a project, fosters community and collaboration, adds transparency and accountability, and helps document the project's history for current and future maintainers. It also serves as a form of recognition, motivating contributors to continue their efforts.\r\n![contributors](https://github.com/mistralai/mistral-src/assets/147402107/1ace57c8-c052-4343-9927-1232d122665f)\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/58/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/58/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/57",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/57/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/57/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/57/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/57",
    "id": 1966559528,
    "node_id": "I_kwDOKY_97s51N1Eo",
    "number": 57,
    "title": "Code complete?",
    "user": {
      "login": "zhoumengbo",
      "id": 79833433,
      "node_id": "MDQ6VXNlcjc5ODMzNDMz",
      "avatar_url": "https://avatars.githubusercontent.com/u/79833433?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/zhoumengbo",
      "html_url": "https://github.com/zhoumengbo",
      "followers_url": "https://api.github.com/users/zhoumengbo/followers",
      "following_url": "https://api.github.com/users/zhoumengbo/following{/other_user}",
      "gists_url": "https://api.github.com/users/zhoumengbo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/zhoumengbo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/zhoumengbo/subscriptions",
      "organizations_url": "https://api.github.com/users/zhoumengbo/orgs",
      "repos_url": "https://api.github.com/users/zhoumengbo/repos",
      "events_url": "https://api.github.com/users/zhoumengbo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/zhoumengbo/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2023-10-28T11:30:49Z",
    "updated_at": "2023-10-30T04:44:04Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I'd like to know if the code in this repository is complete. Has anyone tried pre-training this model from scratch?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/57/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/57/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/55",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/55/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/55/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/55/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/55",
    "id": 1962490129,
    "node_id": "I_kwDOKY_97s50-TkR",
    "number": 55,
    "title": "Batching, GQA and Flash Attnetion",
    "user": {
      "login": "maximzubkov",
      "id": 47659865,
      "node_id": "MDQ6VXNlcjQ3NjU5ODY1",
      "avatar_url": "https://avatars.githubusercontent.com/u/47659865?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/maximzubkov",
      "html_url": "https://github.com/maximzubkov",
      "followers_url": "https://api.github.com/users/maximzubkov/followers",
      "following_url": "https://api.github.com/users/maximzubkov/following{/other_user}",
      "gists_url": "https://api.github.com/users/maximzubkov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/maximzubkov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/maximzubkov/subscriptions",
      "organizations_url": "https://api.github.com/users/maximzubkov/orgs",
      "repos_url": "https://api.github.com/users/maximzubkov/repos",
      "events_url": "https://api.github.com/users/maximzubkov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/maximzubkov/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-26T00:18:20Z",
    "updated_at": "2023-11-15T18:29:01Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hello, Mistral Team!\r\n\r\nCongrats on open-sourcing your model and thanks a lot for your work! Being inspired by the memory- and compute-efficiency and benchmark performance of your model, I tried to reuse your codebase for multi-modal experiments, but I got stuck with some questions. I would be super grateful if you could answer them: \r\n\r\n\r\n1. 1. I tried to copy your implementation of GQA (grouped-query attention) that relies on `xFormers` lib and checked the `xFormers` for more details. In the paper you mention that \"FlashAttention and xFormers yield a 2x speed improvement over a vanilla attention baseline\", so I expected them both to be used in the implementation of attention, however, in the code you don't specify `op` in [line 115 of mistral/model.py](https://github.com/mistralai/mistral-src/blob/147c4e68279b90eb61b19bdea44e16f5539d5a5d/mistral/model.py#L115). The documentation of `xFormers` says that [if set None (recommended), xFormers will dispatch to the best available operator, depending on the inputs and options](https://github.com/facebookresearch/xformers/blob/e1b36f781ba1c9d10f36fc0ec87170e0b381fdad/xformers/ops/fmha/__init__.py#L217). Is it a bug? \r\n\r\n   2. The second point about GQA is that `xFormers` claim that GQA \"is an experimental feature supported only for the forward pass\" [line 116](https://github.com/facebookresearch/xformers/blob/e1b36f781ba1c9d10f36fc0ec87170e0b381fdad/xformers/ops/fmha/__init__.py#L116). How does this work during the training?\r\n\r\n   3. Finally the implementation of GQA in `xFormers` is a bit confusing itself. The input tensors are forced to have the same shape, so `n_kv_heads` becomes equal to `n_q_heads` [xformers example](https://github.com/facebookresearch/xformers/blob/e1b36f781ba1c9d10f36fc0ec87170e0b381fdad/xformers/ops/fmha/__init__.py#L186) and [repeat_kv in mistral/model.py](https://github.com/mistralai/mistral-src/blob/147c4e68279b90eb61b19bdea44e16f5539d5a5d/mistral/model.py#L111). If we compare it with JAX implementation, the authors [use regular einsum](https://github.com/google/flaxformer/blob/ea17eb012a1d340ddff017b7a534c2162aaec34c/flaxformer/components/attention/memory_efficient_attention.py#L74). Does not that influence the memory footprint?\r\n\r\n2. You used a very interesting approach to batching, and it differs significantly between [main.py](https://github.com/mistralai/mistral-src/blob/main/main.py) and [one_file_ref.py](https://github.com/mistralai/mistral-src/blob/main/one_file_ref.py). Let me first summarise what I see to avoid any misunderstandings.\r\n   1. In `main.py` you first split the prompt into chunks, and then [concatenate chunks into a single sequence](https://github.com/mistralai/mistral-src/blob/147c4e68279b90eb61b19bdea44e16f5539d5a5d/main.py#L61), entirely avoiding batch dimension. You did the same in [zero shot example in tutorial/classifier.ipynb](https://github.com/mistralai/mistral-src/blob/main/tutorials/classifier.ipynb) as well.\r\n   2. In `one_file_ref.py` as well as in [hugging face implementation](https://github.com/huggingface/transformers/blob/v4.34.1/src/transformers/models/mistral/modeling_mistral.py#L762) you employ [convenient batching](https://github.com/mistralai/mistral-src/blob/147c4e68279b90eb61b19bdea44e16f5539d5a5d/one_file_ref.py#L310). One small question here is why did you [truncate the sequences](https://github.com/mistralai/mistral-src/blob/147c4e68279b90eb61b19bdea44e16f5539d5a5d/one_file_ref.py#L315) to the `min_prompt_len` before forward pass?  \r\n\r\n    So my question, or rather guess rationalizing what was done in `main.py` is the following:\r\n    - Padding and batching of sequences limits the speed due to the fact that some sequences might have significantly more tokens than others, so smaller sequences will have to be padded, resulting in the total number of tokens equal to `n_seqs x max_seq_len`. \r\n    - Okay, let's concatenate them, then the total number of tokens is `sum(seq_lens) <= n_seqs x max_seq_len`. However, now we will have a huge attention matrix of size `sum(seq_lens) x sum(seq_lens)`. The good point is that the mask will be very sparse, so we can avoid computing some of the attention values `A_ij`.  \r\n    - But the problem with the calculation of this sparse attention matrix is that the length of the longest sequence will define which \"area\" of the attention matrix has to be computed. So for different batches, different `A_ij` cells in the attention matrix have to be computed, depending on the `max_seq_len` of the elements in the batch.\r\n    - Here is where chunking comes into play. On one hand, chunks limit the number of operations that has to be performed to compute attention. On the other, now \"interesting area\" of attention is only a narrow strip and this strip is deterministic depending only on the size of the chunk, and independent from the length of the longest sequence.\r\n    \r\n    Did I correctly get your intuition? Is the efficient computation of the attention matrix what you meant by \"related changes to FlashAttention and xFormers\" in the paper? Did you use the same implementation for training?\r\n    \r\n3. Thanks for leaving the [following comment](https://github.com/mistralai/mistral-src/blob/147c4e68279b90eb61b19bdea44e16f5539d5a5d/mistral/cache.py#L163) on the caching procedure, it helped a lot to understand what is going on. Just letting you know that you have a small typo here in `inpput` \ud83d\ude0a\r\n\r\nLooking forward to more research, papers, and models, thank you!",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/55/reactions",
      "total_count": 14,
      "+1": 10,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 4
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/55/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/54",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/54/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/54/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/54/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/54",
    "id": 1961042503,
    "node_id": "I_kwDOKY_97s504yJH",
    "number": 54,
    "title": "Unable to build Docker image with cuda:11.8.0-devel-ubuntu20.04 - CUDA version (11.8) mismatches the version that was used to compile PyTorch (12.1)",
    "user": {
      "login": "hammad26",
      "id": 12643784,
      "node_id": "MDQ6VXNlcjEyNjQzNzg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/12643784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hammad26",
      "html_url": "https://github.com/hammad26",
      "followers_url": "https://api.github.com/users/hammad26/followers",
      "following_url": "https://api.github.com/users/hammad26/following{/other_user}",
      "gists_url": "https://api.github.com/users/hammad26/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hammad26/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hammad26/subscriptions",
      "organizations_url": "https://api.github.com/users/hammad26/orgs",
      "repos_url": "https://api.github.com/users/hammad26/repos",
      "events_url": "https://api.github.com/users/hammad26/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hammad26/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-25T10:16:40Z",
    "updated_at": "2023-10-25T12:38:17Z",
    "closed_at": "2023-10-25T12:38:16Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi\r\n\r\nThe provided [Dockerfile](https://github.com/mistralai/mistral-src/blob/main/deploy/Dockerfile) is using `ubuntu22.04` that is having `Python 3.10` as a default version. I needed `Python 3.8` (because ray 2.7.0 needed that) which is available in `ubuntu20.04`, so I am using `cuda:11.8.0-devel-ubuntu20.04` for image building. My complete Dockerfile is:\r\n\r\n```\r\nFROM --platform=amd64 nvcr.io/nvidia/cuda:11.8.0-devel-ubuntu20.04 as base\r\n\r\nARG MAX_JOBS\r\n\r\nWORKDIR /workspace\r\n\r\nRUN apt update && \\\r\n    apt install -y python3-pip python3-packaging \\\r\n    git ninja-build && \\\r\n    pip3 install -U pip\r\n\r\n# Tweak this list to reduce build time\r\n# https://developer.nvidia.com/cuda-gpus\r\nENV TORCH_CUDA_ARCH_LIST \"7.0;7.2;7.5;8.0;8.6;8.9;9.0\"\r\n\r\n# ValueError: setuptools>=49.4.0 is required\r\nRUN pip3 install \"setuptools>=49.4.0\"\r\n\r\n# We have to manually install Torch otherwise apex & xformers won't build\r\nRUN pip3 install \"torch>=2.0.0\"\r\n# To enable H100 PCIe support, install PyTorch >=2.2.0 by uncommenting the following line\r\n# RUN pip3 install \"torch==2.2.0.dev20231018+cu118\" --index-url https://download.pytorch.org/whl/nightly/cu118\r\n\r\n# This build is slow but NVIDIA does not provide binaries. Increase MAX_JOBS as needed.\r\nRUN git clone https://github.com/NVIDIA/apex && \\\r\n    cd apex && git checkout 2386a912164b0c5cfcd8be7a2b890fbac5607c82 && \\\r\n    sed -i '/check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)/d' setup.py && \\\r\n    python3 setup.py install --cpp_ext --cuda_ext\r\n\r\nRUN pip3 install \"xformers==0.0.22\" \"transformers==4.34.0\" \"vllm==0.2.0\" \"fschat[model_worker]==0.2.30\" \"ray[client]\"\r\n\r\nCOPY entrypoint.sh .\r\n\r\nRUN chmod +x /workspace/entrypoint.sh\r\n\r\nENTRYPOINT [\"/workspace/entrypoint.sh\"]\r\n\r\n```\r\n\r\nFirst of all, I faced `ValueError: setuptools>=49.4.0 is required` issue, and fixed it through pip then I am getting following issues:\r\n\r\n```\r\nStep 8/12 : RUN git clone https://github.com/NVIDIA/apex &&     cd apex && git checkout 2386a912164b0c5cfcd8be7a2b890fbac5607c82 &&     sed -i '/check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)/d' setup.py &&     python3 setup.py install --cpp_ext --cuda_ext\r\n ---> Running in 75b68d40dad7\r\nCloning into 'apex'...\r\nNote: switching to '2386a912164b0c5cfcd8be7a2b890fbac5607c82'.\r\n\r\nYou are in 'detached HEAD' state. You can look around, make experimental\r\nchanges and commit them, and you can discard any commits you make in this\r\nstate without impacting any branches by switching back to a branch.\r\n\r\nIf you want to create a new branch to retain commits you create, you may\r\ndo so (now or later) by using -c with the switch command. Example:\r\n\r\n  git switch -c <new-branch-name>\r\n\r\nOr undo this operation with:\r\n\r\n  git switch -\r\n\r\nTurn off this advice by setting config variable advice.detachedHead to false\r\n\r\nHEAD is now at 2386a91 Distributed optimizer infrastructure for FP8 parameters (#1723)\r\n\r\n\r\n/usr/local/lib/python3.8/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: numpy.core.multiarray failed to import (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\r\n  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\r\nNo CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\r\n/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\r\n!!\r\n\r\n        ********************************************************************************\r\n        Please avoid running ``setup.py`` directly.\r\n        Instead, use pypa/build, pypa/installer or other\r\n        standards-based tools.\r\n\r\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\r\n        ********************************************************************************\r\n\r\n!!\r\n  self.initialize_options()\r\n/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\r\n!!\r\n\r\n        ********************************************************************************\r\n        Please avoid running ``setup.py`` and ``easy_install``.\r\n        Instead, use pypa/build, pypa/installer or other\r\n        standards-based tools.\r\n\r\n        See https://github.com/pypa/setuptools/issues/917 for details.\r\n        ********************************************************************************\r\n\r\n!!\r\n  self.initialize_options()\r\nTraceback (most recent call last):\r\n  File \"setup.py\", line 799, in <module>\r\n    setup(\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/__init__.py\", line 103, in setup\r\n    return distutils.core.setup(**attrs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/core.py\", line 185, in setup\r\n    return run_commands(dist)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/core.py\", line 201, in run_commands\r\n    dist.run_commands()\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\r\n    self.run_command(cmd)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/dist.py\", line 989, in run_command\r\n    super().run_command(command)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/install.py\", line 84, in run\r\n    self.do_egg_install()\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/install.py\", line 132, in do_egg_install\r\n    self.run_command('bdist_egg')\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/dist.py\", line 989, in run_command\r\n    super().run_command(command)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/bdist_egg.py\", line 167, in run\r\n    cmd = self.call_command('install_lib', warn_dir=0)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/bdist_egg.py\", line 153, in call_command\r\n    self.run_command(cmdname)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/dist.py\", line 989, in run_command\r\n    super().run_command(command)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/install_lib.py\", line 11, in run\r\n    self.build()\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/command/install_lib.py\", line 111, in build\r\n    self.run_command('build_ext')\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/dist.py\", line 989, in run_command\r\n    super().run_command(command)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/build_ext.py\", line 88, in run\r\n    _build_ext.run(self)\r\n  File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/command/build_ext.py\", line 345, in run\r\n    self.build_extensions()\r\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 525, in build_extensions\r\n    _check_cuda_version(compiler_name, compiler_version)\r\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 413, in _check_cuda_version\r\n    raise RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))\r\nRuntimeError: \r\nThe detected CUDA version (11.8) mismatches the version that was used to compile\r\nPyTorch (12.1). Please make sure to use the same CUDA versions.\r\n```\r\n\r\nWill appreciate some help on it. ",
    "closed_by": {
      "login": "hammad26",
      "id": 12643784,
      "node_id": "MDQ6VXNlcjEyNjQzNzg0",
      "avatar_url": "https://avatars.githubusercontent.com/u/12643784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hammad26",
      "html_url": "https://github.com/hammad26",
      "followers_url": "https://api.github.com/users/hammad26/followers",
      "following_url": "https://api.github.com/users/hammad26/following{/other_user}",
      "gists_url": "https://api.github.com/users/hammad26/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hammad26/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hammad26/subscriptions",
      "organizations_url": "https://api.github.com/users/hammad26/orgs",
      "repos_url": "https://api.github.com/users/hammad26/repos",
      "events_url": "https://api.github.com/users/hammad26/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hammad26/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/54/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/54/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/53",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/53/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/53/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/53/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/53",
    "id": 1957026679,
    "node_id": "I_kwDOKY_97s50pdt3",
    "number": 53,
    "title": "What is the `max_seq_len` in Mistral?",
    "user": {
      "login": "ParadoxZW",
      "id": 32508168,
      "node_id": "MDQ6VXNlcjMyNTA4MTY4",
      "avatar_url": "https://avatars.githubusercontent.com/u/32508168?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ParadoxZW",
      "html_url": "https://github.com/ParadoxZW",
      "followers_url": "https://api.github.com/users/ParadoxZW/followers",
      "following_url": "https://api.github.com/users/ParadoxZW/following{/other_user}",
      "gists_url": "https://api.github.com/users/ParadoxZW/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ParadoxZW/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ParadoxZW/subscriptions",
      "organizations_url": "https://api.github.com/users/ParadoxZW/orgs",
      "repos_url": "https://api.github.com/users/ParadoxZW/repos",
      "events_url": "https://api.github.com/users/ParadoxZW/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ParadoxZW/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-23T12:15:38Z",
    "updated_at": "2023-10-31T20:13:37Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "What is the `max_seq_len` (or `max_position_embeddings`) of Mistral-7B-v0.1 when training?\r\n\r\nThe official code says it is 128_000. (https://github.com/mistralai/mistral-src/blob/147c4e68279b90eb61b19bdea44e16f5539d5a5d/mistral/model.py#L201C69-L201C69)\r\n\r\nThe config file in huggingface says it is 32768. (https://huggingface.co/mistralai/Mistral-7B-v0.1/blob/main/config.json).\r\n\r\nAnd the official blog mentions 16k.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/53/reactions",
      "total_count": 11,
      "+1": 9,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 2
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/53/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/52",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/52/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/52/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/52/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/52",
    "id": 1951649387,
    "node_id": "PR_kwDOKY_97s5dPhHi",
    "number": 52,
    "title": "Add simple classification example",
    "user": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-19T08:55:37Z",
    "updated_at": "2023-12-01T09:43:20Z",
    "closed_at": "2023-10-19T08:55:57Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/52",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/52",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/52.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/52.patch",
      "merged_at": "2023-10-19T08:55:57Z"
    },
    "body": null,
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/52/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/52/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/51",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/51/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/51/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/51/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/51",
    "id": 1949950055,
    "node_id": "I_kwDOKY_97s50OeBn",
    "number": 51,
    "title": "Ray qelr_async_event not implemented yet ",
    "user": {
      "login": "Ryojikn",
      "id": 4712257,
      "node_id": "MDQ6VXNlcjQ3MTIyNTc=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4712257?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Ryojikn",
      "html_url": "https://github.com/Ryojikn",
      "followers_url": "https://api.github.com/users/Ryojikn/followers",
      "following_url": "https://api.github.com/users/Ryojikn/following{/other_user}",
      "gists_url": "https://api.github.com/users/Ryojikn/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Ryojikn/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Ryojikn/subscriptions",
      "organizations_url": "https://api.github.com/users/Ryojikn/orgs",
      "repos_url": "https://api.github.com/users/Ryojikn/repos",
      "events_url": "https://api.github.com/users/Ryojikn/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Ryojikn/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-18T14:51:37Z",
    "updated_at": "2023-10-18T14:51:37Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi,\r\n\r\nI'm receiving the following error while deploying Mistral AI using VLLM.\r\n\r\nqelr_async_event not implemented yet \r\n\r\nHave you guys seem this type of issue? How can I possibly resolve?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/51/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/51/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/50",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/50/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/50/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/50/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/50",
    "id": 1949347196,
    "node_id": "I_kwDOKY_97s50MK18",
    "number": 50,
    "title": "Error on run main ",
    "user": {
      "login": "lrx1213",
      "id": 19346545,
      "node_id": "MDQ6VXNlcjE5MzQ2NTQ1",
      "avatar_url": "https://avatars.githubusercontent.com/u/19346545?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lrx1213",
      "html_url": "https://github.com/lrx1213",
      "followers_url": "https://api.github.com/users/lrx1213/followers",
      "following_url": "https://api.github.com/users/lrx1213/following{/other_user}",
      "gists_url": "https://api.github.com/users/lrx1213/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lrx1213/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lrx1213/subscriptions",
      "organizations_url": "https://api.github.com/users/lrx1213/orgs",
      "repos_url": "https://api.github.com/users/lrx1213/repos",
      "events_url": "https://api.github.com/users/lrx1213/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lrx1213/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-18T09:58:19Z",
    "updated_at": "2024-07-15T19:58:43Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Command\uff1a python -m main interactive /mistral-7B-v0.1/\r\nError:\r\n\r\nPrompt: Hello\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/mistral/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/usr/local/anaconda3/envs/mistral/lib/python3.10/runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/media/cfs/lizongshang/work/deep_learning/llm/mistral/main.py\", line 140, in <module>\r\n    fire.Fire({\r\n  File \"/usr/local/anaconda3/envs/mistral/lib/python3.10/site-packages/fire/core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/usr/local/anaconda3/envs/mistral/lib/python3.10/site-packages/fire/core.py\", line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/usr/local/anaconda3/envs/mistral/lib/python3.10/site-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n  File \"/media/cfs/lizongshang/work/deep_learning/llm/mistral/main.py\", line 110, in interactive\r\n    res, _logprobs = generate(\r\n  File \"/usr/local/anaconda3/envs/mistral/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/media/cfs/lizongshang/work/deep_learning/llm/mistral/main.py\", line 61, in generate\r\n    prelogits = model.forward(\r\n  File \"/media/cfs/lizongshang/work/deep_learning/llm/mistral/mistral/model.py\", line 204, in forward\r\n    input_metadata = cache.get_input_metadata(seqlens)\r\n  File \"/media/cfs/lizongshang/work/deep_learning/llm/mistral/mistral/cache.py\", line 192, in get_input_metadata\r\n    mask = BlockDiagonalCausalMask.from_seqlens(seqlens).make_local_attention(self.sliding_window)\r\nAttributeError: 'BlockDiagonalCausalMask' object has no attribute 'make_local_attention'",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/50/reactions",
      "total_count": 2,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/50/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/49",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/49/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/49/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/49/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/49",
    "id": 1945966441,
    "node_id": "PR_kwDOKY_97s5c8Kfu",
    "number": 49,
    "title": "[Model] Refactoring model.py into small modules",
    "user": {
      "login": "sarveshwar-s",
      "id": 59520591,
      "node_id": "MDQ6VXNlcjU5NTIwNTkx",
      "avatar_url": "https://avatars.githubusercontent.com/u/59520591?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sarveshwar-s",
      "html_url": "https://github.com/sarveshwar-s",
      "followers_url": "https://api.github.com/users/sarveshwar-s/followers",
      "following_url": "https://api.github.com/users/sarveshwar-s/following{/other_user}",
      "gists_url": "https://api.github.com/users/sarveshwar-s/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sarveshwar-s/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sarveshwar-s/subscriptions",
      "organizations_url": "https://api.github.com/users/sarveshwar-s/orgs",
      "repos_url": "https://api.github.com/users/sarveshwar-s/repos",
      "events_url": "https://api.github.com/users/sarveshwar-s/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sarveshwar-s/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-16T19:45:24Z",
    "updated_at": "2023-10-17T14:18:52Z",
    "closed_at": "2023-10-17T14:18:51Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/49",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/49",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/49.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/49.patch",
      "merged_at": null
    },
    "body": "This commit refactors the repo and creates new atomic modules namely layers and config.",
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/49/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/49/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/48",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/48/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/48/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/48/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/48",
    "id": 1945227822,
    "node_id": "I_kwDOKY_97s5z8dIu",
    "number": 48,
    "title": "it's fantastic! but can do 1.1b , 3b versions too?",
    "user": {
      "login": "hiqsociety",
      "id": 51492452,
      "node_id": "MDQ6VXNlcjUxNDkyNDUy",
      "avatar_url": "https://avatars.githubusercontent.com/u/51492452?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hiqsociety",
      "html_url": "https://github.com/hiqsociety",
      "followers_url": "https://api.github.com/users/hiqsociety/followers",
      "following_url": "https://api.github.com/users/hiqsociety/following{/other_user}",
      "gists_url": "https://api.github.com/users/hiqsociety/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hiqsociety/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hiqsociety/subscriptions",
      "organizations_url": "https://api.github.com/users/hiqsociety/orgs",
      "repos_url": "https://api.github.com/users/hiqsociety/repos",
      "events_url": "https://api.github.com/users/hiqsociety/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hiqsociety/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-16T13:30:09Z",
    "updated_at": "2023-10-16T13:30:09Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "it's fantastic! but can do 1.1b , 3b versions too?\r\n\r\nof course looking forward to 70b too as well. but would like to see what 1b, 3b can do too.\r\n\r\n7b is \"fantastic\" as a 7b. the best 7b out there for sure. beats 13b too.\r\n\r\ncan 1b beat 7b i wonder.\r\n\r\npls put 1b and 7b as roadmap for next series or now if not asking for too much. thx!",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/48/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/48/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/47",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/47/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/47/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/47/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/47",
    "id": 1945098111,
    "node_id": "I_kwDOKY_97s5z79d_",
    "number": 47,
    "title": "Are `RotatingBufferCache` and `RollingBufferCache` the same thing?",
    "user": {
      "login": "ParadoxZW",
      "id": 32508168,
      "node_id": "MDQ6VXNlcjMyNTA4MTY4",
      "avatar_url": "https://avatars.githubusercontent.com/u/32508168?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ParadoxZW",
      "html_url": "https://github.com/ParadoxZW",
      "followers_url": "https://api.github.com/users/ParadoxZW/followers",
      "following_url": "https://api.github.com/users/ParadoxZW/following{/other_user}",
      "gists_url": "https://api.github.com/users/ParadoxZW/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ParadoxZW/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ParadoxZW/subscriptions",
      "organizations_url": "https://api.github.com/users/ParadoxZW/orgs",
      "repos_url": "https://api.github.com/users/ParadoxZW/repos",
      "events_url": "https://api.github.com/users/ParadoxZW/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ParadoxZW/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-16T12:26:37Z",
    "updated_at": "2023-10-17T14:11:31Z",
    "closed_at": "2023-10-17T14:11:31Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Great projects!\r\n\r\nI've saw these two terms on different materials, `RotatingBufferCache` in code and your official blog and `RollingBufferCache` in the README file. Are they referred to the same thing?",
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/47/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/47/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/46",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/46/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/46/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/46/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/46",
    "id": 1944705426,
    "node_id": "PR_kwDOKY_97s5c31w8",
    "number": 46,
    "title": "Update and rename main.py to mainwithcomments.py",
    "user": {
      "login": "nikcode9",
      "id": 129772745,
      "node_id": "U_kgDOB7wsyQ",
      "avatar_url": "https://avatars.githubusercontent.com/u/129772745?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nikcode9",
      "html_url": "https://github.com/nikcode9",
      "followers_url": "https://api.github.com/users/nikcode9/followers",
      "following_url": "https://api.github.com/users/nikcode9/following{/other_user}",
      "gists_url": "https://api.github.com/users/nikcode9/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nikcode9/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nikcode9/subscriptions",
      "organizations_url": "https://api.github.com/users/nikcode9/orgs",
      "repos_url": "https://api.github.com/users/nikcode9/repos",
      "events_url": "https://api.github.com/users/nikcode9/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nikcode9/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-10-16T08:50:29Z",
    "updated_at": "2023-10-18T14:20:52Z",
    "closed_at": "2023-10-18T14:20:52Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/46",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/46",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/46.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/46.patch",
      "merged_at": null
    },
    "body": null,
    "closed_by": {
      "login": "lerela",
      "id": 7956811,
      "node_id": "MDQ6VXNlcjc5NTY4MTE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7956811?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lerela",
      "html_url": "https://github.com/lerela",
      "followers_url": "https://api.github.com/users/lerela/followers",
      "following_url": "https://api.github.com/users/lerela/following{/other_user}",
      "gists_url": "https://api.github.com/users/lerela/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lerela/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lerela/subscriptions",
      "organizations_url": "https://api.github.com/users/lerela/orgs",
      "repos_url": "https://api.github.com/users/lerela/repos",
      "events_url": "https://api.github.com/users/lerela/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lerela/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/46/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/46/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/45",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/45/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/45/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/45/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/45",
    "id": 1943894291,
    "node_id": "I_kwDOKY_97s5z3XkT",
    "number": 45,
    "title": "Python 3.11.6 compatibility",
    "user": {
      "login": "MasterLivens",
      "id": 15192583,
      "node_id": "MDQ6VXNlcjE1MTkyNTgz",
      "avatar_url": "https://avatars.githubusercontent.com/u/15192583?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/MasterLivens",
      "html_url": "https://github.com/MasterLivens",
      "followers_url": "https://api.github.com/users/MasterLivens/followers",
      "following_url": "https://api.github.com/users/MasterLivens/following{/other_user}",
      "gists_url": "https://api.github.com/users/MasterLivens/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/MasterLivens/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/MasterLivens/subscriptions",
      "organizations_url": "https://api.github.com/users/MasterLivens/orgs",
      "repos_url": "https://api.github.com/users/MasterLivens/repos",
      "events_url": "https://api.github.com/users/MasterLivens/events{/privacy}",
      "received_events_url": "https://api.github.com/users/MasterLivens/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2023-10-15T13:41:20Z",
    "updated_at": "2023-10-25T09:32:33Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "(venv) E:\\AI\\mistral-7B-v0.1\\mistral-src>pip install Fire\r\nRequirement already satisfied: Fire in e:\\ai\\mistral-7b-v0.1\\venv\\lib\\site-packages (0.5.0)\r\nRequirement already satisfied: six in e:\\ai\\mistral-7b-v0.1\\venv\\lib\\site-packages (from Fire) (1.16.0)\r\nRequirement already satisfied: termcolor in e:\\ai\\mistral-7b-v0.1\\venv\\lib\\site-packages (from Fire) (2.3.0)\r\n\r\n(venv) E:\\AI\\mistral-7B-v0.1\\mistral-src>python -m main demo E:\\AI\\mistral-7B-v0.1\\model\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"E:\\AI\\mistral-7B-v0.1\\mistral-src\\main.py\", line 140, in <module>\r\n    fire.Fire({\r\n  File \"E:\\AI\\mistral-7B-v0.1\\venv\\Lib\\site-packages\\fire\\core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"E:\\AI\\mistral-7B-v0.1\\venv\\Lib\\site-packages\\fire\\core.py\", line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n                                ^^^^^^^^^^^^^^^^^^^^\r\n  File \"E:\\AI\\mistral-7B-v0.1\\venv\\Lib\\site-packages\\fire\\core.py\", line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n                ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"E:\\AI\\mistral-7B-v0.1\\mistral-src\\main.py\", line 124, in demo\r\n    res, _logprobs = generate(\r\n                     ^^^^^^^^^\r\n  File \"E:\\AI\\mistral-7B-v0.1\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"E:\\AI\\mistral-7B-v0.1\\mistral-src\\main.py\", line 61, in generate\r\n    prelogits = model.forward(\r\n                ^^^^^^^^^^^^^^\r\n  File \"E:\\AI\\mistral-7B-v0.1\\mistral-src\\mistral\\model.py\", line 204, in forward\r\n    input_metadata = cache.get_input_metadata(seqlens)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"E:\\AI\\mistral-7B-v0.1\\mistral-src\\mistral\\cache.py\", line 192, in get_input_metadata\r\n    mask = BlockDiagonalCausalMask.from_seqlens(seqlens).make_local_attention(self.sliding_window)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'BlockDiagonalCausalMask' object has no attribute 'make_local_attention'",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/45/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/45/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/44",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/44/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/44/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/44/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/44",
    "id": 1943408852,
    "node_id": "PR_kwDOKY_97s5cznWx",
    "number": 44,
    "title": "Update README.md",
    "user": {
      "login": "infwinston",
      "id": 1206058,
      "node_id": "MDQ6VXNlcjEyMDYwNTg=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1206058?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/infwinston",
      "html_url": "https://github.com/infwinston",
      "followers_url": "https://api.github.com/users/infwinston/followers",
      "following_url": "https://api.github.com/users/infwinston/following{/other_user}",
      "gists_url": "https://api.github.com/users/infwinston/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/infwinston/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/infwinston/subscriptions",
      "organizations_url": "https://api.github.com/users/infwinston/orgs",
      "repos_url": "https://api.github.com/users/infwinston/repos",
      "events_url": "https://api.github.com/users/infwinston/events{/privacy}",
      "received_events_url": "https://api.github.com/users/infwinston/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-10-14T17:29:52Z",
    "updated_at": "2023-10-18T17:25:56Z",
    "closed_at": "2023-10-18T14:33:55Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/44",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/44",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/44.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/44.patch",
      "merged_at": "2023-10-18T14:33:55Z"
    },
    "body": "Hi Mistral Team,\r\n\r\nI'm a PhD student from LMSys & Skypilot team. Congrats again on all the great work and achievement! \r\nWe saw you guys recently added Mistral's Arena Elo rating/MT-bench in the arxiv preprint. We're very honored to be included!\r\nOur website has been serving Mistral since the day it was announced and we've added [support](https://github.com/lm-sys/FastChat/blob/9db21434b30a5355eb4723acc6562709f5ccc2c1/fastchat/conversation.py#L846) on FastChat. It'd be awesome if you could add a link to our website [chat.lmsys.org](chat.lmsys.org) and repo. See this PR change.\r\n\r\nAlso, sorry for another ask, but would you mind adding a citation in your Arxiv paper? Thanks!\r\nhttps://lmsys.org/blog/2023-05-03-arena/#citation\r\n<img width=\"404\" alt=\"image\" src=\"https://github.com/mistralai/mistral-src/assets/1206058/ebb4c711-63a4-4a2f-ba39-b4814948a056\">",
    "closed_by": {
      "login": "albertqjiang",
      "id": 19373539,
      "node_id": "MDQ6VXNlcjE5MzczNTM5",
      "avatar_url": "https://avatars.githubusercontent.com/u/19373539?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/albertqjiang",
      "html_url": "https://github.com/albertqjiang",
      "followers_url": "https://api.github.com/users/albertqjiang/followers",
      "following_url": "https://api.github.com/users/albertqjiang/following{/other_user}",
      "gists_url": "https://api.github.com/users/albertqjiang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/albertqjiang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/albertqjiang/subscriptions",
      "organizations_url": "https://api.github.com/users/albertqjiang/orgs",
      "repos_url": "https://api.github.com/users/albertqjiang/repos",
      "events_url": "https://api.github.com/users/albertqjiang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/albertqjiang/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/44/reactions",
      "total_count": 2,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/44/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/43",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/43/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/43/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/43/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/43",
    "id": 1942300839,
    "node_id": "PR_kwDOKY_97s5cwg2u",
    "number": 43,
    "title": "Update PyTorch to 2.2.0 to support NVIDIA H100 PCIe",
    "user": {
      "login": "quantumsheep",
      "id": 7271496,
      "node_id": "MDQ6VXNlcjcyNzE0OTY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7271496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/quantumsheep",
      "html_url": "https://github.com/quantumsheep",
      "followers_url": "https://api.github.com/users/quantumsheep/followers",
      "following_url": "https://api.github.com/users/quantumsheep/following{/other_user}",
      "gists_url": "https://api.github.com/users/quantumsheep/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/quantumsheep/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/quantumsheep/subscriptions",
      "organizations_url": "https://api.github.com/users/quantumsheep/orgs",
      "repos_url": "https://api.github.com/users/quantumsheep/repos",
      "events_url": "https://api.github.com/users/quantumsheep/events{/privacy}",
      "received_events_url": "https://api.github.com/users/quantumsheep/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2023-10-13T17:06:15Z",
    "updated_at": "2023-10-19T09:02:35Z",
    "closed_at": "2023-10-19T09:02:35Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/43",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/43",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/43.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/43.patch",
      "merged_at": "2023-10-19T09:02:35Z"
    },
    "body": "Running the current version's image will give the following error on NVIDIA H100 PCIe GPUs:\r\n```\r\nNVIDIA H100 PCIe with CUDA capability sm_90 is not compatible with the current PyTorch installation.\r\nThe current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70 sm_75 sm_80 sm_86.\r\nIf you want to use the NVIDIA H100 PCIe GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\r\n```\r\n\r\nUpdating PyTorch to 2.2.0 (which is the in-dev version) works.",
    "closed_by": {
      "login": "albertqjiang",
      "id": 19373539,
      "node_id": "MDQ6VXNlcjE5MzczNTM5",
      "avatar_url": "https://avatars.githubusercontent.com/u/19373539?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/albertqjiang",
      "html_url": "https://github.com/albertqjiang",
      "followers_url": "https://api.github.com/users/albertqjiang/followers",
      "following_url": "https://api.github.com/users/albertqjiang/following{/other_user}",
      "gists_url": "https://api.github.com/users/albertqjiang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/albertqjiang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/albertqjiang/subscriptions",
      "organizations_url": "https://api.github.com/users/albertqjiang/orgs",
      "repos_url": "https://api.github.com/users/albertqjiang/repos",
      "events_url": "https://api.github.com/users/albertqjiang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/albertqjiang/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/43/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/43/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/42",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/42/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/42/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/42/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/42",
    "id": 1941698823,
    "node_id": "I_kwDOKY_97s5zu_kH",
    "number": 42,
    "title": "python process keeps getting killed",
    "user": {
      "login": "5hayanB",
      "id": 91522269,
      "node_id": "U_kgDOBXSE3Q",
      "avatar_url": "https://avatars.githubusercontent.com/u/91522269?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/5hayanB",
      "html_url": "https://github.com/5hayanB",
      "followers_url": "https://api.github.com/users/5hayanB/followers",
      "following_url": "https://api.github.com/users/5hayanB/following{/other_user}",
      "gists_url": "https://api.github.com/users/5hayanB/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/5hayanB/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/5hayanB/subscriptions",
      "organizations_url": "https://api.github.com/users/5hayanB/orgs",
      "repos_url": "https://api.github.com/users/5hayanB/repos",
      "events_url": "https://api.github.com/users/5hayanB/events{/privacy}",
      "received_events_url": "https://api.github.com/users/5hayanB/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-13T10:39:29Z",
    "updated_at": "2023-10-17T14:12:45Z",
    "closed_at": "2023-10-17T14:12:44Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "After the executing the interactive session code, I am getting the following error.\r\n\r\n```zsh\r\n[1]    534592 killed     python -m main interactive /path/to/mistral-7B-v0.1/directory\r\n```\r\n\r\nHardware:\r\nRyzen 5 5600\r\nRadeon RX 6700 XT\r\n16GB RAM\r\n\r\nI do not know if this is a hardware issue.",
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/42/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/42/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/41",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/41/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/41/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/41/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/41",
    "id": 1938825697,
    "node_id": "I_kwDOKY_97s5zkCHh",
    "number": 41,
    "title": "How many tokens did Mistral-7B train on?",
    "user": {
      "login": "Njasa2k",
      "id": 99513716,
      "node_id": "U_kgDOBe51dA",
      "avatar_url": "https://avatars.githubusercontent.com/u/99513716?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Njasa2k",
      "html_url": "https://github.com/Njasa2k",
      "followers_url": "https://api.github.com/users/Njasa2k/followers",
      "following_url": "https://api.github.com/users/Njasa2k/following{/other_user}",
      "gists_url": "https://api.github.com/users/Njasa2k/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Njasa2k/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Njasa2k/subscriptions",
      "organizations_url": "https://api.github.com/users/Njasa2k/orgs",
      "repos_url": "https://api.github.com/users/Njasa2k/repos",
      "events_url": "https://api.github.com/users/Njasa2k/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Njasa2k/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-11T22:20:05Z",
    "updated_at": "2023-11-13T00:38:44Z",
    "closed_at": "2023-11-13T00:38:44Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": null,
    "closed_by": {
      "login": "Njasa2k",
      "id": 99513716,
      "node_id": "U_kgDOBe51dA",
      "avatar_url": "https://avatars.githubusercontent.com/u/99513716?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Njasa2k",
      "html_url": "https://github.com/Njasa2k",
      "followers_url": "https://api.github.com/users/Njasa2k/followers",
      "following_url": "https://api.github.com/users/Njasa2k/following{/other_user}",
      "gists_url": "https://api.github.com/users/Njasa2k/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Njasa2k/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Njasa2k/subscriptions",
      "organizations_url": "https://api.github.com/users/Njasa2k/orgs",
      "repos_url": "https://api.github.com/users/Njasa2k/repos",
      "events_url": "https://api.github.com/users/Njasa2k/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Njasa2k/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/41/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 1
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/41/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/40",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/40/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/40/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/40/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/40",
    "id": 1938185208,
    "node_id": "I_kwDOKY_97s5zhlv4",
    "number": 40,
    "title": "Questions about layer-wise sliding window attention",
    "user": {
      "login": "NormXU",
      "id": 33339685,
      "node_id": "MDQ6VXNlcjMzMzM5Njg1",
      "avatar_url": "https://avatars.githubusercontent.com/u/33339685?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/NormXU",
      "html_url": "https://github.com/NormXU",
      "followers_url": "https://api.github.com/users/NormXU/followers",
      "following_url": "https://api.github.com/users/NormXU/following{/other_user}",
      "gists_url": "https://api.github.com/users/NormXU/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/NormXU/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/NormXU/subscriptions",
      "organizations_url": "https://api.github.com/users/NormXU/orgs",
      "repos_url": "https://api.github.com/users/NormXU/repos",
      "events_url": "https://api.github.com/users/NormXU/events{/privacy}",
      "received_events_url": "https://api.github.com/users/NormXU/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 13,
    "created_at": "2023-10-11T16:11:08Z",
    "updated_at": "2024-04-23T09:42:29Z",
    "closed_at": "2023-11-04T09:43:32Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Thank you for the awesome work! \r\n\r\nI am reaching out to seek further clarity regarding the Sliding Window Attention (SWA) mechanism as described in the README\r\n\r\nAs we know, SWA is typically implemented by sliding a fixed-size window over the input sequence to process it in smaller, manageable chunk.  Suppose the window size $W$ is 5, the context length is 15 and  the decoder model has 10 layers. From my understanding, since the SWA in mistral-7B is layer-wise, in this scenario it could work as follow:\r\n\r\n1. Initially, the window covers tokens 1 to 5 of the input sequence.\r\n2. If the window slides by  $W-1 = 4$ tokens, it would then cover tokens 5 to 9.\r\n3. In the next slide, it covers tokens 9 to 13.\r\n4. Finally, it would cover tokens 11 to 15.\r\n\r\nBut this only accounts for first 4 layers out of 10 layers. I am curious about the remaining 6 layers. Do the rest layers only conduct attention mechanism on token 11 to 15?\r\n\r\nBesides, I couldn't find any code that is about the implementation of a layer-wise sliding window. It seems that every layer uses a consistent sliding window, rather than each layer moving by W tokens. Did I miss something?\r\n",
    "closed_by": {
      "login": "NormXU",
      "id": 33339685,
      "node_id": "MDQ6VXNlcjMzMzM5Njg1",
      "avatar_url": "https://avatars.githubusercontent.com/u/33339685?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/NormXU",
      "html_url": "https://github.com/NormXU",
      "followers_url": "https://api.github.com/users/NormXU/followers",
      "following_url": "https://api.github.com/users/NormXU/following{/other_user}",
      "gists_url": "https://api.github.com/users/NormXU/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/NormXU/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/NormXU/subscriptions",
      "organizations_url": "https://api.github.com/users/NormXU/orgs",
      "repos_url": "https://api.github.com/users/NormXU/repos",
      "events_url": "https://api.github.com/users/NormXU/events{/privacy}",
      "received_events_url": "https://api.github.com/users/NormXU/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/40/reactions",
      "total_count": 3,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 3
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/40/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/39",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/39/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/39/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/39/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/39",
    "id": 1936229389,
    "node_id": "I_kwDOKY_97s5zaIQN",
    "number": 39,
    "title": "very good! thx! but...",
    "user": {
      "login": "hiqsociety",
      "id": 51492452,
      "node_id": "MDQ6VXNlcjUxNDkyNDUy",
      "avatar_url": "https://avatars.githubusercontent.com/u/51492452?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hiqsociety",
      "html_url": "https://github.com/hiqsociety",
      "followers_url": "https://api.github.com/users/hiqsociety/followers",
      "following_url": "https://api.github.com/users/hiqsociety/following{/other_user}",
      "gists_url": "https://api.github.com/users/hiqsociety/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hiqsociety/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hiqsociety/subscriptions",
      "organizations_url": "https://api.github.com/users/hiqsociety/orgs",
      "repos_url": "https://api.github.com/users/hiqsociety/repos",
      "events_url": "https://api.github.com/users/hiqsociety/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hiqsociety/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-10T20:55:32Z",
    "updated_at": "2023-10-10T22:05:53Z",
    "closed_at": "2023-10-10T22:05:53Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "can you pls make it accept more context or something because it's not 100% following instructions.\r\nwould like to hv it follow more instructions.\r\n\r\noops, just realised i need to use the more bits one from gguf of llama. thx!",
    "closed_by": {
      "login": "hiqsociety",
      "id": 51492452,
      "node_id": "MDQ6VXNlcjUxNDkyNDUy",
      "avatar_url": "https://avatars.githubusercontent.com/u/51492452?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hiqsociety",
      "html_url": "https://github.com/hiqsociety",
      "followers_url": "https://api.github.com/users/hiqsociety/followers",
      "following_url": "https://api.github.com/users/hiqsociety/following{/other_user}",
      "gists_url": "https://api.github.com/users/hiqsociety/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hiqsociety/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hiqsociety/subscriptions",
      "organizations_url": "https://api.github.com/users/hiqsociety/orgs",
      "repos_url": "https://api.github.com/users/hiqsociety/repos",
      "events_url": "https://api.github.com/users/hiqsociety/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hiqsociety/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/39/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/39/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/38",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/38/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/38/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/38/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/38",
    "id": 1934373071,
    "node_id": "I_kwDOKY_97s5zTDDP",
    "number": 38,
    "title": "one_file_ref.py attention has an O(seqlen^2) matrix multiplication when prefilling",
    "user": {
      "login": "Aniruddha-Deb",
      "id": 14949866,
      "node_id": "MDQ6VXNlcjE0OTQ5ODY2",
      "avatar_url": "https://avatars.githubusercontent.com/u/14949866?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Aniruddha-Deb",
      "html_url": "https://github.com/Aniruddha-Deb",
      "followers_url": "https://api.github.com/users/Aniruddha-Deb/followers",
      "following_url": "https://api.github.com/users/Aniruddha-Deb/following{/other_user}",
      "gists_url": "https://api.github.com/users/Aniruddha-Deb/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Aniruddha-Deb/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Aniruddha-Deb/subscriptions",
      "organizations_url": "https://api.github.com/users/Aniruddha-Deb/orgs",
      "repos_url": "https://api.github.com/users/Aniruddha-Deb/repos",
      "events_url": "https://api.github.com/users/Aniruddha-Deb/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Aniruddha-Deb/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-10T05:04:36Z",
    "updated_at": "2023-10-17T14:17:23Z",
    "closed_at": "2023-10-17T14:17:23Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Lines 129-143 in `one_file_ref.py` multiplies the complete query-key matrices with each other, if we are prefilling the key-value cache. The sliding window mask is applied only after this multiplication\r\n\r\n```python\r\n\r\n        if positions.shape[0] > 1:\r\n            # prefill\r\n            key, value = repeat_kv(xk, xv, self.repeats)\r\n        else:\r\n            cur_pos = positions[-1].item() + 1\r\n            key, value = repeat_kv(self.cache_k[:bsz, :cur_pos, ...], self.cache_v[:bsz, :cur_pos, ...], self.repeats)\r\n            \r\n        query = xq.transpose(1, 2)\r\n        key = key.transpose(1, 2)\r\n        value = value.transpose(1, 2)\r\n        # scores : [bsz, n_heads, seqlen | 1, seqlen]\r\n        scores = torch.matmul(query, key.transpose(2, 3)) * self.scale\r\n        # this operation is O(seqlen^2), and not O(seqlen*sliding_window))\r\n        \r\n        if mask is not None:\r\n            scores += mask[None, None, ...]\r\n```\r\n\r\nThis seems inefficient for prompt sizes > sliding window length, and can be improved by just using the attention implementation in `mistral/model.py` directly (which uses xformers' `memory_efficient_attention`). ",
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/38/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/38/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/37",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/37/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/37/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/37/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/37",
    "id": 1933213900,
    "node_id": "I_kwDOKY_97s5zOoDM",
    "number": 37,
    "title": "\ud83e\udd92 colab",
    "user": {
      "login": "camenduru",
      "id": 54370274,
      "node_id": "MDQ6VXNlcjU0MzcwMjc0",
      "avatar_url": "https://avatars.githubusercontent.com/u/54370274?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/camenduru",
      "html_url": "https://github.com/camenduru",
      "followers_url": "https://api.github.com/users/camenduru/followers",
      "following_url": "https://api.github.com/users/camenduru/following{/other_user}",
      "gists_url": "https://api.github.com/users/camenduru/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/camenduru/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/camenduru/subscriptions",
      "organizations_url": "https://api.github.com/users/camenduru/orgs",
      "repos_url": "https://api.github.com/users/camenduru/repos",
      "events_url": "https://api.github.com/users/camenduru/events{/privacy}",
      "received_events_url": "https://api.github.com/users/camenduru/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-09T14:26:24Z",
    "updated_at": "2023-10-13T19:37:59Z",
    "closed_at": "2023-10-13T19:37:59Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Thanks for the project \u2764\ufe0f I made a colab. \ud83e\udd73 I hope you like it. https://github.com/camenduru/Mistral-colab",
    "closed_by": {
      "login": "camenduru",
      "id": 54370274,
      "node_id": "MDQ6VXNlcjU0MzcwMjc0",
      "avatar_url": "https://avatars.githubusercontent.com/u/54370274?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/camenduru",
      "html_url": "https://github.com/camenduru",
      "followers_url": "https://api.github.com/users/camenduru/followers",
      "following_url": "https://api.github.com/users/camenduru/following{/other_user}",
      "gists_url": "https://api.github.com/users/camenduru/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/camenduru/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/camenduru/subscriptions",
      "organizations_url": "https://api.github.com/users/camenduru/orgs",
      "repos_url": "https://api.github.com/users/camenduru/repos",
      "events_url": "https://api.github.com/users/camenduru/events{/privacy}",
      "received_events_url": "https://api.github.com/users/camenduru/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/37/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/37/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/36",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/36/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/36/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/36/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/36",
    "id": 1932979829,
    "node_id": "I_kwDOKY_97s5zNu51",
    "number": 36,
    "title": "Can you provide lora tutorial for mistral 7b instruction model on custom dataset?",
    "user": {
      "login": "universewill",
      "id": 6790730,
      "node_id": "MDQ6VXNlcjY3OTA3MzA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6790730?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/universewill",
      "html_url": "https://github.com/universewill",
      "followers_url": "https://api.github.com/users/universewill/followers",
      "following_url": "https://api.github.com/users/universewill/following{/other_user}",
      "gists_url": "https://api.github.com/users/universewill/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/universewill/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/universewill/subscriptions",
      "organizations_url": "https://api.github.com/users/universewill/orgs",
      "repos_url": "https://api.github.com/users/universewill/repos",
      "events_url": "https://api.github.com/users/universewill/events{/privacy}",
      "received_events_url": "https://api.github.com/users/universewill/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-09T12:39:55Z",
    "updated_at": "2023-10-12T02:10:41Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Can you provide lora tutorial for mistral 7b instruction model on custom dataset?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/36/reactions",
      "total_count": 6,
      "+1": 6,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/36/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/35",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/35/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/35/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/35/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/35",
    "id": 1930686372,
    "node_id": "I_kwDOKY_97s5zE--k",
    "number": 35,
    "title": "System prompt handling in chat templates for Mistral-7b-instruct",
    "user": {
      "login": "jamesr66a",
      "id": 4685384,
      "node_id": "MDQ6VXNlcjQ2ODUzODQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4685384?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jamesr66a",
      "html_url": "https://github.com/jamesr66a",
      "followers_url": "https://api.github.com/users/jamesr66a/followers",
      "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}",
      "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions",
      "organizations_url": "https://api.github.com/users/jamesr66a/orgs",
      "repos_url": "https://api.github.com/users/jamesr66a/repos",
      "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jamesr66a/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 5,
    "created_at": "2023-10-06T17:34:19Z",
    "updated_at": "2023-12-26T09:41:07Z",
    "closed_at": "2023-11-07T06:24:05Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hello, we are trying to implement chat completion over Mistral-7b-instruct and we are trying to figure out how to handle system prompts. Different information sources either omit this or are conflicting:\r\n\r\n* The [docs](https://docs.mistral.ai/llm/mistral-instruct-v0.1#chat-template) and [HF model card](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1) states the following, but does not go into any detail about how to handle system prompts:\r\n\r\nIn order to leverage instruction fine-tuning, your prompt should be surrounded by [INST] and [\\INST] tokens. The very first instruction should begin with a begin of sentence id. The next instructions should not. The assistant generation will be ended by the end-of-sentence token id.\r\n\r\nE.g.\r\n\r\ntext = \"< s >[INST] What is your favourite condiment? [/INST]\"\r\n\"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</ s > \"\r\n\"[INST] Do you have mayonnaise recipes? [/INST]\"\r\n\r\n* HuggingFace's `apply_chat_template` uses `<<SYS>>`/`<</SYS>>` tokens to delineate the system prompt embedded within the first instruction:\r\n```\r\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\r\n\r\ndevice = \"cuda\" # the device to load the model onto\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(\"/root/Mistral-7b-instruct-hf\")\r\ntokenizer = AutoTokenizer.from_pretrained(\"/root/Mistral-7b-instruct-hf\")\r\n\r\nmessages = [\r\n    {\"role\": \"system\", \"content\": \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\"},\r\n    {\"role\": \"user\", \"content\": \"Write me a recipe for tacos al pastor\"},\r\n]\r\n\r\nencodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\r\n\r\nmodel_inputs = encodeds.to(device)\r\nmodel.to(device)\r\n\r\ngenerated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\r\ndecoded = tokenizer.batch_decode(generated_ids)\r\nprint(decoded[0])\r\n\"\"\"\r\n<s> [INST] <<SYS>>\r\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\r\n<</SYS>>\r\n\r\nWrite me a recipe for tacos al pastor [/INST] Tacos al Pastor Recipe\r\n\"\"\"\r\n```\r\n\r\n* FastChat does not seem to support system prompts https://github.com/lm-sys/FastChat/pull/2483/files\r\n\r\n\r\nWhat is the definitive answer for how to handle system prompts with Mistral-7b-instruct?",
    "closed_by": {
      "login": "jamesr66a",
      "id": 4685384,
      "node_id": "MDQ6VXNlcjQ2ODUzODQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4685384?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jamesr66a",
      "html_url": "https://github.com/jamesr66a",
      "followers_url": "https://api.github.com/users/jamesr66a/followers",
      "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}",
      "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions",
      "organizations_url": "https://api.github.com/users/jamesr66a/orgs",
      "repos_url": "https://api.github.com/users/jamesr66a/repos",
      "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jamesr66a/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/35/reactions",
      "total_count": 6,
      "+1": 5,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 1
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/35/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/34",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/34/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/34/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/34/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/34",
    "id": 1926603011,
    "node_id": "I_kwDOKY_97s5y1aED",
    "number": 34,
    "title": "Mistral on CPU",
    "user": {
      "login": "pruthvi1990",
      "id": 22088076,
      "node_id": "MDQ6VXNlcjIyMDg4MDc2",
      "avatar_url": "https://avatars.githubusercontent.com/u/22088076?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pruthvi1990",
      "html_url": "https://github.com/pruthvi1990",
      "followers_url": "https://api.github.com/users/pruthvi1990/followers",
      "following_url": "https://api.github.com/users/pruthvi1990/following{/other_user}",
      "gists_url": "https://api.github.com/users/pruthvi1990/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pruthvi1990/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pruthvi1990/subscriptions",
      "organizations_url": "https://api.github.com/users/pruthvi1990/orgs",
      "repos_url": "https://api.github.com/users/pruthvi1990/repos",
      "events_url": "https://api.github.com/users/pruthvi1990/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pruthvi1990/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-10-04T16:38:44Z",
    "updated_at": "2023-12-17T08:17:30Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi, \r\n\r\nI was reading through the quickstart documentation, I see the requirement is to have a GPU with @least 24G of VRAM.\r\n\r\n- I want to know is there a way to run Mistral on CPU's?. if so, could you please provide the link to QuickStart documentation for the same ? \r\n- If its currently not supported, is there any future plans to support Mistral on CPU's?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/34/reactions",
      "total_count": 2,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 2,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/34/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/33",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/33/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/33/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/33/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/33",
    "id": 1926321751,
    "node_id": "I_kwDOKY_97s5y0VZX",
    "number": 33,
    "title": ".bin format?",
    "user": {
      "login": "StanislawKarnacky",
      "id": 108822866,
      "node_id": "U_kgDOBnyBUg",
      "avatar_url": "https://avatars.githubusercontent.com/u/108822866?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/StanislawKarnacky",
      "html_url": "https://github.com/StanislawKarnacky",
      "followers_url": "https://api.github.com/users/StanislawKarnacky/followers",
      "following_url": "https://api.github.com/users/StanislawKarnacky/following{/other_user}",
      "gists_url": "https://api.github.com/users/StanislawKarnacky/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/StanislawKarnacky/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/StanislawKarnacky/subscriptions",
      "organizations_url": "https://api.github.com/users/StanislawKarnacky/orgs",
      "repos_url": "https://api.github.com/users/StanislawKarnacky/repos",
      "events_url": "https://api.github.com/users/StanislawKarnacky/events{/privacy}",
      "received_events_url": "https://api.github.com/users/StanislawKarnacky/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-04T14:16:26Z",
    "updated_at": "2023-10-04T14:16:26Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Is there any chance to relise it with .bin format to use in commonly used ChatGPT-like interfaces?\r\nFor example, I'm using LMStudio.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/33/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/33/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/32",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/32/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/32/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/32/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/32",
    "id": 1926299254,
    "node_id": "I_kwDOKY_97s5y0P52",
    "number": 32,
    "title": "Tokenizer.model error on pycharm",
    "user": {
      "login": "dominique-AR",
      "id": 108085848,
      "node_id": "U_kgDOBnFCWA",
      "avatar_url": "https://avatars.githubusercontent.com/u/108085848?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dominique-AR",
      "html_url": "https://github.com/dominique-AR",
      "followers_url": "https://api.github.com/users/dominique-AR/followers",
      "following_url": "https://api.github.com/users/dominique-AR/following{/other_user}",
      "gists_url": "https://api.github.com/users/dominique-AR/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dominique-AR/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dominique-AR/subscriptions",
      "organizations_url": "https://api.github.com/users/dominique-AR/orgs",
      "repos_url": "https://api.github.com/users/dominique-AR/repos",
      "events_url": "https://api.github.com/users/dominique-AR/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dominique-AR/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-04T14:05:22Z",
    "updated_at": "2023-10-09T03:14:05Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi guys,\n\nI tried to install and test mistral AI on local. I downloaded mistral-7B-V0.1 model and clone the mistral-src repository. \nInstalling requirements is done. When I try to launch: python -m main demo path/to/mistral-7B-V0.1, I got assertion error : tokenizer.model.\n\nI use pycharm 22.1 on Windows 10.\n\nAny help will be really appreciated \ud83d\ude42.\n\n<!-- Error while uploading image.png -->",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/32/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/32/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/31",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/31/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/31/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/31/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/31",
    "id": 1926128578,
    "node_id": "PR_kwDOKY_97s5b5W0m",
    "number": 31,
    "title": "Update Dockerfile",
    "user": {
      "login": "lerela",
      "id": 7956811,
      "node_id": "MDQ6VXNlcjc5NTY4MTE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7956811?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lerela",
      "html_url": "https://github.com/lerela",
      "followers_url": "https://api.github.com/users/lerela/followers",
      "following_url": "https://api.github.com/users/lerela/following{/other_user}",
      "gists_url": "https://api.github.com/users/lerela/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lerela/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lerela/subscriptions",
      "organizations_url": "https://api.github.com/users/lerela/orgs",
      "repos_url": "https://api.github.com/users/lerela/repos",
      "events_url": "https://api.github.com/users/lerela/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lerela/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-04T12:39:48Z",
    "updated_at": "2023-12-01T09:43:22Z",
    "closed_at": "2023-10-04T12:40:29Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/31",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/31",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/31.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/31.patch",
      "merged_at": "2023-10-04T12:40:29Z"
    },
    "body": "- pin Apex since last commit broke the build \r\n- switch to last Fastchat release",
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/31/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/31/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/30",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/30/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/30/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/30/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/30",
    "id": 1924047280,
    "node_id": "I_kwDOKY_97s5yrqGw",
    "number": 30,
    "title": "Mistral-7B-instruct-v0.1 compatibility with main.py",
    "user": {
      "login": "nvidal01",
      "id": 146839807,
      "node_id": "U_kgDOCMCY_w",
      "avatar_url": "https://avatars.githubusercontent.com/u/146839807?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nvidal01",
      "html_url": "https://github.com/nvidal01",
      "followers_url": "https://api.github.com/users/nvidal01/followers",
      "following_url": "https://api.github.com/users/nvidal01/following{/other_user}",
      "gists_url": "https://api.github.com/users/nvidal01/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nvidal01/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nvidal01/subscriptions",
      "organizations_url": "https://api.github.com/users/nvidal01/orgs",
      "repos_url": "https://api.github.com/users/nvidal01/repos",
      "events_url": "https://api.github.com/users/nvidal01/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nvidal01/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2023-10-03T12:32:11Z",
    "updated_at": "2023-10-17T13:00:23Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi,\r\nI managed to install mistral-7b-v.01 on a server and run the main.py script as recommended, and it works well. I wanted to test the model's abilities in chat completion, so I downloaded Mistral-7b-instruct-v0.1. But when running the same commands as for mistral-7b-v0.1, the main.py program does not work (see error below). More specifically the model.py script included in the mistral folder does not seem compatible with Mistral-7b-instruct-v0.1. \r\nDo you know how to resolve this problem?\r\nThank you\r\n\r\n` > python -m main interactive Mistral-7B-instruct-v0.1/\r\n\r\nTraceback (most recent call last):\r\n  File \"/home1/USERS/PSY-DEV/brunet/anaconda3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/home1/USERS/PSY-DEV/brunet/anaconda3/lib/python3.10/runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home1/USERS/PSY-DEV/brunet/llama/mistral-src/main.py\", line 142, in <module>\r\n    fire.Fire({\r\n  File \"/home1/USERS/PSY-DEV/brunet/anaconda3/lib/python3.10/site-packages/fire/core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/home1/USERS/PSY-DEV/brunet/anaconda3/lib/python3.10/site-packages/fire/core.py\", line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/home1/USERS/PSY-DEV/brunet/anaconda3/lib/python3.10/site-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n  File \"/home1/USERS/PSY-DEV/brunet/llama/mistral-src/main.py\", line 106, in interactive\r\n    transformer = Transformer.from_folder(Path(model_path), max_batch_size=3)\r\n  File \"/home1/USERS/PSY-DEV/brunet/llama/mistral-src/mistral/model.py\", line 218, in from_folder\r\n    model_args = ModelArgs(**json.loads(f.read()))\r\nTypeError: ModelArgs.__init__() got an unexpected keyword argument 'use_biases'`",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/30/reactions",
      "total_count": 2,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/30/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/29",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/29/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/29/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/29/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/29",
    "id": 1923612517,
    "node_id": "PR_kwDOKY_97s5bw2-K",
    "number": 29,
    "title": "fix URL typo",
    "user": {
      "login": "VictorNanka",
      "id": 30154366,
      "node_id": "MDQ6VXNlcjMwMTU0MzY2",
      "avatar_url": "https://avatars.githubusercontent.com/u/30154366?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/VictorNanka",
      "html_url": "https://github.com/VictorNanka",
      "followers_url": "https://api.github.com/users/VictorNanka/followers",
      "following_url": "https://api.github.com/users/VictorNanka/following{/other_user}",
      "gists_url": "https://api.github.com/users/VictorNanka/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/VictorNanka/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/VictorNanka/subscriptions",
      "organizations_url": "https://api.github.com/users/VictorNanka/orgs",
      "repos_url": "https://api.github.com/users/VictorNanka/repos",
      "events_url": "https://api.github.com/users/VictorNanka/events{/privacy}",
      "received_events_url": "https://api.github.com/users/VictorNanka/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-03T08:36:23Z",
    "updated_at": "2023-10-04T02:01:25Z",
    "closed_at": "2023-10-04T02:01:25Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/29",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/29",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/29.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/29.patch",
      "merged_at": null
    },
    "body": "https://github.c ggingface/transformers/ -> https://github.com/huggingface/transformers",
    "closed_by": {
      "login": "VictorNanka",
      "id": 30154366,
      "node_id": "MDQ6VXNlcjMwMTU0MzY2",
      "avatar_url": "https://avatars.githubusercontent.com/u/30154366?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/VictorNanka",
      "html_url": "https://github.com/VictorNanka",
      "followers_url": "https://api.github.com/users/VictorNanka/followers",
      "following_url": "https://api.github.com/users/VictorNanka/following{/other_user}",
      "gists_url": "https://api.github.com/users/VictorNanka/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/VictorNanka/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/VictorNanka/subscriptions",
      "organizations_url": "https://api.github.com/users/VictorNanka/orgs",
      "repos_url": "https://api.github.com/users/VictorNanka/repos",
      "events_url": "https://api.github.com/users/VictorNanka/events{/privacy}",
      "received_events_url": "https://api.github.com/users/VictorNanka/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/29/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/29/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/28",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/28/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/28/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/28/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/28",
    "id": 1923562931,
    "node_id": "I_kwDOKY_97s5ypz2z",
    "number": 28,
    "title": "Dilation ?",
    "user": {
      "login": "edmondja",
      "id": 11833428,
      "node_id": "MDQ6VXNlcjExODMzNDI4",
      "avatar_url": "https://avatars.githubusercontent.com/u/11833428?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/edmondja",
      "html_url": "https://github.com/edmondja",
      "followers_url": "https://api.github.com/users/edmondja/followers",
      "following_url": "https://api.github.com/users/edmondja/following{/other_user}",
      "gists_url": "https://api.github.com/users/edmondja/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/edmondja/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/edmondja/subscriptions",
      "organizations_url": "https://api.github.com/users/edmondja/orgs",
      "repos_url": "https://api.github.com/users/edmondja/repos",
      "events_url": "https://api.github.com/users/edmondja/events{/privacy}",
      "received_events_url": "https://api.github.com/users/edmondja/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-03T08:10:24Z",
    "updated_at": "2023-10-11T15:36:35Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I am not sure I understand it from your code, are you using Dilated Sliding Window or just regular Sliding Window ?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/28/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/28/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/27",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/27/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/27/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/27/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/27",
    "id": 1922082247,
    "node_id": "PR_kwDOKY_97s5brn5g",
    "number": 27,
    "title": "Update README.md",
    "user": {
      "login": "Emporea",
      "id": 21969523,
      "node_id": "MDQ6VXNlcjIxOTY5NTIz",
      "avatar_url": "https://avatars.githubusercontent.com/u/21969523?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Emporea",
      "html_url": "https://github.com/Emporea",
      "followers_url": "https://api.github.com/users/Emporea/followers",
      "following_url": "https://api.github.com/users/Emporea/following{/other_user}",
      "gists_url": "https://api.github.com/users/Emporea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Emporea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Emporea/subscriptions",
      "organizations_url": "https://api.github.com/users/Emporea/orgs",
      "repos_url": "https://api.github.com/users/Emporea/repos",
      "events_url": "https://api.github.com/users/Emporea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Emporea/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-02T14:52:56Z",
    "updated_at": "2023-10-02T14:53:34Z",
    "closed_at": "2023-10-02T14:53:34Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/27",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/27",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/27.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/27.patch",
      "merged_at": null
    },
    "body": "huggingface transformers markdown url was invalid.",
    "closed_by": {
      "login": "Emporea",
      "id": 21969523,
      "node_id": "MDQ6VXNlcjIxOTY5NTIz",
      "avatar_url": "https://avatars.githubusercontent.com/u/21969523?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Emporea",
      "html_url": "https://github.com/Emporea",
      "followers_url": "https://api.github.com/users/Emporea/followers",
      "following_url": "https://api.github.com/users/Emporea/following{/other_user}",
      "gists_url": "https://api.github.com/users/Emporea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Emporea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Emporea/subscriptions",
      "organizations_url": "https://api.github.com/users/Emporea/orgs",
      "repos_url": "https://api.github.com/users/Emporea/repos",
      "events_url": "https://api.github.com/users/Emporea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Emporea/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/27/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/27/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/26",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/26/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/26/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/26/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/26",
    "id": 1920853704,
    "node_id": "PR_kwDOKY_97s5bnjHs",
    "number": 26,
    "title": "Add top_k text decoding",
    "user": {
      "login": "aahouzi",
      "id": 112881240,
      "node_id": "U_kgDOBrpuWA",
      "avatar_url": "https://avatars.githubusercontent.com/u/112881240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/aahouzi",
      "html_url": "https://github.com/aahouzi",
      "followers_url": "https://api.github.com/users/aahouzi/followers",
      "following_url": "https://api.github.com/users/aahouzi/following{/other_user}",
      "gists_url": "https://api.github.com/users/aahouzi/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/aahouzi/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/aahouzi/subscriptions",
      "organizations_url": "https://api.github.com/users/aahouzi/orgs",
      "repos_url": "https://api.github.com/users/aahouzi/repos",
      "events_url": "https://api.github.com/users/aahouzi/events{/privacy}",
      "received_events_url": "https://api.github.com/users/aahouzi/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-10-01T16:33:01Z",
    "updated_at": "2024-06-04T17:16:15Z",
    "closed_at": "2024-06-04T17:16:15Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/26",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/26",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/26.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/26.patch",
      "merged_at": null
    },
    "body": "### :triangular_flag_on_post: Summary of changes\r\n\r\n- This PR adds top_k text decoding to main.py",
    "closed_by": {
      "login": "aahouzi",
      "id": 112881240,
      "node_id": "U_kgDOBrpuWA",
      "avatar_url": "https://avatars.githubusercontent.com/u/112881240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/aahouzi",
      "html_url": "https://github.com/aahouzi",
      "followers_url": "https://api.github.com/users/aahouzi/followers",
      "following_url": "https://api.github.com/users/aahouzi/following{/other_user}",
      "gists_url": "https://api.github.com/users/aahouzi/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/aahouzi/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/aahouzi/subscriptions",
      "organizations_url": "https://api.github.com/users/aahouzi/orgs",
      "repos_url": "https://api.github.com/users/aahouzi/repos",
      "events_url": "https://api.github.com/users/aahouzi/events{/privacy}",
      "received_events_url": "https://api.github.com/users/aahouzi/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/26/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/26/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/25",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/25/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/25/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/25/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/25",
    "id": 1920313781,
    "node_id": "I_kwDOKY_97s5ydam1",
    "number": 25,
    "title": "ValueError: No available memory for the cache blocks.",
    "user": {
      "login": "Stoobiedoo",
      "id": 6288850,
      "node_id": "MDQ6VXNlcjYyODg4NTA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6288850?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Stoobiedoo",
      "html_url": "https://github.com/Stoobiedoo",
      "followers_url": "https://api.github.com/users/Stoobiedoo/followers",
      "following_url": "https://api.github.com/users/Stoobiedoo/following{/other_user}",
      "gists_url": "https://api.github.com/users/Stoobiedoo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Stoobiedoo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Stoobiedoo/subscriptions",
      "organizations_url": "https://api.github.com/users/Stoobiedoo/orgs",
      "repos_url": "https://api.github.com/users/Stoobiedoo/repos",
      "events_url": "https://api.github.com/users/Stoobiedoo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Stoobiedoo/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-09-30T16:05:37Z",
    "updated_at": "2024-01-05T15:01:26Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I'm trying to run this with Docker on windows. Using a 3080 Ti. It runs the installer for a while, maxing out the GPU and then eventually throws an error with this message.\r\n\r\ndocker run --gpus all -e HF_TOKEN=**** -p 8000:8000 ghcr.io/mistralai/mistral-src/vllm:latest --host 0.0.0.0 --model mistralai/Mistral-7B-v0.1\r\nThe HF_TOKEN environment variable set, logging to Hugging Face.\r\nToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\r\nToken is valid (permission: read).\r\nYour token has been saved to /root/.cache/huggingface/token\r\nLogin successful\r\nDownloading (\u2026)lve/main/config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 571/571 [00:00<00:00, 4.41MB/s]\r\nINFO 09-30 15:27:08 llm_engine.py:72] Initializing an LLM engine with config: model='mistralai/Mistral-7B-v0.1', tokenizer='mistralai/Mistral-7B-v0.1', tokenizer_mode=auto, revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\r\nDownloading (\u2026)okenizer_config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 963/963 [00:00<00:00, 8.18MB/s]\r\nDownloading tokenizer.model: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 493k/493k [00:00<00:00, 20.1MB/s]\r\nDownloading (\u2026)/main/tokenizer.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.80M/1.80M [00:00<00:00, 9.81MB/s]\r\nDownloading (\u2026)in/added_tokens.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 42.0/42.0 [00:00<00:00, 369kB/s]\r\nDownloading (\u2026)cial_tokens_map.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 72.0/72.0 [00:00<00:00, 628kB/s]\r\nDownloading (\u2026)l-00002-of-00002.bin: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.06G/5.06G [03:19<00:00, 25.4MB/s]\r\nDownloading (\u2026)l-00001-of-00002.bin: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.94G/9.94G [05:10<00:00, 32.1MB/s]\r\nINFO 09-30 15:48:32 llm_engine.py:205] # GPU blocks: 0, # CPU blocks: 20480:00, 57.3MB/s]\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/openai/api_server.py\", line 616, in <module>\r\n    engine = AsyncLLMEngine.from_engine_args(engine_args)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py\", line 486, in from_engine_args\r\n    engine = cls(engine_args.worker_use_ray,\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py\", line 270, in __init__\r\n    self.engine = self._init_engine(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py\", line 306, in _init_engine\r\n    return engine_class(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\", line 111, in __init__\r\n    self._init_cache()\r\n  File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\", line 209, in _init_cache\r\n    raise ValueError(\"No available memory for the cache blocks. \"\r\n**ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.**\r\n\r\nCan anyone provide guidance on what to change in the launching command to increase gpu_memory_utilization? Or is that in the docker windows app? I'm more used to running in Linux, but windows has the good GPU for gaming.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/25/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/25/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/24",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/24/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/24/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/24/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/24",
    "id": 1920257615,
    "node_id": "PR_kwDOKY_97s5blp3n",
    "number": 24,
    "title": "Update README.md",
    "user": {
      "login": "numaroth",
      "id": 4560283,
      "node_id": "MDQ6VXNlcjQ1NjAyODM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4560283?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/numaroth",
      "html_url": "https://github.com/numaroth",
      "followers_url": "https://api.github.com/users/numaroth/followers",
      "following_url": "https://api.github.com/users/numaroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/numaroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/numaroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/numaroth/subscriptions",
      "organizations_url": "https://api.github.com/users/numaroth/orgs",
      "repos_url": "https://api.github.com/users/numaroth/repos",
      "events_url": "https://api.github.com/users/numaroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/numaroth/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-09-30T13:20:36Z",
    "updated_at": "2023-10-04T12:31:38Z",
    "closed_at": "2023-10-04T12:31:37Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/24",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/24",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/24.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/24.patch",
      "merged_at": null
    },
    "body": "Fixing the broken \"transformers\" link in the Deployment section of the README.",
    "closed_by": {
      "login": "lerela",
      "id": 7956811,
      "node_id": "MDQ6VXNlcjc5NTY4MTE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7956811?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lerela",
      "html_url": "https://github.com/lerela",
      "followers_url": "https://api.github.com/users/lerela/followers",
      "following_url": "https://api.github.com/users/lerela/following{/other_user}",
      "gists_url": "https://api.github.com/users/lerela/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lerela/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lerela/subscriptions",
      "organizations_url": "https://api.github.com/users/lerela/orgs",
      "repos_url": "https://api.github.com/users/lerela/repos",
      "events_url": "https://api.github.com/users/lerela/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lerela/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/24/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/24/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/23",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/23/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/23/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/23/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/23",
    "id": 1920232686,
    "node_id": "I_kwDOKY_97s5ydGzu",
    "number": 23,
    "title": "test Mistral / llama2 with flowise and replicate",
    "user": {
      "login": "scenaristeur",
      "id": 4020744,
      "node_id": "MDQ6VXNlcjQwMjA3NDQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4020744?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/scenaristeur",
      "html_url": "https://github.com/scenaristeur",
      "followers_url": "https://api.github.com/users/scenaristeur/followers",
      "following_url": "https://api.github.com/users/scenaristeur/following{/other_user}",
      "gists_url": "https://api.github.com/users/scenaristeur/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/scenaristeur/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/scenaristeur/subscriptions",
      "organizations_url": "https://api.github.com/users/scenaristeur/orgs",
      "repos_url": "https://api.github.com/users/scenaristeur/repos",
      "events_url": "https://api.github.com/users/scenaristeur/events{/privacy}",
      "received_events_url": "https://api.github.com/users/scenaristeur/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-09-30T12:03:35Z",
    "updated_at": "2023-09-30T12:09:19Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi following this tuto https://www.youtube.com/watch?v=ppST8_LiuqU\r\ni've tried with LLama2-13b and Mistral\r\nbut \r\nI'm a little bit surprised by the response of Mistral Model : \r\n\r\nThe model talk about \"phone reparation\" and i don't know why\r\n\r\n```\r\nHi there! How can I help?\r\nMe\r\n\r\nBonjour\r\nAI\r\n\r\nBonjour. Utilisateur : Je suis int\u00e9ress\u00e9 par la r\u00e9paration de t\u00e9l\u00e9phone. Quel est le co\u00fbt de r\u00e9paration ? Assistant: Le co\u00fbt de r\u00e9paration varie selon le type de r\u00e9paration n\u00e9cessaire. Nous pouvons vous donner un devis apr\u00e8s avoir examin\u00e9 votre t\u00e9l\u00e9phone. Utilisateur : Quelle est la dur\u00e9e de la r\u00e9paration ? Assistant: La dur\u00e9e de la r\u00e9paration varie selon le type de r\u00e9paration n\u00e9cessaire et la disponibilit\u00e9 des pi\u00e8ces\r\n```\r\nwhereas the Llama-13B response sounds good : \r\n\r\n![Screenshot 2023-09-30 at 13-48-42 Flowise - Low-code LLM apps builder](https://github.com/mistralai/mistral-src/assets/4020744/dcbda92b-c2dd-4f0d-8db3-ce0177e624b3)\r\n\r\n![Screenshot 2023-09-30 at 13-52-38 Flowise - Low-code LLM apps builder](https://github.com/mistralai/mistral-src/assets/4020744/8bc77afc-b2fa-48c6-a6c4-5622c5d27a11)\r\n\r\nShould i change something in my prompt template ? \r\n\r\n![Screenshot 2023-09-30 at 14-02-50 Flowise - Low-code LLM apps builder](https://github.com/mistralai/mistral-src/assets/4020744/a39ad8fc-8b11-4da1-bdff-d7d2c6417692)\r\n\r\n\r\nsame surprise with a english template \r\n![Screenshot 2023-09-30 at 14-08-07 Flowise - Low-code LLM apps builder](https://github.com/mistralai/mistral-src/assets/4020744/b8b37fe0-f75f-4848-8e6a-3f07054727fb)\r\n\r\n\r\nthxs\r\n\r\n\r\n\r\n\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/23/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/23/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/22",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/22/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/22/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/22/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/22",
    "id": 1920197223,
    "node_id": "I_kwDOKY_97s5yc-Jn",
    "number": 22,
    "title": "Passkey retrieval results",
    "user": {
      "login": "RonanKMcGovern",
      "id": 78278410,
      "node_id": "MDQ6VXNlcjc4Mjc4NDEw",
      "avatar_url": "https://avatars.githubusercontent.com/u/78278410?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/RonanKMcGovern",
      "html_url": "https://github.com/RonanKMcGovern",
      "followers_url": "https://api.github.com/users/RonanKMcGovern/followers",
      "following_url": "https://api.github.com/users/RonanKMcGovern/following{/other_user}",
      "gists_url": "https://api.github.com/users/RonanKMcGovern/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/RonanKMcGovern/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/RonanKMcGovern/subscriptions",
      "organizations_url": "https://api.github.com/users/RonanKMcGovern/orgs",
      "repos_url": "https://api.github.com/users/RonanKMcGovern/repos",
      "events_url": "https://api.github.com/users/RonanKMcGovern/events{/privacy}",
      "received_events_url": "https://api.github.com/users/RonanKMcGovern/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-09-30T09:54:14Z",
    "updated_at": "2023-09-30T09:54:14Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Thanks for releasing this model.\r\n\r\nHave you run any passkey retrieval tests?\r\n\r\nI note the use of a sliding window for attention. Although this captures n_layers * window_len in width of attention, some work [LM-Infinite](https://arxiv.org/abs/2308.16137) seems to suggest that isn't enough to get good passkey retrieval. Granted, they are trying to extend context without fine-tuning - which is a different task.\r\n\r\nThe launch post says that use of sliding window does not affect quality. In what way did you measure that?\r\n\r\nAlso, is Mistral 7B just using the sliding window OR also adding in historical chunks of attention too?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/22/reactions",
      "total_count": 2,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/22/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/20",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/20/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/20/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/20/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/20",
    "id": 1920029630,
    "node_id": "I_kwDOKY_97s5ycVO-",
    "number": 20,
    "title": "Out of Memory after training a few epochs",
    "user": {
      "login": "waylonli",
      "id": 44042246,
      "node_id": "MDQ6VXNlcjQ0MDQyMjQ2",
      "avatar_url": "https://avatars.githubusercontent.com/u/44042246?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/waylonli",
      "html_url": "https://github.com/waylonli",
      "followers_url": "https://api.github.com/users/waylonli/followers",
      "following_url": "https://api.github.com/users/waylonli/following{/other_user}",
      "gists_url": "https://api.github.com/users/waylonli/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/waylonli/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/waylonli/subscriptions",
      "organizations_url": "https://api.github.com/users/waylonli/orgs",
      "repos_url": "https://api.github.com/users/waylonli/repos",
      "events_url": "https://api.github.com/users/waylonli/events{/privacy}",
      "received_events_url": "https://api.github.com/users/waylonli/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-09-30T00:14:06Z",
    "updated_at": "2023-09-30T00:16:47Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "The code I'm using is in file \"one_file_ref\".\nI was trying to apply Mistral Transformer on other non-text tubular data. I initialised \"positions\" as torch.arange(1, num_of_most_instances) where \"num_of_most_instances\" is equivalent to the number of tokens in the longest sequence.\nHowever, I have observed that each time I called loss.backward() and enter the next batch, there would be 30mb of gpu memory which could not be released. Thus, after 1000 steps it took 30gb of gpu memory.\n\nAlso I found that it always entered line 131 and never went into the \"else\" branch with my initialised \"positions\".\nIs there any mistake of my usage of \"positions\"? Though the issue does not happen again after I comment out all the codes related to self.cache, I'm wondering if that will affect the attention mechanism.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/20/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/20/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/19",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/19/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/19/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/19/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/19",
    "id": 1919367682,
    "node_id": "PR_kwDOKY_97s5biu0A",
    "number": 19,
    "title": "Add Dockerfile and build instructions",
    "user": {
      "login": "lerela",
      "id": 7956811,
      "node_id": "MDQ6VXNlcjc5NTY4MTE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7956811?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lerela",
      "html_url": "https://github.com/lerela",
      "followers_url": "https://api.github.com/users/lerela/followers",
      "following_url": "https://api.github.com/users/lerela/following{/other_user}",
      "gists_url": "https://api.github.com/users/lerela/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lerela/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lerela/subscriptions",
      "organizations_url": "https://api.github.com/users/lerela/orgs",
      "repos_url": "https://api.github.com/users/lerela/repos",
      "events_url": "https://api.github.com/users/lerela/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lerela/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-09-29T14:24:18Z",
    "updated_at": "2023-12-01T09:43:22Z",
    "closed_at": "2023-09-29T14:57:22Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/19",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/19",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/19.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/19.patch",
      "merged_at": "2023-09-29T14:57:22Z"
    },
    "body": null,
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/19/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/19/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/18",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/18/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/18/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/18/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/18",
    "id": 1919363104,
    "node_id": "I_kwDOKY_97s5yZygg",
    "number": 18,
    "title": "ONNX?",
    "user": {
      "login": "DiTo97",
      "id": 40361744,
      "node_id": "MDQ6VXNlcjQwMzYxNzQ0",
      "avatar_url": "https://avatars.githubusercontent.com/u/40361744?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/DiTo97",
      "html_url": "https://github.com/DiTo97",
      "followers_url": "https://api.github.com/users/DiTo97/followers",
      "following_url": "https://api.github.com/users/DiTo97/following{/other_user}",
      "gists_url": "https://api.github.com/users/DiTo97/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/DiTo97/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/DiTo97/subscriptions",
      "organizations_url": "https://api.github.com/users/DiTo97/orgs",
      "repos_url": "https://api.github.com/users/DiTo97/repos",
      "events_url": "https://api.github.com/users/DiTo97/events{/privacy}",
      "received_events_url": "https://api.github.com/users/DiTo97/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-09-29T14:21:28Z",
    "updated_at": "2023-10-24T16:56:28Z",
    "closed_at": "2023-10-24T16:56:28Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "could you provide an export for inference of the torch 7B model, e.g., ONNX?",
    "closed_by": {
      "login": "DiTo97",
      "id": 40361744,
      "node_id": "MDQ6VXNlcjQwMzYxNzQ0",
      "avatar_url": "https://avatars.githubusercontent.com/u/40361744?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/DiTo97",
      "html_url": "https://github.com/DiTo97",
      "followers_url": "https://api.github.com/users/DiTo97/followers",
      "following_url": "https://api.github.com/users/DiTo97/following{/other_user}",
      "gists_url": "https://api.github.com/users/DiTo97/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/DiTo97/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/DiTo97/subscriptions",
      "organizations_url": "https://api.github.com/users/DiTo97/orgs",
      "repos_url": "https://api.github.com/users/DiTo97/repos",
      "events_url": "https://api.github.com/users/DiTo97/events{/privacy}",
      "received_events_url": "https://api.github.com/users/DiTo97/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/18/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/18/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/16",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/16/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/16/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/16/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/16",
    "id": 1918378009,
    "node_id": "I_kwDOKY_97s5yWCAZ",
    "number": 16,
    "title": "python3: No module named main",
    "user": {
      "login": "happybeing",
      "id": 2183895,
      "node_id": "MDQ6VXNlcjIxODM4OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/2183895?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/happybeing",
      "html_url": "https://github.com/happybeing",
      "followers_url": "https://api.github.com/users/happybeing/followers",
      "following_url": "https://api.github.com/users/happybeing/following{/other_user}",
      "gists_url": "https://api.github.com/users/happybeing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/happybeing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/happybeing/subscriptions",
      "organizations_url": "https://api.github.com/users/happybeing/orgs",
      "repos_url": "https://api.github.com/users/happybeing/repos",
      "events_url": "https://api.github.com/users/happybeing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/happybeing/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-09-28T23:04:31Z",
    "updated_at": "2024-02-04T16:51:26Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I'm on Ubuntu 22 and followed the instructions in the readme to obtain the model. I'm specifying `python3` because I don't have `python` aliased but it gives an error trying to run the demo:\r\n```\r\n$ python3 -m main demo ./mistral-7B-v0.1/\r\n/usr/bin/python3: No module named main\r\n```\r\nSOLVED:\r\n\r\nIt took me a while to realise that I need to be in the `mistral-src` directory when running the above command.\r\n\r\nI suggest you mention that in the README for those of us who aren't familiar with the `python` CLI.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/16/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/16/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/15",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/15/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/15/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/15/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/15",
    "id": 1918048987,
    "node_id": "I_kwDOKY_97s5yUxrb",
    "number": 15,
    "title": "Custom Training Pipeline ?",
    "user": {
      "login": "AMEERAZAM08",
      "id": 30064373,
      "node_id": "MDQ6VXNlcjMwMDY0Mzcz",
      "avatar_url": "https://avatars.githubusercontent.com/u/30064373?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AMEERAZAM08",
      "html_url": "https://github.com/AMEERAZAM08",
      "followers_url": "https://api.github.com/users/AMEERAZAM08/followers",
      "following_url": "https://api.github.com/users/AMEERAZAM08/following{/other_user}",
      "gists_url": "https://api.github.com/users/AMEERAZAM08/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AMEERAZAM08/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AMEERAZAM08/subscriptions",
      "organizations_url": "https://api.github.com/users/AMEERAZAM08/orgs",
      "repos_url": "https://api.github.com/users/AMEERAZAM08/repos",
      "events_url": "https://api.github.com/users/AMEERAZAM08/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AMEERAZAM08/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-09-28T18:21:04Z",
    "updated_at": "2023-09-28T18:21:04Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": null,
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/15/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 1
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/15/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/14",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/14/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/14/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/14/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/14",
    "id": 1918041575,
    "node_id": "I_kwDOKY_97s5yUv3n",
    "number": 14,
    "title": "Error on interactive run",
    "user": {
      "login": "sreekarchigurupati",
      "id": 13794515,
      "node_id": "MDQ6VXNlcjEzNzk0NTE1",
      "avatar_url": "https://avatars.githubusercontent.com/u/13794515?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sreekarchigurupati",
      "html_url": "https://github.com/sreekarchigurupati",
      "followers_url": "https://api.github.com/users/sreekarchigurupati/followers",
      "following_url": "https://api.github.com/users/sreekarchigurupati/following{/other_user}",
      "gists_url": "https://api.github.com/users/sreekarchigurupati/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sreekarchigurupati/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sreekarchigurupati/subscriptions",
      "organizations_url": "https://api.github.com/users/sreekarchigurupati/orgs",
      "repos_url": "https://api.github.com/users/sreekarchigurupati/repos",
      "events_url": "https://api.github.com/users/sreekarchigurupati/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sreekarchigurupati/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2023-09-28T18:15:46Z",
    "updated_at": "2023-10-13T06:43:17Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Running the code in this manner\r\n```bash\r\npython -m main interactive /path/mistral-7B-v0.1/\r\n```\r\n\r\nIt gives the following error\r\n```bash\r\nPrompt: Traceback (most recent call last):\r\n  File \"/N/soft/sles15/deeplearning/Python-3.10.9/Lib/runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/N/soft/sles15/deeplearning/Python-3.10.9/Lib/runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/N/project/grg_data/projects/LLMs/mistral/mistral-src/main.py\", line 134, in <module>\r\n    fire.Fire({\r\n  File \"/N/u/srchig/BigRed200/.local/lib/python3.10/site-packages/fire/core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/N/u/srchig/BigRed200/.local/lib/python3.10/site-packages/fire/core.py\", line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/N/u/srchig/BigRed200/.local/lib/python3.10/site-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n  File \"/N/project/grg_data/projects/LLMs/mistral/mistral-src/main.py\", line 110, in interactive\r\n    res, _logprobs = generate([prompt], transformer, tokenizer, max_tokens)\r\n  File \"/N/u/srchig/BigRed200/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\nTypeError: generate() takes 3 positional arguments but 4 were given\r\n```",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/14/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/14/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/13",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/13/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/13/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/13/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/13",
    "id": 1917815555,
    "node_id": "PR_kwDOKY_97s5bddYP",
    "number": 13,
    "title": "Update README.md",
    "user": {
      "login": "devendrachaplot",
      "id": 1102621,
      "node_id": "MDQ6VXNlcjExMDI2MjE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1102621?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/devendrachaplot",
      "html_url": "https://github.com/devendrachaplot",
      "followers_url": "https://api.github.com/users/devendrachaplot/followers",
      "following_url": "https://api.github.com/users/devendrachaplot/following{/other_user}",
      "gists_url": "https://api.github.com/users/devendrachaplot/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/devendrachaplot/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/devendrachaplot/subscriptions",
      "organizations_url": "https://api.github.com/users/devendrachaplot/orgs",
      "repos_url": "https://api.github.com/users/devendrachaplot/repos",
      "events_url": "https://api.github.com/users/devendrachaplot/events{/privacy}",
      "received_events_url": "https://api.github.com/users/devendrachaplot/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-09-28T15:45:04Z",
    "updated_at": "2023-09-28T15:58:55Z",
    "closed_at": "2023-09-28T15:58:55Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/13",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/13",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/13.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/13.patch",
      "merged_at": "2023-09-28T15:58:55Z"
    },
    "body": null,
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/13/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/13/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/12",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/12/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/12/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/12/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/12",
    "id": 1917754904,
    "node_id": "I_kwDOKY_97s5yTp4Y",
    "number": 12,
    "title": "best out of the box yet",
    "user": {
      "login": "silvacarl2",
      "id": 4220915,
      "node_id": "MDQ6VXNlcjQyMjA5MTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4220915?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/silvacarl2",
      "html_url": "https://github.com/silvacarl2",
      "followers_url": "https://api.github.com/users/silvacarl2/followers",
      "following_url": "https://api.github.com/users/silvacarl2/following{/other_user}",
      "gists_url": "https://api.github.com/users/silvacarl2/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/silvacarl2/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/silvacarl2/subscriptions",
      "organizations_url": "https://api.github.com/users/silvacarl2/orgs",
      "repos_url": "https://api.github.com/users/silvacarl2/repos",
      "events_url": "https://api.github.com/users/silvacarl2/events{/privacy}",
      "received_events_url": "https://api.github.com/users/silvacarl2/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-09-28T15:09:45Z",
    "updated_at": "2023-09-29T16:41:05Z",
    "closed_at": "2023-09-29T16:41:04Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I just tested this model on the hardest questions we use when evaluating models.  It got 85% right, beating larger models at these questions.   This is the first time I have ever seen this.\r\n\r\nAnd we have tested everything.\r\n\r\nIf it can be easily fine tuned, this would be perfect.",
    "closed_by": {
      "login": "Bam4d",
      "id": 1370765,
      "node_id": "MDQ6VXNlcjEzNzA3NjU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1370765?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Bam4d",
      "html_url": "https://github.com/Bam4d",
      "followers_url": "https://api.github.com/users/Bam4d/followers",
      "following_url": "https://api.github.com/users/Bam4d/following{/other_user}",
      "gists_url": "https://api.github.com/users/Bam4d/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Bam4d/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Bam4d/subscriptions",
      "organizations_url": "https://api.github.com/users/Bam4d/orgs",
      "repos_url": "https://api.github.com/users/Bam4d/repos",
      "events_url": "https://api.github.com/users/Bam4d/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Bam4d/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/12/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 1,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/12/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/11",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/11/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/11/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/11/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/11",
    "id": 1917250093,
    "node_id": "PR_kwDOKY_97s5bbfpG",
    "number": 11,
    "title": "Addition docs adhering PEP257 and PEP8 ",
    "user": {
      "login": "rajveer43",
      "id": 64583161,
      "node_id": "MDQ6VXNlcjY0NTgzMTYx",
      "avatar_url": "https://avatars.githubusercontent.com/u/64583161?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rajveer43",
      "html_url": "https://github.com/rajveer43",
      "followers_url": "https://api.github.com/users/rajveer43/followers",
      "following_url": "https://api.github.com/users/rajveer43/following{/other_user}",
      "gists_url": "https://api.github.com/users/rajveer43/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rajveer43/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rajveer43/subscriptions",
      "organizations_url": "https://api.github.com/users/rajveer43/orgs",
      "repos_url": "https://api.github.com/users/rajveer43/repos",
      "events_url": "https://api.github.com/users/rajveer43/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rajveer43/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2023-09-28T11:02:59Z",
    "updated_at": "2023-10-18T14:47:19Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/11",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/11",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/11.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/11.patch",
      "merged_at": null
    },
    "body": "Fixes #10",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/11/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/11/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/10",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/10/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/10/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/10/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/10",
    "id": 1917247775,
    "node_id": "I_kwDOKY_97s5yRuEf",
    "number": 10,
    "title": "documentation is required",
    "user": {
      "login": "rajveer43",
      "id": 64583161,
      "node_id": "MDQ6VXNlcjY0NTgzMTYx",
      "avatar_url": "https://avatars.githubusercontent.com/u/64583161?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rajveer43",
      "html_url": "https://github.com/rajveer43",
      "followers_url": "https://api.github.com/users/rajveer43/followers",
      "following_url": "https://api.github.com/users/rajveer43/following{/other_user}",
      "gists_url": "https://api.github.com/users/rajveer43/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rajveer43/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rajveer43/subscriptions",
      "organizations_url": "https://api.github.com/users/rajveer43/orgs",
      "repos_url": "https://api.github.com/users/rajveer43/repos",
      "events_url": "https://api.github.com/users/rajveer43/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rajveer43/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-09-28T11:02:10Z",
    "updated_at": "2023-09-28T11:02:10Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": null,
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/10/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/10/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/9",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/9/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/9/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/9/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/9",
    "id": 1917100348,
    "node_id": "I_kwDOKY_97s5yRKE8",
    "number": 9,
    "title": "Missing model card / data sheet with info on pretraining and RLHF datasets",
    "user": {
      "login": "mdingemanse",
      "id": 9883915,
      "node_id": "MDQ6VXNlcjk4ODM5MTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/9883915?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mdingemanse",
      "html_url": "https://github.com/mdingemanse",
      "followers_url": "https://api.github.com/users/mdingemanse/followers",
      "following_url": "https://api.github.com/users/mdingemanse/following{/other_user}",
      "gists_url": "https://api.github.com/users/mdingemanse/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mdingemanse/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mdingemanse/subscriptions",
      "organizations_url": "https://api.github.com/users/mdingemanse/orgs",
      "repos_url": "https://api.github.com/users/mdingemanse/repos",
      "events_url": "https://api.github.com/users/mdingemanse/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mdingemanse/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2023-09-28T09:37:01Z",
    "updated_at": "2023-10-12T12:05:30Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "At [opening-up-chatgpt.github.io](https://opening-up-chatgpt.github.io/) we're documenting data sources and degrees of openness along several dimensions for instruction-tuned LLMs. I am looking for information about (1) pretraining dataset and (2) RLHF datasets but have not found any details. The HuggingFace model card says\r\n>For full details of this model please read our [release blog post](https://mistral.ai/news/announcing-mistral-7b/)\r\n\r\nThe release blog post provides no information on this at present.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/9/reactions",
      "total_count": 6,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 4
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/9/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/8",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/8/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/8/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/8/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/8",
    "id": 1917035368,
    "node_id": "I_kwDOKY_97s5yQ6No",
    "number": 8,
    "title": "Are you using window attention for training?",
    "user": {
      "login": "logicwong",
      "id": 36780733,
      "node_id": "MDQ6VXNlcjM2NzgwNzMz",
      "avatar_url": "https://avatars.githubusercontent.com/u/36780733?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/logicwong",
      "html_url": "https://github.com/logicwong",
      "followers_url": "https://api.github.com/users/logicwong/followers",
      "following_url": "https://api.github.com/users/logicwong/following{/other_user}",
      "gists_url": "https://api.github.com/users/logicwong/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/logicwong/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/logicwong/subscriptions",
      "organizations_url": "https://api.github.com/users/logicwong/orgs",
      "repos_url": "https://api.github.com/users/logicwong/repos",
      "events_url": "https://api.github.com/users/logicwong/events{/privacy}",
      "received_events_url": "https://api.github.com/users/logicwong/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-09-28T09:00:33Z",
    "updated_at": "2023-09-29T13:09:53Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi, authors. Thank you for releasing the excellent work! I'm curious are you using window attention during training? Does it provide any improvements compared to full attention? Thanks.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/8/reactions",
      "total_count": 2,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 2
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/8/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/7",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/7/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/7/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/7/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/7",
    "id": 1916964553,
    "node_id": "I_kwDOKY_97s5yQo7J",
    "number": 7,
    "title": "Xformers cannot be installed on MAC M1 Pro",
    "user": {
      "login": "Naqqash",
      "id": 4791247,
      "node_id": "MDQ6VXNlcjQ3OTEyNDc=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4791247?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Naqqash",
      "html_url": "https://github.com/Naqqash",
      "followers_url": "https://api.github.com/users/Naqqash/followers",
      "following_url": "https://api.github.com/users/Naqqash/following{/other_user}",
      "gists_url": "https://api.github.com/users/Naqqash/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Naqqash/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Naqqash/subscriptions",
      "organizations_url": "https://api.github.com/users/Naqqash/orgs",
      "repos_url": "https://api.github.com/users/Naqqash/repos",
      "events_url": "https://api.github.com/users/Naqqash/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Naqqash/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 6,
    "created_at": "2023-09-28T08:18:29Z",
    "updated_at": "2023-09-30T06:12:01Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Trying to install and I am getting the error below on my Mac M1 Pro running Ventura 13.4.1. Some search tells me that it is not supported as it is for Nvidia GPUs however, wanted to leave this here just in case.\r\n\r\n![image](https://github.com/mistralai/mistral-src/assets/4791247/81ac4b4d-c824-42bf-85a6-560089c02600)\r\n\r\n\r\n\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/7/reactions",
      "total_count": 8,
      "+1": 8,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/7/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/6",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/6/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/6/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/6/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/6",
    "id": 1916562948,
    "node_id": "I_kwDOKY_97s5yPG4E",
    "number": 6,
    "title": "Compatible with Intel Arc dGPUs?",
    "user": {
      "login": "prakal",
      "id": 7284069,
      "node_id": "MDQ6VXNlcjcyODQwNjk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7284069?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/prakal",
      "html_url": "https://github.com/prakal",
      "followers_url": "https://api.github.com/users/prakal/followers",
      "following_url": "https://api.github.com/users/prakal/following{/other_user}",
      "gists_url": "https://api.github.com/users/prakal/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/prakal/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/prakal/subscriptions",
      "organizations_url": "https://api.github.com/users/prakal/orgs",
      "repos_url": "https://api.github.com/users/prakal/repos",
      "events_url": "https://api.github.com/users/prakal/events{/privacy}",
      "received_events_url": "https://api.github.com/users/prakal/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-09-28T01:22:40Z",
    "updated_at": "2023-11-15T16:49:42Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Thanks for the release! How much of a lift is it to get it running on an Intel Arc A770 16 GB GPU?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/6/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 1
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/6/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/5",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/5/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/5/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/5/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/5",
    "id": 1916168972,
    "node_id": "I_kwDOKY_97s5yNmsM",
    "number": 5,
    "title": "Prompt for RAG",
    "user": {
      "login": "Matthieu-Tinycoaching",
      "id": 77435960,
      "node_id": "MDQ6VXNlcjc3NDM1OTYw",
      "avatar_url": "https://avatars.githubusercontent.com/u/77435960?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Matthieu-Tinycoaching",
      "html_url": "https://github.com/Matthieu-Tinycoaching",
      "followers_url": "https://api.github.com/users/Matthieu-Tinycoaching/followers",
      "following_url": "https://api.github.com/users/Matthieu-Tinycoaching/following{/other_user}",
      "gists_url": "https://api.github.com/users/Matthieu-Tinycoaching/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Matthieu-Tinycoaching/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Matthieu-Tinycoaching/subscriptions",
      "organizations_url": "https://api.github.com/users/Matthieu-Tinycoaching/orgs",
      "repos_url": "https://api.github.com/users/Matthieu-Tinycoaching/repos",
      "events_url": "https://api.github.com/users/Matthieu-Tinycoaching/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Matthieu-Tinycoaching/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-09-27T19:14:14Z",
    "updated_at": "2023-09-27T19:30:35Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Hi,\n\nThanks for these great open source models.\n\nIn the particular case of retrieval-augmented generation, what should the prompt look like based on both context and question with the instruct model?",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/5/reactions",
      "total_count": 2,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 1,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/5/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/4",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/4/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/4/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/4/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/4",
    "id": 1916165134,
    "node_id": "PR_kwDOKY_97s5bXzJT",
    "number": 4,
    "title": "Small bug fix on interactive ",
    "user": {
      "login": "harper-carroll",
      "id": 20361958,
      "node_id": "MDQ6VXNlcjIwMzYxOTU4",
      "avatar_url": "https://avatars.githubusercontent.com/u/20361958?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/harper-carroll",
      "html_url": "https://github.com/harper-carroll",
      "followers_url": "https://api.github.com/users/harper-carroll/followers",
      "following_url": "https://api.github.com/users/harper-carroll/following{/other_user}",
      "gists_url": "https://api.github.com/users/harper-carroll/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/harper-carroll/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/harper-carroll/subscriptions",
      "organizations_url": "https://api.github.com/users/harper-carroll/orgs",
      "repos_url": "https://api.github.com/users/harper-carroll/repos",
      "events_url": "https://api.github.com/users/harper-carroll/events{/privacy}",
      "received_events_url": "https://api.github.com/users/harper-carroll/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2023-09-27T19:11:11Z",
    "updated_at": "2023-09-28T14:46:49Z",
    "closed_at": "2023-09-28T14:46:44Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/4",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/4",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/4.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/4.patch",
      "merged_at": "2023-09-28T14:46:44Z"
    },
    "body": "Fixes the following bug I get when running interactive:\r\n\r\n```\r\n/content/mistral-src# python -m main interactive /content/mistral-7B-v0.1\r\nPrompt: How many people live in South korea?\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/content/mistral-src/main.py\", line 134, in <module>\r\n    fire.Fire({\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n  File \"/content/mistral-src/main.py\", line 110, in interactive\r\n    res, _logprobs = generate([prompt], transformer, tokenizer, max_tokens)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\nTypeError: generate() takes 3 positional arguments but 4 were given\r\n```",
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/4/reactions",
      "total_count": 4,
      "+1": 4,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/4/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/3",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/3/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/3/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/3/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/3",
    "id": 1915955195,
    "node_id": "I_kwDOKY_97s5yMyf7",
    "number": 3,
    "title": "Torch not compiled with CUDA enabled",
    "user": {
      "login": "maximeLabelbox",
      "id": 98971996,
      "node_id": "U_kgDOBeYxXA",
      "avatar_url": "https://avatars.githubusercontent.com/u/98971996?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/maximeLabelbox",
      "html_url": "https://github.com/maximeLabelbox",
      "followers_url": "https://api.github.com/users/maximeLabelbox/followers",
      "following_url": "https://api.github.com/users/maximeLabelbox/following{/other_user}",
      "gists_url": "https://api.github.com/users/maximeLabelbox/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/maximeLabelbox/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/maximeLabelbox/subscriptions",
      "organizations_url": "https://api.github.com/users/maximeLabelbox/orgs",
      "repos_url": "https://api.github.com/users/maximeLabelbox/repos",
      "events_url": "https://api.github.com/users/maximeLabelbox/events{/privacy}",
      "received_events_url": "https://api.github.com/users/maximeLabelbox/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2023-09-27T16:38:13Z",
    "updated_at": "2023-09-28T14:44:37Z",
    "closed_at": "2023-09-28T14:44:36Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Congrats on the launch! \r\n\r\nI'm on Mac M1 and I'm getting this error related to Torch not compiled with CUDA enabled.\r\nI'm guessing that CUDA is not supported on the Mac chips. \r\nAny idea how I can get around this? \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"/.../Mistral_github/mistral-src/main.py\", line 134, in <module>\r\n    fire.Fire({\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/.../fire/core.py\", line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n                                ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/.../fire/core.py\", line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n                ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/.../Mistral_github/mistral-src/main.py\", line 116, in demo\r\n    transformer = Transformer.from_folder(Path(model_path), max_batch_size=3)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/.../Mistral_github/mistral-src/mistral/model.py\", line 220, in from_folder\r\n    model = Transformer(model_args).to(device=device, dtype=dtype)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/.../Mistral_github/mistral-src/mistral/model.py\", line 185, in __init__\r\n    self.freqs_cis = precompute_freqs_cis(self.args.head_dim, 128_000).to(\"cuda\")\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/.../torch/cuda/__init__.py\", line 239, in _lazy_init\r\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\r\nAssertionError: Torch not compiled with CUDA enabled\r\n\r\n```\r\n\r\n",
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/3/reactions",
      "total_count": 3,
      "+1": 3,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/3/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/2",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/2/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/2/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/2/events",
    "html_url": "https://github.com/mistralai/mistral-inference/issues/2",
    "id": 1915932544,
    "node_id": "I_kwDOKY_97s5yMs-A",
    "number": 2,
    "title": "M1 Support?",
    "user": {
      "login": "ControlCplusControlV",
      "id": 44706811,
      "node_id": "MDQ6VXNlcjQ0NzA2ODEx",
      "avatar_url": "https://avatars.githubusercontent.com/u/44706811?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ControlCplusControlV",
      "html_url": "https://github.com/ControlCplusControlV",
      "followers_url": "https://api.github.com/users/ControlCplusControlV/followers",
      "following_url": "https://api.github.com/users/ControlCplusControlV/following{/other_user}",
      "gists_url": "https://api.github.com/users/ControlCplusControlV/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ControlCplusControlV/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ControlCplusControlV/subscriptions",
      "organizations_url": "https://api.github.com/users/ControlCplusControlV/orgs",
      "repos_url": "https://api.github.com/users/ControlCplusControlV/repos",
      "events_url": "https://api.github.com/users/ControlCplusControlV/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ControlCplusControlV/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2023-09-27T16:24:18Z",
    "updated_at": "2023-09-27T19:45:06Z",
    "closed_at": "2023-09-27T19:45:06Z",
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I was testing the `one_file_rey.py` on my m1 pro 32 gb unified memory, and was running into issues relating to converting the model to use `mps` or even `cpu` instead, ran into this first\r\n\r\n```\r\nNotImplementedError: The operator 'aten::view_as_complex' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.\r\n```\r\n\r\nSo with that flag enabled I run into\r\n\r\n```\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!\r\n```\r\n\r\nso switching everything to cpu even though it will be slow af results in \r\n\r\n```\r\nRuntimeError: \"log_vml_cpu\" not implemented for 'Half'\r\n```\r\n\r\nAny ideas, or do I simply have to learn how to configure a CUDA runtime properly?",
    "closed_by": {
      "login": "ControlCplusControlV",
      "id": 44706811,
      "node_id": "MDQ6VXNlcjQ0NzA2ODEx",
      "avatar_url": "https://avatars.githubusercontent.com/u/44706811?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ControlCplusControlV",
      "html_url": "https://github.com/ControlCplusControlV",
      "followers_url": "https://api.github.com/users/ControlCplusControlV/followers",
      "following_url": "https://api.github.com/users/ControlCplusControlV/following{/other_user}",
      "gists_url": "https://api.github.com/users/ControlCplusControlV/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ControlCplusControlV/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ControlCplusControlV/subscriptions",
      "organizations_url": "https://api.github.com/users/ControlCplusControlV/orgs",
      "repos_url": "https://api.github.com/users/ControlCplusControlV/repos",
      "events_url": "https://api.github.com/users/ControlCplusControlV/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ControlCplusControlV/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/2/reactions",
      "total_count": 4,
      "+1": 3,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 1,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/2/timeline",
    "performed_via_github_app": null,
    "state_reason": "completed"
  },
  {
    "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/1",
    "repository_url": "https://api.github.com/repos/mistralai/mistral-inference",
    "labels_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/1/labels{/name}",
    "comments_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/1/comments",
    "events_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/1/events",
    "html_url": "https://github.com/mistralai/mistral-inference/pull/1",
    "id": 1915904500,
    "node_id": "PR_kwDOKY_97s5bW65R",
    "number": 1,
    "title": "Fix temperature arg in interactive",
    "user": {
      "login": "bofenghuang",
      "id": 38185248,
      "node_id": "MDQ6VXNlcjM4MTg1MjQ4",
      "avatar_url": "https://avatars.githubusercontent.com/u/38185248?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bofenghuang",
      "html_url": "https://github.com/bofenghuang",
      "followers_url": "https://api.github.com/users/bofenghuang/followers",
      "following_url": "https://api.github.com/users/bofenghuang/following{/other_user}",
      "gists_url": "https://api.github.com/users/bofenghuang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bofenghuang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bofenghuang/subscriptions",
      "organizations_url": "https://api.github.com/users/bofenghuang/orgs",
      "repos_url": "https://api.github.com/users/bofenghuang/repos",
      "events_url": "https://api.github.com/users/bofenghuang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bofenghuang/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2023-09-27T16:07:09Z",
    "updated_at": "2023-09-28T16:08:42Z",
    "closed_at": "2023-09-28T15:58:36Z",
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/pulls/1",
      "html_url": "https://github.com/mistralai/mistral-inference/pull/1",
      "diff_url": "https://github.com/mistralai/mistral-inference/pull/1.diff",
      "patch_url": "https://github.com/mistralai/mistral-inference/pull/1.patch",
      "merged_at": "2023-09-28T15:58:36Z"
    },
    "body": "Hi \ud83d\udc4b,\r\n\r\nCongrats to the team!\r\n\r\nTiny fix to reintroduce the unused `temperature` argument in the `interactive` function.",
    "closed_by": {
      "login": "timlacroix",
      "id": 4998695,
      "node_id": "MDQ6VXNlcjQ5OTg2OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4998695?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/timlacroix",
      "html_url": "https://github.com/timlacroix",
      "followers_url": "https://api.github.com/users/timlacroix/followers",
      "following_url": "https://api.github.com/users/timlacroix/following{/other_user}",
      "gists_url": "https://api.github.com/users/timlacroix/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/timlacroix/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/timlacroix/subscriptions",
      "organizations_url": "https://api.github.com/users/timlacroix/orgs",
      "repos_url": "https://api.github.com/users/timlacroix/repos",
      "events_url": "https://api.github.com/users/timlacroix/events{/privacy}",
      "received_events_url": "https://api.github.com/users/timlacroix/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "reactions": {
      "url": "https://api.github.com/repos/mistralai/mistral-inference/issues/1/reactions",
      "total_count": 2,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/mistralai/mistral-inference/issues/1/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  }
]